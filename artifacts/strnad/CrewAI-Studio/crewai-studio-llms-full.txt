# llms-full (private-aware)
> Built from GitHub files and website pages. Large files may be truncated.

--- app/tools/CustomApiTool.py ---
from typing import Optional, Dict, Any, Type
from crewai.tools import BaseTool
import requests
from pydantic import BaseModel, Field


class CustomApiToolInputSchema(BaseModel):
    endpoint: str = Field(..., description="The specific endpoint for the API call")
    method: str = Field(..., description="HTTP method to use (GET, POST, PUT, DELETE)")
    headers: Optional[Dict[str, str]] = Field(None, description="HTTP headers to include in the request")
    query_params: Optional[Dict[str, Any]] = Field(None, description="Query parameters for the request")
    body: Optional[Dict[str, Any]] = Field(None, description="Body of the request for POST/PUT methods")

class CustomApiTool(BaseTool):
    name: str = "Call Api"
    description: str = "Tool to make API calls with customizable parameters"
    args_schema: Type[BaseModel] = CustomApiToolInputSchema
    base_url: Optional[str] = None
    default_headers: Optional[Dict[str, str]] = None
    default_query_params: Optional[Dict[str, Any]] = None

    def __init__(self, base_url: Optional[str] = None, headers: Optional[Dict[str, str]] = None, query_params: Optional[Dict[str, Any]] = None, **kwargs):
        super().__init__(**kwargs)
        self.base_url = base_url
        self.default_headers = headers or {}
        self.default_query_params = query_params or {}
        self._generate_description()
        

    def _run(self, endpoint: str, method: str, headers: Optional[Dict[str, str]] = None, query_params: Optional[Dict[str, Any]] = None, body: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        url = f"{self.base_url}/{endpoint}".rstrip("/")
        headers = {**self.default_headers, **(headers or {})}
        query_params = {**self.default_query_params, **(query_params or {})}

        try:
            response = requests.request(
                method=method.upper(),
                url=url,
                headers=headers,
                params=query_params,
                json=body,
                verify=False #TODO: add option to disable SSL verification
            )
            return {
                "status_code": response.status_code,
                "response": response.json() if response.headers.get("Content-Type") == "application/json" else response.text
            }
        except Exception as e:
            return {
                "status_code": 500,
                "response": str(e)
            }

    def run(self, input_data: CustomApiToolInputSchema) -> Any:
        response_data = self._run(
            endpoint=input_data.endpoint,
            method=input_data.method,
            headers=input_data.headers,
            query_params=input_data.query_params,
            body=input_data.body
            
        )
        return response_data


--- README.md ---
# CrewAI Studio

Welcome to CrewAI Studio! This application provides a user-friendly interface written in Streamlit for interacting with CrewAI, suitable even for those who don't want to write any code. Follow the steps below to install and run the application using Docker/docker-compose or Conda/venv.

## Features

- **Multi-platform support**: Works on Windows, Linux and MacOS.
- **No coding required**: User-friendly interface for interacting with CrewAI.
- **Conda and virtual environment support**: Choose between Conda and a Python virtual environment for installation.
- **Results history**: You can view previous results.
- **Knowledge sources**: You can add knowledge sources for your crews
- **CrewAI tools** You can use crewai tools to interact with real world. ~~Crewai studio uses a forked version of crewai-tools with some bugfixes and enhancements (https://github.com/strnad/crewAI-tools)~~ (bugfixes already merged to crewai-tools)
- **Custom Tools** Custom tools for calling APIs, writing files, enhanced code interpreter, enhanced web scraper... More will be added soon
- **LLM providers supported**: Currently OpenAI, Groq, Anthropic, ollama, Grok and LM Studio backends are supported. OpenAI key is probably still needed for embeddings in many tools. Don't forget to load an embedding model when using LM Studio.
- **Single Page app export**: Feature to export crew as simple single page streamlit app.
- **Threaded crew run**: Crews can run in background and can be stopped.

## Support CrewAI Studio

Your support helps fund the development and growth of our project. Every contribution is greatly appreciated!

### Donate with Bitcoin
bc1qgsn45g02wran4lph5gsyqtk0k7t98zsg6qur0y

### Sponsor via GitHub
[![Sponsor on GitHub](https://img.shields.io/badge/Sponsor-GitHub-ff69b4?style=for-the-badge&logo=github)](https://github.com/sponsors/strnad)


## Screenshots

<img src="https://raw.githubusercontent.com/strnad/CrewAI-Studio/main/img/ss1.png" alt="crews definition" style="width:50%;"/><img src="https://raw.githubusercontent.com/strnad/CrewAI-Studio/main/img/ss2.png" alt="kickoff" style="width:50%;"/>
<img src="https://raw.githubusercontent.com/strnad/CrewAI-Studio/main/img/ss3.png" alt="kickoff" style="width:50%;"/><img src="https://raw.githubusercontent.com/strnad/CrewAI-Studio/main/img/ss4.png" alt="kickoff" style="width:50%;"/>
<img src="https://raw.githubusercontent.com/strnad/CrewAI-Studio/main/img/ss5.png" alt="kickoff" style="width:50%;"/><img src="https://raw.githubusercontent.com/strnad/CrewAI-Studio/main/img/ss6.png" alt="kickoff" style="width:50%;"/>

## Installation

### Using Virtual Environment

**For Virtual Environment**: Ensure you have Python installed. If you dont have python instaled, you can simply use the conda installer.

#### On Linux or MacOS

1. **Clone the repository (or use downloaded ZIP file)**:

   ```bash
   git clone https://github.com/strnad/CrewAI-Studio.git
   cd CrewAI-Studio
   ```

2. **Run the installation script**:

   ```bash
   ./install_venv.sh
   ```

3. **Run the application**:
   ```bash
   ./run_venv.sh
   ```

#### On Windows

1. **Clone the repository (or use downloaded ZIP file)**:

   ```powershell
   git clone https://github.com/strnad/CrewAI-Studio.git
   cd CrewAI-Studio
   ```

2. **Run the Conda installation script**:

   ```powershell
   ./install_venv.bat
   ```

3. **Run the application**:
   ```powershell
   ./run_venv.bat
   ```

### Using Conda

Conda will be installed locally in the project folder. No need for a pre-existing Conda installation.

#### On Linux

1. **Clone the repository (or use downloaded ZIP file)**:

   ```bash
   git clone https://github.com/strnad/CrewAI-Studio.git
   cd CrewAI-Studio
   ```

2. **Run the Conda installation script**:

   ```bash
   ./install_conda.sh
   ```

3. **Run the application**:
   ```bash
   ./run_conda.sh
   ```

#### On Windows

1. **Clone the repository (or use downloaded ZIP file)**:

   ```powershell
   git clone https://github.com/strnad/CrewAI-Studio.git
   cd CrewAI-Studio
   ```

2. **Run the Conda installation script**:

   ```powershell
   ./install_conda.bat
   ```

3. **Run the application**:
   ```powershell
   ./run_conda.bat
   ```

### One-Click Deployment

[![Deploy to RepoCloud](https://d16t0pc4846x52.cloudfront.net/deploylobe.svg)](https://repocloud.io/details/?app_id=318)

## Running with Docker Compose

To quickly set up and run CrewAI-Studio using Docker Compose, follow these steps:

### Prerequisites

- Ensure [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) are installed on your system.

### Steps

1. Clone the repository:
```
git clone https://github.com/strnad/CrewAI-Studio.git
cd CrewAI-Studio
```

2. Create a .env file for configuration.  Edit for your own configuration:
```
cp .env_example .env
```

3. Start the application with Docker Compose:
```
docker-compose up --build
```

4. Access the application: http://localhost:8501

## Configuration

Before running the application, ensure you update the `.env` file with your API keys and other necessary configurations. An example `.env` file is provided for reference.

## Troubleshooting
In case of problems:
- Delete the `venv/miniconda` folder and reinstall `crewai-studio`.
- Rename `crewai.db` (it contains your crews but sometimes new versions can break compatibility).
- Raise an issue and I will help you.

## Video tutorial
Video tutorial on CrewAI Studio made by Josh Poco

[![FREE CrewAI Studio GUI EASY AI Agent Creation!ðŸ¤– Open Source AI Agent Orchestration Self Hosted](https://img.youtube.com/vi/3Uxdggt88pY/hqdefault.jpg)](https://www.youtube.com/watch?v=3Uxdggt88pY)

## Star History

<a href="https://star-history.com/#strnad/CrewAI-Studio&Date">
 <picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=strnad/CrewAI-Studio&type=Date&theme=dark" />
   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=strnad/CrewAI-Studio&type=Date" />
   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=strnad/CrewAI-Studio&type=Date" />
 </picture>   
</a>


## Links discovered
- [![Sponsor on GitHub](https://img.shields.io/badge/Sponsor-GitHub-ff69b4?style=for-the-badge&logo=github)
- [![Deploy to RepoCloud](https://d16t0pc4846x52.cloudfront.net/deploylobe.svg)
- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)
- [![FREE CrewAI Studio GUI EASY AI Agent Creation!ðŸ¤– Open Source AI Agent Orchestration Self Hosted](https://img.youtube.com/vi/3Uxdggt88pY/hqdefault.jpg)

--- requirements.txt ---
accelerate==1.12.0
aiohappyeyeballs==2.6.1
aiohttp==3.13.2
aiosignal==1.4.0
altair==5.5.0
annotated-types==0.7.0
anthropic==0.75.0
antlr4-python3-runtime==4.9.3
anyio==4.11.0
appdirs==1.4.4
asn1crypto==1.5.1
attrs==25.4.0
backoff==2.2.1
bcrypt==5.0.0
beautifulsoup4==4.14.2
blinker==1.9.0
boto3==1.41.3
botocore==1.41.3
build==1.3.0
cachetools==6.2.2
certifi==2025.11.12
cffi==2.0.0
cfgv==3.5.0
charset-normalizer==3.4.4
chromadb==1.1.1
click==8.3.1
colorama==0.4.6
coloredlogs==15.0.1
colorlog==6.10.1
crewai==1.5.0
crewai-tools==1.5.0
cryptography==46.0.3
dataclasses-json==0.6.7
defusedxml==0.7.1
deprecation==2.1.0
dill==0.4.0
diskcache==5.6.3
distlib==0.4.0
distro==1.9.0
docker==7.1.0
docling==2.63.0
docling-core==2.52.0
docling-ibm-models==3.10.2
docling-parse==4.7.1
docstring_parser==0.17.0
duckduckgo-search==8.1.1
durationpy==0.10
et_xmlfile==2.0.0
Faker==38.2.0
fastuuid==0.14.0
filelock==3.20.0
filetype==1.2.0
flatbuffers==25.9.23
frozenlist==1.8.0
fsspec==2025.10.0
gitdb==4.0.12
GitPython==3.1.45
google-auth==2.43.0
googleapis-common-protos==1.72.0
greenlet==3.2.4
groq==0.36.0
grpcio==1.76.0
h11==0.16.0
httpcore==1.0.9
httptools==0.7.1
httpx==0.28.1
httpx-sse==0.4.3
huggingface-hub==0.36.0
humanfriendly==10.0
identify==2.6.15
idna==3.11
importlib_metadata==8.7.0
importlib_resources==6.5.2
instructor==1.13.0
Jinja2==3.1.6
jiter==0.11.1
jmespath==1.0.1
json5==0.12.1
json_repair==0.25.2
jsonlines==4.0.0
jsonpatch==1.33
jsonpointer==3.0.0
jsonref==1.1.0
jsonschema==4.25.1
jsonschema-specifications==2025.9.1
kubernetes==34.1.0
lance-namespace==0.0.21
lance-namespace-urllib3-client==0.0.21
lancedb==0.25.3
langchain==1.1.0
langchain-anthropic==1.2.0
langchain-classic==1.0.0
langchain-community==0.4.1
langchain-core==1.1.0
langchain-groq==1.1.0
langchain-ollama==1.0.0
langchain-openai==1.1.0
langchain-text-splitters==1.0.0
langgraph==1.0.3
langgraph-checkpoint==3.0.1
langgraph-prebuilt==1.0.5
langgraph-sdk==0.2.10
langsmith==0.4.47
latex2mathml==3.78.1
litellm==1.80.5
lxml==6.0.2
Markdown==3.10
markdown-it-py==4.0.0
marko==2.2.1
MarkupSafe==3.0.3
marshmallow==3.26.1
mcp==1.22.0
mdurl==0.1.2
mmh3==5.2.0
mpire==2.10.2
mpmath==1.3.0
multidict==6.7.0
multiprocess==0.70.18
mypy_extensions==1.1.0
narwhals==2.12.0
networkx==3.6
nodeenv==1.9.1
numpy==2.2.6
oauthlib==3.3.1
ollama==0.6.1
omegaconf==2.3.0
onnxruntime==1.23.2
openai==2.8.1
opencv-python==4.12.0.88
openpyxl==3.1.5
opentelemetry-api==1.38.0
opentelemetry-exporter-otlp-proto-common==1.38.0
opentelemetry-exporter-otlp-proto-grpc==1.38.0
opentelemetry-exporter-otlp-proto-http==1.38.0
opentelemetry-proto==1.38.0
opentelemetry-sdk==1.38.0
opentelemetry-semantic-conventions==0.59b0
orjson==3.11.4
ormsgpack==1.12.0
overrides==7.7.0
packaging==25.0
pandas==2.3.3
pdfminer.six==20251107
pdfplumber==0.11.8
pillow==11.3.0
platformdirs==4.5.0
pluggy==1.6.0
polyfactory==3.0.0
portalocker==2.7.0
posthog==5.4.0
pre_commit==4.5.0
primp==0.15.0
propcache==0.4.1
protobuf==6.33.1
psutil==7.1.3
psycopg2-binary==2.9.11
pyarrow==21.0.0
pyasn1==0.6.1
pyasn1_modules==0.4.2
pybase64==1.4.2
pyclipper==1.3.0.post6
pycparser==2.23
pydantic==2.12.4
pydantic-settings==2.12.0
pydantic_core==2.41.5
pydeck==0.9.1
Pygments==2.19.2
PyJWT==2.10.1
pylance==0.39.0
pylatexenc==2.10
pyOpenSSL==25.3.0
pypdf==6.4.0
pypdfium2==4.30.0
PyPika==0.48.9
pyproject_hooks==1.2.0
pyreadline3==3.5.4; sys_platform == 'win32'
python-dateutil==2.9.0.post0
python-docx==1.2.0
python-dotenv==1.2.1
python-multipart==0.0.20
python-pptx==1.0.2
pytube==15.0.0
pytz==2025.2
pywin32==311; sys_platform == 'win32'
PyYAML==6.0.3
rapidocr==3.4.2
referencing==0.37.0
regex==2025.11.3
requests==2.32.5
requests-oauthlib==2.0.0
requests-toolbelt==1.0.0
rich==14.2.0
rpds-py==0.29.0
rsa==4.9.1
rtree==1.4.1
s3transfer==0.15.0
safetensors==0.7.0
scipy==1.16.3
semchunk==2.2.2
setuptools==80.9.0
shapely==2.1.2
shellingham==1.5.4
six==1.17.0
smmap==5.0.2
sniffio==1.3.1
snowflake-connector-python==4.1.0
sortedcontainers==2.4.0
soupsieve==2.8
SQLAlchemy==2.0.44
sse-starlette==3.0.3
starlette==0.50.0
streamlit==1.51.0
sympy==1.14.0
tabulate==0.9.0
tenacity==9.1.2
tiktoken==0.12.0
tokenizers==0.22.1
toml==0.10.2
tomli==2.3.0
tomli_w==1.2.0
tomlkit==0.13.3
torch==2.9.1
torchvision==0.24.1
tornado==6.5.2
tqdm==4.67.1
transformers==4.57.2
tree-sitter==0.25.2
tree-sitter-c==0.24.1
tree-sitter-java==0.23.5
tree-sitter-javascript==0.25.0
tree-sitter-python==0.25.0
tree-sitter-typescript==0.23.2
ty==0.0.1a27
typer==0.19.2
typing-inspect==0.9.0
typing-inspection==0.4.2
typing_extensions==4.15.0
tzdata==2025.2
urllib3==2.3.0
uv==0.9.11
uvicorn==0.38.0
virtualenv==20.35.4
watchdog==6.0.0
watchfiles==1.1.1
websocket-client==1.9.0
websockets==15.0.1
xlsxwriter==3.2.9
xxhash==3.6.0
yarl==1.22.0
youtube-transcript-api==1.2.3
zipp==3.23.0
zstandard==0.25.0


--- app/app.py ---
import streamlit as st
from streamlit import session_state as ss
import db_utils
from pg_agents import PageAgents
from pg_tasks import PageTasks
from pg_crews import PageCrews
from pg_tools import PageTools
from pg_crew_run import PageCrewRun
from pg_export_crew import PageExportCrew
from pg_results import PageResults
from pg_knowledge import PageKnowledge
from dotenv import load_dotenv
from llms import load_secrets_fron_env
import os

def pages():
    return {
        'Crews': PageCrews(),
        'Tools': PageTools(),
        'Agents': PageAgents(),
        'Tasks': PageTasks(),
        'Knowledge': PageKnowledge(),  # Add this line
        'Kickoff!': PageCrewRun(),
        'Results': PageResults(),
        'Import/export': PageExportCrew()
    }

def load_data():
    ss.agents = db_utils.load_agents()
    ss.tasks = db_utils.load_tasks()
    ss.crews = db_utils.load_crews()
    ss.tools = db_utils.load_tools()
    ss.enabled_tools = db_utils.load_tools_state()
    ss.knowledge_sources = db_utils.load_knowledge_sources()


def draw_sidebar():
    with st.sidebar:
        st.image("img/crewai_logo.png")

        if 'page' not in ss:
            ss.page = 'Crews'
        
        selected_page = st.radio('Page', list(pages().keys()), index=list(pages().keys()).index(ss.page),label_visibility="collapsed")
        if selected_page != ss.page:
            ss.page = selected_page
            st.rerun()
            
def main():
    st.set_page_config(page_title="CrewAI Studio", page_icon="img/favicon.ico", layout="wide")
    load_dotenv()
    load_secrets_fron_env()
    if (str(os.getenv('AGENTOPS_ENABLED')).lower() in ['true', '1']) and not ss.get('agentops_failed', False):
        try:
            import agentops
            agentops.init(api_key=os.getenv('AGENTOPS_API_KEY'),auto_start_session=False)    
        except ModuleNotFoundError as e:
            ss.agentops_failed = True
            print(f"Error initializing AgentOps: {str(e)}")            
        
    db_utils.initialize_db()
    load_data()
    draw_sidebar()
    PageCrewRun.maintain_session_state() #this will persist the session state for the crew run page so crew run can be run in a separate thread
    pages()[ss.page].draw()
    
if __name__ == '__main__':
    main()


--- app/console_capture.py ---
import sys
import threading
from queue import Queue
import re

class ConsoleCapture:
    def __init__(self):
        self.output_queue = Queue()
        self.original_stdout = sys.stdout
        self.original_stderr = sys.stderr
        self._lock = threading.Lock()
        self._line_buffer = ""
        self.active = False
        # Pattern pro veÅ¡kerÃ© ANSI a speciÃ¡lnÃ­ znaky
        self.clean_pattern = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-9;]*[ -/]*[@-~])|[\x00-\x1F\x7F-\x9F]')

    def clean_text(self, text):
        """OdstranÃ­ vÅ¡echny ANSI a kontrolnÃ­ znaky"""
        return self.clean_pattern.sub('', text)
        #return text

    def start(self):
        with self._lock:
            sys.stdout = self
            sys.stderr = self
            self.active = True

    def stop(self):
        with self._lock:
            if self.active:
                sys.stdout = self.original_stdout
                sys.stderr = self.original_stderr
                if self._line_buffer:
                    cleaned_text = self.clean_text(self._line_buffer)
                    if cleaned_text:
                        self.output_queue.put(cleaned_text)
                    self._line_buffer = ""
                self.active = False

    def write(self, text):
        with self._lock:
            if self.active:
                self.original_stdout.write(text)
                self._line_buffer += text
                
                while '\n' in self._line_buffer:
                    line, self._line_buffer = self._line_buffer.split('\n', 1)
                    if line:
                        cleaned_line = self.clean_text(line)
                        if cleaned_line:
                            self.output_queue.put(cleaned_line)
                
                self.original_stdout.flush()

    def flush(self):
        with self._lock:
            if self.active:
                self.original_stdout.flush()

    def get_output(self):
        messages = []
        with self._lock:
            while not self.output_queue.empty():
                messages.append(self.output_queue.get_nowait())
        return messages

--- app/db_utils.py ---
import sqlite3
import os
import json
from my_tools import TOOL_CLASSES
from sqlalchemy import create_engine, text

# If you have an environment variable DB_URL for Postgres, use that. 
# Otherwise, fallback to local SQLite file: 'sqlite:///crewai.db'
DEFAULT_SQLITE_URL = 'sqlite:///crewai.db'
DB_URL = os.getenv('DB_URL', DEFAULT_SQLITE_URL)

# Create a SQLAlchemy Engine.
# For example, DB_URL could be:
#   "postgresql://username:password@hostname:5432/dbname"
# or fallback to: "sqlite:///crewai.db"
engine = create_engine(DB_URL, echo=False)

def get_db_connection():
    # conn = sqlite3.connect(DB_NAME)
    # conn.row_factory = sqlite3.Row
    # return conn
    """
    Return a context-managed connection from the SQLAlchemy engine.
    """
    return engine.connect()

def create_tables():
    create_sql = text('''
        CREATE TABLE IF NOT EXISTS entities (
            id TEXT PRIMARY KEY,
            entity_type TEXT,
            data TEXT
        )
    ''')
    with get_db_connection() as conn:
        conn.execute(create_sql)
        conn.commit()

def initialize_db():
    """
    Initialize the database by creating tables if they do not exist.
    """
    create_tables()


def save_entity(entity_type, entity_id, data):
    # For SQLite â‰¥ 3.24 and for Postgres, we can do:
    #   INSERT ... ON CONFLICT(id) DO UPDATE ...
    # to emulate "INSERT OR REPLACE"
    upsert_sql = text('''
        INSERT INTO entities (id, entity_type, data)
        VALUES (:id, :etype, :data)
        ON CONFLICT(id) DO UPDATE
            SET entity_type = EXCLUDED.entity_type,
                data = EXCLUDED.data
    ''')
    with get_db_connection() as conn:
        conn.execute(
            upsert_sql,
            {
                "id": entity_id,
                "etype": entity_type,
                "data": json.dumps(data),
            }
        )
        conn.commit()

def load_entities(entity_type):
    query = text('SELECT id, data FROM entities WHERE entity_type = :etype')
    with get_db_connection() as conn:
        result = conn.execute(query, {"etype": entity_type})
        # result.mappings() gives us rows as dicts (if using SQLAlchemy 1.4+)
        rows = result.mappings().all()
    return [(row["id"], json.loads(row["data"])) for row in rows]

def delete_entity(entity_type, entity_id):
    delete_sql = text('''
        DELETE FROM entities
        WHERE id = :id AND entity_type = :etype
    ''')
    with get_db_connection() as conn:
        conn.execute(delete_sql, {"id": entity_id, "etype": entity_type})
        conn.commit()

def save_tools_state(enabled_tools):
    data = {
        'enabled_tools': enabled_tools
    }
    save_entity('tools_state', 'enabled_tools', data)

def load_tools_state():
    rows = load_entities('tools_state')
    if rows:
        return rows[0][1].get('enabled_tools', {})
    return {}

def save_knowledge_source(knowledge_source):
    data = {
        'name': knowledge_source.name,
        'source_type': knowledge_source.source_type,
        'source_path': knowledge_source.source_path,
        'content': knowledge_source.content,
        'metadata': knowledge_source.metadata,
        'chunk_size': knowledge_source.chunk_size,
        'chunk_overlap': knowledge_source.chunk_overlap,
        'created_at': knowledge_source.created_at
    }
    save_entity('knowledge_source', knowledge_source.id, data)

def load_knowledge_sources():
    from my_knowledge_source import MyKnowledgeSource
    rows = load_entities('knowledge_source')
    knowledge_sources = []
    for row in rows:
        data = row[1]
        knowledge_source = MyKnowledgeSource(id=row[0], **data)
        knowledge_sources.append(knowledge_source)
    return sorted(knowledge_sources, key=lambda x: x.created_at)

def delete_knowledge_source(knowledge_source_id):
    delete_entity('knowledge_source', knowledge_source_id)

def save_agent(agent):
    data = {
        'created_at': agent.created_at,
        'role': agent.role,
        'backstory': agent.backstory,
        'goal': agent.goal,
        'allow_delegation': agent.allow_delegation,
        'verbose': agent.verbose,
        'cache': agent.cache,
        'llm_provider_model': agent.llm_provider_model,
        'temperature': agent.temperature,
        'max_iter': agent.max_iter,
        'tool_ids': [tool.tool_id for tool in agent.tools],
        'knowledge_source_ids': agent.knowledge_source_ids
    }
    save_entity('agent', agent.id, data)

def load_agents():
    from my_agent import MyAgent
    rows = load_entities('agent')
    tools_dict = {tool.tool_id: tool for tool in load_tools()}
    agents = []
    for row in rows:
        data = row[1]
        tool_ids = data.pop('tool_ids', [])
        knowledge_source_ids = data.pop('knowledge_source_ids', [])
        agent = MyAgent(id=row[0], knowledge_source_ids=knowledge_source_ids, **data)
        agent.tools = [tools_dict[tool_id] for tool_id in tool_ids if tool_id in tools_dict]
        agents.append(agent)
    return sorted(agents, key=lambda x: x.created_at)


def delete_agent(agent_id):
    delete_entity('agent', agent_id)

def save_task(task):
    data = {
        'description': task.description,
        'expected_output': task.expected_output,
        'async_execution': task.async_execution,
        'agent_id': task.agent.id if task.agent else None,
        'context_from_async_tasks_ids': task.context_from_async_tasks_ids,
        'context_from_sync_tasks_ids': task.context_from_sync_tasks_ids,
        'created_at': task.created_at
    }
    save_entity('task', task.id, data)

def load_tasks():
    from my_task import MyTask
    rows = load_entities('task')
    agents_dict = {agent.id: agent for agent in load_agents()}
    tasks = []
    for row in rows:
        data = row[1]
        agent_id = data.pop('agent_id', None)
        task = MyTask(id=row[0], agent=agents_dict.get(agent_id), **data)
        tasks.append(task)
    return sorted(tasks, key=lambda x: x.created_at)

def delete_task(task_id):
    delete_entity('task', task_id)

def save_crew(crew):
    data = {
        'name': crew.name,
        'process': crew.process,
        'verbose': crew.verbose,
        'agent_ids': [agent.id for agent in crew.agents],
        'task_ids': [task.id for task in crew.tasks],
        'memory': crew.memory,
        'cache': crew.cache,
        'planning': crew.planning,
        'planning_llm': crew.planning_llm,
        'max_rpm': crew.max_rpm,
        'manager_llm': crew.manager_llm,
        'manager_agent_id': crew.manager_agent.id if crew.manager_agent else None,
        'created_at': crew.created_at,
        'knowledge_source_ids': crew.knowledge_source_ids  # Add this line
    }
    save_entity('crew', crew.id, data)

def load_crews():
    from my_crew import MyCrew
    rows = load_entities('crew')
    agents_dict = {agent.id: agent for agent in load_agents()}
    tasks_dict = {task.id: task for task in load_tasks()}
    crews = []
    for row in rows:
        data = row[1]
        crew = MyCrew(
            id=row[0], 
            name=data['name'], 
            process=data['process'], 
            verbose=data['verbose'], 
            created_at=data['created_at'], 
            memory=data.get('memory'),
            cache=data.get('cache'),
            planning=data.get('planning'),
            planning_llm=data.get('planning_llm'),
            max_rpm=data.get('max_rpm'), 
            manager_llm=data.get('manager_llm'),
            manager_agent=agents_dict.get(data.get('manager_agent_id')),
            knowledge_source_ids=data.get('knowledge_source_ids', [])  # Add this line
        )
        crew.agents = [agents_dict[agent_id] for agent_id in data['agent_ids'] if agent_id in agents_dict]
        crew.tasks = [tasks_dict[task_id] for task_id in data['task_ids'] if task_id in tasks_dict]
        crews.append(crew)
    return sorted(crews, key=lambda x: x.created_at)

def delete_crew(crew_id):
    delete_entity('crew', crew_id)

def save_tool(tool):
    data = {
        'name': tool.name,
        'description': tool.description,
        'parameters': tool.get_parameters()
    }
    save_entity('tool', tool.tool_id, data)

def load_tools():
    rows = load_entities('tool')
    tools = []
    for row in rows:
        data = row[1]
        tool_class = TOOL_CLASSES[data['name']]
        tool = tool_class(tool_id=row[0])
        tool.set_parameters(**data['parameters'])
        tools.append(tool)
    return tools

def delete_tool(tool_id):
    delete_entity('tool', tool_id)

def export_to_json(file_path):
    with get_db_connection() as conn:
        # Use SQLAlchemy's text() for raw SQL
        query = text('SELECT * FROM entities')
        result = conn.execute(query)
        
        # Convert to list of dictionaries
        rows = [
            {
                'id': row.id,
                'entity_type': row.entity_type,
                'data': json.loads(row.data)
            }
            for row in result
        ]

        # Write to file
        with open(file_path, 'w') as f:
            json.dump(rows, f, indent=4)

def import_from_json(file_path):
    with open(file_path, 'r') as f:
        data = json.load(f)

    with get_db_connection() as conn:
        for entity in data:
            # Use SQLAlchemy's text() for raw SQL with parameters
            upsert_sql = text('''
                INSERT INTO entities (id, entity_type, data)
                VALUES (:id, :etype, :data)
                ON CONFLICT(id) DO UPDATE
                    SET entity_type = EXCLUDED.entity_type,
                        data = EXCLUDED.data
            ''')
            
            conn.execute(
                upsert_sql,
                {
                    "id": entity['id'],
                    "etype": entity['entity_type'],
                    "data": json.dumps(entity['data'])
                }
            )
            
        conn.commit()
        
def save_result(result):
    """Save a result to the database."""
    data = {
        'crew_id': result.crew_id,
        'crew_name': result.crew_name,
        'inputs': result.inputs,
        'result': result.result,
        'created_at': result.created_at
    }
    save_entity('result', result.id, data)

def load_results():
    """Load all results from the database."""
    from result import Result
    rows = load_entities('result')
    results = []
    for row in rows:
        data = row[1]
        result = Result(
            id=row[0],
            crew_id=data['crew_id'],
            crew_name=data['crew_name'],
            inputs=data['inputs'],
            result=data['result'],
            created_at=data['created_at']
        )
        results.append(result)
    return sorted(results, key=lambda x: x.created_at, reverse=True)

def delete_result(result_id):
    """Delete a result from the database."""
    delete_entity('result', result_id)

--- app/llms.py ---
import os
from dotenv import load_dotenv
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_groq import ChatGroq
from langchain_anthropic import ChatAnthropic
from crewai import LLM
from langchain_openai.chat_models.base import BaseChatOpenAI
from litellm import completion

def load_secrets_fron_env():
    load_dotenv(override=True)
    if "env_vars" not in st.session_state:
        st.session_state.env_vars = {
            "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY"),
            "OPENAI_API_BASE": os.getenv("OPENAI_API_BASE", "https://api.openai.com/v1/"),
            "GROQ_API_KEY": os.getenv("GROQ_API_KEY"),
            "LMSTUDIO_API_BASE": os.getenv("LMSTUDIO_API_BASE"),
            "ANTHROPIC_API_KEY": os.getenv("ANTHROPIC_API_KEY"),
            "OLLAMA_HOST": os.getenv("OLLAMA_HOST"),
            "XAI_API_KEY": os.getenv("XAI_API_KEY"),
        }
    else:
        st.session_state.env_vars = st.session_state.env_vars

def switch_environment(new_env_vars):
    for key, value in new_env_vars.items():
        if value is not None:
            os.environ[key] = value
            st.session_state.env_vars[key] = value

def restore_environment():
    for key, value in st.session_state.env_vars.items():
        if value is not None:
            os.environ[key] = value
        elif key in os.environ:
            del os.environ[key]

def safe_pop_env_var(key):
    os.environ.pop(key, None)

def create_openai_llm(model, temperature):
    switch_environment({
        "OPENAI_API_KEY": st.session_state.env_vars["OPENAI_API_KEY"],
        "OPENAI_API_BASE": st.session_state.env_vars["OPENAI_API_BASE"],
    })
    api_key = os.getenv("OPENAI_API_KEY")
    api_base = os.getenv("OPENAI_API_BASE")

    if api_key:
        return LLM(model=model, temperature=temperature, base_url=api_base)
    else:
        raise ValueError("OpenAI API key not set in .env file")

def create_anthropic_llm(model, temperature):
    switch_environment({
        "ANTHROPIC_API_KEY": st.session_state.env_vars["ANTHROPIC_API_KEY"],
    })
    api_key = os.getenv("ANTHROPIC_API_KEY")

    if api_key:
        return ChatAnthropic(
            anthropic_api_key=api_key,
            model_name=model,
            temperature=temperature,
            max_tokens=4095,
        )
    else:
        raise ValueError("Anthropic API key not set in .env file")

def create_groq_llm(model, temperature):
    switch_environment({
        "GROQ_API_KEY": st.session_state.env_vars["GROQ_API_KEY"],
    })
    api_key = os.getenv("GROQ_API_KEY")

    if api_key:
        return ChatGroq(groq_api_key=api_key, model_name=model, temperature=temperature, max_tokens=4095)
    else:
        raise ValueError("Groq API key not set in .env file")

def create_ollama_llm(model, temperature):
    host = st.session_state.env_vars["OLLAMA_HOST"]
    if host:
        switch_environment({
            "OPENAI_API_KEY": "ollama",  # NastavÃ­ OpenAI API klÃ­Ä na "ollama"
            "OPENAI_API_BASE": host,    # NastavÃ­ OpenAI API Base na hodnotu OLLAMA_HOST
        })
        return LLM(model=model, temperature=temperature, base_url=host)
    else:
        raise ValueError("Ollama Host is not set in .env file")


def create_xai_llm(model, temperature):
    host = "https://api.x.ai/v1"
    api_key = st.session_state.env_vars.get("XAI_API_KEY")

    if not api_key:
        raise ValueError("XAI_API_KEY must be set in .env file")

    switch_environment({
        "OPENAI_API_KEY": api_key,
        "OPENAI_API_BASE": host,
    })

    return LLM(
        model=model,
        temperature=temperature,
        api_key=api_key,
        base_url=host
    )

def create_lmstudio_llm(model, temperature):
    switch_environment({
        "OPENAI_API_KEY": "lm-studio",
        "OPENAI_API_BASE": st.session_state.env_vars["LMSTUDIO_API_BASE"],
    })
    api_base = os.getenv("OPENAI_API_BASE")

    if api_base:
        return ChatOpenAI(
            openai_api_key="lm-studio",
            openai_api_base=api_base,
            temperature=temperature,
            max_tokens=4095,
        )
    else:
        raise ValueError("LM Studio API base not set in .env file")

LLM_CONFIG = {
    "OpenAI": {
        "models": os.getenv("OPENAI_PROXY_MODELS", "").split(",") if os.getenv("OPENAI_PROXY_MODELS") else ["gpt-4.1-mini","gpt-4o-mini", "gpt-4o", "gpt-5-mini", "gpt-5-nano"],
        "create_llm": create_openai_llm,
    },
    "Groq": {
        "models": ["groq/llama3-8b-8192", "groq/llama3-70b-8192", "groq/mixtral-8x7b-32768"],
        "create_llm": create_groq_llm,
    },
    "Ollama": {
        "models": os.getenv("OLLAMA_MODELS", "").split(",") if os.getenv("OLLAMA_MODELS") else [],
        "create_llm": create_ollama_llm,
    },
    "Anthropic": {
        "models": ["claude-3-5-sonnet-20240620","claude-3-7-sonnet-20250219"],
        "create_llm": create_anthropic_llm,
    },
    "LM Studio": {
        "models": ["lms-default"],
        "create_llm": create_lmstudio_llm,
    },
     "Xai": {
        "models": ["xai/grok-2-1212", "xai/grok-beta"],
        "create_llm": create_xai_llm,
    },
}

def llm_providers_and_models():
    return [f"{provider}: {model}" for provider in LLM_CONFIG.keys() for model in LLM_CONFIG[provider]["models"]]

def create_llm(provider_and_model, temperature=0.15):
    # RozdÄ›lit pouze na prvnÃ­ vÃ½skyt ': ', aby model mohl obsahovat dvojteÄku
    if ": " not in provider_and_model:
        raise ValueError("Input string must be in format 'Provider: Model'")
    provider, model = provider_and_model.split(": ", 1)
    create_llm_func = LLM_CONFIG.get(provider, {}).get("create_llm")

    if create_llm_func:
        llm = create_llm_func(model, temperature)
        restore_environment()  # ObnovÃ­ pÅ¯vodnÃ­ prostÅ™edÃ­ po vytvoÅ™enÃ­ LLM
        return llm
    else:
        raise ValueError(f"LLM provider {provider} is not recognized or not supported")


--- app/my_agent.py ---
from crewai import Agent
import streamlit as st
from utils import rnd_id, fix_columns_width
from streamlit import session_state as ss
from db_utils import save_agent, delete_agent
from llms import llm_providers_and_models, create_llm
from datetime import datetime

class MyAgent:
    def __init__(self, id=None, role=None, backstory=None, goal=None, temperature=None, allow_delegation=False, verbose=False, cache= None, llm_provider_model=None, max_iter=None, created_at=None, tools=None, knowledge_source_ids=None):
        self.id = id or "A_" + rnd_id()
        self.role = role or "Senior Researcher"
        self.backstory = backstory or "Driven by curiosity, you're at the forefront of innovation, eager to explore and share knowledge that could change the world."
        self.goal = goal or "Uncover groundbreaking technologies in AI"
        self.temperature = temperature or 0.1
        self.allow_delegation = allow_delegation if allow_delegation is not None else False
        self.verbose = verbose if verbose is not None else True
        self.llm_provider_model = llm_providers_and_models()[0] if llm_provider_model is None else llm_provider_model
        self.created_at = created_at or datetime.now().isoformat()
        self.tools = tools or []
        self.max_iter = max_iter or 25
        self.cache = cache if cache is not None else True
        self.knowledge_source_ids = knowledge_source_ids or []
        self.edit_key = f'edit_{self.id}'
        if self.edit_key not in ss:
            ss[self.edit_key] = False

    @property
    def edit(self):
        return ss[self.edit_key]

    @edit.setter
    def edit(self, value):
        ss[self.edit_key] = value

    def get_crewai_agent(self) -> Agent:
        llm = create_llm(self.llm_provider_model, temperature=self.temperature)
        tools = [tool.create_tool() for tool in self.tools]
        
        # Add knowledge sources if they exist
        knowledge_sources = []
        if 'knowledge_sources' in ss and self.knowledge_source_ids:
            valid_knowledge_source_ids = []
            
            for ks_id in self.knowledge_source_ids:
                ks = next((k for k in ss.knowledge_sources if k.id == ks_id), None)
                if ks:
                    try:
                        knowledge_sources.append(ks.get_crewai_knowledge_source())
                        valid_knowledge_source_ids.append(ks_id)
                    except Exception as e:
                        print(f"Error loading knowledge source {ks.id}: {str(e)}")
        if knowledge_sources:
            print(f"Loaded {len(knowledge_sources)} knowledge sources for agent {self.id}")
            print(knowledge_sources)
        return Agent(
            role=self.role,
            backstory=self.backstory,
            goal=self.goal,
            allow_delegation=self.allow_delegation,
            verbose=self.verbose,
            max_iter=self.max_iter,
            cache=self.cache,
            tools=tools,
            llm=llm,
            knowledge_sources=knowledge_sources if knowledge_sources else None
        )

    def delete(self):
        ss.agents = [agent for agent in ss.agents if agent.id != self.id]
        delete_agent(self.id)

    def get_tool_display_name(self, tool):
        first_param_name = tool.get_parameter_names()[0] if tool.get_parameter_names() else None
        first_param_value = tool.parameters.get(first_param_name, '') if first_param_name else ''
        return f"{tool.name} ({first_param_value if first_param_value else tool.tool_id})"

    def is_valid(self, show_warning=False):
        for tool in self.tools:
            if not tool.is_valid(show_warning=show_warning):
                if show_warning:
                    st.warning(f"Tool {tool.name} is not valid")
                return False
        return True

    def validate_llm_provider_model(self):
        available_models = llm_providers_and_models()
        if self.llm_provider_model not in available_models:
            self.llm_provider_model = available_models[0]

    def draw(self, key=None):
        self.validate_llm_provider_model()
        expander_title = f"{self.role[:60]} -{self.llm_provider_model.split(':')[1]}" if self.is_valid() else f"â— {self.role[:20]} -{self.llm_provider_model.split(':')[1]}"
        form_key = f'form_{self.id}_{key}' if key else f'form_{self.id}'        
        if self.edit:
            with st.expander(f"Agent: {self.role}", expanded=True):
                with st.form(key=form_key):
                    self.role = st.text_input("Role", value=self.role)
                    self.backstory = st.text_area("Backstory", value=self.backstory)
                    self.goal = st.text_area("Goal", value=self.goal)
                    self.allow_delegation = st.checkbox("Allow delegation", value=self.allow_delegation)
                    self.verbose = st.checkbox("Verbose", value=self.verbose)
                    self.cache = st.checkbox("Cache", value=self.cache)
                    self.llm_provider_model = st.selectbox("LLM Provider and Model", options=llm_providers_and_models(), index=llm_providers_and_models().index(self.llm_provider_model))
                    self.temperature = st.slider("Temperature", value=self.temperature, min_value=0.0, max_value=1.0)
                    self.max_iter = st.number_input("Max Iterations", value=self.max_iter, min_value=1, max_value=100)                    
                    enabled_tools = [tool for tool in ss.tools]
                    tools_key = f"{self.id}_tools_{key}" if key else f"{self.id}_tools"
                    selected_tools = st.multiselect(
                        "Select Tools",
                        [self.get_tool_display_name(tool) for tool in enabled_tools],
                        default=[self.get_tool_display_name(tool) for tool in self.tools],
                        key=tools_key
                    )                    
                    if 'knowledge_sources' in ss and len(ss.knowledge_sources) > 0:
                        knowledge_source_options = [ks.id for ks in ss.knowledge_sources]
                        knowledge_source_labels = {ks.id: ks.name for ks in ss.knowledge_sources}
                        
                        # Filter out any knowledge source IDs that no longer exist
                        valid_knowledge_sources = [ks_id for ks_id in self.knowledge_source_ids 
                                                if ks_id in knowledge_source_options]
                        
                        # If we filtered out any IDs, update the agent's knowledge sources
                        if len(valid_knowledge_sources) != len(self.knowledge_source_ids):
                            self.knowledge_source_ids = valid_knowledge_sources
                            save_agent(self)
                        
                        # Generate a unique key for the knowledge sources multiselect
                        ks_key = f"knowledge_sources_{self.id}_{key}" if key else f"knowledge_sources_{self.id}"
                        
                        # Now use the filtered list for the multiselect with the unique key
                        selected_knowledge_sources = st.multiselect(
                            "Knowledge Sources",
                            options=knowledge_source_options,
                            default=valid_knowledge_sources,
                            format_func=lambda x: knowledge_source_labels.get(x, "Unknown"),
                            key=ks_key
                        )
                        self.knowledge_source_ids = selected_knowledge_sources                
                    submitted = st.form_submit_button("Save")
                    if submitted:
                        self.tools = [tool for tool in enabled_tools if self.get_tool_display_name(tool) in selected_tools]
                        self.set_editable(False)
        else:
            fix_columns_width()
            with st.expander(expander_title, expanded=False):
                st.markdown(f"**Role:** {self.role}")
                st.markdown(f"**Backstory:** {self.backstory}")
                st.markdown(f"**Goal:** {self.goal}")
                st.markdown(f"**Allow delegation:** {self.allow_delegation}")
                st.markdown(f"**Verbose:** {self.verbose}")
                st.markdown(f"**Cache:** {self.cache}")
                st.markdown(f"**LLM Provider and Model:** {self.llm_provider_model}")
                st.markdown(f"**Temperature:** {self.temperature}")
                st.markdown(f"**Max Iterations:** {self.max_iter}")
                st.markdown(f"**Tools:** {[self.get_tool_display_name(tool) for tool in self.tools]}")                
                # Display knowledge sources
                if self.knowledge_source_ids and 'knowledge_sources' in ss:
                    knowledge_sources = [ks for ks in ss.knowledge_sources if ks.id in self.knowledge_source_ids]
                    if knowledge_sources:
                        st.markdown("**Knowledge Sources:**")
                        for ks in knowledge_sources:
                            st.markdown(f"- {ks.name}")
                self.is_valid(show_warning=True)
                col1, col2 = st.columns(2)
                with col1:
                    btn_key = f"edit_btn_{rnd_id()}"
                    st.button("Edit", on_click=self.set_editable, args=(True,), key=btn_key)
                with col2:
                    del_key = f"del_btn_{rnd_id()}"
                    st.button("Delete", on_click=self.delete, key=del_key)

    def set_editable(self, edit):
        self.edit = edit
        save_agent(self)
        if not edit:
            st.rerun()

--- app/my_crew.py ---
from crewai import Crew, Process
import streamlit as st
from utils import rnd_id, fix_columns_width
from streamlit import session_state as ss
from datetime import datetime
from llms import llm_providers_and_models, create_llm
import db_utils

class MyCrew:
    def __init__(self, id=None, name=None, agents=None, tasks=None, process=None, cache=None, max_rpm=None, verbose=None, manager_llm=None, manager_agent=None, created_at=None, memory=None, planning=None, planning_llm=None, knowledge_source_ids=None):
        self.id = id or "C_" + rnd_id()
        self.name = name or "Crew 1"
        self.agents = agents or []
        self.tasks = tasks or []
        self.process = process or Process.sequential
        self.verbose = bool(verbose) if verbose is not None else True
        self.manager_llm = manager_llm
        self.manager_agent = manager_agent
        self.memory = memory if memory is not None else False
        self.cache = cache if cache is not None else True
        self.max_rpm = max_rpm or 1000
        self.planning = planning if planning is not None else False
        self.planning_llm = planning_llm
        self.created_at = created_at or datetime.now().isoformat()
        self.knowledge_source_ids = knowledge_source_ids or []
        self.edit_key = f'edit_{self.id}'
        if self.edit_key not in ss:
            ss[self.edit_key] = False
        self.tasks_order_key = f'tasks_order_{self.id}'
        if self.tasks_order_key not in ss:
            ss[self.tasks_order_key] = [task.id for task in self.tasks]

    @property
    def edit(self):
        return ss[self.edit_key]

    @edit.setter
    def edit(self, value):
        ss[self.edit_key] = value

    def get_crewai_crew(self, *args, **kwargs) -> Crew:
        crewai_agents = [agent.get_crewai_agent() for agent in self.agents]

        # Create a dictionary to hold the Task objects
        task_objects = {}

        def create_task(task):
            if task.id in task_objects:
                return task_objects[task.id]

            context_tasks = []
            if task.async_execution or task.context_from_async_tasks_ids or task.context_from_sync_tasks_ids:
                for context_task_id in (task.context_from_async_tasks_ids or []) + (task.context_from_sync_tasks_ids or []):
                    if context_task_id not in task_objects:
                        context_task = next((t for t in self.tasks if t.id == context_task_id), None)
                        if context_task:
                            context_tasks.append(create_task(context_task))
                        else:
                            print(f"Warning: Context task with id {context_task_id} not found for task {task.id}")
                    else:
                        context_tasks.append(task_objects[context_task_id])

            # Only pass context if it's an async task or if specific context is defined
            if task.async_execution or context_tasks:
                crewai_task = task.get_crewai_task(context_from_async_tasks=context_tasks)
            else:
                crewai_task = task.get_crewai_task()

            task_objects[task.id] = crewai_task
            return crewai_task

        # Create all tasks, resolving dependencies recursively
        for task in self.tasks:
            create_task(task)

        # Collect the final list of tasks in the original order
        crewai_tasks = [task_objects[task.id] for task in self.tasks]

        # Add knowledge sources if they exist
        knowledge_sources = []
        if 'knowledge_sources' in ss and self.knowledge_source_ids:
            valid_knowledge_source_ids = []
            
            for ks_id in self.knowledge_source_ids:
                ks = next((k for k in ss.knowledge_sources if k.id == ks_id), None)
                if ks:
                    try:
                        knowledge_sources.append(ks.get_crewai_knowledge_source())
                        valid_knowledge_source_ids.append(ks_id)
                    except Exception as e:
                        print(f"Error loading knowledge source {ks.id}: {str(e)}")
            
            # If any knowledge sources were invalid, update the list
            if len(valid_knowledge_source_ids) != len(self.knowledge_source_ids):
                self.knowledge_source_ids = valid_knowledge_source_ids
                db_utils.save_crew(self)

        # Create the crew with knowledge sources
        if self.manager_llm:
            crew_params = {
                'agents': crewai_agents,
                'tasks': crewai_tasks,
                'cache': self.cache,
                'process': self.process,
                'max_rpm': self.max_rpm,
                'verbose': self.verbose,
                'manager_llm': create_llm(self.manager_llm),
                'memory': self.memory,
                'planning': self.planning,
                'knowledge_sources': knowledge_sources if knowledge_sources else None,
            }
            if self.planning and self.planning_llm:
                crew_params['planning_llm'] = create_llm(self.planning_llm)
            crew_params.update(kwargs)
            return Crew(*args, **crew_params)
        elif self.manager_agent:
            crew_params = {
                'agents': crewai_agents,
                'tasks': crewai_tasks,
                'cache': self.cache,
                'process': self.process,
                'max_rpm': self.max_rpm,
                'verbose': self.verbose,
                'manager_agent': self.manager_agent.get_crewai_agent(),
                'memory': self.memory,
                'planning': self.planning,
                'knowledge_sources': knowledge_sources if knowledge_sources else None,
            }
            if self.planning and self.planning_llm:
                crew_params['planning_llm'] = create_llm(self.planning_llm)
            crew_params.update(kwargs)
            return Crew(*args, **crew_params)
        
        crew_params = {
            'agents': crewai_agents,
            'tasks': crewai_tasks,
            'cache': self.cache,
            'process': self.process,
            'max_rpm': self.max_rpm,
            'verbose': self.verbose,
            'memory': self.memory,
            'planning': self.planning,
            'knowledge_sources': knowledge_sources if knowledge_sources else None,
        }
        if self.planning and self.planning_llm:
            crew_params['planning_llm'] = create_llm(self.planning_llm)
        crew_params.update(kwargs)
        return Crew(*args, **crew_params)
    
    def update_knowledge_sources(self):
        self.knowledge_source_ids = ss[f'knowledge_sources_{self.id}']
        db_utils.save_crew(self)

    def delete(self):
        ss.crews = [crew for crew in ss.crews if crew.id != self.id]
        db_utils.delete_crew(self.id)

    def update_name(self):
        self.name = ss[f'name_{self.id}']
        db_utils.save_crew(self)

    def update_process(self):
        self.process = ss[f'process_{self.id}']
        db_utils.save_crew(self)

    def update_tasks(self):
        selected_tasks_ids = ss[f'tasks_{self.id}']
        self.tasks = [task for task in ss.tasks if task.id in selected_tasks_ids and task.agent.id in [agent.id for agent in self.agents]]
        self.tasks = sorted(self.tasks, key=lambda task: selected_tasks_ids.index(task.id))
        ss[self.tasks_order_key] = selected_tasks_ids
        db_utils.save_crew(self)

    def update_verbose(self):
        self.verbose = ss[f'verbose_{self.id}']
        db_utils.save_crew(self)

    def update_agents(self):
        selected_agents = ss[f'agents_{self.id}']
        self.agents = [agent for agent in ss.agents if agent.role in selected_agents]        
        db_utils.save_crew(self)

    def update_manager_llm(self):
        selected_llm = ss[f'manager_llm_{self.id}']
        self.manager_llm = selected_llm if selected_llm != "None" else None
        if self.manager_llm:
            self.manager_agent = None
        db_utils.save_crew(self)

    def update_manager_agent(self):
        selected_agent_role = ss[f'manager_agent_{self.id}']
        self.manager_agent = next((agent for agent in ss.agents if agent.role == selected_agent_role), None) if selected_agent_role != "None" else None
        if self.manager_agent:
            self.manager_llm = None
        db_utils.save_crew(self)

    def update_memory(self):
        self.memory = ss[f'memory_{self.id}']
        db_utils.save_crew(self)
    
    def update_max_rpm(self):
        self.max_rpm = ss[f'max_rpm_{self.id}']
        db_utils.save_crew(self)

    def update_cache(self):
        self.cache = ss[f'cache_{self.id}']
        db_utils.save_crew(self)

    def update_planning(self):
        self.planning = ss[f'planning_{self.id}']
        db_utils.save_crew(self)

    def update_planning_llm(self):
        selected_llm = ss[f'planning_llm_{self.id}']
        self.planning_llm = selected_llm if selected_llm != "None" else None
        db_utils.save_crew(self)

    def is_valid(self, show_warning=False):
        if len(self.agents) == 0:
            if show_warning:
                st.warning(f"Crew {self.name} has no agents")
            return False
        if len(self.tasks) == 0:
            if show_warning:
                st.warning(f"Crew {self.name} has no tasks")
            return False
        if any([not agent.is_valid(show_warning=show_warning) for agent in self.agents]):
            return False
        if any([not task.is_valid(show_warning=show_warning) for task in self.tasks]):
            return False
        if self.process == Process.hierarchical and not (self.manager_llm or self.manager_agent):
            if show_warning:
                st.warning(f"Crew {self.name} has no manager agent or manager llm set for hierarchical process")
            return False
        if self.planning and not self.planning_llm:
            if show_warning:
                st.warning(f"Crew {self.name} has planning enabled but no planning LLM selected")
            return False
        return True

    def validate_manager_llm(self):
        available_models = llm_providers_and_models()
        if self.manager_llm and self.manager_llm not in available_models:
            self.manager_llm = None

    def validate_planning_llm(self):
        available_models = llm_providers_and_models()
        if self.planning_llm and self.planning_llm not in available_models:
            self.planning_llm = None

    def draw(self,expanded=False, buttons=True):
        self.validate_manager_llm()
        self.validate_planning_llm()
        name_key = f"name_{self.id}"
        process_key = f"process_{self.id}"
        verbose_key = f"verbose_{self.id}"
        agents_key = f"agents_{self.id}"
        tasks_key = f"tasks_{self.id}"
        manager_llm_key = f"manager_llm_{self.id}"
        manager_agent_key = f"manager_agent_{self.id}"
        memory_key = f"memory_{self.id}"
        planning_key = f"planning_{self.id}"
        planning_llm_key = f"planning_llm_{self.id}"
        cache_key = f"cache_{self.id}"
        max_rpm_key = f"max_rpm_{self.id}"
        
        if self.edit:
            with st.container(border=True):
                st.text_input("Name (just id, it doesn't affect anything)", value=self.name, key=name_key, on_change=self.update_name)
                st.selectbox("Process", options=[Process.sequential, Process.hierarchical], index=[Process.sequential, Process.hierarchical].index(self.process), key=process_key, on_change=self.update_process)
                st.multiselect("Agents", options=[agent.role for agent in ss.agents], default=[agent.role for agent in self.agents], key=agents_key, on_change=self.update_agents)                
                # Filter tasks by selected agents
                available_tasks = [task for task in ss.tasks if task.agent and task.agent.id in [agent.id for agent in self.agents]]
                available_task_ids = [task.id for task in available_tasks]
                default_task_ids = [task.id for task in self.tasks if task.id in available_task_ids]             
                st.multiselect("Tasks", options=available_task_ids, default=default_task_ids, format_func=lambda x: next(task.description for task in ss.tasks if task.id == x), key=tasks_key, on_change=self.update_tasks)                
                st.selectbox("Manager LLM", options=["None"] + llm_providers_and_models(), index=0 if self.manager_llm is None else llm_providers_and_models().index(self.manager_llm) + 1, key=manager_llm_key, on_change=self.update_manager_llm, disabled=(self.process != Process.hierarchical))
                st.selectbox("Manager Agent", options=["None"] + [agent.role for agent in ss.agents], index=0 if self.manager_agent is None else [agent.role for agent in ss.agents].index(self.manager_agent.role) + 1, key=manager_agent_key, on_change=self.update_manager_agent, disabled=(self.process != Process.hierarchical))
                st.checkbox("Verbose", value=self.verbose, key=verbose_key, on_change=self.update_verbose)
                st.checkbox("Memory", value=self.memory, key=memory_key, on_change=self.update_memory)
                st.checkbox("Cache", value=self.cache, key=cache_key, on_change=self.update_cache)
                st.checkbox("Planning", value=self.planning, key=planning_key, on_change=self.update_planning)
                st.selectbox("Planning LLM", options=["None"] + llm_providers_and_models(), index=0 if self.planning_llm is None else llm_providers_and_models().index(self.planning_llm) + 1, key=planning_llm_key, on_change=self.update_planning_llm, disabled=not self.planning)
                st.number_input("Max req/min", value=self.max_rpm, key=max_rpm_key, on_change=self.update_max_rpm)  
                # for some reason knowledge sources for crews are not working, use the knowledge sources in the agents instead
                # if 'knowledge_sources' in ss and len(ss.knowledge_sources) > 0:
                #     knowledge_source_options = [ks.id for ks in ss.knowledge_sources]
                #     knowledge_source_labels = {ks.id: ks.name for ks in ss.knowledge_sources}
                #     valid_knowledge_sources = [ks_id for ks_id in self.knowledge_source_ids 
                #                             if ks_id in knowledge_source_options]

                #     if len(valid_knowledge_sources) != len(self.knowledge_source_ids):
                #         self.knowledge_source_ids = valid_knowledge_sources
                #         db_utils.save_crew(self)
                #     st.multiselect(
                #         "Knowledge Sources",
                #         options=knowledge_source_options,
                #         default=valid_knowledge_sources,
                #         format_func=lambda x: knowledge_source_labels.get(x, "Unknown"),
                #         key=f"knowledge_sources_{self.id}",
                #         on_change=self.update_knowledge_sources
                #     )

                st.button("Save", on_click=self.set_editable, args=(False,), key=rnd_id())
        else:
            fix_columns_width()
            expander_title = f"Crew: {self.name}" if self.is_valid() else f"â— Crew: {self.name}"
            with st.expander(expander_title, expanded=expanded):
                st.markdown(f"**Process:** {self.process}")
                if self.process == Process.hierarchical:
                    st.markdown(f"**Manager LLM:** {self.manager_llm}")
                    st.markdown(f"**Manager Agent:** {self.manager_agent.role if self.manager_agent else 'None'}")
                st.markdown(f"**Verbose:** {self.verbose}")
                st.markdown(f"**Memory:** {self.memory}")
                st.markdown(f"**Cache:** {self.cache}")
                st.markdown(f"**Planning:** {self.planning}")
                if self.planning and self.planning_llm:
                    st.markdown(f"**Planning LLM:** {self.planning_llm}")
                st.markdown(f"**Max req/min:** {self.max_rpm}")
                st.markdown("**Tasks:**")
                for i, task in enumerate([task for task in self.tasks if task.agent and task.agent.id in [agent.id for agent in self.agents]], 1):
                    with st.container(border=True):
                        async_tag = "(async)" if task.async_execution else ""
                        st.markdown(f"**{i}.{async_tag}  {task.description}**")
                        st.markdown(f"**Agent:** {task.agent.role if task.agent else 'None'}")
                        tools_list = ", ".join([tool.name for tool in task.agent.tools]) if task.agent else "None"
                        st.markdown(f" **Tools:** {tools_list}")
                        st.markdown(f" **LLM:** {task.agent.llm_provider_model}")
                if self.knowledge_source_ids and 'knowledge_sources' in ss:
                    source_names = [ks.name for ks in ss.knowledge_sources if ks.id in self.knowledge_source_ids]
                    st.markdown(f"**Knowledge Sources:** {', '.join(source_names)}")
                if buttons:
                    col1, col2 = st.columns(2)
                    with col1:                    
                        st.button("Edit", on_click=self.set_editable, key=rnd_id(), args=(True,))
                    with col2:                   
                        # Instead of direct delete, open modal for cascade delete handling
                        st.button("Delete", on_click=self.request_delete_modal, key=rnd_id())
                self.is_valid(show_warning=True)
                # If this crew was selected for deletion, draw the modal here
                if ss.get('delete_crew_target_id') == self.id:
                    self.draw_delete_dialog()

    def set_editable(self, edit):
        self.edit = edit
        db_utils.save_crew(self)

    # ---------------------- Deletion & Cascade Handling ----------------------
    def request_delete_modal(self):
        """Flag this crew for deletion and trigger modal display."""
        ss['delete_crew_target_id'] = self.id

    def clear_delete_modal(self):
        if 'delete_crew_target_id' in ss:
            del ss['delete_crew_target_id']

    def analyze_dependencies(self):
        """Analyze agents and tasks belonging to this crew for conflicts.

        Returns:
            dict with keys 'agents' and 'tasks'. Each value is a list of dicts:
            {'obj': <agent|task>, 'conflicts': [str,...]}
        """
        # Other crews
        other_crews = [c for c in ss.crews if c.id != self.id]

        # Map task id -> tasks referencing it as context (across all tasks)
        context_refs = {}
        for t in ss.tasks:
            for ref in (t.context_from_async_tasks_ids or []) + (t.context_from_sync_tasks_ids or []):
                context_refs.setdefault(ref, []).append(t)

        agents_info = []
        for agent in self.agents:
            conflicts = []
            # Used in other crews
            used_in_crews = [c.name for c in other_crews if any(a.id == agent.id for a in c.agents)]
            if used_in_crews:
                conflicts.append(f"Used in other crews: {', '.join(used_in_crews)}")
            # Tasks outside this crew that use the agent
            external_tasks = [t for t in ss.tasks if t.agent and t.agent.id == agent.id and t.id not in [ct.id for ct in self.tasks]]
            if external_tasks:
                conflicts.append("Used in tasks outside this crew: " + ", ".join([t.description[:40] for t in external_tasks]))
            agents_info.append({'obj': agent, 'conflicts': conflicts})

        tasks_info = []
        for task in self.tasks:
            conflicts = []
            # Used in other crews
            used_in_crews = [c.name for c in other_crews if any(t.id == task.id for t in c.tasks)]
            if used_in_crews:
                conflicts.append(f"Shared with other crews: {', '.join(used_in_crews)}")
            # Referenced as context by tasks not being deleted
            ref_tasks = [rt for rt in context_refs.get(task.id, []) if rt.id not in [t.id for t in self.tasks]]
            if ref_tasks:
                conflicts.append("Referenced as context in other tasks: " + ", ".join([rt.description[:40] for rt in ref_tasks]))
            tasks_info.append({'obj': task, 'conflicts': conflicts})

        return {'agents': agents_info, 'tasks': tasks_info}

    def draw_delete_dialog(self):
        deps = self.analyze_dependencies()

        if not hasattr(st, 'dialog'):
            st.error("This Streamlit version does not support st.dialog â€“ please upgrade Streamlit.")
            return

        @st.dialog(f"Delete crew: {self.name}")
        def _dlg():
            st.markdown("### Confirm deleting entire crew")
            st.markdown("This action will delete the selected crew. You can optionally delete its agents and tasks.")
            st.markdown("If an item is used elsewhere it's marked as a conflict and unchecked by default.")

            st.markdown("#### Agents")
            for info in deps['agents']:
                agent = info['obj']
                conflict = len(info['conflicts']) > 0
                checkbox_key = f"del_agent_{agent.id}"
                label = f"Agent: {agent.role}"
                default_val = False if conflict else True
                st.checkbox(label, value=default_val if checkbox_key not in ss else ss[checkbox_key], key=checkbox_key, help=("Conflict: " + " | ".join(info['conflicts'])) if conflict else None)

            st.markdown("#### Tasks")
            for info in deps['tasks']:
                task = info['obj']
                conflict = len(info['conflicts']) > 0
                checkbox_key = f"del_task_{task.id}"
                label = f"Task: {task.description[:60]}"
                default_val = False if conflict else True
                st.checkbox(label, value=default_val if checkbox_key not in ss else ss[checkbox_key], key=checkbox_key, help=("Conflict: " + " | ".join(info['conflicts'])) if conflict else None)

            st.divider()
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                if st.button("Cancel"):
                    self.clear_delete_modal()
                    st.rerun()
            with col_b:
                if st.button("Delete crew only"):
                    self.delete()
                    self.clear_delete_modal()
                    st.rerun()
            with col_c:
                if st.button("Delete crew + selected items", type="primary"):
                    selected_agent_ids = [info['obj'].id for info in deps['agents'] if ss.get(f"del_agent_{info['obj'].id}")]
                    selected_task_ids = [info['obj'].id for info in deps['tasks'] if ss.get(f"del_task_{info['obj'].id}")]
                    if selected_task_ids:
                        ss.tasks = [t for t in ss.tasks if t.id not in selected_task_ids]
                        for crew in ss.crews:
                            original_len = len(crew.tasks)
                            crew.tasks = [t for t in crew.tasks if t.id not in selected_task_ids]
                            if len(crew.tasks) != original_len:
                                db_utils.save_crew(crew)
                        for tid in selected_task_ids:
                            db_utils.delete_task(tid)
                    if selected_agent_ids:
                        ss.agents = [a for a in ss.agents if a.id not in selected_agent_ids]
                        for crew in ss.crews:
                            orig_len = len(crew.agents)
                            crew.agents = [a for a in crew.agents if a.id not in selected_agent_ids]
                            if len(crew.agents) != orig_len:
                                db_utils.save_crew(crew)
                        for task in ss.tasks:
                            if task.agent and task.agent.id in selected_agent_ids:
                                task.agent = None
                                db_utils.save_task(task)
                        for aid in selected_agent_ids:
                            db_utils.delete_agent(aid)
                    self.delete()
                    self.clear_delete_modal()
                    st.rerun()

        _dlg()

--- app/my_knowledge_source.py ---
from datetime import datetime
from utils import rnd_id, fix_columns_width
from streamlit import session_state as ss
import streamlit as st
import os
import db_utils
from pathlib import Path  # Using Path for cross-platform path handling

class MyKnowledgeSource:
    def __init__(self, id=None, name=None, source_type=None, source_path=None, 
                content=None, metadata=None, chunk_size=None, chunk_overlap=None, 
                created_at=None):
        self.id = id or "KS_" + rnd_id()
        self.name = name or "Knowledge Source 1"
        self.source_type = source_type or "string"  # string, text_file, pdf, csv, excel, json, docling
        self.source_path = source_path or ""  # For file-based sources
        self.content = content or ""  # For string-based sources
        self.metadata = metadata or {}
        self.chunk_size = chunk_size or 4000
        self.chunk_overlap = chunk_overlap or 200
        self.created_at = created_at or datetime.now().isoformat()
        self.edit_key = f'edit_{self.id}'
        if self.edit_key not in ss:
            ss[self.edit_key] = False

    @property
    def edit(self):
        return ss[self.edit_key]

    @edit.setter
    def edit(self, value):
        ss[self.edit_key] = value

    def find_file(self, file_path):
        """
        Tries to find the file at various possible locations.
        Returns the correct path if found, or None if not found.
        """
        if not file_path:
            return None
        else: #simply check if the file exists in the folder knowledge
            if Path("knowledge", file_path).exists():
                return file_path
            else:
                return None

    def get_crewai_knowledge_source(self):
        # Import knowledge source classes based on type
        if self.source_type == "string":
            from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource
            return StringKnowledgeSource(
                content=self.content,
                metadata=self.metadata,
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
        elif self.source_type == "docling":
            from crewai.knowledge.source.crew_docling_source import CrewDoclingSource
            return CrewDoclingSource(
                file_paths=[self.source_path],
                metadata=self.metadata,
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            )
        else:
            # For file-based sources, find the actual file path
            actual_path = self.find_file(self.source_path)
            if not actual_path:
                raise FileNotFoundError(f"File not found: {self.source_path}")
                
            # Import the appropriate class based on source type
            if self.source_type == "text_file":
                from crewai.knowledge.source.text_file_knowledge_source import TextFileKnowledgeSource
                return TextFileKnowledgeSource(
                    file_paths=[actual_path],
                    metadata=self.metadata,
                    chunk_size=self.chunk_size,
                    chunk_overlap=self.chunk_overlap
                )
            elif self.source_type == "pdf":
                from crewai.knowledge.source.pdf_knowledge_source import PDFKnowledgeSource               
                return PDFKnowledgeSource(
                    file_paths=[actual_path],
                    metadata=self.metadata,
                    chunk_size=self.chunk_size,
                    chunk_overlap=self.chunk_overlap
                )
            elif self.source_type == "csv":
                from crewai.knowledge.source.csv_knowledge_source import CSVKnowledgeSource
                return CSVKnowledgeSource(
                    file_paths=[actual_path],
                    metadata=self.metadata,
                    chunk_size=self.chunk_size,
                    chunk_overlap=self.chunk_overlap
                )
            elif self.source_type == "excel":
                from crewai.knowledge.source.excel_knowledge_source import ExcelKnowledgeSource
                return ExcelKnowledgeSource(
                    file_paths=[actual_path],
                    metadata=self.metadata,
                    chunk_size=self.chunk_size,
                    chunk_overlap=self.chunk_overlap
                )
            elif self.source_type == "json":
                from crewai.knowledge.source.json_knowledge_source import JSONKnowledgeSource
                return JSONKnowledgeSource(
                    file_paths=[actual_path],
                    metadata=self.metadata,
                    chunk_size=self.chunk_size,
                    chunk_overlap=self.chunk_overlap
                )
            else:
                raise ValueError(f"Unsupported knowledge source type: {self.source_type}")

    def is_valid(self, show_warning=False):
        # Validate the knowledge source based on its type
        if self.source_type == "string" and not self.content:
            if show_warning:
                st.warning(f"Knowledge source {self.name} has no content")
            return False
        
        if self.source_type != "string" and self.source_type != "docling" and not self.source_path:
            if show_warning:
                st.warning(f"Knowledge source {self.name} has no source path")
            return False
            
        # For file-based sources, check if the file exists (except for docling URLs)
        if self.source_type != "string" and self.source_type != "docling":
            actual_path = self.find_file(self.source_path)
            if not actual_path:
                if show_warning:
                    st.warning(f"File not found: {self.source_path}")
                return False

            
        return True

    def delete(self):
        ss.knowledge_sources = [ks for ks in ss.knowledge_sources if ks.id != self.id]
        db_utils.delete_knowledge_source(self.id)

    def draw(self, key=None):
        source_types = {
            "string": "Text String",
            "text_file": "Text File (.txt)",
            "pdf": "PDF Document",
            "csv": "CSV File",
            "excel": "Excel File",
            "json": "JSON File",
            "docling": "DocLing (URL or file)"
        }
        
        # Create an ID for the upload field that includes both the knowledge source ID and type
        # This ensures the field is recreated when the type changes
        upload_field_id = f"uploader_{self.id}_{self.source_type}"
        
        if self.edit:
            # Use a container instead of an expander for the main form
            with st.container():
                st.subheader(f"Knowledge Source: {self.name}")
                
                # Name and type are outside the form to trigger immediate updates
                self.name = st.text_input("Name", value=self.name, key=f"name_{self.id}")
                
                prev_type = self.source_type
                self.source_type = st.selectbox(
                    "Source Type", 
                    options=list(source_types.keys()),
                    format_func=lambda x: source_types[x],
                    index=list(source_types.keys()).index(self.source_type),
                    key=f"type_{self.id}"
                )
                
                # If type changed, save immediately to trigger rerender
                if prev_type != self.source_type:
                    db_utils.save_knowledge_source(self)
                    st.rerun()
                
                # Create the form for the rest of the fields
                with st.form(key=f'form_{self.id}' if key is None else key):
                    if self.source_type == "string":
                        self.content = st.text_area("Content", value=self.content, height=200)
                    else:
                        self.source_path = st.text_input(
                            "Source Path", 
                            value=self.source_path,
                            help="Enter file path relative to the 'knowledge' directory or a URL for docling"
                        )
                        
                        # File uploader for local files
                        if self.source_type != "docling":
                            # Define file types for the uploader based on source type
                            upload_types = {
                                "text_file": "txt", 
                                "pdf": "pdf", 
                                "csv": "csv", 
                                "excel": ["xlsx", "xls"], 
                                "json": "json"
                            }
                            
                            file_type = upload_types.get(self.source_type)
                            if file_type:
                                uploaded_file = st.file_uploader(
                                    f"Upload {source_types[self.source_type]}", 
                                    type=file_type,
                                    key=upload_field_id
                                )
                                
                                if uploaded_file is not None:
                                    # Create knowledge directory if it doesn't exist
                                    os.makedirs("knowledge", exist_ok=True)
                                    
                                    # Save the uploaded file to the knowledge directory
                                    file_name = uploaded_file.name                                   
                                    file_path = os.path.join("knowledge", file_name)
                                    
                                    with open(file_path, "wb") as f:
                                        f.write(uploaded_file.getbuffer())
                                    
                                    # Set the source path to just the filename with knowledge prefix
                                    self.source_path = file_name
                    
                    # Advanced settings
                    st.subheader("Advanced Settings")
                    
                    # Chunk configuration
                    col1, col2 = st.columns(2)
                    with col1:
                        self.chunk_size = st.number_input(
                            "Chunk Size", 
                            value=self.chunk_size,
                            min_value=100,
                            max_value=8000,
                            help="Maximum size of each chunk (default: 4000)"
                        )
                    with col2:
                        self.chunk_overlap = st.number_input(
                            "Chunk Overlap", 
                            value=self.chunk_overlap,
                            min_value=0,
                            max_value=1000,
                            help="Overlap between chunks (default: 200)"
                        )
                    
                    # Metadata section
                    st.subheader("Metadata (optional)")
                    col1, col2 = st.columns([3, 1])
                    with col1:
                        metadata_key = st.text_input("Key", key=f"metadata_key_{self.id}")
                        metadata_value = st.text_input("Value", key=f"metadata_value_{self.id}")
                    with col2:
                        add_metadata = st.form_submit_button("Add Metadata")
                        if add_metadata and metadata_key:
                            self.metadata[metadata_key] = metadata_value
                            st.rerun()
                    
                    # Display current metadata
                    if self.metadata:
                        st.write("Current Metadata:")
                        for key, value in dict(self.metadata).items():
                            col1, col2, col3 = st.columns([3, 3, 1])
                            with col1:
                                st.text(key)
                            with col2:
                                st.text(value)
                            with col3:
                                remove_key = st.form_submit_button(f"Remove {key[:6]}...")
                                if remove_key:
                                    self.metadata.pop(key)
                                    st.rerun()
                    
                    # Save button for the entire form
                    submitted = st.form_submit_button("Save Knowledge Source")
                    if submitted:
                        db_utils.save_knowledge_source(self)
                        self.set_editable(False)
        else:
            fix_columns_width()
            source_name = f"{self.name}" if self.is_valid() else f"â— {self.name}"
            with st.expander(source_name, expanded=False):
                st.markdown(f"**Name:** {self.name}")
                st.markdown(f"**Type:** {source_types[self.source_type]}")
                
                if self.source_type == "string":
                    preview = self.content[:100] + "..." if len(self.content) > 100 else self.content
                    st.markdown(f"**Content Preview:** {preview}")
                else:
                    st.markdown(f"**Source Path:** {self.source_path}")
                
                st.markdown(f"**Chunk Size:** {self.chunk_size}")
                st.markdown(f"**Chunk Overlap:** {self.chunk_overlap}")
                
                if self.metadata:
                    st.markdown("**Metadata:**")
                    for key, value in self.metadata.items():
                        st.markdown(f"- {key}: {value}")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.button("Edit", on_click=self.set_editable, args=(True,), key=rnd_id())
                with col2:
                    st.button("Delete", on_click=self.delete, key=rnd_id())
                
                self.is_valid(show_warning=True)

    def set_editable(self, edit):
        self.edit = edit
        db_utils.save_knowledge_source(self)
        if not edit:
            st.rerun()

--- app/my_task.py ---
from crewai import Task
import streamlit as st
from utils import rnd_id, fix_columns_width
from streamlit import session_state as ss
from db_utils import save_task, delete_task
from datetime import datetime

class MyTask:
    def __init__(self, id=None, description=None, expected_output=None, agent=None, async_execution=None, created_at=None, context_from_async_tasks_ids=None, context_from_sync_tasks_ids=None, **kwargs):
        self.id = id or "T_" + rnd_id()
        self.description = description or "Identify the next big trend in AI. Focus on identifying pros and cons and the overall narrative."
        self.expected_output = expected_output or "A comprehensive 3 paragraphs long report on the latest AI trends."
        self.agent = agent or ss.agents[0] if ss.agents else None
        self.async_execution = async_execution or False
        self.context_from_async_tasks_ids = context_from_async_tasks_ids or None
        self.context_from_sync_tasks_ids = context_from_sync_tasks_ids or None
        self.created_at = created_at or datetime.now().isoformat()
        self.edit_key = f'edit_{self.id}'
        if self.edit_key not in ss:
            ss[self.edit_key] = False

    @property
    def edit(self):
        return ss[self.edit_key]

    @edit.setter
    def edit(self, value):
        ss[self.edit_key] = value

    def get_crewai_task(self, context_from_async_tasks=None, context_from_sync_tasks=None) -> Task:
        context = []
        if context_from_async_tasks:
            context.extend(context_from_async_tasks)
        if context_from_sync_tasks:
            context.extend(context_from_sync_tasks)
        
        if context:
            return Task(description=self.description, expected_output=self.expected_output, async_execution=self.async_execution, agent=self.agent.get_crewai_agent(), context=context)
        else:
            return Task(description=self.description, expected_output=self.expected_output, async_execution=self.async_execution, agent=self.agent.get_crewai_agent())

    def delete(self):
        ss.tasks = [task for task in ss.tasks if task.id != self.id]
        delete_task(self.id)

    def is_valid(self, show_warning=False):
        if not self.agent:
            if show_warning:
                st.warning(f"Task {self.description} has no agent")
            return False
        if not self.agent.is_valid(show_warning):
            return False
        return True

    def draw(self, key=None):
        agent_options = [agent.role for agent in ss.agents]
        expander_title = f"({self.agent.role if self.agent else 'unassigned'}) - {self.description}" if self.is_valid() else f"â— ({self.agent.role if self.agent else 'unassigned'}) - {self.description}"
        if self.edit:
            with st.expander(expander_title, expanded=True):
                with st.form(key=f'form_{self.id}' if key is None else key):
                    self.description = st.text_area("Description", value=self.description)
                    self.expected_output = st.text_area("Expected output", value=self.expected_output)
                    self.agent = st.selectbox("Agent", options=ss.agents, format_func=lambda x: x.role, index=0 if self.agent is None else agent_options.index(self.agent.role))
                    self.async_execution = st.checkbox("Async execution", value=self.async_execution)
                    self.context_from_async_tasks_ids = st.multiselect("Context from async tasks", options=[task.id for task in ss.tasks if task.async_execution], default=self.context_from_async_tasks_ids, format_func=lambda x: [task.description[:120] for task in ss.tasks if task.id == x][0])
                    self.context_from_sync_tasks_ids = st.multiselect("Context from sync tasks", options=[task.id for task in ss.tasks if not task.async_execution], default=self.context_from_sync_tasks_ids, format_func=lambda x: [task.description[:120] for task in ss.tasks if task.id == x][0])
                    submitted = st.form_submit_button("Save")
                    if submitted:
                        self.set_editable(False)
        else:
            fix_columns_width()
            with st.expander(expander_title):
                st.markdown(f"**Description:** {self.description}")
                st.markdown(f"**Expected output:** {self.expected_output}")
                st.markdown(f"**Agent:** {self.agent.role if self.agent else 'None'}")
                st.markdown(f"**Async execution:** {self.async_execution}")
                st.markdown(f"**Context from async tasks:** {', '.join([task.description[:120] for task in ss.tasks if task.id in self.context_from_async_tasks_ids]) if self.context_from_async_tasks_ids else 'None'}")
                st.markdown(f"**Context from sync tasks:** {', '.join([task.description[:120] for task in ss.tasks if task.id in self.context_from_sync_tasks_ids]) if self.context_from_sync_tasks_ids else 'None'}")
                col1, col2 = st.columns(2)
                with col1:
                    st.button("Edit", on_click=self.set_editable, args=(True,), key=rnd_id())
                with col2:
                    st.button("Delete", on_click=self.delete, key=rnd_id())
                self.is_valid(show_warning=True)

    def set_editable(self, edit):
        self.edit = edit
        save_task(self)
        if not edit:
            st.rerun()

--- app/my_tools.py ---
import streamlit as st
import os
from utils import rnd_id
from crewai_tools import CodeInterpreterTool,ScrapeElementFromWebsiteTool,TXTSearchTool,SeleniumScrapingTool,PDFSearchTool,MDXSearchTool,JSONSearchTool,GithubSearchTool,EXASearchTool,DOCXSearchTool,CSVSearchTool,ScrapeWebsiteTool, FileReadTool, DirectorySearchTool, DirectoryReadTool, CodeDocsSearchTool, YoutubeVideoSearchTool,SerperDevTool,YoutubeChannelSearchTool,WebsiteSearchTool
from tools.CSVSearchToolEnhanced import CSVSearchToolEnhanced
from tools.CustomApiTool import CustomApiTool
from tools.CustomCodeInterpreterTool import CustomCodeInterpreterTool
from tools.CustomFileWriteTool import CustomFileWriteTool
from tools.ScrapeWebsiteToolEnhanced import ScrapeWebsiteToolEnhanced
from tools.ScrapflyScrapeWebsiteTool import ScrapflyScrapeWebsiteTool

from tools.DuckDuckGoSearchTool import DuckDuckGoSearchTool

from langchain_community.tools import YahooFinanceNewsTool

class MyTool:
    def __init__(self, tool_id, name, description, parameters, **kwargs):
        self.tool_id = tool_id or rnd_id()
        self.name = name
        self.description = description
        self.parameters = kwargs
        self.parameters_metadata = parameters

    def create_tool(self):
        pass

    def get_parameters(self):
        return self.parameters

    def set_parameters(self, **kwargs):
        self.parameters.update(kwargs)

    def get_parameter_names(self):
        return list(self.parameters_metadata.keys())

    def is_parameter_mandatory(self, param_name):
        return self.parameters_metadata.get(param_name, {}).get('mandatory', False)

    def is_valid(self,show_warning=False):
        for param_name, metadata in self.parameters_metadata.items():
            if metadata['mandatory'] and not self.parameters.get(param_name):
                if show_warning:
                    st.warning(f"Parameter '{param_name}' is mandatory for tool '{self.name}'")
                return False
        return True

class MyScrapeWebsiteTool(MyTool):
    def __init__(self, tool_id=None, website_url=None):
        parameters = {
            'website_url': {'mandatory': False}
        }
        super().__init__(tool_id, 'ScrapeWebsiteTool', "A tool that can be used to read website content.", parameters, website_url=website_url)

    def create_tool(self) -> ScrapeWebsiteTool:
        return ScrapeWebsiteTool(self.parameters.get('website_url') if self.parameters.get('website_url') else None)

class MyFileReadTool(MyTool):
    def __init__(self, tool_id=None, file_path=None):
        parameters = {
            'file_path': {'mandatory': False}
        }
        super().__init__(tool_id, 'FileReadTool', "A tool that can be used to read a file's content.", parameters, file_path=file_path)

    def create_tool(self) -> FileReadTool:
        return FileReadTool(self.parameters.get('file_path') if self.parameters.get('file_path') else None)

class MyDirectorySearchTool(MyTool):
    def __init__(self, tool_id=None, directory=None):
        parameters = {
            'directory': {'mandatory': False}
        }
        super().__init__(tool_id, 'DirectorySearchTool', "A tool that can be used to semantic search a query from a directory's content.", parameters, directory_path=directory)

    def create_tool(self) -> DirectorySearchTool:
        return DirectorySearchTool(self.parameters.get('directory') if self.parameters.get('directory') else None)

class MyDirectoryReadTool(MyTool):
    def __init__(self, tool_id=None, directory_contents=None):
        parameters = {
            'directory_contents': {'mandatory': True}
        }
        super().__init__(tool_id, 'DirectoryReadTool', "Use the tool to list the contents of the specified directory", parameters, directory_contents=directory_contents)

    def create_tool(self) -> DirectoryReadTool:
        return DirectoryReadTool(self.parameters.get('directory_contents'))

class MyCodeDocsSearchTool(MyTool):
    def __init__(self, tool_id=None, code_docs=None):
        parameters = {
            'code_docs': {'mandatory': False}
        }
        super().__init__(tool_id, 'CodeDocsSearchTool', "A tool that can be used to search through code documentation.", parameters, code_docs=code_docs)

    def create_tool(self) -> CodeDocsSearchTool:
        return CodeDocsSearchTool(self.parameters.get('code_docs') if self.parameters.get('code_docs') else None)

class MyYoutubeVideoSearchTool(MyTool):
    def __init__(self, tool_id=None, youtube_video_url=None):
        parameters = {
            'youtube_video_url': {'mandatory': False}
        }
        super().__init__(tool_id, 'YoutubeVideoSearchTool', "A tool that can be used to semantic search a query from a Youtube Video content.", parameters, youtube_video_url=youtube_video_url)

    def create_tool(self) -> YoutubeVideoSearchTool:
        return YoutubeVideoSearchTool(self.parameters.get('youtube_video_url') if self.parameters.get('youtube_video_url') else None)

class MySerperDevTool(MyTool):
    def __init__(self, tool_id=None, SERPER_API_KEY=None):
        parameters = {
            'SERPER_API_KEY': {'mandatory': True}
        }

        super().__init__(tool_id, 'SerperDevTool', "A tool that can be used to search the internet with a search_query", parameters)

    def create_tool(self) -> SerperDevTool:
        os.environ['SERPER_API_KEY'] = self.parameters.get('SERPER_API_KEY')
        return SerperDevTool()
    
class MyYoutubeChannelSearchTool(MyTool):
    def __init__(self, tool_id=None, youtube_channel_handle=None):
        parameters = {
            'youtube_channel_handle': {'mandatory': False}
        }
        super().__init__(tool_id, 'YoutubeChannelSearchTool', "A tool that can be used to semantic search a query from a Youtube Channels content. Channel can be added as @channel", parameters, youtube_channel_handle=youtube_channel_handle)

    def create_tool(self) -> YoutubeChannelSearchTool:
        return YoutubeChannelSearchTool(self.parameters.get('youtube_channel_handle') if self.parameters.get('youtube_channel_handle') else None)

class MyWebsiteSearchTool(MyTool):
    def __init__(self, tool_id=None, website=None):
        parameters = {
            'website': {'mandatory': False}
        }
        super().__init__(tool_id, 'WebsiteSearchTool', "A tool that can be used to semantic search a query from a specific URL content.", parameters, website=website)

    def create_tool(self) -> WebsiteSearchTool:
        return WebsiteSearchTool(self.parameters.get('website') if self.parameters.get('website') else None)
   
class MyCSVSearchTool(MyTool):
    def __init__(self, tool_id=None, csv=None):
        parameters = {
            'csv': {'mandatory': False}
        }
        super().__init__(tool_id, 'CSVSearchTool', "A tool that can be used to semantic search a query from a CSV's content.", parameters, csv=csv)

    def create_tool(self) -> CSVSearchTool:
        return CSVSearchTool(csv=self.parameters.get('csv') if self.parameters.get('csv') else None)

class MyDocxSearchTool(MyTool):
    def __init__(self, tool_id=None, docx=None):
        parameters = {
            'docx': {'mandatory': False}
        }
        super().__init__(tool_id, 'DOCXSearchTool', "A tool that can be used to semantic search a query from a DOCX's content.", parameters, docx=docx)

    def create_tool(self) -> DOCXSearchTool:
        return DOCXSearchTool(docx=self.parameters.get('docx') if self.parameters.get('docx') else None)

class MyEXASearchTool(MyTool):
    def __init__(self, tool_id=None, EXA_API_KEY=None):
        parameters = {
            'EXA_API_KEY': {'mandatory': True}
        }
        super().__init__(tool_id, 'EXASearchTool', "A tool that can be used to search the internet from a search_query", parameters, EXA_API_KEY=EXA_API_KEY)

    def create_tool(self) -> EXASearchTool:
        os.environ['EXA_API_KEY'] = self.parameters.get('EXA_API_KEY')
        return EXASearchTool()

class MyGithubSearchTool(MyTool):
    def __init__(self, tool_id=None, github_repo=None, gh_token=None, content_types=None):
        parameters = {
            'github_repo': {'mandatory': False},
            'gh_token': {'mandatory': True},
            'content_types': {'mandatory': False}
        }
        super().__init__(tool_id, 'GithubSearchTool', "A tool that can be used to semantic search a query from a Github repository's content. Valid content_types: code,repo,pr,issue (comma sepparated)", parameters, github_repo=github_repo, gh_token=gh_token, content_types=content_types)

    def create_tool(self) -> GithubSearchTool:
        return GithubSearchTool(
            github_repo=self.parameters.get('github_repo') if self.parameters.get('github_repo') else None,
            gh_token=self.parameters.get('gh_token'),
            content_types=self.parameters.get('search_query').split(",") if self.parameters.get('search_query') else ["code", "repo", "pr", "issue"]
        )

class MyJSONSearchTool(MyTool):
    def __init__(self, tool_id=None, json_path=None):
        parameters = {
            'json_path': {'mandatory': False}
        }
        super().__init__(tool_id, 'JSONSearchTool', "A tool that can be used to semantic search a query from a JSON's content.", parameters, json_path=json_path)

    def create_tool(self) -> JSONSearchTool:
        return JSONSearchTool(json_path=self.parameters.get('json_path') if self.parameters.get('json_path') else None)

class MyMDXSearchTool(MyTool):
    def __init__(self, tool_id=None, mdx=None):
        parameters = {
            'mdx': {'mandatory': False}
        }
        super().__init__(tool_id, 'MDXSearchTool', "A tool that can be used to semantic search a query from a MDX's content.", parameters, mdx=mdx)

    def create_tool(self) -> MDXSearchTool:
        return MDXSearchTool(mdx=self.parameters.get('mdx') if self.parameters.get('mdx') else None)
    
class MyPDFSearchTool(MyTool):
    def __init__(self, tool_id=None, pdf=None):
        parameters = {
            'pdf': {'mandatory': False}
        }
        super().__init__(tool_id, 'PDFSearchTool', "A tool that can be used to semantic search a query from a PDF's content.", parameters, pdf=pdf)

    def create_tool(self) -> PDFSearchTool:
        return PDFSearchTool(self.parameters.get('pdf') if self.parameters.get('pdf') else None)

class MySeleniumScrapingTool(MyTool):
    def __init__(self, tool_id=None, website_url=None, css_element=None, cookie=None, wait_time=None):
        parameters = {
            'website_url': {'mandatory': False},
            'css_element': {'mandatory': False},
            'cookie': {'mandatory': False},
            'wait_time': {'mandatory': False}
        }
        super().__init__(
            tool_id, 
            'SeleniumScrapingTool', 
            r"A tool that can be used to read a specific part of website content. CSS elements are separated by comma, cookies are in format {key1\:value1},{key2\:value2}", 
            parameters, 
            website_url=website_url, 
            css_element=css_element, 
            cookie=cookie, 
            wait_time=wait_time
)
    def create_tool(self) -> SeleniumScrapingTool:
        cookie_arrayofdicts = [{k: v} for k, v in (item.strip('{}').split(':') for item in self.parameters.get('cookie', '').split(','))] if self.parameters.get('cookie') else None

        return SeleniumScrapingTool(
            website_url=self.parameters.get('website_url') if self.parameters.get('website_url') else None,
            css_element=self.parameters.get('css_element').split(',') if self.parameters.get('css_element') else None,
            cookie=cookie_arrayofdicts,
            wait_time=self.parameters.get('wait_time') if self.parameters.get('wait_time') else 10
        )

class MyTXTSearchTool(MyTool):
    def __init__(self, tool_id=None, txt=None):
        parameters = {
            'txt': {'mandatory': False}
        }
        super().__init__(tool_id, 'TXTSearchTool', "A tool that can be used to semantic search a query from a TXT's content.", parameters, txt=txt)

    def create_tool(self) -> TXTSearchTool:
        return TXTSearchTool(self.parameters.get('txt'))

class MyScrapeElementFromWebsiteTool(MyTool):
    def __init__(self, tool_id=None, website_url=None, css_element=None, cookie=None):
        parameters = {
            'website_url': {'mandatory': False},
            'css_element': {'mandatory': False},
            'cookie': {'mandatory': False}
        }
        super().__init__(
            tool_id, 
            'ScrapeElementFromWebsiteTool', 
            r"A tool that can be used to read a specific part of website content. CSS elements are separated by comma, cookies are in format {key1\:value1},{key2\:value2}", 
            parameters, 
            website_url=website_url, 
            css_element=css_element, 
            cookie=cookie
        )

    def create_tool(self) -> ScrapeElementFromWebsiteTool:
        cookie_arrayofdicts = [{k: v} for k, v in (item.strip('{}').split(':') for item in self.parameters.get('cookie', '').split(','))] if self.parameters.get('cookie') else None
        return ScrapeElementFromWebsiteTool(
            website_url=self.parameters.get('website_url') if self.parameters.get('website_url') else None,
            css_element=self.parameters.get('css_element').split(",") if self.parameters.get('css_element') else None,
            cookie=cookie_arrayofdicts
        )
    
class MyYahooFinanceNewsTool(MyTool):
    def __init__(self, tool_id=None):
        parameters = {}
        super().__init__(tool_id, 'YahooFinanceNewsTool', "A tool that can be used to search Yahoo Finance News.", parameters)

    def create_tool(self) -> YahooFinanceNewsTool:
        return YahooFinanceNewsTool()
    
class MyCustomApiTool(MyTool):
    def __init__(self, tool_id=None, base_url=None, headers=None, query_params=None):
        parameters = {
            'base_url': {'mandatory': False},
            'headers': {'mandatory': False},
            'query_params': {'mandatory': False}
        }
        super().__init__(tool_id, 'CustomApiTool', "A tool that can be used to make API calls with customizable parameters.", parameters, base_url=base_url, headers=headers, query_params=query_params)

    def create_tool(self) -> CustomApiTool:
        return CustomApiTool(
            base_url=self.parameters.get('base_url') if self.parameters.get('base_url') else None,
            headers=eval(self.parameters.get('headers')) if self.parameters.get('headers') else None,
            query_params=self.parameters.get('query_params') if self.parameters.get('query_params') else None
        )

class MyCustomFileWriteTool(MyTool):
    def __init__(self, tool_id=None, base_folder=None, filename=None):
        parameters = {
            'base_folder': {'mandatory': True},
            'filename': {'mandatory': False}
        }
        super().__init__(tool_id, 'CustomFileWriteTool', "A tool that can be used to write a file to a specific folder.", parameters,base_folder=base_folder, filename=filename)

    def create_tool(self) -> CustomFileWriteTool:
        return CustomFileWriteTool(
            base_folder=self.parameters.get('base_folder') if self.parameters.get('base_folder') else "workspace",
            filename=self.parameters.get('filename') if self.parameters.get('filename') else None
        )


class MyDuckDuckGoSearchTool(MyTool):
    def __init__(self, tool_id=None):
        parameters = {}
        super().__init__(tool_id, 'DuckDuckGoSearchTool', "A tool to search the web using DuckDuckGo engine.", parameters)

    def create_tool(self) -> DuckDuckGoSearchTool:
        return DuckDuckGoSearchTool()


class MyCodeInterpreterTool(MyTool):
    def __init__(self, tool_id=None):
        parameters = {}
        super().__init__(tool_id, 'CodeInterpreterTool', "This tool is used to give the Agent the ability to run code (Python3) from the code generated by the Agent itself. The code is executed in a sandboxed environment, so it is safe to run any code. Docker required.", parameters)

    def create_tool(self) -> CodeInterpreterTool:
        return CodeInterpreterTool()
    

class MyCustomCodeInterpreterTool(MyTool):
    def __init__(self, tool_id=None,workspace_dir=None):
        parameters = {
            'workspace_dir': {'mandatory': False}
        }
        super().__init__(tool_id, 'CustomCodeInterpreterTool', "This tool is used to give the Agent the ability to run code (Python3) from the code generated by the Agent itself. The code is executed in a sandboxed environment, so it is safe to run any code. Worskpace folder is shared. Docker required.", parameters, workspace_dir=workspace_dir)

    def create_tool(self) -> CustomCodeInterpreterTool:
        return CustomCodeInterpreterTool(workspace_dir=self.parameters.get('workspace_dir') if self.parameters.get('workspace_dir') else "workspace")

class MyCSVSearchToolEnhanced(MyTool):
    def __init__(self, tool_id=None, csv=None):
        parameters = {
            'csv': {'mandatory': False}
        }
        super().__init__(tool_id, 'CSVSearchToolEnhanced', "A tool that can be used to semantic search a query from a CSV's content.", parameters, csv=csv)

    def create_tool(self) -> CSVSearchToolEnhanced:
        return CSVSearchToolEnhanced(csv=self.parameters.get('csv') if self.parameters.get('csv') else None)
    
class MyScrapeWebsiteToolEnhanced(MyTool):
    def __init__(self, tool_id=None, website_url=None, cookies=None, show_urls=None, css_selector=None):
        parameters = {
            'website_url': {'mandatory': False},
            'cookies': {'mandatory': False},
            'show_urls': {'mandatory': False},
            'css_selector': {'mandatory': False}
        }
        super().__init__(tool_id, 'ScrapeWebsiteToolEnhanced', "An enhanced tool that can be used to read website content.", parameters, website_url=website_url, cookies=cookies, show_urls=show_urls, css_selector=css_selector)

    def create_tool(self) -> ScrapeWebsiteToolEnhanced:
        return ScrapeWebsiteToolEnhanced(
            website_url=self.parameters.get('website_url') if self.parameters.get('website_url') else None,
            cookies=self.parameters.get('cookies') if self.parameters.get('cookies') else None,
            show_urls=self.parameters.get('show_urls') if self.parameters.get('show_urls') else False,
            css_selector=self.parameters.get('css_selector') if self.parameters.get('css_selector') else None
        )

class MyScrapflyScrapeWebsiteTool(MyTool):
    def __init__(self, tool_id=None, api_key=None):
        parameters = {
            'api_key': {'mandatory': False}
        }
        super().__init__(tool_id, 'ScrapflyScrapeWebsiteTool', "A tool that uses Scrapfly API to scrape websites with advanced features like headless browser support, proxies, and anti-bot bypass.", parameters, api_key=api_key)

    def create_tool(self) -> ScrapflyScrapeWebsiteTool:
        api_key = self.parameters.get('api_key') or os.getenv('SCRAPFLY_API_KEY')
        if not api_key:
            raise ValueError("Scrapfly API key not provided and not set in .env file (SCRAPFLY_API_KEY)")
        return ScrapflyScrapeWebsiteTool(
            api_key=api_key
        )

# Register all tools here
TOOL_CLASSES = {
    'DuckDuckGoSearchTool': MyDuckDuckGoSearchTool,
    'SerperDevTool': MySerperDevTool,
    'WebsiteSearchTool': MyWebsiteSearchTool,
    'ScrapeWebsiteTool': MyScrapeWebsiteTool,
    'ScrapeWebsiteToolEnhanced': MyScrapeWebsiteToolEnhanced,
    'ScrapflyScrapeWebsiteTool': MyScrapflyScrapeWebsiteTool,
    
    'SeleniumScrapingTool': MySeleniumScrapingTool,
    'ScrapeElementFromWebsiteTool': MyScrapeElementFromWebsiteTool,
    'CustomApiTool': MyCustomApiTool,
    'CodeInterpreterTool': MyCodeInterpreterTool,
    'CustomCodeInterpreterTool': MyCustomCodeInterpreterTool,
    'FileReadTool': MyFileReadTool,
    'CustomFileWriteTool': MyCustomFileWriteTool,
    'DirectorySearchTool': MyDirectorySearchTool,
    'DirectoryReadTool': MyDirectoryReadTool,

    'YoutubeVideoSearchTool': MyYoutubeVideoSearchTool,
    'YoutubeChannelSearchTool' :MyYoutubeChannelSearchTool,
    'GithubSearchTool': MyGithubSearchTool,
    'CodeDocsSearchTool': MyCodeDocsSearchTool,
    'YahooFinanceNewsTool': MyYahooFinanceNewsTool,

    'TXTSearchTool': MyTXTSearchTool,
    'CSVSearchTool': MyCSVSearchTool,
    'CSVSearchToolEnhanced': MyCSVSearchToolEnhanced,
    'DOCXSearchTool': MyDocxSearchTool, 
    'EXASearchTool': MyEXASearchTool,
    'JSONSearchTool': MyJSONSearchTool,
    'MDXSearchTool': MyMDXSearchTool,
    'PDFSearchTool': MyPDFSearchTool
}

--- app/pg_agents.py ---
import streamlit as st
from streamlit import session_state as ss
from my_agent import MyAgent
import db_utils

class PageAgents:
    def __init__(self):
        self.name = "Agents"

    def create_agent(self, crew=None):
        agent = MyAgent()
        if 'agents' not in ss:
            ss.agents = [MyAgent]
        ss.agents.append(agent)
        agent.edit = True
        db_utils.save_agent(agent)  # Save agent to database

        if crew:
            crew.agents.append(agent)
            db_utils.save_crew(crew)

        return agent

    def draw(self):
        with st.container():
            st.subheader(self.name)
            editing = False
            if 'agents' not in ss:
                ss.agents = db_utils.load_agents()  # Load agents from database
            if 'crews' not in ss:
                ss.crews = db_utils.load_crews()  # Load crews from database

            # Dictionary to track agent assignment
            agent_assignment = {agent.id: [] for agent in ss.agents}

            # Assign agents to crews
            for crew in ss.crews:
                for agent in crew.agents:
                    agent_assignment[agent.id].append(crew.name)

            # Display agents grouped by crew in tabs
            tabs = ["All Agents"] + ["Unassigned Agents"] + [crew.name for crew in ss.crews]
            tab_objects = st.tabs(tabs)

            # Display all agents
            with tab_objects[0]:
                st.markdown("#### All Agents")
                for agent in ss.agents:
                    agent.draw()
                    if agent.edit:
                        editing = True
                st.button('Create agent', on_click=self.create_agent, disabled=editing, key="create_agent_all")

            # Display unassigned agents
            with tab_objects[1]:
                st.markdown("#### Unassigned Agents")
                unassigned_agents = [agent for agent in ss.agents if not agent_assignment[agent.id]]
                for agent in unassigned_agents:
                    unique_key = f"{agent.id}_unassigned"
                    agent.draw(key=unique_key)
                    if agent.edit:
                        editing = True
                st.button('Create agent', on_click=self.create_agent, disabled=editing, key="create_agent_unassigned")

            # Display agents grouped by crew
            for i, crew in enumerate(ss.crews, 2):
                with tab_objects[i]:
                    st.markdown(f"#### {crew.name}")
                    assigned_agents = [agent for agent in crew.agents]
                    for agent in assigned_agents:
                        unique_key = f"{agent.id}_{crew.name}"
                        agent.draw(key=unique_key)
                        if agent.edit:
                            editing = True
                    st.button('Create agent', on_click=self.create_agent, disabled=editing, kwargs={'crew': crew}, key=f"create_agent_{crew.name}")

            if len(ss.agents) == 0:
                st.write("No agents defined yet.")
                st.button('Create agent', on_click=self.create_agent, disabled=editing)
