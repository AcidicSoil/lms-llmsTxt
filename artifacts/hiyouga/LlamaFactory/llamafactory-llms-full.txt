# llms-full (private-aware)
> Built from GitHub files and website pages. Large files may be truncated.

--- examples/README.md ---
We provide diverse examples about fine-tuning LLMs.

Make sure to execute these commands in the `LLaMA-Factory` directory.

## Table of Contents

- [LoRA Fine-Tuning](#lora-fine-tuning)
- [QLoRA Fine-Tuning](#qlora-fine-tuning)
- [Full-Parameter Fine-Tuning](#full-parameter-fine-tuning)
- [Merging LoRA Adapters and Quantization](#merging-lora-adapters-and-quantization)
- [Inferring LoRA Fine-Tuned Models](#inferring-lora-fine-tuned-models)
- [Extras](#extras)

Use `CUDA_VISIBLE_DEVICES` (GPU) or `ASCEND_RT_VISIBLE_DEVICES` (NPU) to choose computing devices.

By default, LLaMA-Factory uses all visible computing devices.

Basic usage:

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml
```

Advanced usage:

```bash
CUDA_VISIBLE_DEVICES=0,1 llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml \
    learning_rate=1e-5 \
    logging_steps=1
```

```bash
bash examples/train_lora/qwen3_lora_sft.sh
```

## Examples

### LoRA Fine-Tuning

#### (Continuous) Pre-Training

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_pretrain.yaml
```

#### Supervised Fine-Tuning

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml
```

#### Multimodal Supervised Fine-Tuning

```bash
llamafactory-cli train examples/train_lora/qwen3vl_lora_sft.yaml
```

#### DPO/ORPO/SimPO Training

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_dpo.yaml
```

#### Multimodal DPO/ORPO/SimPO Training

```bash
llamafactory-cli train examples/train_lora/qwen3vl_lora_dpo.yaml
```

#### Reward Modeling

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_reward.yaml
```

#### KTO Training

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_kto.yaml
```

#### Preprocess Dataset

It is useful for large dataset, use `tokenized_path` in config to load the preprocessed dataset.

```bash
llamafactory-cli train examples/train_lora/qwen3_preprocess.yaml
```

#### Supervised Fine-Tuning on Multiple Nodes

```bash
FORCE_TORCHRUN=1 NNODES=2 NODE_RANK=0 MASTER_ADDR=192.168.0.1 MASTER_PORT=29500 llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml
FORCE_TORCHRUN=1 NNODES=2 NODE_RANK=1 MASTER_ADDR=192.168.0.1 MASTER_PORT=29500 llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml
```

#### Supervised Fine-Tuning with DeepSpeed ZeRO-3 (Weight Sharding)

```bash
FORCE_TORCHRUN=1 llamafactory-cli train examples/train_lora/qwen3_lora_sft_ds3.yaml
```

#### Supervised Fine-Tuning with Ray on 4 GPUs

```bash
USE_RAY=1 llamafactory-cli train examples/train_lora/qwen3_lora_sft_ray.yaml
```

### QLoRA Fine-Tuning

#### Supervised Fine-Tuning with 4/8-bit Bitsandbytes/HQQ/EETQ Quantization (Recommended)

```bash
llamafactory-cli train examples/train_qlora/qwen3_lora_sft_otfq.yaml
```

#### Supervised Fine-Tuning with 4-bit Bitsandbytes Quantization on Ascend NPU

```bash
llamafactory-cli train examples/train_qlora/qwen3_lora_sft_bnb_npu.yaml
```

#### Supervised Fine-Tuning with 4/8-bit GPTQ Quantization

```bash
llamafactory-cli train examples/train_qlora/llama3_lora_sft_gptq.yaml
```

#### Supervised Fine-Tuning with 4-bit AWQ Quantization

```bash
llamafactory-cli train examples/train_qlora/llama3_lora_sft_awq.yaml
```

#### Supervised Fine-Tuning with 2-bit AQLM Quantization

```bash
llamafactory-cli train examples/train_qlora/llama3_lora_sft_aqlm.yaml
```

### Full-Parameter Fine-Tuning

#### Supervised Fine-Tuning on Single Node

```bash
FORCE_TORCHRUN=1 llamafactory-cli train examples/train_full/qwen3_full_sft.yaml
```

#### Supervised Fine-Tuning on Multiple Nodes

```bash
FORCE_TORCHRUN=1 NNODES=2 NODE_RANK=0 MASTER_ADDR=192.168.0.1 MASTER_PORT=29500 llamafactory-cli train examples/train_full/qwen3_full_sft.yaml
FORCE_TORCHRUN=1 NNODES=2 NODE_RANK=1 MASTER_ADDR=192.168.0.1 MASTER_PORT=29500 llamafactory-cli train examples/train_full/qwen3_full_sft.yaml
```

### Elastic and Fault-Tolerant Supervised Fine-Tuning on Multiple Nodes

To launch an elastic job with `MAX_RESTARTS` failures retries, run the following on at least `MIN_NNODES` nodes and at most `MAX_NNODES` nodes. `RDZV_ID` should be set as a unique job id (shared by all nodes participating in the job). See also [torchrun](https://docs.pytorch.org/docs/stable/elastic/run.html).

```bash
FORCE_TORCHRUN=1 MIN_NNODES=1 MAX_NNODES=3 MAX_RESTARTS=3 RDZV_ID=llamafactory MASTER_ADDR=192.168.0.1 MASTER_PORT=29500 llamafactory-cli train examples/train_full/qwen3_full_sft.yaml
```

#### Multimodal Supervised Fine-Tuning

```bash
FORCE_TORCHRUN=1 llamafactory-cli train examples/train_full/qwen3vl_full_sft.yaml
```

### Merging LoRA Adapters and Quantization

#### Merge LoRA Adapters

Note: DO NOT use quantized model or `quantization_bit` when merging LoRA adapters.

```bash
llamafactory-cli export examples/merge_lora/qwen3_lora_sft.yaml
```

#### Quantizing Model using AutoGPTQ

```bash
llamafactory-cli export examples/merge_lora/qwen3_gptq.yaml
```

### Save Ollama modelfile

```bash
llamafactory-cli export examples/merge_lora/qwen3_full_sft.yaml
```

### Inferring LoRA Fine-Tuned Models

#### Evaluation using vLLM's Multi-GPU Inference

```
python scripts/vllm_infer.py --model_name_or_path Qwen/Qwen3-4B-Instruct-2507 --template qwen3_nothink --dataset alpaca_en_demo
python scripts/eval_bleu_rouge.py generated_predictions.jsonl
```

#### Use CLI ChatBox

```bash
llamafactory-cli chat examples/inference/qwen3_lora_sft.yaml
```

#### Use Web UI ChatBox

```bash
llamafactory-cli webchat examples/inference/qwen3_lora_sft.yaml
```

#### Launch OpenAI-style API

```bash
llamafactory-cli api examples/inference/qwen3_lora_sft.yaml
```

### Extras

#### Full-Parameter Fine-Tuning using GaLore

```bash
llamafactory-cli train examples/extras/galore/llama3_full_sft.yaml
```

#### Full-Parameter Fine-Tuning using APOLLO

```bash
llamafactory-cli train examples/extras/apollo/llama3_full_sft.yaml
```

#### Full-Parameter Fine-Tuning using BAdam

```bash
llamafactory-cli train examples/extras/badam/llama3_full_sft.yaml
```

#### Full-Parameter Fine-Tuning using Adam-mini

```bash
llamafactory-cli train examples/extras/adam_mini/qwen2_full_sft.yaml
```

#### Full-Parameter Fine-Tuning using Muon

```bash
llamafactory-cli train examples/extras/muon/qwen2_full_sft.yaml
```

#### LoRA+ Fine-Tuning

```bash
llamafactory-cli train examples/extras/loraplus/llama3_lora_sft.yaml
```

#### PiSSA Fine-Tuning

```bash
llamafactory-cli train examples/extras/pissa/llama3_lora_sft.yaml
```

#### Mixture-of-Depths Fine-Tuning

```bash
llamafactory-cli train examples/extras/mod/llama3_full_sft.yaml
```

#### LLaMA-Pro Fine-Tuning

```bash
bash examples/extras/llama_pro/expand.sh
llamafactory-cli train examples/extras/llama_pro/llama3_freeze_sft.yaml
```

#### FSDP+QLoRA Fine-Tuning

```bash
bash examples/extras/fsdp_qlora/train.sh
```

#### OFT Fine-Tuning

```bash
llamafactory-cli train examples/extras/oft/llama3_oft_sft.yaml
```

#### QOFT Fine-Tuning

```bash
llamafactory-cli train examples/extras/qoft/llama3_oft_sft_bnb_npu.yaml
```


## Links discovered
- [torchrun](https://docs.pytorch.org/docs/stable/elastic/run.html)

--- examples/README_zh.md ---
我们提供了多样化的大模型微调示例脚本。

请确保在 `LLaMA-Factory` 目录下执行下述命令。

## 目录

- [LoRA 微调](#lora-微调)
- [QLoRA 微调](#qlora-微调)
- [全参数微调](#全参数微调)
- [合并 LoRA 适配器与模型量化](#合并-lora-适配器与模型量化)
- [推理 LoRA 模型](#推理-lora-模型)
- [杂项](#杂项)

使用 `CUDA_VISIBLE_DEVICES`（GPU）或 `ASCEND_RT_VISIBLE_DEVICES`（NPU）选择计算设备。

LLaMA-Factory 默认使用所有可见的计算设备。

基础用法：

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml
```

高级用法：

```bash
CUDA_VISIBLE_DEVICES=0,1 llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml \
    learning_rate=1e-5 \
    logging_steps=1
```

```bash
bash examples/train_lora/qwen3_lora_sft.sh
```

## 示例

### LoRA 微调

#### （增量）预训练

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_pretrain.yaml
```

#### 指令监督微调

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml
```

#### 多模态指令监督微调

```bash
llamafactory-cli train examples/train_lora/qwen3vl_lora_sft.yaml
```

#### DPO/ORPO/SimPO 训练

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_dpo.yaml
```

#### 多模态 DPO/ORPO/SimPO 训练

```bash
llamafactory-cli train examples/train_lora/qwen3vl_lora_dpo.yaml
```

#### 奖励模型训练

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_reward.yaml
```

#### KTO 训练

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_kto.yaml
```

#### 预处理数据集

对于大数据集有帮助，在配置中使用 `tokenized_path` 以加载预处理后的数据集。

```bash
llamafactory-cli train examples/train_lora/qwen3_preprocess.yaml
```

#### 多机指令监督微调

```bash
FORCE_TORCHRUN=1 NNODES=2 NODE_RANK=0 MASTER_ADDR=192.168.0.1 MASTER_PORT=29500 llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml
FORCE_TORCHRUN=1 NNODES=2 NODE_RANK=1 MASTER_ADDR=192.168.0.1 MASTER_PORT=29500 llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml
```

### 支持弹性和容错的多机指令监督微调

要启动一个支持弹性节点和容错的多机指令微调，在每个节点上执行以下命令。弹性节点数量范围为 `MIN_NNODES:MAX_NNODES`，每个节点最多允许因为错误重启 `MAX_RESTARTS` 次。`RDZV_ID` 应设置为一个唯一的作业 ID（由参与该作业的所有节点共享）。更多新可以参考官方文档 [torchrun](https://docs.pytorch.org/docs/stable/elastic/run.html)。

```bash
FORCE_TORCHRUN=1 MIN_NNODES=1 MAX_NNODES=3 MAX_RESTARTS=3 RDZV_ID=llamafactory MASTER_ADDR=192.168.0.1 MASTER_PORT=29500 llamafactory-cli train examples/train_full/qwen3_full_sft.yaml
```

#### 使用 DeepSpeed ZeRO-3 平均分配显存

```bash
FORCE_TORCHRUN=1 llamafactory-cli train examples/train_lora/qwen3_lora_sft_ds3.yaml
```

#### 使用 Ray 在 4 张 GPU 上微调

```bash
USE_RAY=1 llamafactory-cli train examples/train_lora/qwen3_lora_sft_ray.yaml
```

### QLoRA 微调

#### 基于 4/8 比特 Bitsandbytes/HQQ/EETQ 量化进行指令监督微调（推荐）

```bash
llamafactory-cli train examples/train_qlora/qwen3_lora_sft_otfq.yaml
```

#### 在 NPU 上基于 4 比特 Bitsandbytes 量化进行指令监督微调

```bash
llamafactory-cli train examples/train_qlora/qwen3_lora_sft_bnb_npu.yaml
```

#### 基于 4/8 比特 GPTQ 量化进行指令监督微调

```bash
llamafactory-cli train examples/train_qlora/llama3_lora_sft_gptq.yaml
```

#### 基于 4 比特 AWQ 量化进行指令监督微调

```bash
llamafactory-cli train examples/train_qlora/llama3_lora_sft_awq.yaml
```

#### 基于 2 比特 AQLM 量化进行指令监督微调

```bash
llamafactory-cli train examples/train_qlora/llama3_lora_sft_aqlm.yaml
```

### 全参数微调

#### 在单机上进行指令监督微调

```bash
FORCE_TORCHRUN=1 llamafactory-cli train examples/train_full/qwen3_full_sft.yaml
```

#### 在多机上进行指令监督微调

```bash
FORCE_TORCHRUN=1 NNODES=2 NODE_RANK=0 MASTER_ADDR=192.168.0.1 MASTER_PORT=29500 llamafactory-cli train examples/train_full/qwen3_full_sft.yaml
FORCE_TORCHRUN=1 NNODES=2 NODE_RANK=1 MASTER_ADDR=192.168.0.1 MASTER_PORT=29500 llamafactory-cli train examples/train_full/qwen3_full_sft.yaml
```

#### 多模态指令监督微调

```bash
FORCE_TORCHRUN=1 llamafactory-cli train examples/train_full/qwen3vl_full_sft.yaml
```

### 合并 LoRA 适配器与模型量化

#### 合并 LoRA 适配器

注：请勿使用量化后的模型或 `quantization_bit` 参数来合并 LoRA 适配器。

```bash
llamafactory-cli export examples/merge_lora/qwen3_lora_sft.yaml
```

#### 使用 AutoGPTQ 量化模型

```bash
llamafactory-cli export examples/merge_lora/qwen3_gptq.yaml
```

### 保存 Ollama 配置文件

```bash
llamafactory-cli export examples/merge_lora/qwen3_full_sft.yaml
```

### 推理 LoRA 模型

#### 使用 vLLM 多卡推理评估

```
python scripts/vllm_infer.py --model_name_or_path Qwen/Qwen3-4B-Instruct-2507 --template qwen3_nothink --dataset alpaca_en_demo
python scripts/eval_bleu_rouge.py generated_predictions.jsonl
```

#### 使用命令行对话框

```bash
llamafactory-cli chat examples/inference/qwen3_lora_sft.yaml
```

#### 使用浏览器对话框

```bash
llamafactory-cli webchat examples/inference/qwen3_lora_sft.yaml
```

#### 启动 OpenAI 风格 API

```bash
llamafactory-cli api examples/inference/qwen3_lora_sft.yaml
```

### 杂项

#### 使用 GaLore 进行全参数训练

```bash
llamafactory-cli train examples/extras/galore/llama3_full_sft.yaml
```

#### 使用 APOLLO 进行全参数训练

```bash
llamafactory-cli train examples/extras/apollo/llama3_full_sft.yaml
```

#### 使用 BAdam 进行全参数训练

```bash
llamafactory-cli train examples/extras/badam/llama3_full_sft.yaml
```

#### 使用 Adam-mini 进行全参数训练

```bash
llamafactory-cli train examples/extras/adam_mini/qwen2_full_sft.yaml
```

#### 使用 Muon 进行全参数训练

```bash
llamafactory-cli train examples/extras/muon/qwen2_full_sft.yaml
```

#### LoRA+ 微调

```bash
llamafactory-cli train examples/extras/loraplus/llama3_lora_sft.yaml
```

#### PiSSA 微调

```bash
llamafactory-cli train examples/extras/pissa/llama3_lora_sft.yaml
```

#### 深度混合微调

```bash
llamafactory-cli train examples/extras/mod/llama3_full_sft.yaml
```

#### LLaMA-Pro 微调

```bash
bash examples/extras/llama_pro/expand.sh
llamafactory-cli train examples/extras/llama_pro/llama3_freeze_sft.yaml
```

#### FSDP+QLoRA 微调

```bash
bash examples/extras/fsdp_qlora/train.sh
```

#### OFT 微调

```bash
llamafactory-cli train examples/extras/oft/llama3_oft_sft.yaml
```

#### QOFT 微调

```bash
llamafactory-cli train examples/extras/qoft/llama3_oft_sft_bnb_npu.yaml
```


## Links discovered
- [torchrun](https://docs.pytorch.org/docs/stable/elastic/run.html)

--- data/wiki_demo.txt ---
Anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary, coercive forms of hierarchy. Anarchism calls for the abolition of the state, which it holds to be unnecessary, undesirable, and harmful. As a historically left-wing movement, placed on the farthest left of the political spectrum, it is usually described alongside communalism and libertarian Marxism as the libertarian wing (libertarian socialism) of the socialist movement, and has a strong historical association with anti-capitalism and socialism.Humans lived in societies without formal hierarchies long before the establishment of formal states, realms, or empires. With the rise of organised hierarchical bodies, scepticism toward authority also rose. Although traces of anarchist thought are found throughout history, modern anarchism emerged from the Enlightenment. During the latter half of the 19th and the first decades of the 20th century, the anarchist movement flourished in most parts of the world and had a significant role in workers' struggles for emancipation. Various anarchist schools of thought formed during this period. Anarchists have taken part in several revolutions, most notably in the Paris Commune, the Russian Civil War and the Spanish Civil War, whose end marked the end of the classical era of anarchism. In the last decades of the 20th and into the 21st century, the anarchist movement has been resurgent once more.Anarchism employs a diversity of tactics in order to meet its ideal ends which can be broadly separated into revolutionary and evolutionary tactics; there is significant overlap between the two, which are merely descriptive. Revolutionary tactics aim to bring down authority and state, having taken a violent turn in the past, while evolutionary tactics aim to prefigure what an anarchist society would be like. Anarchist thought, criticism, and praxis have played a part in diverse areas of human society. Criticism of anarchism include claims that it is internally inconsistent, violent, or utopian.Etymology, terminology, and definition The etymological origin of anarchism is from the Ancient Greek anarkhia, meaning "without a ruler", composed of the prefix an- ("without") and the word arkhos ("leader" or "ruler"). The suffix -ism denotes the ideological current that favours anarchy. Anarchism appears in English from 1642 as anarchisme and anarchy from 1539; early English usages emphasised a sense of disorder. Various factions within the French Revolution labelled their opponents as anarchists, although few such accused shared many views with later anarchists. Many revolutionaries of the 19th century such as William Godwin (1756–1836) and Wilhelm Weitling (1808–1871) would contribute to the anarchist doctrines of the next generation but did not use anarchist or anarchism in describing themselves or their beliefs.The first political philosopher to call himself an anarchist () was Pierre-Joseph Proudhon (1809–1865), marking the formal birth of anarchism in the mid-19th century. Since the 1890s and beginning in France, libertarianism has often been used as a synonym for anarchism and its use as a synonym is still common outside the United States. Some usages of libertarianism refer to individualistic free-market philosophy only, and free-market anarchism in particular is termed libertarian anarchism.While the term libertarian has been largely synonymous with anarchism, its meaning has more recently diluted with wider adoption from ideologically disparate groups, including both the New Left and libertarian Marxists, who do not associate themselves with authoritarian socialists or a vanguard party, and extreme cultural liberals, who are primarily concerned with civil liberties. Additionally, some anarchists use libertarian socialist to avoid anarchism's negative connotations and emphasise its connections with socialism. Anarchism is broadly used to describe the anti-authoritarian wing of the socialist movement. Anarchism is contrasted to socialist forms which are state-oriented or from above. Scholars of anarchism generally highlight anarchism's socialist credentials and criticise attempts at creating dichotomies between the two. Some scholars describe anarchism as having many influences from liberalism, and being both liberals and socialists but more so, while most scholars reject anarcho-capitalism as a misunderstanding of anarchist principles.While opposition to the state is central to anarchist thought, defining anarchism is not an easy task for scholars, as there is a lot of discussion among scholars and anarchists on the matter, and various currents perceive anarchism slightly differently. Major definitional elements include the will for a non-coercive society, the rejection of the state apparatus, the belief that human nature allows humans to exist in or progress toward such a non-coercive society, and a suggestion on how to act to pursue the ideal of anarchy.HistoryPre-modern era Before the establishment of towns and cities, an established authority did not exist. It was after the creation of institutions of authority that anarchistic ideas espoused as a reaction. The most notable precursors to anarchism in the ancient world were in China and Greece. In China, philosophical anarchism (the discussion on the legitimacy of the state) was delineated by Taoist philosophers Zhuang Zhou and Laozi. Alongside Stoicism, Taoism has been said to have had "significant anticipations" of anarchism. Anarchic attitudes were also articulated by tragedians and philosophers in Greece. Aeschylus and Sophocles used the myth of Antigone to illustrate the conflict between rules set by the state and personal autonomy. Socrates questioned Athenian authorities constantly and insisted on the right of individual freedom of conscience. Cynics dismissed human law (nomos) and associated authorities while trying to live according to nature (physis). Stoics were supportive of a society based on unofficial and friendly relations among its citizens without the presence of a state.In medieval Europe, there was no anarchistic activity except some ascetic religious movements. These, and other Muslim movements, later gave birth to religious anarchism. In the Sasanian Empire, Mazdak called for an egalitarian society and the abolition of monarchy, only to be soon executed by Emperor Kavad I.In Basra, religious sects preached against the state. In Europe, various sects developed anti-state and libertarian tendencies. Renewed interest in antiquity during the Renaissance and in private judgment during the Reformation restored elements of anti-authoritarian secularism, particularly in France. Enlightenment challenges to intellectual authority (secular and religious) and the revolutions of the 1790s and 1848 all spurred the ideological development of what became the era of classical anarchism.Modern era During the French Revolution, partisan groups such as the Enragés and the  saw a turning point in the fermentation of anti-state and federalist sentiments. The first anarchist currents developed throughout the 18th century as William Godwin espoused philosophical anarchism in England, morally delegitimising the state, Max Stirner's thinking paved the way to individualism and Pierre-Joseph Proudhon's theory of mutualism found fertile soil in France. By the late 1870s, various anarchist schools of thought had become well-defined and a wave of then unprecedented globalisation occurred from 1880 to 1914. This era of classical anarchism lasted until the end of the Spanish Civil War and is considered the golden age of anarchism.Drawing from mutualism, Mikhail Bakunin founded collectivist anarchism and entered the International Workingmen's Association, a class worker union later known as the First International that formed in 1864 to unite diverse revolutionary currents. The International became a significant political force, with Karl Marx being a leading figure and a member of its General Council. Bakunin's faction (the Jura Federation) and Proudhon's followers (the mutualists) opposed state socialism, advocating political abstentionism and small property holdings. After bitter disputes, the Bakuninists were expelled from the International by the Marxists at the 1872 Hague Congress. Anarchists were treated similarly in the Second International, being ultimately expelled in 1896. Bakunin famously predicted that if revolutionaries gained power by Marx's terms, they would end up the new tyrants of workers. In response to their expulsion from the First International, anarchists formed the St. Imier International. Under the influence of Peter Kropotkin, a Russian philosopher and scientist, anarcho-communism overlapped with collectivism. Anarcho-communists, who drew inspiration from the 1871 Paris Commune, advocated for free federation and for the distribution of goods according to one's needs.At the turn of the century, anarchism had spread all over the world. It was a notable feature of the international syndicalism movement. In China, small groups of students imported the humanistic pro-science version of anarcho-communism. Tokyo was a hotspot for rebellious youth from countries of the far east, travelling to the Japanese capital to study. In Latin America, Argentina was a stronghold for anarcho-syndicalism, where it became the most prominent left-wing ideology. During this time, a minority of anarchists adopted tactics of revolutionary political violence. This strategy became known as propaganda of the deed. The dismemberment of the French socialist movement into many groups and the execution and exile of many Communards to penal colonies following the suppression of the Paris Commune favoured individualist political expression and acts. Even though many anarchists distanced themselves from these terrorist acts, infamy came upon the movement and attempts were made to exclude them from American immigration, including the Immigration Act of 1903, also called the Anarchist Exclusion Act. Illegalism was another strategy which some anarchists adopted during this period.Despite concerns, anarchists enthusiastically participated in the Russian Revolution in opposition to the White movement; however, they met harsh suppression after the Bolshevik government was stabilised. Several anarchists from Petrograd and Moscow fled to Ukraine, notably leading to the Kronstadt rebellion and Nestor Makhno's struggle in the Free Territory. With the anarchists being crushed in Russia, two new antithetical currents emerged, namely platformism and synthesis anarchism. The former sought to create a coherent group that would push for revolution while the latter were against anything that would resemble a political party. Seeing the victories of the Bolsheviks in the October Revolution and the resulting Russian Civil War, many workers and activists turned to communist parties which grew at the expense of anarchism and other socialist movements. In France and the United States, members of major syndicalist movements such as the General Confederation of Labour and the Industrial Workers of the World left their organisations and joined the Communist International.In the Spanish Civil War of 1936, anarchists and syndicalists (CNT and FAI) once again allied themselves with various currents of leftists. A long tradition of Spanish anarchism led to anarchists playing a pivotal role in the war. In response to the army rebellion, an anarchist-inspired movement of peasants and workers, supported by armed militias, took control of Barcelona and of large areas of rural Spain, where they collectivised the land. The Soviet Union provided some limited assistance at the beginning of the war, but the result was a bitter fight among communists and anarchists at a series of events named May Days as Joseph Stalin tried to seize control of the Republicans.Post-war era At the end of World War II, the anarchist movement was severely weakened. The 1960s witnessed a revival of anarchism, likely caused by a perceived failure of Marxism–Leninism and tensions built by the Cold War. During this time, anarchism found a presence in other movements critical towards both capitalism and the state such as the anti-nuclear, environmental, and peace movements, the counterculture of the 1960s, and the New Left. It also saw a transition from its previous revolutionary nature to provocative anti-capitalist reformism. Anarchism became associated with punk subculture as exemplified by bands such as Crass and the Sex Pistols. The established feminist tendencies of anarcha-feminism returned with vigour during the second wave of feminism. Black anarchism began to take form at this time and influenced anarchism's move from a Eurocentric demographic. This coincided with its failure to gain traction in Northern Europe and its unprecedented height in Latin America.Around the turn of the 21st century, anarchism grew in popularity and influence within anti-capitalist, anti-war and anti-globalisation movements. Anarchists became known for their involvement in protests against the World Trade Organization (WTO), the Group of Eight and the World Economic Forum. During the protests, ad hoc leaderless anonymous cadres known as black blocs engaged in rioting, property destruction and violent confrontations with the police. Other organisational tactics pioneered in this time include affinity groups, security culture and the use of decentralised technologies such as the Internet. A significant event of this period was the confrontations at the 1999 Seattle WTO conference. Anarchist ideas have been influential in the development of the Zapatistas in Mexico and the Democratic Federation of Northern Syria, more commonly known as Rojava, a de facto autonomous region in northern Syria.Thought Anarchist schools of thought have been generally grouped into two main historical traditions, social anarchism and individualist anarchism, owing to their different origins, values and evolution. The individualist current emphasises negative liberty in opposing restraints upon the free individual, while the social current emphasises positive liberty in aiming to achieve the free potential of society through equality and social ownership. In a chronological sense, anarchism can be segmented by the classical currents of the late 19th century and the post-classical currents (anarcha-feminism, green anarchism, and post-anarchism) developed thereafter.Beyond the specific factions of anarchist movements which constitute political anarchism lies philosophical anarchism which holds that the state lacks moral legitimacy, without necessarily accepting the imperative of revolution to eliminate it. A component especially of individualist anarchism, philosophical anarchism may tolerate the existence of a minimal state but claims that citizens have no moral obligation to obey government when it conflicts with individual autonomy. Anarchism pays significant attention to moral arguments since ethics have a central role in anarchist philosophy. Anarchism's emphasis on anti-capitalism, egalitarianism, and for the extension of community and individuality sets it apart from anarcho-capitalism and other types of economic libertarianism.Anarchism is usually placed on the far-left of the political spectrum. Much of its economics and legal philosophy reflect anti-authoritarian, anti-statist, libertarian, and radical interpretations of left-wing and socialist politics such as collectivism, communism, individualism, mutualism, and syndicalism, among other libertarian socialist economic theories. As anarchism does not offer a fixed body of doctrine from a single particular worldview, many anarchist types and traditions exist and varieties of anarchy diverge widely. One reaction against sectarianism within the anarchist milieu was anarchism without adjectives, a call for toleration and unity among anarchists first adopted by Fernando Tarrida del Mármol in 1889 in response to the bitter debates of anarchist theory at the time. Belief in political nihilism has been espoused by anarchists. Despite separation, the various anarchist schools of thought are not seen as distinct entities but rather as tendencies that intermingle and are connected through a set of uniform principles such as individual and local autonomy, mutual aid, network organisation, communal democracy, justified authority and decentralisation.Classical Inceptive currents among classical anarchist currents were mutualism and individualism. They were followed by the major currents of social anarchism (collectivist, communist and syndicalist). They differ on organisational and economic aspects of their ideal society.Mutualism is an 18th-century economic theory that was developed into anarchist theory by Pierre-Joseph Proudhon. Its aims include reciprocity, free association, voluntary contract, federation and monetary reform of both credit and currency that would be regulated by a bank of the people. Mutualism has been retrospectively characterised as ideologically situated between individualist and collectivist forms of anarchism. In What Is Property? (1840), Proudhon first characterised his goal as a "third form of society, the synthesis of communism and property." Collectivist anarchism is a revolutionary socialist form of anarchism commonly associated with Mikhail Bakunin. Collectivist anarchists advocate collective ownership of the means of production which is theorised to be achieved through violent revolution and that workers be paid according to time worked, rather than goods being distributed according to need as in communism. Collectivist anarchism arose alongside Marxism but rejected the dictatorship of the proletariat despite the stated Marxist goal of a collectivist stateless society.Anarcho-communism is a theory of anarchism that advocates a communist society with common ownership of the means of production, direct democracy and a horizontal network of voluntary associations, workers' councils and worker cooperatives, with production and consumption based on the guiding principle "From each according to his ability, to each according to his need." Anarcho-communism developed from radical socialist currents after the French Revolution but was first formulated as such in the Italian section of the First International. It was later expanded upon in the theoretical work of Peter Kropotkin, whose specific style would go onto become the dominating view of anarchists by the late 19th century. Anarcho-syndicalism is a branch of anarchism that views labour syndicates as a potential force for revolutionary social change, replacing capitalism and the state with a new society democratically self-managed by workers. The basic principles of anarcho-syndicalism are direct action, workers' solidarity and workers' self-management.Individualist anarchism is a set of several traditions of thought within the anarchist movement that emphasise the individual and their will over any kinds of external determinants. Early influences on individualist forms of anarchism include William Godwin, Max Stirner, and Henry David Thoreau. Through many countries, individualist anarchism attracted a small yet diverse following of Bohemian artists and intellectuals as well as young anarchist outlaws in what became known as illegalism and individual reclamation.Post-classical and contemporary Anarchist principles undergird contemporary radical social movements of the left. Interest in the anarchist movement developed alongside momentum in the anti-globalisation movement, whose leading activist networks were anarchist in orientation. As the movement shaped 21st century radicalism, wider embrace of anarchist principles signaled a revival of interest. Anarchism has continued to generate many philosophies and movements, at times eclectic, drawing upon various sources and combining disparate concepts to create new philosophical approaches. The anti-capitalist tradition of classical anarchism has remained prominent within contemporary currents.Contemporary news coverage which emphasizes black bloc demonstrations has reinforced anarchism's historical association with chaos and violence. Its publicity has also led more scholars in fields such as anthropology and history to engage with the anarchist movement, although contemporary anarchism favours actions over academic theory. Various anarchist groups, tendencies, and schools of thought exist today, making it difficult to describe the contemporary anarchist movement. While theorists and activists have established "relatively stable constellations of anarchist principles", there is no consensus on which principles are core and commentators describe multiple anarchisms, rather than a singular anarchism, in which common principles are shared between schools of anarchism while each group prioritizes those principles differently. Gender equality can be a common principle, although it ranks as a higher priority to anarcha-feminists than anarcho-communists.Anarchists are generally committed against coercive authority in all forms, namely "all centralized and hierarchical forms of government (e.g., monarchy, representative democracy, state socialism, etc.), economic class systems (e.g., capitalism, Bolshevism, feudalism, slavery, etc.), autocratic religions (e.g., fundamentalist Islam, Roman Catholicism, etc.), patriarchy, heterosexism, white supremacy, and imperialism." Anarchist schools disagree on the methods by which these forms should be opposed. The principle of equal liberty is closer to anarchist political ethics in that it transcends both the liberal and socialist traditions. This entails that liberty and equality cannot be implemented within the state, resulting in the questioning of all forms of domination and hierarchy.Tactics Anarchists' tactics take various forms but in general serve two major goals, namely to first oppose the Establishment and secondly to promote anarchist ethics and reflect an anarchist vision of society, illustrating the unity of means and ends. A broad categorisation can be made between aims to destroy oppressive states and institutions by revolutionary means on one hand and aims to change society through evolutionary means on the other. Evolutionary tactics embrace nonviolence, reject violence and take a gradual approach to anarchist aims, although there is significant overlap between the two.Anarchist tactics have shifted during the course of the last century. Anarchists during the early 20th century focused more on strikes and militancy while contemporary anarchists use a broader array of approaches.Classical era tactics During the classical era, anarchists had a militant tendency. Not only did they confront state armed forces, as in Spain and Ukraine, but some of them also employed terrorism as propaganda of the deed. Assassination attempts were carried out against heads of state, some of which were successful. Anarchists also took part in revolutions. Many anarchists, especially the Galleanists, believed that these attempts would be the impetus for a revolution against capitalism and the state. Many of these attacks were done by individual assailants and the majority took place in the late 1870s, the early 1880s and the 1890s, with some still occurring in the early 1900s. Their decrease in prevalence was the result of further judicial power and targeting and cataloging by state institutions.Anarchist perspectives towards violence have always been controversial. Anarcho-pacifists advocate for non-violence means to achieve their stateless, nonviolent ends. Other anarchist groups advocate direct action, a tactic which can include acts of sabotage or terrorism. This attitude was quite prominent a century ago when seeing the state as a tyrant and some anarchists believing that they had every right to oppose its oppression by any means possible. Emma Goldman and Errico Malatesta, who were proponents of limited use of violence, stated that violence is merely a reaction to state violence as a necessary evil.Anarchists took an active role in strike actions, although they tended to be antipathetic to formal syndicalism, seeing it as reformist. They saw it as a part of the movement which sought to overthrow the state and capitalism. Anarchists also reinforced their propaganda within the arts, some of whom practiced naturism and nudism. Those anarchists also built communities which were based on friendship and were involved in the news media.Revolutionary tactics In the current era, Italian anarchist Alfredo Bonanno, a proponent of insurrectionary anarchism, has reinstated the debate on violence by rejecting the nonviolence tactic adopted since the late 19th century by Kropotkin and other prominent anarchists afterwards. Both Bonanno and the French group The Invisible Committee advocate for small, informal affiliation groups, where each member is responsible for their own actions but works together to bring down oppression utilizing sabotage and other violent means against state, capitalism, and other enemies. Members of The Invisible Committee were arrested in 2008 on various charges, terrorism included.Overall, contemporary anarchists are much less violent and militant than their ideological ancestors. They mostly engage in confronting the police during demonstrations and riots, especially in countries such as Canada, Greece, and Mexico. Militant black bloc protest groups are known for clashing with the police; however, anarchists not only clash with state operators, they also engage in the struggle against fascists and racists, taking anti-fascist action and mobilizing to prevent hate rallies from happening.Evolutionary tactics Anarchists commonly employ direct action. This can take the form of disrupting and protesting against unjust hierarchy, or the form of self-managing their lives through the creation of counter-institutions such as communes and non-hierarchical collectives. Decision-making is often handled in an anti-authoritarian way, with everyone having equal say in each decision, an approach known as horizontalism. Contemporary-era anarchists have been engaging with various grassroots movements that are more or less based on horizontalism, although not explicitly anarchist, respecting personal autonomy and participating in mass activism such as strikes and demonstrations. In contrast with the big-A anarchism of the classical era, the newly coined term small-a anarchism signals their tendency not to base their thoughts and actions on classical-era anarchism or to refer to classical anarchists such as Peter Kropotkin and Pierre-Joseph Proudhon to justify their opinions. Those anarchists would rather base their thought and praxis on their own experience which they will later theorize.The decision-making process of small anarchist affinity groups plays a significant tactical role. Anarchists have employed various methods in order to build a rough consensus among members of their group without the need of a leader or a leading group. One way is for an individual from the group to play the role of facilitator to help achieve a consensus without taking part in the discussion themselves or promoting a specific point. Minorities usually accept rough consensus, except when they feel the proposal contradicts anarchist ethics, goals and values. Anarchists usually form small groups (5–20 individuals) to enhance autonomy and friendships among their members. These kinds of groups more often than not interconnect with each other, forming larger networks. Anarchists still support and participate in strikes, especially wildcat strikes as these are leaderless strikes not organised centrally by a syndicate.As in the past, newspapers and journals are used, and anarchists have gone online in the World Wide Web to spread their message. Anarchists have found it easier to create websites because of distributional and other difficulties, hosting electronic libraries and other portals. Anarchists were also involved in developing various software that are available for free. The way these hacktivists work to develop and distribute resembles the anarchist ideals, especially when it comes to preserving users' privacy from state surveillance.Anarchists organize themselves to squat and reclaim public spaces. During important events such as protests and when spaces are being occupied, they are often called Temporary Autonomous Zones (TAZ), spaces where art, poetry, and surrealism are blended to display the anarchist ideal. As seen by anarchists, squatting is a way to regain urban space from the capitalist market, serving pragmatical needs and also being an exemplary direct action. Acquiring space enables anarchists to experiment with their ideas and build social bonds. Adding up these tactics while having in mind that not all anarchists share the same attitudes towards them, along with various forms of protesting at highly symbolic events, make up a carnivalesque atmosphere that is part of contemporary anarchist vividity.Key issues As anarchism is a philosophy that embodies many diverse attitudes, tendencies, and schools of thought; disagreement over questions of values, ideology, and tactics is common. Its diversity has led to widely different uses of identical terms among different anarchist traditions which has created a number of definitional concerns in anarchist theory. The compatibility of capitalism, nationalism, and religion with anarchism is widely disputed, and anarchism enjoys complex relationships with ideologies such as communism, collectivism, Marxism, and trade unionism. Anarchists may be motivated by humanism, divine authority, enlightened self-interest, veganism, or any number of alternative ethical doctrines. Phenomena such as civilisation, technology (e.g. within anarcho-primitivism), and the democratic process may be sharply criticised within some anarchist tendencies and simultaneously lauded in others.Gender, sexuality, and free love As gender and sexuality carry along them dynamics of hierarchy, many anarchists address, analyse, and oppose the suppression of one's autonomy imposed by gender roles.Sexuality was not often discussed by classical anarchists but the few that did felt that an anarchist society would lead to sexuality naturally developing. Sexual violence was a concern for anarchists such as Benjamin Tucker, who opposed age of consent laws, believing they would benefit predatory men. A historical current that arose and flourished during 1890 and 1920 within anarchism was free love. In contemporary anarchism, this current survives as a tendency to support polyamory and queer anarchism. Free love advocates were against marriage, which they saw as a way of men imposing authority over women, largely because marriage law greatly favoured the power of men. The notion of free love was much broader and included a critique of the established order that limited women's sexual freedom and pleasure. Those free love movements contributed to the establishment of communal houses, where large groups of travelers, anarchists and other activists slept in beds together. Free love had roots both in Europe and the United States; however, some anarchists struggled with the jealousy that arose from free love. Anarchist feminists were advocates of free love, against marriage, and pro-choice (utilising a contemporary term), and had a similar agenda. Anarchist and non-anarchist feminists differed on suffrage but were supportive of one another.During the second half of the 20th century, anarchism intermingled with the second wave of feminism, radicalising some currents of the feminist movement and being influenced as well. By the latest decades of the 20th century, anarchists and feminists were advocating for the rights and autonomy of women, gays, queers and other marginalised groups, with some feminist thinkers suggesting a fusion of the two currents. With the third wave of feminism, sexual identity and compulsory heterosexuality became a subject of study for anarchists, yielding a post-structuralist critique of sexual normality. Some anarchists distanced themselves from this line of thinking, suggesting that it leaned towards an individualism that was dropping the cause of social liberation.Anarchism and education The interest of anarchists in education stretches back to the first emergence of classical anarchism. Anarchists consider proper education, one which sets the foundations of the future autonomy of the individual and the society, to be an act of mutual aid. Anarchist writers such as William Godwin (Political Justice) and Max Stirner ("The False Principle of Our Education") attacked both state education and private education as another means by which the ruling class replicate their privileges.In 1901, Catalan anarchist and free thinker Francisco Ferrer established the Escuela Moderna in Barcelona as an opposition to the established education system which was dictated largely by the Catholic Church. Ferrer's approach was secular, rejecting both state and church involvement in the educational process whilst giving pupils large amounts of autonomy in planning their work and attendance. Ferrer aimed to educate the working class and explicitly sought to foster class consciousness among students. The school closed after constant harassment by the state and Ferrer was later arrested. Nonetheless, his ideas formed the inspiration for a series of modern schools around the world. Christian anarchist Leo Tolstoy, who published the essay Education and Culture, also established a similar school with its founding principle being that "for education to be effective it had to be free." In a similar token, A. S. Neill founded what became the Summerhill School in 1921, also declaring being free from coercion.Anarchist education is based largely on the idea that a child's right to develop freely and without manipulation ought to be respected and that rationality would lead children to morally good conclusions; however, there has been little consensus among anarchist figures as to what constitutes manipulation. Ferrer believed that moral indoctrination was necessary and explicitly taught pupils that equality, liberty and social justice were not possible under capitalism, along with other critiques of government and nationalism.Late 20th century and contemporary anarchist writers (Paul Goodman, Herbert Read, and Colin Ward) intensified and expanded the anarchist critique of state education, largely focusing on the need for a system that focuses on children's creativity rather than on their ability to attain a career or participate in consumerism as part of a consumer society. Contemporary anarchists such as Ward claim that state education serves to perpetuate socioeconomic inequality.While few anarchist education institutions have survived to the modern-day, major tenets of anarchist schools, among them respect for child autonomy and relying on reasoning rather than indoctrination as a teaching method, have spread among mainstream educational institutions. Judith Suissa names three schools as explicitly anarchists schools, namely the Free Skool Santa Cruz in the United States which is part of a wider American-Canadian network of schools, the Self-Managed Learning College in Brighton, England, and the Paideia School in Spain.Anarchism and the state Objection to the state and its institutions is a sine qua non of anarchism. Anarchists consider the state as a tool of domination and believe it to be illegitimate regardless of its political tendencies. Instead of people being able to control the aspects of their life, major decisions are taken by a small elite. Authority ultimately rests solely on power, regardless of whether that power is open or transparent, as it still has the ability to coerce people. Another anarchist argument against states is that the people constituting a government, even the most altruistic among officials, will unavoidably seek to gain more power, leading to corruption. Anarchists consider the idea that the state is the collective will of the people to be an unachievable fiction due to the fact that the ruling class is distinct from the rest of society.Specific anarchist attitudes towards the state vary. Robert Paul Wolff believed that the tension between authority and autonomy would mean the state could never be legitimate. Bakunin saw the state as meaning "coercion, domination by means of coercion, camouflaged if possible but unceremonious and overt if need be." A. John Simmons and Leslie Green, who leaned toward philosophical anarchism, believed that the state could be legitimate if it is governed by consensus, although they saw this as highly unlikely. Beliefs on how to abolish the state also differ.Anarchism and the arts The connection between anarchism and art was quite profound during the classical era of anarchism, especially among artistic currents that were developing during that era such as futurists, surrealists and others. In literature, anarchism was mostly associated with the New Apocalyptics and the neo-romanticism movement. In music, anarchism has been associated with music scenes such as punk. Anarchists such as Leo Tolstoy and Herbert Read stated that the border between the artist and the non-artist, what separates art from a daily act, is a construct produced by the alienation caused by capitalism and it prevents humans from living a joyful life.Other anarchists advocated for or used art as a means to achieve anarchist ends. In his book Breaking the Spell: A History of Anarchist Filmmakers, Videotape Guerrillas, and Digital Ninjas, Chris Robé claims that "anarchist-inflected practices have increasingly structured movement-based video activism." Throughout the 20th century, many prominent anarchists (Peter Kropotkin, Emma Goldman, Gustav Landauer and Camillo Berneri) and publications such as Anarchy wrote about matters pertaining to the arts.Three overlapping properties made art useful to anarchists. It could depict a critique of existing society and hierarchies, serve as a prefigurative tool to reflect the anarchist ideal society and even turn into a means of direct action such as in protests. As it appeals to both emotion and reason, art could appeal to the whole human and have a powerful effect. The 19th-century neo-impressionist movement had an ecological aesthetic and offered an example of an anarchist perception of the road towards socialism. In Les chataigniers a Osny by anarchist painter Camille Pissarro, the blending of aesthetic and social harmony is prefiguring an ideal anarchistic agrarian community.Analysis The most common critique of anarchism is that humans cannot self-govern and so a state is necessary for human survival. Philosopher Bertrand Russell supported this critique, stating that "[p]eace and war, tariffs, regulations of sanitary conditions and the sale of noxious drugs, the preservation of a just system of distribution: these, among others, are functions which could hardly be performed in a community in which there was no central government." Another common criticism of anarchism is that it fits a world of isolation in which only the small enough entities can be self-governing; a response would be that major anarchist thinkers advocated anarchist federalism.Philosophy lecturer Andrew G. Fiala composed a list of common arguments against anarchism which includes critiques such as that anarchism is innately related to violence and destruction, not only in the pragmatic world, such as at protests, but in the world of ethics as well. Secondly, anarchism is evaluated as unfeasible or utopian since the state cannot be defeated practically. This line of arguments most often calls for political action within the system to reform it. The third argument is that anarchism is self-contradictory. While it advocates for no-one to archiei, if accepted by the many, then anarchism would turn into the ruling political theory. In this line of criticism also comes the self-contradiction that anarchism calls for collective action whilst endorsing the autonomy of the individual, hence no collective action can be taken. Lastly, Fiala mentions a critique towards philosophical anarchism of being ineffective (all talk and thoughts) and in the meantime capitalism and bourgeois class remains strong.Philosophical anarchism has met the criticism of members of academia following the release of pro-anarchist books such as A. John Simmons' Moral Principles and Political Obligations. Law professor William A. Edmundson authored an essay to argue against three major philosophical anarchist principles which he finds fallacious. Edmundson says that while the individual does not owe the state a duty of obedience, this does not imply that anarchism is the inevitable conclusion and the state is still morally legitimate. In The Problem of Political Authority, Michael Huemer defends philosophical anarchism, claiming that "political authority is a moral illusion."One of the earliest criticisms is that anarchism defies and fails to understand the biological inclination to authority. Joseph Raz states that the acceptance of authority implies the belief that following their instructions will afford more success. Raz believes that this argument is true in following both authorities' successful and mistaken instruction. Anarchists reject this criticism because challenging or disobeying authority does not entail the disappearance of its advantages by acknowledging authority such as doctors or lawyers as reliable, nor does it involve a complete surrender of independent judgment. Anarchist perception of human nature, rejection of the state, and commitment to social revolution has been criticised by academics as naive, overly simplistic, and unrealistic, respectively. Classical anarchism has been criticised for relying too heavily on the belief that the abolition of the state will lead to human cooperation prospering.Friedrich Engels, considered to be one of the principal founders of Marxism, criticised anarchism's anti-authoritarianism as inherently counter-revolutionary because in his view a revolution is by itself authoritarian. Academic John Molyneux writes in his book Anarchism: A Marxist Criticism that "anarchism cannot win", believing that it lacks the ability to properly implement its ideas. The Marxist criticism of anarchism is that it has a utopian character because all individuals should have anarchist views and values. According to the Marxist view, that a social idea would follow directly from this human ideal and out of the free will of every individual formed its essence. Marxists state that this contradiction was responsible for their inability to act. In the anarchist vision, the conflict between liberty and equality was resolved through coexistence and intertwining.See also  Anarchism by country Governance without government List of anarchist political ideologies List of books about anarchismReferencesCitationsNotesSourcesPrimary sourcesSecondary sourcesTertiary sourcesFurther reading    Criticism of philosophical anarchism.   A defence of philosophical anarchism, stating that "both kinds of 'anarchism' [i.e. philosophical and political anarchism] are philosophical and political claims." (p. 137)  Anarchistic popular fiction novel.     An argument for philosophical anarchism.External links  Anarchy Archives. Anarchy Archives is an online research center on the history and theory of anarchism. Anti-capitalismAnti-fascismEconomic ideologiesLeft-wing politicsLibertarian socialismLibertarianismPolitical culturePolitical movementsPolitical ideologiesSocial theoriesSocialismFar-left politics
Autism is a neurodevelopmental disorder characterized by difficulties with social interaction and communication, and by restricted and repetitive behavior. Parents often notice signs during the first three years of their child's life. These signs often develop gradually, though some autistic children experience regression in their communication and social skills after reaching developmental milestones at a normal pace.Autism is associated with a combination of genetic and environmental factors. Risk factors during pregnancy include certain infections, such as rubella, toxins including valproic acid, alcohol, cocaine, pesticides, lead, and air pollution, fetal growth restriction, and autoimmune diseases. Controversies surround other proposed environmental causes; for example, the vaccine hypothesis, which has been disproven. Autism affects information processing in the brain and how nerve cells and their synapses connect and organize; how this occurs is not well understood. The Diagnostic and Statistical Manual of Mental Disorders (DSM-5) combines forms of the condition, including Asperger syndrome and pervasive developmental disorder not otherwise specified (PDD-NOS) into the diagnosis of autism spectrum disorder (ASD).Several interventions have been shown to reduce symptoms and improve the ability of autistic people to function and participate independently in the community. Behavioral, psychological, education, and/or skill-building interventions may be used to assist autistic people to learn life skills necessary for living independently, as well as other social, communication, and language skills. Therapy also aims to reduce challenging behaviors and build upon strengths. Some autistic adults are unable to live independently. An autistic culture has developed, with some individuals seeking a cure and others believing autism should be accepted as a difference to be accommodated instead of cured.Globally, autism is estimated to affect 24.8 million people . In the 2000s, the number of autistic people worldwide was estimated at 1–2 per 1,000 people. In the developed countries, about 1.5% of children are diagnosed with ASD , up from 0.7% in 2000 in the United States. It is diagnosed four to five times more often in males than females. The number of people diagnosed has increased considerably since the 1990s, which may be partly due to increased recognition of the condition.CharacteristicsAutism is a highly variable neurodevelopmental disorder whose symptoms first appear during infancy or childhood, and generally follows a steady course without remission. Autistic people may be severely impaired in some respects but average, or even superior, in others. Overt symptoms gradually begin after the age of six months, become established by age two or three years and tend to continue through adulthood, although often in more muted form. It is distinguished by a characteristic triad of symptoms: impairments in social interaction, impairments in communication, and repetitive behavior. Other aspects, such as atypical eating, are also common but are not essential for diagnosis. Individual symptoms of autism occur in the general population and appear not to associate highly, without a sharp line separating pathologically severe from common traits.Social developmentSocial deficits distinguish autism and the related autism spectrum disorders (ASD; see Classification) from other developmental disorders. Autistic people have social impairments and often lack the intuition about others that many people take for granted. Noted autistic Temple Grandin described her inability to understand the social communication of neurotypicals, or people with typical neural development, as leaving her feeling "like an anthropologist on Mars".Unusual social development becomes apparent early in childhood. Autistic infants show less attention to social stimuli, smile and look at others less often, and respond less to their own name. Autistic toddlers differ more strikingly from social norms; for example, they have less eye contact and turn-taking, and do not have the ability to use simple movements to express themselves, such as pointing at things. Three- to five-year-old autistic children are less likely to exhibit social understanding, approach others spontaneously, imitate and respond to emotions, communicate nonverbally, and take turns with others. However, they do form attachments to their primary caregivers. Most autistic children display moderately less attachment security than neurotypical children, although this difference disappears in children with higher mental development or less pronounced autistic traits. Older children and adults with ASD perform worse on tests of face and emotion recognition although this may be partly due to a lower ability to define a person's own emotions.Children with high-functioning autism have more intense and frequent loneliness compared to non-autistic peers, despite the common belief that autistic children prefer to be alone. Making and maintaining friendships often proves to be difficult for autistic people. For them, the quality of friendships, not the number of friends, predicts how lonely they feel. Functional friendships, such as those resulting in invitations to parties, may affect the quality of life more deeply.There are many anecdotal reports, but few systematic studies, of aggression and violence in individuals with ASD. The limited data suggest that, in children with intellectual disability, autism is associated with aggression, destruction of property, and meltdowns.CommunicationAbout one third to half of autistic people do not develop enough natural speech to meet their daily communication needs. Differences in communication may be present from the first year of life, and may include delayed onset of babbling, unusual gestures, diminished responsiveness, and vocal patterns that are not synchronized with the caregiver. In the second and third years, autistic children have less frequent and less diverse babbling, consonants, words, and word combinations; their gestures are less often integrated with words. Autistic children are less likely to make requests or share experiences, and are more likely to simply repeat others' words (echolalia) or reverse pronouns. Joint attention seems to be necessary for functional speech, and deficits in joint attention seem to distinguish infants with ASD. For example, they may look at a pointing hand instead of the object to which the hand is pointing, and they consistently fail to point at objects in order to comment on or share an experience. Autistic children may have difficulty with imaginative play and with developing symbols into language.In a pair of studies, high-functioning autistic children aged 8–15 performed equally well as, and as adults better than, individually matched controls at basic language tasks involving vocabulary and spelling. Both autistic groups performed worse than controls at complex language tasks such as figurative language, comprehension, and inference. As people are often sized up initially from their basic language skills, these studies suggest that people speaking to autistic individuals are more likely to overestimate what their audience comprehends.Repetitive behaviorAutistic individuals can display many forms of repetitive or restricted behavior, which the Repetitive Behavior Scale-Revised (RBS-R) categorizes as follows. Stereotyped behaviors: Repetitive movements, such as hand flapping, head rolling, or body rocking. Compulsive behaviors: Time-consuming behaviors intended to reduce the anxiety that an individual feels compelled to perform repeatedly or according to rigid rules, such as placing objects in a specific order, checking things, or handwashing. Sameness: Resistance to change; for example, insisting that the furniture not be moved or refusing to be interrupted. Ritualistic behavior: Unvarying pattern of daily activities, such as an unchanging menu or a dressing ritual. This is closely associated with sameness and an independent validation has suggested combining the two factors. Restricted interests: Interests or fixations that are abnormal in theme or intensity of focus, such as preoccupation with a single television program, toy, or game. Self-injury: Behaviors such as eye-poking, skin-picking, hand-biting and head-banging.No single repetitive or self-injurious behavior seems to be specific to autism, but autism appears to have an elevated pattern of occurrence and severity of these behaviors.Other symptomsAutistic individuals may have symptoms that are independent of the diagnosis, but that can affect the individual or the family.An estimated 0.5% to 10% of individuals with ASD show unusual abilities, ranging from splinter skills such as the memorization of trivia to the extraordinarily rare talents of prodigious autistic savants. Many individuals with ASD show superior skills in perception and attention, relative to the general population. Sensory abnormalities are found in over 90% of autistic people, and are considered core features by some, although there is no good evidence that sensory symptoms differentiate autism from other developmental disorders. Differences are greater for under-responsivity (for example, walking into things) than for over-responsivity (for example, distress from loud noises) or for sensation seeking (for example, rhythmic movements). An estimated 60–80% of autistic people have motor signs that include poor muscle tone, poor motor planning, and toe walking;  deficits in motor coordination are pervasive across ASD and are greater in autism proper. Unusual eating behavior occurs in about three-quarters of children with ASD, to the extent that it was formerly a diagnostic indicator. Selectivity is the most common problem, although eating rituals and food refusal also occur.There is tentative evidence that gender dysphoria occurs more frequently in autistic people (see Autism and LGBT identities). As well as that, a 2021 anonymized online survey of 16-90 year-olds revealed that autistic males are more likely to be bisexual, while autistic females are more likely to be homosexual.Gastrointestinal problems are one of the most commonly co-occurring medical conditions in autistic people. These are linked to greater social impairment, irritability, behavior and sleep problems, language impairments and mood changes.Parents of children with ASD have higher levels of stress. Siblings of children with ASD report greater admiration of and less conflict with the affected sibling than siblings of unaffected children and were similar to siblings of children with Down syndrome in these aspects of the sibling relationship. However, they reported lower levels of closeness and intimacy than siblings of children with Down syndrome; siblings of individuals with ASD have greater risk of negative well-being and poorer sibling relationships as adults.CausesIt has long been presumed that there is a common cause at the genetic, cognitive, and neural levels for autism's characteristic triad of symptoms. However, there is increasing suspicion that autism is instead a complex disorder whose core aspects have distinct causes that often co-occur.Autism has a strong genetic basis, although the genetics of autism are complex and it is unclear whether ASD is explained more by rare mutations with major effects, or by rare multigene interactions of common genetic variants. Complexity arises due to interactions among multiple genes, the environment, and epigenetic factors which do not change DNA sequencing but are heritable and influence gene expression. Many genes have been associated with autism through sequencing the genomes of affected individuals and their parents. Studies of twins suggest that heritability is 0.7 for autism and as high as 0.9 for ASD, and siblings of those with autism are about 25 times more likely to be autistic than the general population. However, most of the mutations that increase autism risk have not been identified. Typically, autism cannot be traced to a Mendelian (single-gene) mutation or to a single chromosome abnormality, and none of the genetic syndromes associated with ASDs have been shown to selectively cause ASD. Numerous candidate genes have been located, with only small effects attributable to any particular gene. Most loci individually explain less than 1% of cases of autism. The large number of autistic individuals with unaffected family members may result from spontaneous structural variation—such as deletions, duplications or inversions in genetic material during meiosis. Hence, a substantial fraction of autism cases may be traceable to genetic causes that are highly heritable but not inherited: that is, the mutation that causes the autism is not present in the parental genome. Autism may be underdiagnosed in women and girls due to an assumption that it is primarily a male condition, but genetic phenomena such as imprinting and X linkage have the ability to raise the frequency and severity of conditions in males, and theories have been put forward for a genetic reason why males are diagnosed more often, such as the imprinted brain hypothesis and the extreme male brain theory.Maternal nutrition and inflammation during preconception and pregnancy influences fetal neurodevelopment. Intrauterine growth restriction is associated with ASD, in both term and preterm infants. Maternal inflammatory and autoimmune diseases may damage fetal tissues, aggravating a genetic problem or damaging the nervous system.Exposure to air pollution during pregnancy, especially heavy metals and particulates, may increase the risk of autism. Environmental factors that have been claimed without evidence to contribute to or exacerbate autism include certain foods, infectious diseases, solvents, PCBs, phthalates and phenols used in plastic products, pesticides, brominated flame retardants, alcohol, smoking, illicit drugs, vaccines, and prenatal stress. Some, such as the MMR vaccine, have been completely disproven.Parents may first become aware of autistic symptoms in their child around the time of a routine vaccination. This has led to unsupported theories blaming vaccine "overload", a vaccine preservative, or the MMR vaccine for causing autism. The latter theory was supported by a litigation-funded study that has since been shown to have been "an elaborate fraud". Although these theories lack convincing scientific evidence and are biologically implausible, parental concern about a potential vaccine link with autism has led to lower rates of childhood immunizations, outbreaks of previously controlled childhood diseases in some countries, and the preventable deaths of several children.MechanismAutism's symptoms result from maturation-related changes in various systems of the brain. How autism occurs is not well understood. Its mechanism can be divided into two areas: the pathophysiology of brain structures and processes associated with autism, and the neuropsychological linkages between brain structures and behaviors. The behaviors appear to have multiple pathophysiologies.There is evidence that gut–brain axis abnormalities may be involved. A 2015 review proposed that immune dysregulation, gastrointestinal inflammation, malfunction of the autonomic nervous system, gut flora alterations, and food metabolites may cause brain neuroinflammation and dysfunction. A 2016 review concludes that enteric nervous system abnormalities might play a role in neurological disorders such as autism. Neural connections and the immune system are a pathway that may allow diseases originated in the intestine to spread to the brain.Several lines of evidence point to synaptic dysfunction as a cause of autism. Some rare mutations may lead to autism by disrupting some synaptic pathways, such as those involved with cell adhesion. Gene replacement studies in mice suggest that autistic symptoms are closely related to later developmental steps that depend on activity in synapses and on activity-dependent changes. All known teratogens (agents that cause birth defects) related to the risk of autism appear to act during the first eight weeks from conception, and though this does not exclude the possibility that autism can be initiated or affected later, there is strong evidence that autism arises very early in development.DiagnosisDiagnosis is based on behavior, not cause or mechanism. Under the DSM-5, autism is characterized by persistent deficits in social communication and interaction across multiple contexts, as well as restricted, repetitive patterns of behavior, interests, or activities. These deficits are present in early childhood, typically before age three, and lead to clinically significant functional impairment. Sample symptoms include lack of social or emotional reciprocity, stereotyped and repetitive use of language or idiosyncratic language, and persistent preoccupation with unusual objects. The disturbance must not be better accounted for by Rett syndrome, intellectual disability or global developmental delay. ICD-10 uses essentially the same definition.Several diagnostic instruments are available. Two are commonly used in autism research: the Autism Diagnostic Interview-Revised (ADI-R) is a semistructured parent interview, and the Autism Diagnostic Observation Schedule (ADOS) uses observation and interaction with the child. The Childhood Autism Rating Scale (CARS) is used widely in clinical environments to assess severity of autism based on observation of children. The Diagnostic interview for social and communication disorders (DISCO) may also be used.A pediatrician commonly performs a preliminary investigation by taking developmental history and physically examining the child. If warranted, diagnosis and evaluations are conducted with help from ASD specialists, observing and assessing cognitive, communication, family, and other factors using standardized tools, and taking into account any associated medical conditions. A pediatric neuropsychologist is often asked to assess behavior and cognitive skills, both to aid diagnosis and to help recommend educational interventions. A differential diagnosis for ASD at this stage might also consider intellectual disability, hearing impairment, and a specific language impairment such as Landau–Kleffner syndrome. The presence of autism can make it harder to diagnose coexisting psychiatric disorders such as depression.Clinical genetics evaluations are often done once ASD is diagnosed, particularly when other symptoms already suggest a genetic cause. Although genetic technology allows clinical geneticists to link an estimated 40% of cases to genetic causes, consensus guidelines in the US and UK are limited to high-resolution chromosome and fragile X testing. A genotype-first model of diagnosis has been proposed, which would routinely assess the genome's copy number variations. As new genetic tests are developed several ethical, legal, and social issues will emerge. Commercial availability of tests may precede adequate understanding of how to use test results, given the complexity of autism's genetics. Metabolic and neuroimaging tests are sometimes helpful, but are not routine.ASD can sometimes be diagnosed by age 14 months, although diagnosis becomes increasingly stable over the first three years of life: for example, a one-year-old who meets diagnostic criteria for ASD is less likely than a three-year-old to continue to do so a few years later. In the UK the National Autism Plan for Children recommends at most 30 weeks from first concern to completed diagnosis and assessment, though few cases are handled that quickly in practice. Although the symptoms of autism and ASD begin early in childhood, they are sometimes missed; years later, adults may seek diagnoses to help them or their friends and family understand themselves, to help their employers make adjustments, or in some locations to claim disability living allowances or other benefits.Signs of autism may be more challenging for clinicians to detect in females. Autistic females have been shown to engage in masking more frequently than autistic males. Masking may include making oneself perform normative facial expressions and eye contact. A notable percentage of autistic females may be misdiagnosed, diagnosed after a considerable delay, or not diagnosed at all.Conversely, the cost of screening and diagnosis and the challenge of obtaining payment can inhibit or delay diagnosis. It is particularly hard to diagnose autism among the visually impaired, partly because some of its diagnostic criteria depend on vision, and partly because autistic symptoms overlap with those of common blindness syndromes or blindisms.ClassificationAutism is one of the five pervasive developmental disorders (PDD), which are characterized by widespread abnormalities of social interactions and communication, severely restricted interests, and highly repetitive behavior. These symptoms do not imply sickness, fragility, or emotional disturbance.Of the five PDD forms, Asperger syndrome is closest to autism in signs and likely causes; Rett syndrome and childhood disintegrative disorder share several signs with autism, but may have unrelated causes; PDD not otherwise specified (PDD-NOS; also called atypical autism) is diagnosed when the criteria are not met for a more specific disorder. Unlike with autism, people with Asperger syndrome have no substantial delay in language development. The terminology of autism can be bewildering, with autism, Asperger syndrome and PDD-NOS often called the autism spectrum disorders (ASD) or sometimes the autistic disorders, whereas autism itself is often called autistic disorder, childhood autism, or infantile autism. In this article, autism refers to the classic autistic disorder; in clinical practice, though, autism, ASD, and PDD are often used interchangeably. ASD, in turn, is a subset of the broader autism phenotype, which describes individuals who may not have ASD but do have autistic-like traits, such as avoiding eye contact.Research into causes has been hampered by the inability to identify biologically meaningful subgroups within the autistic population and by the traditional boundaries between the disciplines of psychiatry, psychology, neurology and pediatrics. Newer technologies such as fMRI and diffusion tensor imaging can help identify biologically relevant phenotypes (observable traits) that can be viewed on brain scans, to help further neurogenetic studies of autism; one example is lowered activity in the fusiform face area of the brain, which is associated with impaired perception of people versus objects. It has been proposed to classify autism using genetics as well as behavior. (For more, see Brett Abrahams, geneticist and neuroscientist)Spectrum Autism has long been thought to cover a wide spectrum, ranging from individuals with severe impairments—who may be silent, developmentally disabled, and prone to frequent repetitive behavior such as hand flapping and rocking—to high functioning individuals who may have active but distinctly odd social approaches, narrowly focused interests, and verbose, pedantic communication. Because the behavior spectrum is continuous, boundaries between diagnostic categories are necessarily somewhat arbitrary.ScreeningAbout half of parents of children with ASD notice their child's unusual behaviors by age 18 months, and about four-fifths notice by age 24 months. According to an article, failure to meet any of the following milestones "is an absolute indication to proceed with further evaluations. Delay in referral for such testing may delay early diagnosis and treatment and affect the long-term outcome". No response to name (or eye-to-eye gaze) by 6 months.  No babbling by 12 months. No gesturing (pointing, waving, etc.) by 12 months. No single words by 16 months. No two-word (spontaneous, not just echolalic) phrases by 24 months. Loss of any language or social skills, at any age.The United States Preventive Services Task Force in 2016 found it was unclear if screening was beneficial or harmful among children in whom there is no concern. The Japanese practice is to screen all children for ASD at 18 and 24 months, using autism-specific formal screening tests. In contrast, in the UK, children whose families or doctors recognize possible signs of autism are screened. It is not known which approach is more effective. Screening tools include the Modified Checklist for Autism in Toddlers (M-CHAT), the Early Screening of Autistic Traits Questionnaire, and the First Year Inventory; initial data on M-CHAT and its predecessor, the Checklist for Autism in Toddlers (CHAT), on children aged 18–30 months suggests that it is best used in a clinical setting and that it has low sensitivity (many false-negatives) but good specificity (few false-positives). It may be more accurate to precede these tests with a broadband screener that does not distinguish ASD from other developmental disorders. Screening tools designed for one culture's norms for behaviors like eye contact may be inappropriate for a different culture. Although genetic screening for autism is generally still impractical, it can be considered in some cases, such as children with neurological symptoms and dysmorphic features.Some authors suggest that automatic motor assessment could be useful to screen the children with ASD for instance with behavioural motor and emotionals reactions during smartphone watching.PreventionWhile infection with rubella during pregnancy causes fewer than 1% of cases of autism, vaccination against rubella can prevent many of those cases.ManagementThe main goals when treating autistic children are to lessen associated deficits and family distress, and to increase quality of life and functional independence. In general, higher IQs are correlated with greater responsiveness to treatment and improved treatment outcomes. No single treatment is best and treatment is typically tailored to the child's needs. Families and the educational system are the main resources for treatment. Services should be carried out by behavior analysts, special education teachers, speech pathologists, and licensed psychologists. Studies of interventions have methodological problems that prevent definitive conclusions about efficacy. However, the development of evidence-based interventions has advanced in recent years. Although many psychosocial interventions have some positive evidence, suggesting that some form of treatment is preferable to no treatment, the methodological quality of systematic reviews of these studies has generally been poor, their clinical results are mostly tentative, and there is little evidence for the relative effectiveness of treatment options. Intensive, sustained special education programs and behavior therapy early in life can help children acquire self-care, communication, and job skills, and often improve functioning and decrease symptom severity and maladaptive behaviors; claims that intervention by around age three years is crucial are not substantiated. While medications have not been found to help with core symptoms, they may be used for associated symptoms, such as irritability, inattention, or repetitive behavior patterns.EducationEducational interventions often used include applied behavior analysis (ABA), developmental models, structured teaching, speech and language therapy, social skills therapy, and occupational therapy and cognitive behavioral interventions in adults without intellectual disability to reduce depression, anxiety, and obsessive-compulsive disorder. Among these approaches, interventions either treat autistic features comprehensively, or focalize treatment on a specific area of deficit. The quality of research for early intensive behavioral intervention (EIBI)—a treatment procedure incorporating over thirty hours per week of the structured type of ABA that is carried out with very young children—is currently low, and more vigorous research designs with larger sample sizes are needed. Two theoretical frameworks outlined for early childhood intervention include structured and naturalistic ABA interventions, and developmental social pragmatic models (DSP). One interventional strategy utilizes a parent training model, which teaches parents how to implement various ABA and DSP techniques, allowing for parents to disseminate interventions themselves. Various DSP programs have been developed to explicitly deliver intervention systems through at-home parent implementation. Despite the recent development of parent training models, these interventions have demonstrated effectiveness in numerous studies, being evaluated as a probable efficacious mode of treatment.Early, intensive ABA therapy has demonstrated effectiveness in enhancing communication and adaptive functioning in preschool children; it is also well-established for improving the intellectual performance of that age group. Similarly, a teacher-implemented intervention that utilizes a more naturalistic form of ABA combined with a developmental social pragmatic approach has been found to be beneficial in improving social-communication skills in young children, although there is less evidence in its treatment of global symptoms. Neuropsychological reports are often poorly communicated to educators, resulting in a gap between what a report recommends and what education is provided. It is not known whether treatment programs for children lead to significant improvements after the children grow up, and the limited research on the effectiveness of adult residential programs shows mixed results. The appropriateness of including children with varying severity of autism spectrum disorders in the general education population is a subject of current debate among educators and researchers.MedicationMedications may be used to treat ASD symptoms that interfere with integrating a child into home or school when behavioral treatment fails. They may also be used for associated health problems, such as ADHD or anxiety. More than half of US children diagnosed with ASD are prescribed psychoactive drugs or anticonvulsants, with the most common drug classes being antidepressants, stimulants, and antipsychotics. The atypical antipsychotic drugs risperidone and aripiprazole are FDA-approved for treating associated aggressive and self-injurious behaviors. However, their side effects must be weighed against their potential benefits, and autistic people may respond atypically. Side effects, for example, may include weight gain, tiredness, drooling, and aggression. SSRI antidepressants, such as fluoxetine and fluvoxamine, have been shown to be effective in reducing repetitive and ritualistic behaviors, while the stimulant medication methylphenidate is beneficial for some children with co-morbid inattentiveness or hyperactivity. There is scant reliable research about the effectiveness or safety of drug treatments for adolescents and adults with ASD. No known medication relieves autism's core symptoms of social and communication impairments. Experiments in mice have reversed or reduced some symptoms related to autism by replacing or modulating gene function, suggesting the possibility of targeting therapies to specific rare mutations known to cause autism.Alternative medicineAlthough many alternative therapies and interventions are available, few are supported by scientific studies. Treatment approaches have little empirical support in quality-of-life contexts, and many programs focus on success measures that lack predictive validity and real-world relevance. Some alternative treatments may place the child at risk. The preference that autistic children have for unconventional foods can lead to reduction in bone cortical thickness with this being greater in those on casein-free diets, as a consequence of the low intake of calcium and vitamin D; however, suboptimal bone development in ASD has also been associated with lack of exercise and gastrointestinal disorders. In 2005, botched chelation therapy killed a five-year-old child with autism. Chelation is not recommended for autistic people since the associated risks outweigh any potential benefits. Another alternative medicine practice with no evidence is CEASE therapy, a mixture of homeopathy, supplements, and 'vaccine detoxing'.Although popularly used as an alternative treatment for autistic people, as of 2018 there is no good evidence to recommend a gluten- and casein-free diet as a standard treatment. A 2018 review concluded that it may be a therapeutic option for specific groups of children with autism, such as those with known food intolerances or allergies, or with food intolerance markers. The authors analyzed the prospective trials conducted to date that studied the efficacy of the gluten- and casein-free diet in children with ASD (4 in total). All of them compared gluten- and casein-free diet versus normal diet with a control group (2 double-blind randomized controlled trials, 1 double-blind crossover trial, 1 single-blind trial). In two of the studies, whose duration was 12 and 24 months, a significant improvement in ASD symptoms (efficacy rate 50%) was identified. In the other two studies, whose duration was 3 months, no significant effect was observed. The authors concluded that a longer duration of the diet may be necessary to achieve the improvement of the ASD symptoms. Other problems documented in the trials carried out include transgressions of the diet, small sample size, the heterogeneity of the participants and the possibility of a placebo effect. In the subset of people who have gluten sensitivity there is limited evidence that suggests that a gluten-free diet may improve some autistic behaviors.Results of a systematic review on interventions to address health outcomes among autistic adults found emerging evidence to support mindfulness-based interventions for improving mental health. This includes decreasing stress, anxiety, ruminating thoughts, anger, and aggression. There is tentative evidence that music therapy may improve social interactions, verbal communication, and non-verbal communication skills. There has been early research looking at hyperbaric treatments in children with autism. Studies on pet therapy have shown positive effects.PrognosisThere is no known cure for autism. The degree of symptoms can decrease, occasionally to the extent that people lose their diagnosis of ASD; this occurs sometimes after intensive treatment and sometimes not. It is not known how often this outcome happens; reported rates in unselected samples have ranged from 3% to 25%. Most autistic children acquire language by age five or younger, though a few have developed communication skills in later years. Many autistic children lack social support, future employment opportunities or self-determination. Although core difficulties tend to persist, symptoms often become less severe with age.Few high-quality studies address long-term prognosis. Some adults show modest improvement in communication skills, but a few decline; no study has focused on autism after midlife. Acquiring language before age six, having an IQ above 50, and having a marketable skill all predict better outcomes; independent living is unlikely with severe autism.Many autistic people face significant obstacles in transitioning to adulthood. Compared to the general population autistic people are more likely to be unemployed and to have never had a job. About half of people in their 20s with autism are not employed.Autistic people tend to face increased stress levels related to psychosocial factors, such as stigma, which may increase the rates of mental health issues in the autistic population.EpidemiologyAs of 2007, reviews estimate a prevalence of 1–2 per 1,000 for autism and close to 6 per 1,000 for ASD. A 2016 survey in the United States reported a rate of 25 per 1,000 children for ASD. Globally, autism affects an estimated 24.8 million people , while Asperger syndrome affects a further 37.2 million. In 2012, the NHS estimated that the overall prevalence of autism among adults aged 18 years and over in the UK was 1.1%. Rates of PDD-NOS's has been estimated at 3.7 per 1,000, Asperger syndrome at roughly 0.6 per 1,000, and childhood disintegrative disorder at 0.02 per 1,000. CDC estimates about 1 out of 59 (1.7%) for 2014, an increase from 1 out of every 68 children (1.5%) for 2010.In the UK, from 1998 to 2018, the autism diagnoses increased by 787%. This increase is largely attributable to changes in diagnostic practices, referral patterns, availability of services, age at diagnosis, and public awareness (particularly among women), though unidentified environmental risk factors cannot be ruled out. The available evidence does not rule out the possibility that autism's true prevalence has increased; a real increase would suggest directing more attention and funding toward psychosocial factors and changing environmental factors instead of continuing to focus on genetics. It has been established that vaccination is not a risk factor for autism and is not behind any increase in autism prevalence rates, if any change in the rate of autism exists at all.Males are at higher risk for ASD than females. The sex ratio averages 4.3:1 and is greatly modified by cognitive impairment: it may be close to 2:1 with intellectual disability and more than 5.5:1 without. Several theories about the higher prevalence in males have been investigated, but the cause of the difference is unconfirmed; one theory is that females are underdiagnosed.Although the evidence does not implicate any single pregnancy-related risk factor as a cause of autism, the risk of autism is associated with advanced age in either parent, and with diabetes, bleeding, and use of psychiatric drugs in the mother during pregnancy. The risk is greater with older fathers than with older mothers; two potential explanations are the known increase in mutation burden in older sperm, and the hypothesis that men marry later if they carry genetic liability and show some signs of autism. Most professionals believe that race, ethnicity, and socioeconomic background do not affect the occurrence of autism.Several other conditions are common in children with autism. They include: Genetic disorders. About 10–15% of autism cases have an identifiable Mendelian (single-gene) condition, chromosome abnormality, or other genetic syndrome, and ASD is associated with several genetic disorders. Intellectual disability. The percentage of autistic individuals who also meet criteria for intellectual disability has been reported as anywhere from 25% to 70%, a wide variation illustrating the difficulty of assessing intelligence of individuals on the autism spectrum. In comparison, for PDD-NOS the association with intellectual disability is much weaker, and by definition, the diagnosis of Asperger's excludes intellectual disability. Anxiety disorders are common among children with ASD; there are no firm data, but studies have reported prevalences ranging from 11% to 84%. Many anxiety disorders have symptoms that are better explained by ASD itself, or are hard to distinguish from ASD's symptoms. Epilepsy, with variations in risk of epilepsy due to age, cognitive level, and type of language disorder. Several metabolic defects, such as phenylketonuria, are associated with autistic symptoms. Minor physical anomalies are significantly increased in the autistic population. Preempted diagnoses. Although the DSM-IV rules out the concurrent diagnosis of many other conditions along with autism, the full criteria for Attention deficit hyperactivity disorder (ADHD), Tourette syndrome, and other of these conditions are often present and these co-occurrent conditions are increasingly accepted. Sleep problems affect about two-thirds of individuals with ASD at some point in childhood. These most commonly include symptoms of insomnia such as difficulty in falling asleep, frequent nocturnal awakenings, and early morning awakenings. Sleep problems are associated with difficult behaviors and family stress, and are often a focus of clinical attention over and above the primary ASD diagnosis.HistoryA few examples of autistic symptoms and treatments were described long before autism was named. The Table Talk of Martin Luther, compiled by his notetaker, Mathesius, contains the story of a 12-year-old boy who may have been severely autistic. The earliest well-documented case of autism is that of Hugh Blair of Borgue, as detailed in a 1747 court case in which his brother successfully petitioned to annul Blair's marriage to gain Blair's inheritance. The Wild Boy of Aveyron, a feral child caught in 1798, showed several signs of autism; the medical student Jean Itard treated him with a behavioral program designed to help him form social attachments and to induce speech via imitation.The New Latin word autismus (English translation autism) was coined by the Swiss psychiatrist Eugen Bleuler in 1910 as he was defining symptoms of schizophrenia. He derived it from the Greek word autós (αὐτός, meaning "self"), and used it to mean morbid self-admiration, referring to "autistic withdrawal of the patient to his fantasies, against which any influence from outside becomes an intolerable disturbance". A Soviet child psychiatrist, Grunya Sukhareva, described a similar syndrome that was published in Russian in 1925, and in German in 1926.Clinical development and diagnoses The word autism first took its modern sense in 1938 when Hans Asperger of the Vienna University Hospital adopted Bleuler's terminology autistic psychopaths in a lecture in German about child psychology. Asperger was investigating an ASD now known as Asperger syndrome, though for various reasons it was not widely recognized as a separate diagnosis until 1981. Leo Kanner of the Johns Hopkins Hospital first used autism in its modern sense in English when he introduced the label early infantile autism in a 1943 report of 11 children with striking behavioral similarities. Almost all the characteristics described in Kanner's first paper on the subject, notably "autistic aloneness" and "insistence on sameness", are still regarded as typical of the autistic spectrum of disorders. It is not known whether Kanner derived the term independently of Asperger.Kanner's reuse of autism led to decades of confused terminology like infantile schizophrenia, and child psychiatry's focus on maternal deprivation led to misconceptions of autism as an infant's response to "refrigerator mothers". Starting in the late 1960s autism was established as a separate syndrome.Terminology and distinction from schizophrenia As late as the mid-1970s there was little evidence of a genetic role in autism, while in 2007 it was believed to be one of the most heritable psychiatric conditions. Although the rise of parent organizations and the destigmatization of childhood ASD have affected how ASD is viewed, parents continue to feel social stigma in situations where their child's autistic behavior is perceived negatively, and many primary care physicians and medical specialists express some beliefs consistent with outdated autism research.It took until 1980 for the DSM-III to differentiate autism from childhood schizophrenia. In 1987, the DSM-III-R provided a checklist for diagnosing autism. In May 2013, the DSM-5 was released, updating the classification for pervasive developmental disorders. The grouping of disorders, including PDD-NOS, autism, Asperger syndrome, Rett syndrome, and CDD, has been removed and replaced with the general term of Autism Spectrum Disorders. The two categories that exist are impaired social communication and/or interaction, and restricted and/or repetitive behaviors.The Internet has helped autistic individuals bypass nonverbal cues and emotional sharing that they find difficult to deal with, and has given them a way to form online communities and work remotely. Societal and cultural aspects of autism have developed: some in the community seek a cure, while others believe that autism is simply another way of being.Society and cultureAn autistic culture has emerged, accompanied by the autistic rights and neurodiversity movements. Events include World Autism Awareness Day, Autism Sunday, Autistic Pride Day, Autreat, and others. Social-science scholars study those with autism in hopes to learn more about "autism as a culture, transcultural comparisons ... and research on social movements." Many autistic individuals have been successful in their fields.Autism rights movement The autism rights movement is a social movement within the context of disability rights that emphasizes the concept of neurodiversity, viewing the autism spectrum as a result of natural variations in the human brain rather than a disorder to be cured. The autism rights movement advocates for including greater acceptance of autistic behaviors; therapies that focus on coping skills rather than on imitating the behaviors of those without autism, and the recognition of the autistic community as a minority group. Autism rights or neurodiversity advocates believe that the autism spectrum is genetic and should be accepted as a natural expression of the human genome. This perspective is distinct from fringe theories that autism is caused by environmental factors such as vaccines. A common criticism against autistic activists is that the majority of them are "high-functioning" or have Asperger syndrome and do not represent the views of "low-functioning" autistic people.EmploymentAbout half of autistic people are unemployed, and one third of those with graduate degrees may be unemployed. Among those who find work, most are employed in sheltered settings working for wages below the national minimum. While employers state hiring concerns about productivity and supervision, experienced employers of autistic people give positive reports of above average memory and detail orientation as well as a high regard for rules and procedure in autistic employees. A majority of the economic burden of autism is caused by decreased earnings in the job market. Some studies also find decreased earning among parents who care for autistic children.ReferencesExternal links 1910s neologismsArticles containing video clipsCommunication disordersNeurological disorders in childrenPervasive developmental disordersWikipedia medicine articles ready to translate
Albedo (; ) is the measure of the diffuse reflection of solar radiation out of the total solar radiation and measured on a scale from 0, corresponding to a black body that absorbs all incident radiation, to 1, corresponding to a body that reflects all incident radiation.Surface albedo is defined as the ratio of radiosity Je to the irradiance Ee (flux per unit area) received by a surface. The proportion reflected is not only determined by properties of the surface itself, but also by the spectral and angular distribution of solar radiation reaching the Earth's surface. These factors vary with atmospheric composition, geographic location, and time (see position of the Sun). While bi-hemispherical reflectance is calculated for a single angle of incidence (i.e., for a given position of the Sun), albedo is the directional integration of reflectance over all solar angles in a given period. The temporal resolution may range from seconds (as obtained from flux measurements) to daily, monthly, or annual averages.Unless given for a specific wavelength (spectral albedo), albedo refers to the entire spectrum of solar radiation. Due to measurement constraints, it is often given for the spectrum in which most solar energy reaches the surface (between 0.3 and 3 μm). This spectrum includes visible light (0.4–0.7 μm), which explains why surfaces with a low albedo appear dark (e.g., trees absorb most radiation), whereas surfaces with a high albedo appear bright (e.g., snow reflects most radiation).Albedo is an important concept in climatology, astronomy, and environmental management (e.g., as part of the Leadership in Energy and Environmental Design (LEED) program for sustainable rating of buildings). The average albedo of the Earth from the upper atmosphere, its planetary albedo, is 30–35% because of cloud cover, but widely varies locally across the surface because of different geological and environmental features.The term albedo was introduced into optics by Johann Heinrich Lambert in his 1760 work Photometria.Terrestrial albedoAny albedo in visible light falls within a range of about 0.9 for fresh snow to about 0.04 for charcoal, one of the darkest substances. Deeply shadowed cavities can achieve an effective albedo approaching the zero of a black body. When seen from a distance, the ocean surface has a low albedo, as do most forests, whereas desert areas have some of the highest albedos among landforms. Most land areas are in an albedo range of 0.1 to 0.4. The average albedo of Earth is about 0.3. This is far higher than for the ocean primarily because of the contribution of clouds.Earth's surface albedo is regularly estimated via Earth observation satellite sensors such as NASA's MODIS instruments on board the Terra and Aqua satellites, and the CERES instrument on the Suomi NPP and JPSS. As the amount of reflected radiation is only measured for a single direction by satellite, not all directions, a mathematical model is used to translate a sample set of satellite reflectance measurements into estimates of directional-hemispherical reflectance and bi-hemispherical reflectance (e.g.,). These calculations are based on the bidirectional reflectance distribution function (BRDF), which describes how the reflectance of a given surface depends on the view angle of the observer and the solar angle. BDRF can facilitate translations of observations of reflectance into albedo.Earth's average surface temperature due to its albedo and the greenhouse effect is currently about . If Earth were frozen entirely (and hence be more reflective), the average temperature of the planet would drop below . If only the continental land masses became covered by glaciers, the mean temperature of the planet would drop to about . In contrast, if the entire Earth was covered by water – a so-called ocean planet – the average temperature on the planet would rise to almost .In 2021, scientists reported that Earth dimmed by ~0.5% over two decades (1998-2017) as measured by earthshine using modern photometric techniques. This may have both been co-caused by climate change as well as a substantial increase in global warming. However, the link to climate change has not been explored to date and it is unclear whether or not this represents an ongoing trend.White-sky, black-sky, and blue-sky albedoFor land surfaces, it has been shown that the albedo at a particular solar zenith angle θi can be approximated by the proportionate sum of two terms: the directional-hemispherical reflectance at that solar zenith angle, , sometimes referred to as black-sky albedo, and the bi-hemispherical reflectance, , sometimes referred to as white-sky albedo.with  being the proportion of direct radiation from a given solar angle, and  being the proportion of diffuse illumination, the actual albedo  (also called blue-sky albedo) can then be given as:This formula is important because it allows the albedo to be calculated for any given illumination conditions from a knowledge of the intrinsic properties of the surface.Examples of terrestrial albedo effectsIlluminationAlbedo is not directly dependent on illumination because changing the amount of incoming light proportionally changes the amount of reflected light, except in circumstances where a change in illumination induces a change in the Earth's surface at that location (e.g. through melting of reflective ice). That said, albedo and illumination both vary by latitude. Albedo is highest near the poles and lowest in the subtropics, with a local maximum in the tropics.Insolation effectsThe intensity of albedo temperature effects depends on the amount of albedo and the level of local insolation (solar irradiance); high albedo areas in the Arctic and Antarctic regions are cold due to low insolation, whereas areas such as the Sahara Desert, which also have a relatively high albedo, will be hotter due to high insolation. Tropical and sub-tropical rainforest areas have low albedo, and are much hotter than their temperate forest counterparts, which have lower insolation. Because insolation plays such a big role in the heating and cooling effects of albedo, high insolation areas like the tropics will tend to show a more pronounced fluctuation in local temperature when local albedo changes.Arctic regions notably release more heat back into space than what they absorb, effectively cooling the Earth. This has been a concern since arctic ice and snow has been melting at higher rates due to higher temperatures, creating regions in the arctic that are notably darker (being water or ground which is darker color) and reflects less heat back into space. This feedback loop results in a reduced albedo effect.Climate and weatherAlbedo affects climate by determining how much radiation a planet absorbs. The uneven heating of Earth from albedo variations between land, ice, or ocean surfaces can drive weather.Albedo–temperature feedbackWhen an area's albedo changes due to snowfall, a snow–temperature feedback results. A layer of snowfall increases local albedo, reflecting away sunlight, leading to local cooling. In principle, if no outside temperature change affects this area (e.g., a warm air mass), the raised albedo and lower temperature would maintain the current snow and invite further snowfall, deepening the snow–temperature feedback. However, because local weather is dynamic due to the change of seasons, eventually warm air masses and a more direct angle of sunlight (higher insolation) cause melting. When the melted area reveals surfaces with lower albedo, such as grass, soil, or ocean, the effect is reversed: the darkening surface lowers albedo, increasing local temperatures, which induces more melting and thus reducing the albedo further, resulting in still more heating.SnowSnow albedo is highly variable, ranging from as high as 0.9 for freshly fallen snow, to about 0.4 for melting snow, and as low as 0.2 for dirty snow. Over Antarctica snow albedo averages a little more than 0.8. If a marginally snow-covered area warms, snow tends to melt, lowering the albedo, and hence leading to more snowmelt because more radiation is being absorbed by the snowpack (the ice–albedo positive feedback).Just as fresh snow has a higher albedo than does dirty snow, the albedo of snow-covered sea ice is far higher than that of sea water. Sea water absorbs more solar radiation than would the same surface covered with reflective snow. When sea ice melts, either due to a rise in sea temperature or in response to increased solar radiation from above, the snow-covered surface is reduced, and more surface of sea water is exposed, so the rate of energy absorption increases. The extra absorbed energy heats the sea water, which in turn increases the rate at which sea ice melts. As with the preceding example of snowmelt, the process of melting of sea ice is thus another example of a positive feedback. Both positive feedback loops have long been recognized as important for global warming.Cryoconite, powdery windblown dust containing soot, sometimes reduces albedo on glaciers and ice sheets.The dynamical nature of albedo in response to positive feedback, together with the effects of small errors in the measurement of albedo, can lead to large errors in energy estimates. Because of this, in order to reduce the error of energy estimates, it is important to measure the albedo of snow-covered areas through remote sensing techniques rather than applying a single value for albedo over broad regions.Small-scale effectsAlbedo works on a smaller scale, too. In sunlight, dark clothes absorb more heat and light-coloured clothes reflect it better, thus allowing some control over body temperature by exploiting the albedo effect of the colour of external clothing.Solar photovoltaic effects Albedo can affect the electrical energy output of solar photovoltaic devices. For example, the effects of a spectrally responsive albedo are illustrated by the differences between the spectrally weighted albedo of solar photovoltaic technology based on hydrogenated amorphous silicon (a-Si:H) and crystalline silicon (c-Si)-based compared to traditional spectral-integrated albedo predictions. Research showed impacts of over 10%. More recently, the analysis was extended to the effects of spectral bias due to the specular reflectivity of 22 commonly occurring surface materials (both human-made and natural) and analyzes the albedo effects on the performance of seven photovoltaic materials covering three common photovoltaic system topologies: industrial (solar farms), commercial flat rooftops and residential pitched-roof applications.TreesBecause forests generally have a low albedo, (the majority of the ultraviolet and visible spectrum is absorbed through photosynthesis), some scientists have suggested that greater heat absorption by trees could offset some of the carbon benefits of afforestation (or offset the negative climate impacts of deforestation). In the case of evergreen forests with seasonal snow cover albedo reduction may be great enough for deforestation to cause a net cooling effect. Trees also impact climate in extremely complicated ways through evapotranspiration. The water vapor causes cooling on the land surface, causes heating where it condenses, acts a strong greenhouse gas, and can increase albedo when it condenses into clouds. Scientists generally treat evapotranspiration as a net cooling impact, and the net climate impact of albedo and evapotranspiration changes from deforestation depends greatly on local climate.In seasonally snow-covered zones, winter albedos of treeless areas are 10% to 50% higher than nearby forested areas because snow does not cover the trees as readily. Deciduous trees have an albedo value of about 0.15 to 0.18 whereas coniferous trees have a value of about 0.09 to 0.15. Variation in summer albedo across both forest types is associated with maximum rates of photosynthesis because plants with high growth capacity display a greater fraction of their foliage for direct interception of incoming radiation in the upper canopy. The result is that wavelengths of light not used in photosynthesis are more likely to be reflected back to space rather than being absorbed by other surfaces lower in the canopy.Studies by the Hadley Centre have investigated the relative (generally warming) effect of albedo change and (cooling) effect of carbon sequestration on planting forests. They found that new forests in tropical and midlatitude areas tended to cool; new forests in high latitudes (e.g., Siberia) were neutral or perhaps warming.WaterWater reflects light very differently from typical terrestrial materials. The reflectivity of a water surface is calculated using the Fresnel equations.At the scale of the wavelength of light even wavy water is always smooth so the light is reflected in a locally specular manner (not diffusely). The glint of light off water is a commonplace effect of this. At small angles of incident light, waviness results in reduced reflectivity because of the steepness of the reflectivity-vs.-incident-angle curve and a locally increased average incident angle.Although the reflectivity of water is very low at low and medium angles of incident light, it becomes very high at high angles of incident light such as those that occur on the illuminated side of Earth near the terminator (early morning, late afternoon, and near the poles). However, as mentioned above, waviness causes an appreciable reduction. Because light specularly reflected from water does not usually reach the viewer, water is usually considered to have a very low albedo in spite of its high reflectivity at high angles of incident light.Note that white caps on waves look white (and have high albedo) because the water is foamed up, so there are many superimposed bubble surfaces which reflect, adding up their reflectivities. Fresh 'black' ice exhibits Fresnel reflection.Snow on top of this sea ice increases the albedo to 0.9.CloudsCloud albedo has substantial influence over atmospheric temperatures. Different types of clouds exhibit different reflectivity, theoretically ranging in albedo from a minimum of near 0 to a maximum approaching 0.8. "On any given day, about half of Earth is covered by clouds, which reflect more sunlight than land and water. Clouds keep Earth cool by reflecting sunlight, but they can also serve as blankets to trap warmth."Albedo and climate in some areas are affected by artificial clouds, such as those created by the contrails of heavy commercial airliner traffic. A study following the burning of the Kuwaiti oil fields during Iraqi occupation showed that temperatures under the burning oil fires were as much as  colder than temperatures several miles away under clear skies.Aerosol effectsAerosols (very fine particles/droplets in the atmosphere) have both direct and indirect effects on Earth's radiative balance. The direct (albedo) effect is generally to cool the planet; the indirect effect (the particles act as cloud condensation nuclei and thereby change cloud properties) is less certain. As per Spracklen et al. the effects are: Aerosol direct effect. Aerosols directly scatter and absorb radiation. The scattering of radiation causes atmospheric cooling, whereas absorption can cause atmospheric warming. Aerosol indirect effect. Aerosols modify the properties of clouds through a subset of the aerosol population called cloud condensation nuclei. Increased nuclei concentrations lead to increased cloud droplet number concentrations, which in turn leads to increased cloud albedo, increased light scattering and radiative cooling (first indirect effect), but also leads to reduced precipitation efficiency and increased lifetime of the cloud (second indirect effect).In extremely polluted cities like Delhi, aerosol pollutants influence local weather and induce an urban cool island effect during the day.Black carbonAnother albedo-related effect on the climate is from black carbon particles. The size of this effect is difficult to quantify: the Intergovernmental Panel on Climate Change estimates that the global mean radiative forcing for black carbon aerosols from fossil fuels is +0.2 W m−2, with a range +0.1 to +0.4 W m−2. Black carbon is a bigger cause of the melting of the polar ice cap in the Arctic than carbon dioxide due to its effect on the albedo.Human activitiesHuman activities (e.g., deforestation, farming, and urbanization) change the albedo of various areas around the globe. However, quantification of this effect on the global scale is difficult, further study is required to determine anthropogenic effects.Albedo in Astronomy In astronomy, the term albedo can be defined in several different ways, depending upon the application and the wavelength of electromagnetic radiation involved.Optical or Visual AlbedoThe albedos of planets, satellites and minor planets such as asteroids can be used to infer much about their properties. The study of albedos, their dependence on wavelength, lighting angle ("phase angle"), and variation in time composes a major part of the astronomical field of photometry. For small and far objects that cannot be resolved by telescopes, much of what we know comes from the study of their albedos. For example, the absolute albedo can indicate the surface ice content of outer Solar System objects, the variation of albedo with phase angle gives information about regolith properties, whereas unusually high radar albedo is indicative of high metal content in asteroids.Enceladus, a moon of Saturn, has one of the highest known optical albedos of any body in the Solar System, with an albedo of 0.99. Another notable high-albedo body is Eris, with an albedo of 0.96. Many small objects in the outer Solar System and asteroid belt have low albedos down to about 0.05. A typical comet nucleus has an albedo of 0.04. Such a dark surface is thought to be indicative of a primitive and heavily space weathered surface containing some organic compounds.The overall albedo of the Moon is measured to be around 0.14, but it is strongly directional and non-Lambertian, displaying also a strong opposition effect. Although such reflectance properties are different from those of any terrestrial terrains, they are typical of the regolith surfaces of airless Solar System bodies.Two common optical albedos that are used in astronomy are the (V-band) geometric albedo (measuring brightness when illumination comes from directly behind the observer) and the Bond albedo (measuring total proportion of electromagnetic energy reflected). Their values can differ significantly, which is a common source of confusion.In detailed studies, the directional reflectance properties of astronomical bodies are often expressed in terms of the five Hapke parameters which semi-empirically describe the variation of albedo with phase angle, including a characterization of the opposition effect of regolith surfaces. One of these five parameters is yet another type of albedo called the single-scattering albedo. It is used to define scattering of electromagnetic waves on small particles. It depends on properties of the material (refractive index), the size of the particle, and the wavelength of the incoming radiation. An important relationship between an object's astronomical (geometric) albedo, absolute magnitude and diameter is given by:where  is the astronomical albedo,  is the diameter in kilometers, and  is the absolute magnitude.Radar AlbedoIn planetary radar astronomy, a microwave (or radar) pulse is transmitted toward a planetary target (e.g. Moon, asteroid, etc.) and the echo from the target is measured. In most instances, the transmitted pulse is circularly polarized and the received pulse is measured in the same sense of polarization as the transmitted pulse (SC) and the opposite sense (OC). The echo power is measured in terms of radar cross-section, , , or  (total power, SC + OC) and is equal to the cross-sectional area of a metallic sphere (perfect reflector) at the same distance as the target that would return the same echo power.Those components of the received echo that return from first-surface reflections (as from a smooth or mirror-like surface) are dominated by the OC component as there is a reversal in polarization upon reflection. If the surface is rough at the wavelength scale or there is significant penetration into the regolith, there will be a significant SC component in the echo caused by multiple scattering.For most objects in the solar system, the OC echo dominates and the most commonly reported radar albedo parameter is the (normalized) OC radar albedo (often shortened to radar albedo):where the denominator is the effective cross-sectional area of the target object with mean radius, . A smooth metallic sphere would have .Radar Albedos of Solar System ObjectsThe values reported for the Moon, Mercury, Mars, Venus, and Comet P/2005 JQ5 are derived from the total (OC+SC) radar albedo reported in those references.Relationship to Surface Bulk DensityIn the event that most of the echo is from first surface reflections ( or so), the OC radar albedo is a first-order approximation of the Fresnel reflection coefficient (aka reflectivity) and can be used to estimate the bulk density of a planetary surface to a depth of a meter or so (a few wavelengths of the radar wavelength which is typically at the decimeter scale) using the following empirical relationships: .See also Cool roof Daisyworld Emissivity Exitance Global dimming Irradiance Kirchhoff's law of thermal radiation Opposition surge Polar see-saw Radar astronomy Solar radiation managementReferencesExternal links Albedo Project Albedo – Encyclopedia of Earth NASA MODIS BRDF/albedo product site Ocean surface albedo look-up-table Surface albedo derived from Meteosat observations A discussion of Lunar albedos reflectivity of metals (chart)Land surface effects on climateClimate change feedbacksClimate forcingClimatologyElectromagnetic radiationRadiometryScattering, absorption and radiative transfer (optics)Radiation1760s neologisms
A, or a, is the first letter and the first vowel of the modern English alphabet and the ISO basic Latin alphabet. Its name in English is a (pronounced ), plural aes. It is similar in shape to the Ancient Greek letter alpha, from which it derives. The uppercase version consists of the two slanting sides of a triangle, crossed in the middle by a horizontal bar. The lowercase version can be written in two forms: the double-storey a and single-storey ɑ. The latter is commonly used in handwriting and fonts based on it, especially fonts intended to be read by children, and is also found in italic type.In the English grammar, "a", and its variant "an", are indefinite articles.HistoryThe earliest certain ancestor of "A" is aleph (also written 'aleph), the first letter of the Phoenician alphabet, which consisted entirely of consonants (for that reason, it is also called an abjad to distinguish it from a true alphabet). In turn, the ancestor of aleph may have been a pictogram of an ox head in proto-Sinaitic script influenced by Egyptian hieroglyphs, styled as a triangular head with two horns extended.When the ancient Greeks adopted the alphabet, they had no use for a letter to represent the glottal stop—the consonant sound that the letter denoted in Phoenician and other Semitic languages, and that was the first phoneme of the Phoenician pronunciation of the letter—so they used their version of the sign to represent the vowel , and called it by the similar name of alpha. In the earliest Greek inscriptions after the Greek Dark Ages, dating to the 8th century BC, the letter rests upon its side, but in the Greek alphabet of later times it generally resembles the modern capital letter, although many local varieties can be distinguished by the shortening of one leg, or by the angle at which the cross line is set.The Etruscans brought the Greek alphabet to their civilization in the Italian Peninsula and left the letter unchanged. The Romans later adopted the Etruscan alphabet to write the Latin language, and the resulting letter was preserved in the Latin alphabet that would come to be used to write many languages, including English.Typographic variantsDuring Roman times, there were many variant forms of the letter "A". First was the monumental or lapidary style, which was used when inscribing on stone or other "permanent" media. There was also a cursive style used for everyday or utilitarian writing, which was done on more perishable surfaces. Due to the "perishable" nature of these surfaces, there are not as many examples of this style as there are of the monumental, but there are still many surviving examples of different types of cursive, such as majuscule cursive, minuscule cursive, and semicursive minuscule. Variants also existed that were intermediate between the monumental and cursive styles. The known variants include the early semi-uncial, the uncial, and the later semi-uncial.At the end of the Roman Empire (5th century AD), several variants of the cursive minuscule developed through Western Europe. Among these were the semicursive minuscule of Italy, the Merovingian script in France, the Visigothic script in Spain, and the Insular or Anglo-Irish semi-uncial or Anglo-Saxon majuscule of Great Britain. By the 9th century, the Caroline script, which was very similar to the present-day form, was the principal form used in book-making, before the advent of the printing press. This form was derived through a combining of prior forms.15th-century Italy saw the formation of the two main variants that are known today. These variants, the Italic and Roman forms, were derived from the Caroline Script version. The Italic form, also called script a, is used in most current handwriting; it consists of a circle and vertical stroke on the right ("ɑ"). This slowly developed from the fifth-century form resembling the Greek letter tau in the hands of medieval Irish and English writers. The Roman form is used in most printed material; it consists of a small loop with an arc over it ("a"). Both derive from the majuscule (capital) form. In Greek handwriting, it was common to join the left leg and horizontal stroke into a single loop, as demonstrated by the uncial version shown. Many fonts then made the right leg vertical. In some of these, the serif that began the right leg stroke developed into an arc, resulting in the printed form, while in others it was dropped, resulting in the modern handwritten form. Graphic designers refer to the Italic and Roman forms as "single decker a" and "double decker a" respectively.Italic type is commonly used to mark emphasis or more generally to distinguish one part of a text from the rest (set in Roman type). There are some other cases aside from italic type where script a ("ɑ"), also called Latin alpha, is used in contrast with Latin "a" (such as in the International Phonetic Alphabet).Use in writing systemsEnglishIn modern English orthography, the letter  represents at least seven different vowel sounds:the near-open front unrounded vowel  as in pad;the open back unrounded vowel  as in father, which is closer to its original Latin and Greek sound;the diphthong  as in ace and major (usually when  is followed by one, or occasionally two, consonants and then another vowel letter) – this results from Middle English lengthening followed by the Great Vowel Shift;the modified form of the above sound that occurs before , as in square and Mary;the rounded vowel of water;the shorter rounded vowel (not present in General American) in was and what;a schwa, in many unstressed syllables, as in about, comma, solar.The double  sequence does not occur in native English words, but is found in some words derived from foreign languages such as Aaron and aardvark. However,  occurs in many common digraphs, all with their own sound or sounds, particularly , , , ,  and . is the third-most-commonly used letter in English (after  and ) and French, the second most common in Spanish, and the most common in Portuguese. About 8.167% of letters used in English texts tend to be ; the number is around 7.636% in French, 11.525% in Spanish, and 14.634% for Portuguese.Other languagesIn most languages that use the Latin alphabet,  denotes an open unrounded vowel, such as , , or . An exception is Saanich, in which  (and the glyph Á) stands for a close-mid front unrounded vowel .Other systemsIn phonetic and phonemic notation:in the International Phonetic Alphabet,  is used for the open front unrounded vowel,  is used for the open central unrounded vowel, and  is used for the open back unrounded vowel.in X-SAMPA,  is used for the open front unrounded vowel and  is used for the open back unrounded vowel.Other usesIn algebra, the letter a along with various other letters of the alphabet is often used to denote a variable, with various conventional meanings in different areas of mathematics. Moreover, in 1637, René Descartes "invented the convention of representing unknowns in equations by x, y, and z, and knowns by a, b, and c", and this convention is still often followed, especially in elementary algebra.In geometry, capital A, B, C etc. are used to denote segments, lines, rays, etc. A capital A is also typically used as one of the letters to represent an angle in a triangle, the lowercase a representing the side opposite angle A."A" is often used to denote something or someone of a better or more prestigious quality or status: A-, A or A+, the best grade that can be assigned by teachers for students' schoolwork; "A grade" for clean restaurants; A-list celebrities, etc. Such associations can have a motivating effect, as exposure to the letter A has been found to improve performance, when compared with other letters."A" is used as a prefix on some words, such as asymmetry, to mean "not" or "without" (from Greek).In English grammar, "a", and its variant "an", is an indefinite article, used to introduce noun phrases.Finally, the letter A is used to denote size, as in a narrow size shoe, or a small cup size in a brassiere.Related charactersDescendants and related characters in the Latin alphabetÆ æ : Latin AE ligatureA with diacritics: Å å Ǻ ǻ Ḁ ḁ ẚ Ă ă Ặ ặ Ắ ắ Ằ ằ Ẳ ẳ Ẵ ẵ Ȃ ȃ Â â Ậ ậ Ấ ấ Ầ ầ Ẫ ẫ Ẩ ẩ Ả ả Ǎ ǎ Ⱥ ⱥ Ȧ ȧ Ǡ ǡ Ạ ạ Ä ä Ǟ ǟ À à Ȁ ȁ Á á Ā ā Ā̀ ā̀ Ã ã Ą ą Ą́ ą́ Ą̃ ą̃ A̲ a̲ ᶏPhonetic alphabet symbols related to A (the International Phonetic Alphabet only uses lowercase, but uppercase forms are used in some other writing systems): Ɑ ɑ : Latin letter alpha / script A, which represents an open back unrounded vowel in the IPAᶐ : Latin small letter alpha with retroflex hookⱯ ɐ : Turned A, which represents a near-open central vowel in the IPAΛ ʌ : Turned V (also called a wedge, a caret, or a hat), which represents an open-mid back unrounded vowel in the IPAⱰ ɒ : Turned alpha / script A, which represents an open back rounded vowel in the IPAᶛ : Modifier letter small turned alphaᴀ : Small capital A, an obsolete or non-standard symbol in the International Phonetic Alphabet used to represent various sounds (mainly open vowels)A a ᵄ : Modifier letters are used in the Uralic Phonetic Alphabet (UPA) (sometimes encoded with Unicode subscripts and superscripts)a : Subscript small a is used in Indo-European studiesꬱ : Small letter a reversed-schwa is used in the Teuthonista phonetic transcription systemꞺ ꞻ : Glottal A, used in the transliteration of UgariticDerived signs, symbols and abbreviationsª : an ordinal indicatorÅ : Ångström sign∀ : a turned capital letter A, used in predicate logic to specify universal quantification ("for all")@ : At sign₳ : Argentine australAncestors and siblings in other alphabets𐤀 : Semitic letter Aleph, from which the following symbols originally deriveΑ α : Greek letter Alpha, from which the following letters deriveА а : Cyrillic letter A : Coptic letter Alpha𐌀 : Old Italic A, which is the ancestor of modern Latin A : Runic letter ansuz, which probably derives from old Italic A : Gothic letter aza/asksԱ ա : Armenian letter AybComputing codes 1Other representationsNotesFootnotesReferencesExternal links History of the Alphabet ISO basic Latin lettersVowel letters
Alabama () is a state in the Southeastern region of the United States, bordered by Tennessee to the north; Georgia to the east; Florida and the Gulf of Mexico to the south; and Mississippi to the west. Alabama is the 30th largest by area and the 24th-most populous of the U.S. states. With a total of  of inland waterways, Alabama has among the most of any state.Alabama is nicknamed the Yellowhammer State, after the state bird. Alabama is also known as the "Heart of Dixie" and the "Cotton State". The state tree is the longleaf pine, and the state flower is the camellia. Alabama's capital is Montgomery, and its largest city by population and area is Huntsville. Its oldest city is Mobile, founded by French colonists in 1702 as the capital of French Louisiana. Greater Birmingham is Alabama's largest metropolitan area and its economic center.Originally home to many native tribes, present-day Alabama was a Spanish territory beginning in the sixteenth century until the French acquired it in the early eighteenth century. The British won the territory in 1763 until losing it in the American Revolutionary War. Spain held Mobile as part of Spanish West Florida until 1813. In December 1819, Alabama was recognized as a state. During the antebellum period, Alabama was a major producer of cotton, and widely used African American slave labor. In 1861, the state seceded from the United States to become part of the Confederate States of America, with Montgomery acting as its first capital, and rejoined the Union in 1868. Following the American Civil War, Alabama would suffer decades of economic hardship, in part due to agriculture and a few cash crops being the main driver of the states economy. Similar to other former slave states, Alabamian legislators employed Jim Crow laws to disenfranchise and discriminate against African Americans from the late 19th century up until the 1960s. In the early 20th century, despite the growth of major industries and urban centers, white rural interests dominated the state legislature through the mid-20th century. During this time, urban interests and African Americans were markedly under-represented. High-profile events such as the Selma to Montgomery march made the state a major focal point of the civil rights movement in the 1950s and 1960s. During and after World War II, Alabama grew as the state's economy diversified with new industries. NASA's Marshall Space Flight Center in Huntsville would help Alabama's economic growth in the mid-to-late 20th century, by developing an aerospace industry. Alabama's economy in the 21st century is based on automotive, finance, tourism, manufacturing, aerospace, mineral extraction, healthcare, education, retail, and technology.The state's geography is diverse, with the north dominated by the mountainous Tennessee Valley and the south by Mobile Bay, a historically significant port. Politically, as part of the Deep South, Alabama is predominantly a conservative state, and culturally is known for its Southern culture. Within Alabama, American football, particularly at the college level at schools such as the University of Alabama, Auburn University, Alabama A&M University, Alabama State University, Troy University, the University of South Alabama, and Jacksonville State University, play a major part of the state's culture.EtymologyThe European-American naming of the Alabama River and state was derived from the Alabama people, a Muskogean-speaking tribe whose members lived just below the confluence of the Coosa and Tallapoosa rivers on the upper reaches of the river. In the Alabama language, the word for a person of Alabama lineage is  (or variously  or  in different dialects; the plural form is ). The suggestion that "Alabama" was borrowed from the Choctaw language is unlikely. The word's spelling varies significantly among historical sources. The first usage appears in three accounts of the Hernando de Soto expedition of 1540: Garcilaso de la Vega used , while the Knight of Elvas and Rodrigo Ranjel wrote Alibamu and Limamu, respectively, in transliterations of the term. As early as 1702, the French called the tribe the , with French maps identifying the river as . Other spellings of the name have included Alibamu, Alabamo, Albama, Alebamon, Alibama, Alibamou, Alabamu, Allibamou. and possibly Alabahmu. The use of state names derived from Native American languages is common in the U.S.; an estimated 27 states have names of Native American origin.Sources disagree on the word's meaning. Some scholars suggest the word comes from the Choctaw  (meaning 'plants' or 'weeds') and  (meaning 'to cut', 'to trim', or 'to gather'). The meaning may have been 'clearers of the thicket' or 'herb gatherers', referring to clearing land for cultivation or collecting medicinal plants. The state has numerous place names of Native American origin. However, there are no correspondingly similar words in the Alabama language.An 1842 article in the Jacksonville Republican proposed it meant 'Here We Rest'. This notion was popularized in the 1850s through the writings of Alexander Beaufort Meek. Experts in the Muskogean languages have not found any evidence to support such a translation.HistoryPre-European settlementIndigenous peoples of varying cultures lived in the area for thousands of years before the advent of European colonization. Trade with the northeastern tribes by the Ohio River began during the Burial Mound Period (1000BCE700CE) and continued until European contact.The agrarian Mississippian culture covered most of the state from 1000 to 1600 CE, with one of its major centers built at what is now the Moundville Archaeological Site in Moundville, Alabama. This is the second-largest complex of the classic Middle Mississippian era, after Cahokia in present-day Illinois, which was the center of the culture. Analysis of artifacts from archaeological excavations at Moundville were the basis of scholars' formulating the characteristics of the Southeastern Ceremonial Complex (SECC). Contrary to popular belief, the SECC appears to have no direct links to Mesoamerican culture, but developed independently. The Ceremonial Complex represents a major component of the religion of the Mississippian peoples; it is one of the primary means by which their religion is understood.Among the historical tribes of Native American people living in present-day Alabama at the time of European contact were the Cherokee, an Iroquoian language people; and the Muskogean-speaking Alabama (Alibamu), Chickasaw, Choctaw, Creek, and Koasati. While part of the same large language family, the Muskogee tribes developed distinct cultures and languages.European settlementThe Spanish were the first Europeans to reach Alabama during their exploration of North America in the 16th century. The expedition of Hernando de Soto passed through Mabila and other parts of the state in 1540. More than 160 years later, the French founded the region's first European settlement at Old Mobile in 1702. The city was moved to the current site of Mobile in 1711. This area was claimed by the French from 1702 to 1763 as part of La Louisiane.After the French lost to the British in the Seven Years' War, it became part of British West Florida from 1763 to 1783. After the United States victory in the American Revolutionary War, the territory was divided between the United States and Spain. The latter retained control of this western territory from 1783 until the surrender of the Spanish garrison at Mobile to U.S. forces on April 13, 1813.Thomas Bassett, a loyalist to the British monarchy during the Revolutionary era, was one of the earliest white settlers in the state outside Mobile. He settled in the Tombigbee District during the early 1770s. The district's boundaries were roughly limited to the area within a few miles of the Tombigbee River and included portions of what is today southern Clarke County, northernmost Mobile County, and most of Washington County.What is now the counties of Baldwin and Mobile became part of Spanish West Florida in 1783, part of the independent Republic of West Florida in 1810, and was finally added to the Mississippi Territory in 1812. Most of what is now the northern two-thirds of Alabama was known as the Yazoo lands beginning during the British colonial period. It was claimed by the Province of Georgia from 1767 onwards. Following the Revolutionary War, it remained a part of Georgia, although heavily disputed.With the exception of the area around Mobile and the Yazoo lands, what is now the lower one-third of Alabama was made part of the Mississippi Territory when it was organized in 1798. The Yazoo lands were added to the territory in 1804, following the Yazoo land scandal. Spain kept a claim on its former Spanish West Florida territory in what would become the coastal counties until the Adams–Onís Treaty officially ceded it to the United States in 1819.Early 19th centuryBefore Mississippi's admission to statehood on December 10, 1817, the more sparsely settled eastern half of the territory was separated and named the Alabama Territory. The United States Congress created the Alabama Territory on March 3, 1817. St. Stephens, now abandoned, served as the territorial capital from 1817 to 1819.Alabama was admitted as the 22nd state on December 14, 1819, with Congress selecting Huntsville as the site for the first Constitutional Convention. From July5 to August 2, 1819, delegates met to prepare the new state constitution. Huntsville served as temporary capital from 1819 to 1820, when the seat of government moved to Cahaba in Dallas County.Cahaba, now a ghost town, was the first permanent state capital from 1820 to 1825. The Alabama Fever land rush was underway when the state was admitted to the Union, with settlers and land speculators pouring into the state to take advantage of fertile land suitable for cotton cultivation. Part of the frontier in the 1820s and 1830s, its constitution provided for universal suffrage for white men.Southeastern planters and traders from the Upper South brought slaves with them as the cotton plantations in Alabama expanded. The economy of the central Black Belt (named for its dark, productive soil) was built around large cotton plantations whose owners' wealth grew mainly from slave labor. The area also drew many poor, disenfranchised people who became subsistence farmers. Alabama had an estimated population of under 10,000 people in 1810, but it increased to more than 300,000 people by 1830. Most Native American tribes were completely removed from the state within a few years of the passage of the Indian Removal Act by Congress in 1830.From 1826 to 1846, Tuscaloosa served as Alabama's capital. On January 30, 1846, the Alabama legislature announced it had voted to move the capital city from Tuscaloosa to Montgomery. The first legislative session in the new capital met in December 1847. A new capitol building was erected under the direction of Stephen Decatur Button of Philadelphia. The first structure burned down in 1849, but was rebuilt on the same site in 1851. This second capitol building in Montgomery remains to the present day. It was designed by Barachias Holt of Exeter, Maine.Civil War and ReconstructionBy 1860, the population had increased to 964,201 people, of which nearly half, 435,080, were enslaved African Americans, and 2,690 were free people of color. On January 11, 1861, Alabama declared its secession from the Union. After remaining an independent republic for a few days, it joined the Confederate States of America. The Confederacy's capital was initially at Montgomery. Alabama was heavily involved in the American Civil War. Although comparatively few battles were fought in the state, Alabama contributed about 120,000 soldiers to the war effort.A company of cavalry soldiers from Huntsville, Alabama, joined Nathan Bedford Forrest's battalion in Hopkinsville, Kentucky. The company wore new uniforms with yellow trim on the sleeves, collar and coattails. This led to them being greeted with "Yellowhammer", and the name later was applied to all Alabama troops in the Confederate Army.Alabama's slaves were freed by the 13th Amendment in 1865. Alabama was under military rule from the end of the war in May 1865 until its official restoration to the Union in 1868. From 1867 to 1874, with most white citizens barred temporarily from voting and freedmen enfranchised, many African Americans emerged as political leaders in the state. Alabama was represented in Congress during this period by three African-American congressmen: Jeremiah Haralson, Benjamin S. Turner, and James T. Rapier.Following the war, the state remained chiefly agricultural, with an economy tied to cotton. During Reconstruction, state legislators ratified a new state constitution in 1868 which created the state's first public school system and expanded women's rights. Legislators funded numerous public road and railroad projects, although these were plagued with allegations of fraud and misappropriation. Organized insurgent, resistance groups tried to suppress the freedmen and Republicans. Besides the short-lived original Ku Klux Klan, these included the Pale Faces, Knights of the White Camellia, Red Shirts, and the White League.Reconstruction in Alabama ended in 1874, when the Democrats regained control of the legislature and governor's office through an election dominated by fraud and violence. They wrote another constitution in 1875, and the legislature passed the Blaine Amendment, prohibiting public money from being used to finance religious-affiliated schools. The same year, legislation was approved that called for racially segregated schools. Railroad passenger cars were segregated in 1891.20th centuryThe new 1901 Constitution of Alabama included provisions for voter registration that effectively disenfranchised large portions of the population, including nearly all African Americans and Native Americans, and tens of thousands of poor European Americans, through making voter registration difficult, requiring a poll tax and literacy test. The 1901 constitution required racial segregation of public schools. By 1903 only 2,980 African Americans were registered in Alabama, although at least 74,000 were literate. This compared to more than 181,000 African Americans eligible to vote in 1900. The numbers dropped even more in later decades. The state legislature passed additional racial segregation laws related to public facilities into the 1950s: jails were segregated in 1911; hospitals in 1915; toilets, hotels, and restaurants in 1928; and bus stop waiting rooms in 1945.While the planter class had persuaded poor whites to vote for this legislative effort to suppress black voting, the new restrictions resulted in their disenfranchisement as well, due mostly to the imposition of a cumulative poll tax. By 1941, whites constituted a slight majority of those disenfranchised by these laws: 600,000 whites vs. 520,000 African-Americans. Nearly all Blacks had lost the ability to vote. Despite numerous legal challenges which succeeded in overturning certain provisions, the state legislature would create new ones to maintain disenfranchisement. The exclusion of blacks from the political system persisted until after passage of federal civil rights legislation in 1965 to enforce their constitutional rights as citizens.The rural-dominated Alabama legislature consistently underfunded schools and services for the disenfranchised African Americans, but it did not relieve them of paying taxes. Partially as a response to chronic underfunding of education for African Americans in the South, the Rosenwald Fund began funding the construction of what came to be known as Rosenwald Schools. In Alabama these schools were designed and the construction partially financed with Rosenwald funds, which paid one-third of the construction costs. The fund required the local community and state to raise matching funds to pay the rest. Black residents effectively taxed themselves twice, by raising additional monies to supply matching funds for such schools, which were built in many rural areas. They often donated land and labor as well.Beginning in 1913, the first 80 Rosenwald Schools were built in Alabama for African-American children. A total of 387 schools, seven teachers' houses, and several vocational buildings were completed by 1937 in the state. Several of the surviving school buildings in the state are now listed on the National Register of Historic Places.Continued racial discrimination and lynchings, agricultural depression, and the failure of the cotton crops due to boll weevil infestation led tens of thousands of African Americans from rural Alabama and other states to seek opportunities in northern and midwestern cities during the early decades of the 20th century as part of the Great Migration out of the South. Reflecting this emigration, the population growth rate in Alabama (see "historical populations" table below) dropped by nearly half from 1910 to 1920.At the same time, many rural people migrated to the city of Birmingham to work in new industrial jobs. Birmingham experienced such rapid growth it was called the "Magic City". By 1920, Birmingham was the 36th-largest city in the United States. Heavy industry and mining were the basis of its economy. Its residents were under-represented for decades in the state legislature, which refused to redistrict after each decennial census according to population changes, as it was required by the state constitution. This did not change until the late 1960s following a lawsuit and court order.Industrial development related to the demands of World War II brought a level of prosperity to the state not seen since before the civil war. Rural workers poured into the largest cities in the state for better jobs and a higher standard of living. One example of this massive influx of workers occurred in Mobile. Between 1940 and 1943, more than 89,000 people moved into the city to work for war-related industries. Cotton and other cash crops faded in importance as the state developed a manufacturing and service base.Despite massive population changes in the state from 1901 to 1961, the rural-dominated legislature refused to reapportion House and Senate seats based on population, as required by the state constitution to follow the results of decennial censuses. They held on to old representation to maintain political and economic power in agricultural areas. One result was that Jefferson County, containing Birmingham's industrial and economic powerhouse, contributed more than one-third of all tax revenue to the state, but did not receive a proportional amount in services. Urban interests were consistently underrepresented in the legislature. A 1960 study noted that because of rural domination, "a minority of about 25% of the total state population is in majority control of the Alabama legislature."In the United States Supreme Court cases of Baker v. Carr (1962) and Reynolds v. Sims (1964), the court ruled that the principle of "one man, one vote" needed to be the basis of both houses of state legislatures, and that their districts had to be based on population rather than geographic counties.In 1972, for the first time since 1901, the legislature completed the congressional redistricting based on the decennial census. This benefited the urban areas that had developed, as well as all in the population who had been underrepresented for more than sixty years. Other changes were made to implement representative state house and senate districts.African Americans continued to press in the 1950s and 1960s to end disenfranchisement and segregation in the state through the civil rights movement, including legal challenges. In 1954, the U.S. Supreme Court ruled in Brown v. Board of Education that public schools had to be desegregated, but Alabama was slow to comply. During the 1960s, under Governor George Wallace, Alabama resisted compliance with federal demands for desegregation. The civil rights movement had notable events in Alabama, including the Montgomery bus boycott (1955–1956), Freedom Rides in 1961, and 1965 Selma to Montgomery marches. These contributed to Congressional passage and enactment of the Civil Rights Act of 1964 and Voting Rights Act of 1965 by the U.S. Congress.Legal segregation ended in the states in 1964, but Jim Crow customs often continued until specifically challenged in court. According to The New York Times, by 2017, many of Alabama's African-Americans were living in Alabama's cities such as Birmingham and Montgomery. Also, the Black Belt region across central Alabama "is home to largely poor counties that are predominantly African-American. These counties include Dallas, Lowndes, Marengo and Perry."Alabama has made some changes since the late 20th century and has used new types of voting to increase representation. In the 1980s, an omnibus redistricting case, Dillard v. Crenshaw County, challenged the at-large voting for representative seats of 180 Alabama jurisdictions, including counties and school boards. At-large voting had diluted the votes of any minority in a county, as the majority tended to take all seats. Despite African Americans making up a significant minority in the state, they had been unable to elect any representatives in most of the at-large jurisdictions.As part of settlement of this case, five Alabama cities and counties, including Chilton County, adopted a system of cumulative voting for election of representatives in multi-seat jurisdictions. This has resulted in more proportional representation for voters. In another form of proportional representation, 23 jurisdictions use limited voting, as in Conecuh County. In 1982, limited voting was first tested in Conecuh County. Together use of these systems has increased the number of African Americans and women being elected to local offices, resulting in governments that are more representative of their citizens.Beginning in the 1960s, the state's economy shifted away from its traditional lumber, steel, and textile industries because of increased foreign competition. Steel jobs, for instance, declined from 46,314 in 1950 to 14,185 in 2011. However, the state, particularly Huntsville, benefited from the opening of the George C. Marshall Space Flight Center in 1960, a major facility in the development of the Saturn rocket program and the space shuttle. Technology and manufacturing industries, such as automobile assembly, replaced some the state's older industries in the late twentieth century, but the state's economy and growth lagged behind other states in the area, such as Georgia and Florida.21st centuryIn 2001, Alabama Supreme Court chief justice Roy Moore installed a statue of the Ten Commandments in the capitol in Montgomery. In 2002, the 11th US Circuit Court ordered the statue removed, but Moore refused to follow the court order, which led to protests around the capitol in favor of keeping the monument.  The monument was removed in August 2003.A few natural disasters have occurred in the state in the twenty-first century. In 2004, Hurricane Ivan, a category 3 storm upon landfall, struck the state and caused over $18 billion of damage. It was among the most destructive storms to strike the state in its modern history. A super outbreak of 62 tornadoes hit the state in April 2011 and killed 238 people, devastating many communities.GeographyAlabama is the thirtieth-largest state in the United States with  of total area: 3.2% of the area is water, making Alabama 23rd in the amount of surface water, also giving it the second-largest inland waterway system in the United States. About three-fifths of the land area is part of the Gulf Coastal Plain, a gentle plain with a general descent towards the Mississippi River and the Gulf of Mexico. The North Alabama region is mostly mountainous, with the Tennessee River cutting a large valley and creating numerous creeks, streams, rivers, mountains, and lakes.Alabama is bordered by the states of Tennessee to the north, Georgia to the east, Florida to the south, and Mississippi to the west. Alabama has coastline at the Gulf of Mexico, in the extreme southern edge of the state. The state ranges in elevation from sea level at Mobile Bay to more than  in the northeast, to Mount Cheaha at .Alabama's land consists of  of forest or 67% of the state's total land area. Suburban Baldwin County, along the Gulf Coast, is the largest county in the state in both land area and water area.Areas in Alabama administered by the National Park Service include Horseshoe Bend National Military Park near Alexander City; Little River Canyon National Preserve near Fort Payne; Russell Cave National Monument in Bridgeport; Tuskegee Airmen National Historic Site in Tuskegee; and Tuskegee Institute National Historic Site near Tuskegee. Additionally, Alabama has four National Forests: Conecuh, Talladega, Tuskegee, and William B. Bankhead. Alabama also contains the Natchez Trace Parkway, the Selma To Montgomery National Historic Trail, and the Trail of Tears National Historic Trail.Notable natural wonders include: the "Natural Bridge" rock, the longest natural bridge east of the Rockies, located just south of Haleyville; Cathedral Caverns in Marshall County, named for its cathedral-like appearance, features one of the largest cave entrances and stalagmites in the world; Ecor Rouge in Fairhope, the highest coastline point between Maine and Mexico; DeSoto Caverns in Childersburg, the first officially recorded cave in the United States; Noccalula Falls in Gadsden features a 90-foot waterfall; Dismals Canyon near Phil Campbell, home to two waterfalls, six natural bridges and allegedly served as a hideout for legendary outlaw Jesse James; Stephens Gap Cave in Jackson County boasts a 143-foot pit, two waterfalls and is one of the most photographed wild cave scenes in America; Little River Canyon near Fort Payne, one of the nation's longest mountaintop rivers; Rickwood Caverns near Warrior features an underground pool, blind cave fish and 260-million-year-old limestone formations; and the Walls of Jericho canyon on the Alabama-Tennessee state line.A -wide meteorite impact crater is located in Elmore County, just north of Montgomery. This is the Wetumpka crater, the site of "Alabama's greatest natural disaster". A -wide meteorite hit the area about 80 million years ago. The hills just east of downtown Wetumpka showcase the eroded remains of the impact crater that was blasted into the bedrock, with the area labeled the Wetumpka crater or astrobleme ("star-wound") because of the concentric rings of fractures and zones of shattered rock that can be found beneath the surface. In 2002, Christian Koeberl with the Institute of Geochemistry University of Vienna published evidence and established the site as the 157th recognized impact crater on Earth.ClimateThe state is classified as humid subtropical (Cfa) under the Koppen Climate Classification. The average annual temperature is 64°F (18°C). Temperatures tend to be warmer in the southern part of the state with its proximity to the Gulf of Mexico, while the northern parts of the state, especially in the Appalachian Mountains in the northeast, tend to be slightly cooler. Generally, Alabama has very hot summers and mild winters with copious precipitation throughout the year. Alabama receives an average of  of rainfall annually and enjoys a lengthy growing season of up to 300 days in the southern part of the state.Summers in Alabama are among the hottest in the U.S., with high temperatures averaging over  throughout the summer in some parts of the state. Alabama is also prone to tropical storms and hurricanes. Areas of the state far away from the Gulf are not immune to the effects of the storms, which often dump tremendous amounts of rain as they move inland and weaken.South Alabama reports many thunderstorms. The Gulf Coast, around Mobile Bay, averages between 70 and 80 days per year with thunder reported. This activity decreases somewhat further north in the state, but even the far north of the state reports thunder on about 60 days per year. Occasionally, thunderstorms are severe with frequent lightning and large hail; the central and northern parts of the state are most vulnerable to this type of storm. Alabama ranks ninth in the number of deaths from lightning and tenth in the number of deaths from lightning strikes per capita.Alabama, along with Oklahoma and Iowa, has the most confirmed F5 and EF5 tornadoes of any state, according to statistics from the National Climatic Data Center for the period January 1, 1950, to June 2013. Several long-tracked F5/EF5 tornadoes have contributed to Alabama reporting more tornado fatalities since 1950 than any other state. The state was affected by the 1974 Super Outbreak and was devastated tremendously by the 2011 Super Outbreak. The 2011 Super Outbreak produced a record amount of tornadoes in the state. The tally reached 62.The peak season for tornadoes varies from the northern to southern parts of the state. Alabama is one of the few places in the world that has a secondary tornado season in November and December besides the typically severe spring. The northern part—along the Tennessee River Valley—is most vulnerable. The area of Alabama and Mississippi most affected by tornadoes is sometimes referred to as Dixie Alley, as distinct from the Tornado Alley of the Southern Plains.Winters are generally mild in Alabama, as they are throughout most of the Southeastern United States, with average January low temperatures around  in Mobile and around  in Birmingham. Although snow is a rare event in much of Alabama, areas of the state north of Montgomery may receive a dusting of snow a few times every winter, with an occasional moderately heavy snowfall every few years. Historic snowfall events include New Year's Eve 1963 snowstorm and the 1993 Storm of the Century. The annual average snowfall for the Birmingham area is  per year. In the southern Gulf coast, snowfall is less frequent, sometimes going several years without any snowfall.Alabama's highest temperature of  was recorded on September 5, 1925, in the unincorporated community of Centerville. The record low of  occurred on January 30, 1966, in New Market.Flora and faunaAlabama is home to a diverse array of flora and fauna in habitats that range from the Tennessee Valley, Appalachian Plateau, and Ridge-and-Valley Appalachians of the north to the Piedmont, Canebrake, and Black Belt of the central region to the Gulf Coastal Plain and beaches along the Gulf of Mexico in the south. The state is usually ranked among the top in nation for its range of overall biodiversity.Alabama is in the subtropical coniferous forest biome and once boasted huge expanses of pine forest, which still form the largest proportion of forests in the state. It currently ranks fifth in the nation for the diversity of its flora. It is home to nearly 4,000 pteridophyte and spermatophyte plant species.Indigenous animal species in the state include 62 mammal species, 93 reptile species, 73 amphibian species, roughly 307 native freshwater fish species, and 420 bird species that spend at least part of their year within the state. Invertebrates include 97 crayfish species and 383 mollusk species. 113 of these mollusk species have never been collected outside the state.Census-designated and metropolitan areasCitiesDemographicsAccording to the 2020 United States census the population of Alabama was 5,024,279 on April 1, 2020, which represents an increase of 244,543 or 5.12%, since the 2010 census. This includes a natural increase since the last census of 121,054 (502,457 births minus 381,403 deaths) and an increase due to net migration of 104,991 into the state.Immigration from outside the U.S. resulted in a net increase of 31,180 people, and migration within the country produced a net gain of 73,811 people. The state had 108,000 foreign-born (2.4% of the state population), of which an estimated 22.2% were undocumented (24,000).The center of population of Alabama is located in Chilton County, outside the town of Jemison.AncestryThose citing "American" ancestry in Alabama are of overwhelmingly English extraction, however most English Americans identify simply as having American ancestry because their roots have been in North America for so long, in many cases since the early sixteen hundreds.  Demographers estimate that a minimum of 20–23% of people in Alabama are of predominantly English ancestry and state that the figure is probably much higher. In the 1980 census 1,139,976 people in Alabama cited that they were of English ancestry out of a total state population of 2,824,719 making them 41% of the state at the time and the largest ethnic group.In 2011, 46.6% of Alabama's population younger than age1 were minorities. The largest reported ancestry groups in Alabama are American (13.4%), Irish (10.5%), English (10.2%), German (7.9%), and Scots-Irish (2.5%) based on 2006-2008 Census data.The Scots-Irish were the largest non-English immigrant group from the British Isles before the American Revolution, and many settled in the South, later moving into the Deep South as it was developed.In 1984, under the Davis–Strong Act, the state legislature established the Alabama Indian Affairs Commission. Native American groups within the state had increasingly been demanding recognition as ethnic groups and seeking an end to discrimination. Given the long history of slavery and associated racial segregation, the Native American peoples, who have sometimes been of mixed race, have insisted on having their cultural identification respected. In the past, their self-identification was often overlooked as the state tried to impose a binary breakdown of society into white and black. The state has officially recognized nine American Indian tribes in the state, descended mostly from the Five Civilized Tribes of the American Southeast. These are the following. Poarch Band of Creek Indians (who also have federal recognition) MOWA Band of Choctaw Indians Star Clan of Muscogee Creeks Echota Cherokee Tribe of Alabama Cherokee Tribe of Northeast Alabama Cher-O-Creek Intra Tribal Indians Ma-Chis Lower Creek Indian Tribe Piqua Shawnee Tribe Ani-Yun-Wiya NationThe state government has promoted recognition of Native American contributions to the state, including the designation in 2000 for Columbus Day to be jointly celebrated as American Indian Heritage Day.LanguageMost Alabama residents (95.1% of those five and older) spoke only English at home in 2010, a minor decrease from 96.1% in 2000. Alabama English is predominantly Southern, and is related to South Midland speech which was taken across the border from Tennessee. In the major Southern speech region, there is the decreasing loss of the final r, for example the "boyd" pronunciation of "bird". In the northern third of the state, there is a South Midland "arm" and "barb" rhyming with "form" and "orb". Unique words in Alabama English include: redworm (earthworm), peckerwood (woodpecker), snake doctor and snake feeder (dragonfly), tow sack (burlap bag), plum peach (clingstone), French harp (harmonica), and dog irons (andirons).ReligionIn the 2008 American Religious Identification Survey, 86% of Alabama respondents reported their religion as Christian, including 6% Catholic, with 11% as having no religion. The composition of other traditions is 0.5% Mormon, 0.5% Jewish, 0.5% Muslim, 0.5% Buddhist, and 0.5% Hindu.Alabama is located in the middle of the Bible Belt, a region of numerous Protestant Christians. Alabama has been identified as one of the most religious states in the United States, with about 58% of the population attending church regularly. A majority of people in the state identify as Evangelical Protestant. , the three largest denominational groups in Alabama are the Southern Baptist Convention, The United Methodist Church, and non-denominational Evangelical Protestant.In Alabama, the Southern Baptist Convention has the highest number of adherents with 1,380,121; this is followed by the United Methodist Church with 327,734 adherents, non-denominational Evangelical Protestant with 220,938 adherents, and the Catholic Church with 150,647 adherents. Many Baptist and Methodist congregations became established in the Great Awakening of the early 19th century, when preachers proselytized across the South. The Assemblies of God had almost 60,000 members, the Churches of Christ had nearly 120,000 members. The Presbyterian churches, strongly associated with Scots-Irish immigrants of the 18th century and their descendants, had a combined membership around 75,000 (PCA—28,009 members in 108 congregations, PC(USA)—26,247 members in 147 congregations, the Cumberland Presbyterian Church—6,000 members in 59 congregations, the Cumberland Presbyterian Church in America—5,000 members and fifty congregations plus the EPC and Associate Reformed Presbyterians with 230 members and nine congregations).In a 2007 survey, nearly 70% of respondents could name all four of the Christian Gospels. Of those who indicated a religious preference, 59% said they possessed a "full understanding" of their faith and needed no further learning. In a 2007 poll, 92% of Alabamians reported having at least some confidence in churches in the state.Although in much smaller numbers, many other religious faiths are represented in the state as well, including Judaism, Islam, Hinduism, Buddhism, Sikhism, the Baháʼí Faith, and Unitarian Universalism.Jews have been present in what is now Alabama since 1763, during the colonial era of Mobile, when Sephardic Jews immigrated from London. The oldest Jewish congregation in the state is Congregation Sha'arai Shomayim in Mobile. It was formally recognized by the state legislature on January 25, 1844. Later immigrants in the nineteenth and twentieth centuries tended to be Ashkenazi Jews from eastern Europe. Jewish denominations in the state include two Orthodox, four Conservative, ten Reform, and one Humanistic synagogue.Muslims have been increasing in Alabama, with 31 mosques built by 2011, many by African-American converts.Several Hindu temples and cultural centers in the state have been founded by Indian immigrants and their descendants, the best-known being the Shri Swaminarayan Mandir in Birmingham, the Hindu Temple and Cultural Center of Birmingham in Pelham, the Hindu Cultural Center of North Alabama in Capshaw, and the Hindu Mandir and Cultural Center in Tuscaloosa.There are six Dharma centers and organizations for Theravada Buddhists. Most monastic Buddhist temples are concentrated in southern Mobile County, near Bayou La Batre. This area has attracted an influx of refugees from Cambodia, Laos, and Vietnam during the 1970s and thereafter. The four temples within a ten-mile radius of Bayou La Batre, include Chua Chanh Giac, Wat Buddharaksa, and Wat Lao Phoutthavihan.The first community of adherents of the Baháʼí Faith in Alabama was founded in 1896 by Paul K. Dealy, who moved from Chicago to Fairhope. Baháʼí centers in Alabama exist in Birmingham, Huntsville, and Florence.HealthIn 2018, life expectancy in Alabama was 75.1 years, below the national average of 78.7 years and is the third lowest life expectancy in the country. Factors that can cause lower life expectancy are maternal mortality, suicide, and gun crimes.A Centers for Disease Control and Prevention study in 2008 showed that obesity in Alabama is a problem, with most counties having more than 29% of adults obese, except for ten which had a rate between 26% and 29%. Residents of the state, along with those in five other states, were least likely in the nation to be physically active during leisure time. Alabama, and the southeastern U.S. in general, has one of the highest incidences of adult onset diabetes in the country, exceeding 10% of adults.On May 14, 2019, Alabama passed the Human Life Protection Act, banning abortion at any stage of pregnancy unless there is a "serious health risk", with no exceptions for rape and incest. The law, if enacted, would punish doctors who perform abortions with 10 to 99 years imprisonment and be the most restrictive abortion law in the country. However, on October 29, 2019, U.S. District Judge Myron Thompson blocked the law from taking effect.EconomyThe state has invested in aerospace, education, health care, banking, and various heavy industries, including automobile manufacturing, mineral extraction, steel production and fabrication. By 2006, crop and animal production in Alabama was valued at $1.5billion. In contrast to the primarily agricultural economy of the previous century, this was only about one percent of the state's gross domestic product. The number of private farms has declined at a steady rate since the 1960s, as land has been sold to developers, timber companies, and large farming conglomerates.Non-agricultural employment in 2008 was 121,800 in management occupations; 71,750 in business and financial operations; 36,790 in computer-related and mathematical occupation; 44,200 in architecture and engineering; 12,410 in life, physical, and social sciences; 32,260 in community and social services; 12,770 in legal occupations; 116,250 in education, training, and library services; 27,840 in art, design and media occupations; 121,110 in healthcare; 44,750 in fire fighting, law enforcement, and security; 154,040 in food preparation and serving; 76,650 in building and grounds cleaning and maintenance; 53,230 in personal care and services; 244,510 in sales; 338,760 in office and administration support; 20,510 in farming, fishing, and forestry; 120,155 in construction and mining, gas, and oil extraction; 106,280 in installation, maintenance, and repair; 224,110 in production; and 167,160 in transportation and material moving.According to the U.S. Bureau of Economic Analysis, the 2008 total gross state product was $170billion, or $29,411 per capita. Alabama's 2012 GDP increased 1.2% from the previous year. The single largest increase came in the area of information. In 2010, per capita income for the state was $22,984.The state's seasonally adjusted unemployment rate was 5.8% in April 2015. This compared to a nationwide seasonally adjusted rate of 5.4%.Alabama has no minimum wage and in February 2016 passed legislation preventing municipalities from setting one. (A Birmingham city ordinance would have raised theirs to $10.10.), Alabama has the sixth highest poverty rate among states in the U.S. In 2017, United Nations Special Rapporteur Philip Alston toured parts of rural Alabama and observed environmental conditions he said were poorer than anywhere he had seen in the developed world.Largest employersThe five employers that employed the most employees in Alabama in April 2011 were:The next twenty largest employers, , included:AgricultureAlabama's agricultural outputs include poultry and eggs, cattle, fish, plant nursery items, peanuts, cotton, grains such as corn and sorghum, vegetables, milk, soybeans, and peaches. Although known as "The Cotton State", Alabama ranks between eighth and tenth in national cotton production, according to various reports, with Texas, Georgia and Mississippi comprising the top three.Aquaculture Aquaculture is a large part of the economy of Alabama. Alabamians began to practice aquaculture in the early 1960s. U.S. farm-raised catfish is the 8th most popular seafood product in America. By 2008, approximately 4,000 people in Alabama were employed by the catfish industry and Alabama produced 132 million pounds of catfish. In 2020, Alabama produced ⅓ of the United States' farm-raised catfish. The total 2020 sales of catfish raised in Alabama equaled $307 million but by 2020 the total employment of Alabamians fell to 2,442.From the early 2000s to 2020, the Alabamian catfish industry has declined from 250 farms and 4 processors to 66 farms and 2 processors. Reasons for this decline include increased feed prices, catfish alternatives, COVID-19’s impact on restaurant sales, disease, and fish size.IndustryAlabama's industrial outputs include iron and steel products (including cast-iron and steel pipe); paper, lumber, and wood products; mining (mostly coal); plastic products; cars and trucks; and apparel. In addition, Alabama produces aerospace and electronic products, mostly in the Huntsville area, the location of NASA's George C. Marshall Space Flight Center and the U.S. Army Materiel Command, headquartered at Redstone Arsenal.A great deal of Alabama's economic growth since the 1990s has been due to the state's expanding automotive manufacturing industry. Located in the state are Honda Manufacturing of Alabama, Hyundai Motor Manufacturing Alabama, Mercedes-Benz U.S. International, and Toyota Motor Manufacturing Alabama, as well as their various suppliers. Since 1993, the automobile industry has generated more than 67,800 new jobs in the state. Alabama currently ranks 4th in the nation for vehicle exports.Automakers accounted for approximately a third of the industrial expansion in the state in 2012. The eight models produced at the state's auto factories totaled combined sales of 74,335 vehicles for 2012. The strongest model sales during this period were the Hyundai Elantra compact car, the Mercedes-Benz GL-Class sport utility vehicle and the Honda Ridgeline sport utility truck.Steel producers Outokumpu, Nucor, SSAB, ThyssenKrupp, and U.S. Steel have facilities in Alabama and employ more than 10,000 people. In May 2007, German steelmaker ThyssenKrupp selected Calvert in Mobile County for a 4.65billion combined stainless and carbon steel processing facility. ThyssenKrupp's stainless steel division, Inoxum, including the stainless portion of the Calvert plant, was sold to Finnish stainless steel company Outokumpu in 2012. The remaining portion of the ThyssenKrupp plant had final bids submitted by ArcelorMittal and Nippon Steel for $1.6billion in March 2013. Companhia Siderúrgica Nacional submitted a combined bid for the mill at Calvert, plus a majority stake in the ThyssenKrupp mill in Brazil, for $3.8billion. In July 2013, the plant was sold to ArcelorMittal and Nippon Steel.The Hunt Refining Company, a subsidiary of Hunt Consolidated, Inc., is based in Tuscaloosa and operates a refinery there. The company also operates terminals in Mobile, Melvin, and Moundville. JVC America, Inc. operates an optical disc replication and packaging plant in Tuscaloosa.The Goodyear Tire and Rubber Company operates a large plant in Gadsden which employs about 1,400 people. It has been in operation since 1929.Construction of an Airbus A320 family aircraft assembly plant in Mobile was formally announced by Airbus CEO Fabrice Brégier from the Mobile Convention Center on July 2, 2012. The plans include a $600million factory at the Brookley Aeroplex for the assembly of the A319, A320 and A321 aircraft. Construction began in 2013, with plans for it to become operable by 2015 and produce up to 50 aircraft per year by 2017. The assembly plant is the company's first factory to be built within the United States. It was announced on February 1, 2013, that Airbus had hired Alabama-based Hoar Construction to oversee construction of the facility.Tourism and entertainmentAccording to Business Insider, Alabama ranked 14th in most popular states to visit in 2014. An estimated 26 million tourists visited the state in 2017 and spent $14.3 billion, providing directly or indirectly 186,900 jobs in the state, which includes 362,000 International tourists spending $589 million.The state is home to various attractions, natural features, parks and events that attract visitors from around the globe, notably the annual Hangout Music Festival, held on the public beaches of Gulf Shores; the Alabama Shakespeare Festival, one of the ten largest Shakespeare festivals in the world; the Robert Trent Jones Golf Trail, a collection of championship caliber golf courses distributed across the state; casinos such as Victoryland; amusement parks such as Alabama Splash Adventure; the Riverchase Galleria, one of the largest shopping centers in the southeast; Guntersville Lake, voted the best lake in Alabama by Southern Living Magazine readers; and the Alabama Museum of Natural History, the oldest museum in the state.Mobile is known for having the oldest organized Mardi Gras celebration in the United States, beginning in 1703. It was also host to the first formally organized Mardi Gras parade in the United States in 1830, a tradition that continues to this day. Mardi Gras is an official state holiday in Mobile and Baldwin counties.In 2018, Mobile's Mardi Gras parade was the state's top event, producing the most tourists with an attendance of 892,811. The top attraction was the U.S. Space & Rocket Center in Huntsville with an attendance of 849,981, followed by the Birmingham Zoo with 543,090. Of the parks and natural destinations, Alabama's Gulf Coast topped the list with 6,700,000 visitors.Alabama has historically been a popular region for film shoots due to its diverse landscapes and contrast of environments. Movies filmed in Alabama include: Close Encounters of the Third Kind, Get Out, 42, Selma, Big Fish, The Final Destination, Due Date, Need For Speed and many more.HealthcareUAB Hospital, USA Health University Hospital, Huntsville Hospital, and Children's Hospital of Alabama are the only LevelI trauma centers in Alabama. UAB is the largest state government employer in Alabama, with a workforce of about 18,000. A 2017 study found that Alabama had the least competitive health insurance market in the country, with Blue Cross and Blue Shield of Alabama having a market share of 84% followed by UnitedHealth Group at 7%.BankingRegions Financial Corporation is the largest bank headquartered in or operating in Alabama. PNC Financial Services  and Wells Fargo also have a major presence in Alabama.Wells Fargo has a regional headquarters, an operations center campus, and a $400million data center in Birmingham. Many smaller banks are also headquartered in the Birmingham area, including ServisFirst and New South Federal Savings Bank. Birmingham also serves as the headquarters for several large investment management companies, including Harbert Management Corporation.Electronics and communicationsTelecommunications provider AT&T, formerly BellSouth, has a major presence in Alabama with several large offices in Birmingham.Many technology companies are headquartered in Huntsville, such as ADTRAN, a network access company; Intergraph, a computer graphics company; and Avocent, an IT infrastructure company.ConstructionBrasfield & Gorrie, BE&K, Hoar Construction, and B.L. Harbert International, based in Alabama and subsidiaries of URS Corporation, are all routinely are included in the Engineering News-Record lists of top design, international construction, and engineering firms.Law and governmentState governmentThe foundational document for Alabama's government is the Alabama Constitution, which was ratified in 1901. With over 850 amendments and almost 87,000 words, it is by some accounts the world's longest constitution and is roughly forty times the length of the United States Constitution.There has been a significant movement to rewrite and modernize Alabama's constitution. Critics argue that Alabama's constitution maintains highly centralized power with the state legislature, leaving practically no power in local hands. Most counties do not have home rule. Any policy changes proposed in different areas of the state must be approved by the entire Alabama legislature and, frequently, by state referendum. One criticism of the current constitution claims that its complexity and length intentionally codify segregation and racism.Alabama's government is divided into three coequal branches. The legislative branch is the Alabama Legislature, a bicameral assembly composed of the Alabama House of Representatives, with 105 members, and the Alabama Senate, with 35 members. The Legislature is responsible for writing, debating, passing, or defeating state legislation. The Republican Party currently holds a majority in both houses of the Legislature. The Legislature has the power to override a gubernatorial veto by a simple majority (most state Legislatures require a two-thirds majority to override a veto).Until 1964, the state elected state senators on a geographic basis by county, with one per county. It had not redistricted congressional districts since passage of its constitution in 1901; as a result, urbanized areas were grossly underrepresented. It had not changed legislative districts to reflect the decennial censuses, either. In Reynolds v. Sims (1964), the U.S. Supreme Court implemented the principle of "one man, one vote", ruling that congressional districts had to be reapportioned based on censuses (as the state already included in its constitution but had not implemented.) Further, the court ruled that both houses of bicameral state legislatures had to be apportioned by population, as there was no constitutional basis for states to have geographically based systems.At that time, Alabama and many other states had to change their legislative districting, as many across the country had systems that underrepresented urban areas and districts. This had caused decades of underinvestment in such areas. For instance, Birmingham and Jefferson County taxes had supplied one-third of the state budget, but Jefferson County received only 1/67th of state services in funding. Through the legislative delegations, the Alabama legislature kept control of county governments.The executive branch is responsible for the execution and oversight of laws. It is headed by the governor of Alabama. Other members of the executive branch include the cabinet, the lieutenant governor of Alabama, the Attorney General of Alabama, the Alabama Secretary of State, the Alabama State Treasurer, and the State Auditor of Alabama. The current governor is Republican Kay Ivey.The members of the Legislature take office immediately after the November elections. Statewide officials, such as the governor, lieutenant governor, attorney general, and other constitutional officers, take office the following January.The judiciary is responsible for interpreting the Constitution of Alabama and applying the law in state criminal and civil cases. The state's highest court is the Supreme Court of Alabama. Alabama uses partisan elections to select judges. Since the 1980s judicial campaigns have become increasingly politicized. The current chief justice of the Alabama Supreme Court is Republican Tom Parker. All sitting justices on the Alabama Supreme Court are members of the Republican Party. There are two intermediate appellate courts, the Court of Civil Appeals and the Court of Criminal Appeals, and four trial courts: the circuit court (trial court of general jurisdiction), and the district, probate, and municipal courts.Some critics believe the election of judges has contributed to an exceedingly high rate of executions. Alabama has the highest per capita death penalty rate in the country. In some years, it imposes more death sentences than does Texas, a state which has a population five times larger. However, executions per capita are significantly higher in Texas. Some of its cases have been highly controversial; the U.S. Supreme Court has overturned 24 convictions in death penalty cases. It was the only state to allow judges to override jury decisions in whether or not to use a death sentence; in 10 cases judges overturned sentences of life imprisonment without parole that were voted unanimously by juries. This judicial authority was removed in April 2017.TaxesTaxes are collected by the Alabama Department of Revenue. Alabama levies a 2%, 4%, or5% personal income tax, depending on the amount earned and filing status. Taxpayers are allowed to deduct their federal income tax from their Alabama state tax, even if taking the standard deduction; those who itemize can also deduct FICA (the Social Security and Medicare tax).The state's general sales tax rate is 4%. Sales tax rates for cities and counties are also added to purchases.</ref> For example, the total sales tax rate in Mobile County, Alabama is 10% and there is an additional restaurant tax of 1%, which means a diner in Mobile County, Alabama would pay an 11% tax on a meal.In 2020, sales and excise taxes in Alabama accounted for 38% of all state and local revenue.Only Alabama, Mississippi, and South Dakota tax groceries at the full state sales tax rate.The corporate income tax rate in Alabama is 6.5%. The overall federal, state, and local tax burden in Alabama ranks the state as the second least tax-burdened state in the country.Property taxes of .40% of assessed value per year, are the second-lowest in the U.S., after Hawaii. The current state constitution requires a voter referendum to raise property taxes.County and local governmentsAlabama has 67 counties. Each county has its own elected legislative branch, usually called the county commission. It also has limited executive authority in the county. Because of the constraints of the Alabama Constitution, which centralizes power in the state legislature, only seven counties (Jefferson, Lee, Mobile, Madison, Montgomery, Shelby, and Tuscaloosa) in the state have limited home rule. Instead, most counties in the state must lobby the Local Legislation Committee of the state legislature to get simple local policies approved, ranging from waste disposal to land use zoning.The state legislature has retained power over local governments by refusing to pass a constitutional amendment establishing home rule for counties, as recommended by the 1973 Alabama Constitutional Commission. Legislative delegations retain certain powers over each county. United States Supreme Court decisions in Baker v. Carr (1964) required that both houses have districts established on the basis of population, and redistricted after each census, to implement the principle of "one man, one vote". Before that, each county was represented by one state senator, leading to under-representation in the state senate for more urbanized, populous counties. The rural bias of the state legislature, which had also failed to redistrict seats in the state house, affected politics well into the 20th century, failing to recognize the rise of industrial cities and urbanized areas."The lack of home rule for counties in Alabama has resulted in the proliferation of local legislation permitting counties to do things not authorized by the state constitution. Alabama's constitution has been amended more than 700 times, and almost one-third of the amendments are local in nature, applying to only one county or city. A significant part of each legislative session is spent on local legislation, taking away time and attention of legislators from issues of statewide importance."Alabama is an alcoholic beverage control state, meaning the state government holds a monopoly on the sale of alcohol. The Alabama Alcoholic Beverage Control Board controls the sale and distribution of alcoholic beverages in the state. A total of 25 of the 67 counties are "dry counties" which ban the sale of alcohol, and there are many dry municipalities in counties which permit alcohol sales.PoliticsDuring Reconstruction following the American Civil War, Alabama was occupied by federal troops of the Third Military District under General John Pope. In 1874, the political coalition of white Democrats known as the Redeemers took control of the state government from the Republicans, in part by suppressing the black vote through violence, fraud, and intimidation.After 1890, a coalition of White Democratic politicians passed laws to segregate and disenfranchise African American residents, a process completed in provisions of the 1901 constitution. Provisions which disenfranchised blacks resulted in excluding many poor Whites. By 1941 more Whites than Blacks had been disenfranchised: 600,000 to 520,000. The total effects were greater on the black community, as almost all its citizens were disfranchised and relegated to separate and unequal treatment under the law.From 1901 through the 1960s, the state did not redraw election districts as population grew and shifted within the state during urbanization and industrialization of certain areas. As counties were the basis of election districts, the result was a rural minority that dominated state politics through nearly three-quarters of the century, until a series of federal court cases required redistricting in 1972 to meet equal representation.Alabama state politics gained nationwide and international attention in the 1950s and 1960s during the civil rights movement, when whites bureaucratically, and at times violently, resisted protests for electoral and social reform. Governor George Wallace, the state's only four-term governor, was a controversial figure who vowed to maintain segregation. Only after passage of the federal Civil Rights Act of 1964 and Voting Rights Act of 1965 did African Americans regain the ability to exercise suffrage, among other civil rights. In many jurisdictions, they continued to be excluded from representation by at-large electoral systems, which allowed the majority of the population to dominate elections. Some changes at the county level have occurred following court challenges to establish single-member districts that enable a more diverse representation among county boards.In 2007, the Alabama Legislature passed, and Republican governor Bob Riley signed a resolution expressing "profound regret" over slavery and its lingering impact. In a symbolic ceremony, the bill was signed in the Alabama State Capitol, which housed Congress of the Confederate States of America.In 2010, Republicans won control of both houses of the legislature for the first time in 136 years., there are a total of 3,589,839 registered voters, with 3,518,285 active, and the others inactive in the state.ElectionsIn a 2020 study, Alabama was ranked as the 12th most difficult state for citizens to vote.State electionsWith the disfranchisement of Blacks in 1901, the state became part of the "Solid South", a system in which the Democratic Party operated as effectively the only viable political party in every Southern state. For nearly a hundred years local and state elections in Alabama were decided in the Democratic Party primary, with generally only token Republican challengers running in the General Election. Since the mid- to late 20th century, however, white conservatives started shifting to the Republican Party. In Alabama, majority-white districts are now expected to regularly elect Republican candidates to federal, state and local office.Members of the nine seats on the Supreme Court of Alabama and all ten seats on the state appellate courts are elected to office. Until 1994, no Republicans held any of the court seats. In that general election, the then-incumbent chief justice, Ernest C. Hornsby, refused to leave office after losing the election by approximately 3,000 votes to Republican Perry O. Hooper Sr. Hornsby sued Alabama and defiantly remained in office for nearly a year before finally giving up the seat after losing in court. The Democrats lost the last of the nineteen court seats in August 2011 with the resignation of the last Democrat on the bench.In the early 21st century, Republicans hold all seven of the statewide elected executive branch offices. Republicans hold six of the eight elected seats on the Alabama State Board of Education. In 2010, Republicans took large majorities of both chambers of the state legislature, giving them control of that body for the first time in 136 years. The last remaining statewide Democrat, who served on the Alabama Public Service Commission, was defeated in 2012.Only three Republican lieutenant governors have been elected since the end of Reconstruction, when Republicans generally represented Reconstruction government, including the newly emancipated freedmen who had gained the franchise. The three GOP lieutenant governors are Steve Windom (1999–2003), Kay Ivey (2011–2017), and Will Ainsworth (2019–present).Local electionsMany local offices (county commissioners, boards of education, tax assessors, tax collectors, etc.) in the state are still held by Democrats. Many rural counties have voters who are majority Democrats, resulting in local elections being decided in the Democratic primary. Similarly many metropolitan and suburban counties are majority-Republican and elections are effectively decided in the Republican Primary, although there are exceptions.Alabama's 67 county sheriffs are elected in partisan, at-large races, and Democrats still retain the narrow majority of those posts. The current split is 35 Democrats, 31 Republicans, and one Independent Fayette. However, most of the Democratic sheriffs preside over rural and less populated counties. The majority of Republican sheriffs have been elected in the more urban/suburban and heavily populated counties. , the state of Alabama has one female sheriff, in Morgan County, Alabama, and ten African-American sheriffs.Federal electionsThe state's two U.S. senators are Republican Richard C. Shelby and Republican Tommy Tuberville. Shelby was originally elected to the Senate as a Democrat in 1986 and re-elected in 1992, but switched parties immediately following the November 1994 general election.In the U.S. House of Representatives, the state is represented by seven members, six of whom are Republicans: (Bradley Byrne, Mike D. Rogers, Robert Aderholt, Morris J. Brooks, Martha Roby, and Gary Palmer) and one Democrat: Terri Sewell who represents the Black Belt as well as most of the predominantly black portions of Birmingham, Tuscaloosa and Montgomery.EducationPrimary and secondary educationPublic primary and secondary education in Alabama is under the purview of the Alabama State Board of Education as well as local oversight by 67 county school boards and 60 city boards of education. Together, 1,496 individual schools provide education for 744,637 elementary and secondary students.Public school funding is appropriated through the Alabama Legislature through the Education Trust Fund. In FY 2006–2007, Alabama appropriated $3,775,163,578 for primary and secondary education. That represented an increase of $444,736,387 over the previous fiscal year. In 2007, more than 82 percent of schools made adequate yearly progress (AYP) toward student proficiency under the National No Child Left Behind law, using measures determined by the state of Alabama.While Alabama's public education system has improved in recent decades, it lags behind in achievement compared to other states. According to U.S. Census data (2000), Alabama's high school graduation rate (75%) is the fourth lowest in the U.S. (after Kentucky, Louisiana and Mississippi). The largest educational gains were among people with some college education but without degrees.Generally prohibited in the West at large, school corporal punishment is not unusual in Alabama, with 27,260 public school students paddled at least one time, according to government data for the 2011–2012 school year. The rate of school corporal punishment in Alabama is surpassed by only Mississippi and Arkansas.Colleges and universitiesAlabama's programs of higher education include 14 four-year public universities, two-year community colleges, and 17 private, undergraduate and graduate universities. In the state are four medical schools (as of fall 2015) (University of Alabama School of Medicine, University of South Alabama and Alabama College of Osteopathic Medicine and The Edward Via College of Osteopathic Medicine—Auburn Campus), two veterinary colleges (Auburn University and Tuskegee University), a dental school (University of Alabama School of Dentistry), an optometry college (University of Alabama at Birmingham), two pharmacy schools (Auburn University and Samford University), and five law schools (University of Alabama School of Law, Birmingham School of Law, Cumberland School of Law, Miles Law School, and the Thomas Goode Jones School of Law). Public, post-secondary education in Alabama is overseen by the Alabama Commission on Higher Education and the Alabama Department of Postsecondary Education. Colleges and universities in Alabama offer degree programs from two-year associate degrees to a multitude of doctoral level programs.The largest single campus is the University of Alabama, located in Tuscaloosa, with 37,665 enrolled for fall 2016. Troy University was the largest institution in the state in 2010, with an enrollment of 29,689 students across four Alabama campuses (Troy, Dothan, Montgomery, and Phenix City), as well as sixty learning sites in seventeen other states and eleven other countries. The oldest institutions are the public University of North Alabama in Florence and the Catholic Church-affiliated Spring Hill College in Mobile, both founded in 1830.Accreditation of academic programs is through the Southern Association of Colleges and Schools (SACS) as well as other subject-focused national and international accreditation agencies such as the Association for Biblical Higher Education (ABHE), the Council on Occupational Education (COE), and the Accrediting Council for Independent Colleges and Schools (ACICS).According to the 2011 U.S. News & World Report, Alabama had three universities ranked in the top 100 Public Schools in America (University of Alabama at 31, Auburn University at 36, and University of Alabama at Birmingham at 73).According to the 2012 U.S. News & World Report, Alabama had four tier one universities (University of Alabama, Auburn University, University of Alabama at Birmingham and University of Alabama in Huntsville).MediaMajor newspapers include Birmingham News, Mobile Press-Register, and Montgomery Advertiser.Major television network affiliates in Alabama include: ABC WGWW 40.2 ABC, Anniston WBMA 58/WABM 68.2 ABC, Birmingham WDHN 18 ABC, Dothan WAAY 31 ABC, Huntsville WEAR 3 ABC Pensacola, Florida/Mobile WNCF 32 ABC, Montgomery WDBB 17.2 ABC, Tuscaloosa CBS WIAT 42 CBS, Birmingham WTVY 4 CBS, Dothan WHNT 19 CBS, Huntsville WKRG 5 CBS, Mobile WAKA 8 CBS, Selma/Montgomery Fox WBRC 6 FOX, Birmingham WZDX 54 FOX, Huntsville WALA 10 FOX, Mobile WCOV 20 FOX, Montgomery WDFX 34 FOX, Ozark/Dothan NBC WVTM 13 NBC, Birmingham WRGX 23 NBC, Dothan WAFF 48 NBC, Huntsville WPMI 15 NBC, Mobile WSFA 12 NBC, Montgomery PBS/Alabama Public Television WBIQ 10 PBS, Birmingham WIIQ 41 PBS, Demopolis WDIQ 2 PBS, Dozier WFIQ 36 PBS, Florence WHIQ 25 PBS, Huntsville WGIQ 43 PBS, Louisville WEIQ 42 PBS, Mobile WAIQ 26 PBS, Montgomery WCIQ 7 PBS, Mount Cheaha The CW WTTO 21, Homewood/Birmingham WTVY 4.3, Dothan WHDF 15, Florence/Huntsville WFNA 55, Gulf Shores/Mobile/Pensacola, FL WDBB 17, Tuscaloosa WBMM 22, Tuskegee/MontgomeryCultureLiteratureSportsProfessional sportsAlabama has several professional and semi-professional sports teams, including three minor league baseball teams.NotesThe Talladega Superspeedway motorsports complex hosts a series of NASCAR events. It has a seating capacity of 143,000 and is the thirteenth largest stadium in the world and sixth largest stadium in America. Also, the Barber Motorsports Park has hosted IndyCar Series and Rolex Sports Car Series races.The ATP Birmingham was a World Championship Tennis tournament held from 1973 to 1980.Alabama has hosted several professional golf tournaments, such as the 1984 and 1990 PGA Championship at Shoal Creek, the Barbasol Championship (PGA Tour), the Mobile LPGA Tournament of Champions, Airbus LPGA Classic, and Yokohama Tire LPGA Classic (LPGA Tour), and The Tradition (Champions Tour).College sportsCollege football is extremely popular in Alabama, particularly the University of Alabama Crimson Tide and Auburn University Tigers, rivals in the Southeastern Conference. Alabama averages over 100,000 fans per game and Auburn averages over 80,000—both numbers among the top twenty in the nation. Bryant–Denny Stadium is the home of the Alabama football team, and has a seating capacity of 101,821, and is the fifth largest stadium in America. Jordan-Hare Stadium is the home field of the Auburn football team and seats up to 87,451.Legion Field is home of the UAB Blazers football program and the Birmingham Bowl. It seats 71,594. Ladd–Peebles Stadium in Mobile is the home of the University of South Alabama football team, and serves as the home of the NCAA Senior Bowl, LendingTree Bowl, and Alabama-Mississippi All Star Classic; the stadium seats 40,646. In 2009, Bryant–Denny Stadium and Jordan-Hare Stadium became the homes of the Alabama High School Athletic Association state football championship games, after previously being held at Legion Field in Birmingham.TransportationAviationMajor airports with sustained operations in Alabama include Birmingham-Shuttlesworth International Airport (BHM), Huntsville International Airport (HSV), Dothan Regional Airport (DHN), Mobile Regional Airport (MOB), Montgomery Regional Airport (MGM), Northwest Alabama Regional Airport (MSL) and Northeast Alabama Regional Airport (GAD).RailFor rail transport, Amtrak schedules the Crescent, a daily passenger train, running from New York to New Orleans with station stops at Anniston, Birmingham, and Tuscaloosa.RoadsAlabama has six major interstate routes: Interstate 65 (I-65) travels north–south roughly through the middle of the state; I-20/I-59 travel from the central west Mississippi state line to Birmingham, where I-59 continues to the north-east corner of the state and I-20 continues east towards Atlanta; I-85 originates in Montgomery and travels east-northeast to the Georgia state line, providing a main thoroughfare to Atlanta; and I-10 traverses the southernmost portion of the state, traveling from west to east through Mobile. I-22 enters the state from Mississippi and connects Birmingham with Memphis, Tennessee. In addition, there are currently five auxiliary interstate routes in the state: I-165 in Mobile, I-359 in Tuscaloosa, I-459 around Birmingham, I-565 in Decatur and Huntsville, and I-759 in Gadsden. A sixth route, I-685, will be formed when I-85 is rerouted along a new southern bypass of Montgomery. A proposed northern bypass of Birmingham will be designated as I-422. Since a direct connection from I-22 to I-422 will not be possible, I-222 has been proposed, as well.Several U.S. Highways also pass through the state, such as U.S. Route 11 (US-11), US-29, US-31, US-43, US-45, US-72, US-78, US-80, US-82, US-84, US-90, US-98, US-231, US-278, US-280, US-331, US-411, and US-431.There are four toll roads in the state: Montgomery Expressway in Montgomery; Northport/Tuscaloosa Western Bypass in Tuscaloosa and Northport; Emerald Mountain Expressway in Wetumpka; and Beach Express in Orange Beach.PortsThe Port of Mobile, Alabama's only saltwater port, is a large seaport on the Gulf of Mexico with inland waterway access to the Midwest by way of the Tennessee–Tombigbee Waterway. The Port of Mobile was ranked 12th by tons of traffic in the United States during 2009. The newly expanded container terminal at the Port of Mobile was ranked as the 25th busiest for container traffic in the nation during 2011. The state's other ports are on rivers with access to the Gulf of Mexico.Water ports of Alabama, listed from north to south:See also Index of Alabama-related articles Outline of Alabama—organized list of topics about AlabamaNotesReferencesFurther reading Atkins, Leah Rawls, Wayne Flynt, William Warren Rogers, and David Ward. Alabama: The History of a Deep South State (1994). Flynt, Wayne. Alabama in the Twentieth Century (2004). Owen Thomas M. History of Alabama and Dictionary of Alabama Biography (4 vols, 1921). Jackson, Harvey H. Inside Alabama: A Personal History of My State (2004). Mohl, Raymond A. "Latinization in the Heart of Dixie: Hispanics in Late-twentieth-century Alabama" Alabama Review (2002, 55(4): 243–274).  Peirce, Neal R. The Deep South States of America: People, Politics, and Power in the Seven Deep South States (1974). Williams, Benjamin Buford. A Literary History of Alabama: The Nineteenth Century (1979). WPA Guide to Alabama (1939).External links   Alabama State Guide, from the Library of Congress Your Not So Ordinary Alabama Tourist Guide All About Alabama, at the Alabama Department of Archives and History Code of Alabama 1975 USGS real-time, geographic, and other scientific resources of Alabama  Alabama QuickFacts from the U.S. Census Bureau Alabama State Fact Sheet  1819 establishments in the United StatesSouthern United StatesStates and territories established in 1819States of the Confederate StatesStates of the Gulf Coast of the United StatesStates of the United StatesU.S. states with multiple time zonesContiguous United States
In Greek mythology, Achilles ( ) or Achilleus () was a hero of the Trojan War, the greatest of all the Greek warriors, and is the central character of Homer's Iliad. He was the son of the Nereid Thetis and Peleus, king of Phthia.Achilles' most notable feat during the Trojan War was the slaying of the Trojan prince Hector outside the gates of Troy. Although the death of Achilles is not presented in the Iliad, other sources concur that he was killed near the end of the Trojan War by Paris, who shot him with an arrow. Later legends (beginning with Statius' unfinished epic Achilleid, written in the 1st century AD) state that Achilles was invulnerable in all of his body except for one heel, because when his mother Thetis dipped him in the river Styx as an infant, she held him by one of his heels. Alluding to these legends, the term "Achilles' heel" has come to mean a point of weakness, especially in someone or something with an otherwise strong constitution. The Achilles tendon is also named after him due to these legends.Etymology Linear B tablets attest to the personal name Achilleus in the forms a-ki-re-u and a-ki-re-we, the latter being the dative of the former. The name grew more popular, even becoming common soon after the seventh century BC and was also turned into the female form Ἀχιλλεία (Achilleía), attested in Attica in the fourth century BC (IG II² 1617) and, in the form Achillia, on a stele in Halicarnassus as the name of a female gladiator fighting an "Amazon".Achilles' name can be analyzed as a combination of  () "distress, pain, sorrow, grief" and  () "people, soldiers, nation", resulting in a proto-form *Akhí-lāu̯os "he who has the people distressed" or "he whose people have distress". The grief or distress of the people is a theme raised numerous times in the Iliad (and frequently by Achilles himself). Achilles' role as the hero of grief or distress forms an ironic juxtaposition with the conventional view of him as the hero of   ("glory", usually in war). Furthermore, laós has been construed by Gregory Nagy, following Leonard Palmer, to mean "a corps of soldiers", a muster. With this derivation, the name obtains a double meaning in the poem: when the hero is functioning rightly, his men bring distress to the enemy, but when wrongly, his men get the grief of war. The poem is in part about the misdirection of anger on the part of leadership.Another etymology relates the name to a Proto-Indo-European compound *h₂eḱ-pṓds "sharp foot" which first gave an Illyrian *āk̂pediós, evolving through time into *ākhpdeós and then *akhiddeús. The shift from -dd- to -ll- is then ascribed to the passing of the name into Greek via a Pre-Greek source. The first root part *h₂eḱ- "sharp, pointed" also gave Greek ἀκή (akḗ "point, silence, healing"), ἀκμή (akmḗ "point, edge, zenith") and ὀξύς (oxús "sharp, pointed, keen, quick, clever"), whereas ἄχος stems from the root *h₂egʰ- "to be upset, afraid". The whole expression would be comparable to the Latin acupedius "swift of foot". Compare also the Latin word family of aciēs "sharp edge or point, battle line, battle, engagement", acus "needle, pin, bodkin", and acuō "to make pointed, sharpen, whet; to exercise; to arouse" (whence acute). Some topical epitheta of Achilles in the Iliad point to this "swift-footedness", namely ποδάρκης δῖος Ἀχιλλεὺς (podárkēs dĩos Achilleús "swift-footed divine Achilles") or, even more frequently, πόδας ὠκὺς Ἀχιλλεύς (pódas ōkús Achilleús "quick-footed Achilles").Some researchers deem the name a loan word, possibly from a Pre-Greek language. Achilles' descent from the Nereid Thetis and a similarity of his name with those of river deities such as Acheron and Achelous have led to speculations about his being an old water divinity (see below Worship). Robert S. P. Beekes has suggested a Pre-Greek origin of the name, based among other things on the coexistence of -λλ- and -λ- in epic language, which may account for a palatalized phoneme /ly/ in the original language.Birth and early years Achilles was the son of the Thetis, a nereid, and Peleus, the king of the Myrmidons. Zeus and Poseidon had been rivals for Thetis's hand in marriage until Prometheus, the fore-thinker, warned Zeus of a prophecy (originally uttered by Themis, goddess of divine law) that Thetis would bear a son greater than his father. For this reason, the two gods withdrew their pursuit, and had her wed Peleus.There is a tale which offers an alternative version of these events: In the Argonautica (4.760) Zeus' sister and wife Hera alludes to Thetis' chaste resistance to the advances of Zeus, pointing out that Thetis was so loyal to Hera's marriage bond that she coolly rejected the father of gods. Thetis, although a daughter of the sea-god Nereus, was also brought up by Hera, further explaining her resistance to the advances of Zeus. Zeus was furious and decreed that she would never marry an immortal.According to the Achilleid, written by Statius in the 1st century AD, and to non-surviving previous sources, when Achilles was born Thetis tried to make him immortal by dipping him in the river Styx; however, he was left vulnerable at the part of the body by which she held him: his left heel (see Achilles' heel, Achilles' tendon). It is not clear if this version of events was known earlier. In another version of this story, Thetis anointed the boy in ambrosia and put him on top of a fire in order to burn away the mortal parts of his body. She was interrupted by Peleus and abandoned both father and son in a rage.None of the sources before Statius make any reference to this general invulnerability. To the contrary, in the Iliad, Homer mentions Achilles being wounded: in Book 21 the Paeonian hero Asteropaeus, son of Pelagon, challenged Achilles by the river Scamander. He was ambidextrous, and cast a spear from each hand; one grazed Achilles' elbow, "drawing a spurt of blood".In the few fragmentary poems of the Epic Cycle which describe the hero's death (i.e. the Cypria, the Little Iliad by Lesches of Pyrrha, the Aithiopis and Iliou persis by Arctinus of Miletus), there is no trace of any reference to his general invulnerability or his famous weakness at the heel. In the later vase paintings presenting the death of Achilles, the arrow (or in many cases, arrows) hit his torso.Peleus entrusted Achilles to Chiron the Centaur, who lived on Mount Pelion, to be reared. Thetis foretold that her son's fate was either to gain glory and die young, or to live a long but uneventful life in obscurity. Achilles chose the former, and decided to take part in the Trojan War. According to Homer, Achilles grew up in Phthia with his companion Patroclus.According to Photius, the sixth book of the New History by Ptolemy Hephaestion reported that Thetis burned in a secret place the children she had by Peleus. When she had Achilles, Peleus noticed, tore him from the flames with only a burnt foot, and confided him to the centaur Chiron. Later Chiron exhumed the body of the Damysus, who was the fastest of all the giants, removed the ankle, and incorporated it into Achilles' burnt foot.Other names Among the appellations under which Achilles is generally known are the following: Pyrisous, "saved from the fire", his first name, which seems to favour the tradition in which his mortal parts were burned by his mother Thetis Aeacides, from his grandfather Aeacus Aemonius, from Aemonia, a country which afterwards acquired the name of Thessaly Aspetos, "inimitable" or "vast", his name at Epirus Larissaeus, from Larissa (also called Cremaste), a town of Thessaly, which still bears the same name Ligyron, his original name Nereius, from his mother Thetis, one of the Nereids Pelides, from his father, Peleus Phthius, from his birthplace, Phthia Podarkes, "swift-footed", due to the wings of Arke being attached to his feet.Hidden on Skyros Some post-Homeric sources claim that in order to keep Achilles safe from the war, Thetis (or, in some versions, Peleus) hid the young man at the court of Lycomedes, king of Skyros.There, Achilles was disguised as a girl and lived among Lycomedes' daughters, perhaps under the name "Pyrrha" (the red-haired girl), Cercysera or Aissa ("swift"). With Lycomedes' daughter Deidamia, whom in the account of Statius he raped, Achilles there fathered two sons, Neoptolemus (also called Pyrrhus, after his father's possible alias) and Oneiros. According to this story, Odysseus learned from the prophet Calchas that the Achaeans would be unable to capture Troy without Achilles' aid. Odysseus went to Skyros in the guise of a peddler selling women's clothes and jewellery and placed a shield and spear among his goods. When Achilles instantly took up the spear, Odysseus saw through his disguise and convinced him to join the Greek campaign. In another version of the story, Odysseus arranged for a trumpet alarm to be sounded while he was with Lycomedes' women. While the women fled in panic, Achilles prepared to defend the court, thus giving his identity away.In the Trojan War According to the Iliad, Achilles arrived at Troy with 50 ships, each carrying 50 Myrmidons. He appointed five leaders (each leader commanding 500 Myrmidons): Menesthius, Eudorus, Peisander, Phoenix and Alcimedon.Telephus When the Greeks left for the Trojan War, they accidentally stopped in Mysia, ruled by King Telephus. In the resulting battle, Achilles gave Telephus a wound that would not heal; Telephus consulted an oracle, who stated that "he that wounded shall heal". Guided by the oracle, he arrived at Argos, where Achilles healed him in order that he might become their guide for the voyage to Troy.According to other reports in Euripides' lost play about Telephus, he went to Aulis pretending to be a beggar and asked Achilles to heal his wound. Achilles refused, claiming to have no medical knowledge. Alternatively, Telephus held Orestes for ransom, the ransom being Achilles' aid in healing the wound. Odysseus reasoned that the spear had inflicted the wound; therefore, the spear must be able to heal it. Pieces of the spear were scraped off onto the wound and Telephus was healed.Troilus According to the Cypria (the part of the Epic Cycle that tells the events of the Trojan War before Achilles' wrath), when the Achaeans desired to return home, they were restrained by Achilles, who afterwards attacked the cattle of Aeneas, sacked neighbouring cities (like Pedasus and Lyrnessus, where the Greeks capture the queen Briseis) and killed Tenes, a son of Apollo, as well as Priam's son Troilus in the sanctuary of Apollo Thymbraios; however, the romance between Troilus and Chryseis described in Geoffrey Chaucer's Troilus and Criseyde and in William Shakespeare's Troilus and Cressida is a medieval invention.In Dares Phrygius' Account of the Destruction of Troy, the Latin summary through which the story of Achilles was transmitted to medieval Europe, as well as in older accounts, Troilus was a young Trojan prince, the youngest of King Priam's and Hecuba's five legitimate sons (or according other sources, another son of Apollo). Despite his youth, he was one of the main Trojan war leaders, a "horse fighter" or "chariot fighter" according to Homer. Prophecies linked Troilus' fate to that of Troy and so he was ambushed in an attempt to capture him. Yet Achilles, struck by the beauty of both Troilus and his sister Polyxena, and overcome with lust, directed his sexual attentions on the youth – who, refusing to yield, instead found himself decapitated upon an altar-omphalos of Apollo Thymbraios. Later versions of the story suggested Troilus was accidentally killed by Achilles in an over-ardent lovers' embrace. In this version of the myth, Achilles' death therefore came in retribution for this sacrilege. Ancient writers treated Troilus as the epitome of a dead child mourned by his parents. Had Troilus lived to adulthood, the First Vatican Mythographer claimed, Troy would have been invincible; however, the motif is older and found already in Plautus' Bacchides.In the Iliad Homer's Iliad is the most famous narrative of Achilles' deeds in the Trojan War. Achilles' wrath (μῆνις Ἀχιλλέως, mênis Achilléōs) is the central theme of the poem. The first two lines of the Iliad read:The Homeric epic only covers a few weeks of the decade-long war, and does not narrate Achilles' death. It begins with Achilles' withdrawal from battle after being dishonoured by Agamemnon, the commander of the Achaean forces. Agamemnon has taken a woman named Chryseis as his slave. Her father Chryses, a priest of Apollo, begs Agamemnon to return her to him. Agamemnon refuses, and Apollo sends a plague amongst the Greeks. The prophet Calchas correctly determines the source of the troubles but will not speak unless Achilles vows to protect him. Achilles does so, and Calchas declares that Chryseis must be returned to her father. Agamemnon consents, but then commands that Achilles' battle prize Briseis, the daughter of Briseus, be brought to him to replace Chryseis. Angry at the dishonour of having his plunder and glory taken away (and, as he says later, because he loves Briseis), with the urging of his mother Thetis, Achilles refuses to fight or lead his troops alongside the other Greek forces. At the same time, burning with rage over Agamemnon's theft, Achilles prays to Thetis to convince Zeus to help the Trojans gain ground in the war, so that he may regain his honour.As the battle turns against the Greeks, thanks to the influence of Zeus, Nestor declares that the Trojans are winning because Agamemnon has angered Achilles, and urges the king to appease the warrior. Agamemnon agrees and sends Odysseus and two other chieftains, Ajax and Phoenix. They promise that, if Achilles returns to battle, Agamemnon will return the captive Briseis and other gifts. Achilles rejects all Agamemnon offers him and simply urges the Greeks to sail home as he was planning to do.The Trojans, led by Hector, subsequently push the Greek army back toward the beaches and assault the Greek ships. With the Greek forces on the verge of absolute destruction, Patroclus leads the Myrmidons into battle, wearing Achilles' armour, though Achilles remains at his camp. Patroclus succeeds in pushing the Trojans back from the beaches, but is killed by Hector before he can lead a proper assault on the city of Troy.After receiving the news of the death of Patroclus from Antilochus, the son of Nestor, Achilles grieves over his beloved companion's death. His mother Thetis comes to comfort the distraught Achilles. She persuades Hephaestus to make new armour for him, in place of the armour that Patroclus had been wearing, which was taken by Hector. The new armour includes the Shield of Achilles, described in great detail in the poem.Enraged over the death of Patroclus, Achilles ends his refusal to fight and takes the field, killing many men in his rage but always seeking out Hector. Achilles even engages in battle with the river god Scamander, who has become angry that Achilles is choking his waters with all the men he has killed. The god tries to drown Achilles but is stopped by Hera and Hephaestus. Zeus himself takes note of Achilles' rage and sends the gods to restrain him so that he will not go on to sack Troy itself before the time allotted for its destruction, seeming to show that the unhindered rage of Achilles can defy fate itself. Finally, Achilles finds his prey. Achilles chases Hector around the wall of Troy three times before Athena, in the form of Hector's favorite and dearest brother, Deiphobus, persuades Hector to stop running and fight Achilles face to face. After Hector realizes the trick, he knows the battle is inevitable. Wanting to go down fighting, he charges at Achilles with his only weapon, his sword, but misses. Accepting his fate, Hector begs Achilles not to spare his life, but to treat his body with respect after killing him. Achilles tells Hector it is hopeless to expect that of him, declaring that "my rage, my fury would drive me now to hack your flesh away and eat you raw – such agonies you have caused me". Achilles then kills Hector and drags his corpse by its heels behind his chariot. After having a dream where Patroclus begs Achilles to hold his funeral, Achilles hosts a series of funeral games in honour of his companion.At the onset of his duel with Hector, Achilles is referred to as the brightest star in the sky, which comes on in the autumn, Orion's dog (Sirius); a sign of evil. During the cremation of Patroclus, he is compared to Hesperus, the evening/western star (Venus), while the burning of the funeral pyre lasts until Phosphorus, the morning/eastern star (also Venus) has set (descended).With the assistance of the god Hermes (Argeiphontes), Hector's father Priam goes to Achilles' tent to plead with Achilles for the return of Hector's body so that he can be buried. Achilles relents and promises a truce for the duration of the funeral, lasting 9 days with a burial on the 10th (in the tradition of Niobe's offspring). The poem ends with a description of Hector's funeral, with the doom of Troy and Achilles himself still to come.Later epic accounts: fighting Penthesilea and Memnon The Aethiopis (7th century BC) and a work named Posthomerica, composed by Quintus of Smyrna in the fourth century CE, relate further events from the Trojan War. When Penthesilea, queen of the Amazons and daughter of Ares, arrives in Troy, Priam hopes that she will defeat Achilles. After his temporary truce with Priam, Achilles fights and kills the warrior queen, only to grieve over her death later. At first, he was so distracted by her beauty, he did not fight as intensely as usual. Once he realized that his distraction was endangering his life, he refocused and killed her.Following the death of Patroclus, Nestor's son Antilochus becomes Achilles' closest companion. When Memnon, son of the Dawn Goddess Eos and king of Ethiopia, slays Antilochus, Achilles once more obtains revenge on the battlefield, killing Memnon. Consequently, Eos will not let the sun rise until Zeus persuades her. The fight between Achilles and Memnon over Antilochus echoes that of Achilles and Hector over Patroclus, except that Memnon (unlike Hector) was also the son of a goddess.Many Homeric scholars argued that episode inspired many details in the Iliads description of the death of Patroclus and Achilles' reaction to it. The episode then formed the basis of the cyclic epic Aethiopis, which was composed after the Iliad, possibly in the 7th century BC. The Aethiopis is now lost, except for scattered fragments quoted by later authors.Achilles and Patroclus The exact nature of Achilles' relationship with Patroclus has been a subject of dispute in both the classical period and modern times. In the Iliad, it appears to be the model of a deep and loyal friendship. Homer does not suggest that Achilles and his close friend Patroclus had sexual relations. Although there is no direct evidence in the text of the Iliad that Achilles and Patroclus were lovers, this theory was expressed by some later authors. Commentators from classical antiquity to the present have often interpreted the relationship through the lens of their own cultures. In 5th-century BCE Athens, the intense bond was often viewed in light of the Greek custom of paiderasteia. In Plato's Symposium, the participants in a dialogue about love assume that Achilles and Patroclus were a couple; Phaedrus argues that Achilles was the younger and more beautiful one so he was the beloved and Patroclus was the lover. However, ancient Greek had no words to distinguish heterosexual and homosexual, and it was assumed that a man could both desire handsome young men and have sex with women. Many pairs of men throughout history have been compared to Achilles and Patroclus to imply a homosexual relationship.Death The death of Achilles, even if considered solely as it occurred in the oldest sources, is a complex one, with many different versions. In the oldest version, the Iliad, and as predicted by Hector with his dying breath, the hero's death was brought about by Paris with an arrow (to the heel according to Statius). In some versions, the god Apollo guided Paris' arrow. Some retellings also state that Achilles was scaling the gates of Troy and was hit with a poisoned arrow. All of these versions deny Paris any sort of valour, owing to the common conception that Paris was a coward and not the man his brother Hector was, and Achilles remained undefeated on the battlefield.After death, Achilles' bones were mingled with those of Patroclus, and funeral games were held. He was represented in the Aethiopis as living after his death in the island of Leuke at the mouth of the river Danube.Another version of Achilles' death is that he fell deeply in love with one of the Trojan princesses, Polyxena. Achilles asks Priam for Polyxena's hand in marriage. Priam is willing because it would mean the end of the war and an alliance with the world's greatest warrior. But while Priam is overseeing the private marriage of Polyxena and Achilles, Paris, who would have to give up Helen if Achilles married his sister, hides in the bushes and shoots Achilles with a divine arrow, killing him.In the Odyssey, Agamemnon informs Achilles of his pompous burial and the erection of his mound at the Hellespont while they are receiving the dead suitors in Hades. He claims they built a massive burial mound on the beach of Ilion that could be seen by anyone approaching from the ocean. Achilles was cremated and his ashes buried in the same urn as those of Patroclus. Paris was later killed by Philoctetes using the enormous bow of Heracles.In Book 11 of Homer's Odyssey, Odysseus sails to the underworld and converses with the shades. One of these is Achilles, who when greeted as "blessed in life, blessed in death", responds that he would rather be a slave to the worst of masters than be king of all the dead. But Achilles then asks Odysseus of his son's exploits in the Trojan war, and when Odysseus tells of Neoptolemus' heroic actions, Achilles is filled with satisfaction. This leaves the reader with an ambiguous understanding of how Achilles felt about the heroic life.According to some accounts, he had married Medea in life, so that after both their deaths they were united in the Elysian Fields of Hades – as Hera promised Thetis in Apollonius' Argonautica (3rd century BC).Fate of Achilles' armour Achilles' armour was the object of a feud between Odysseus and Telamonian Ajax (Ajax the greater). They competed for it by giving speeches on why they were the bravest after Achilles to their Trojan prisoners, who, after considering both men's presentations, decided Odysseus was more deserving of the armour. Furious, Ajax cursed Odysseus, which earned him the ire of Athena, who temporarily made Ajax so mad with grief and anguish that he began killing sheep, thinking them his comrades. After a while, when Athena lifted his madness and Ajax realized that he had actually been killing sheep, he was so ashamed that he committed suicide. Odysseus eventually gave the armour to Neoptolemus, the son of Achilles. When Odysseus encounters the shade of Ajax much later in the House of Hades (Odyssey 11.543–566), Ajax is still so angry about the outcome of the competition that he refuses to speak to Odysseus.A relic claimed to be Achilles' bronze-headed spear was preserved for centuries in the temple of Athena on the acropolis of Phaselis, Lycia, a port on the Pamphylian Gulf. The city was visited in 333 BCE by Alexander the Great, who envisioned himself as the new Achilles and carried the Iliad with him, but his court biographers do not mention the spear; however, it was shown in the time of Pausanias in the 2nd century CE.Achilles, Ajax and a game of petteia Numerous paintings on pottery have suggested a tale not mentioned in the literary traditions. At some point in the war, Achilles and Ajax were playing a board game (petteia). They were absorbed in the game and oblivious to the surrounding battle. The Trojans attacked and reached the heroes, who were saved only by an intervention of Athena.Worship and heroic cult The tomb of Achilles, extant throughout antiquity in Troad, was venerated by Thessalians, but also by Persian expeditionary forces, as well as by Alexander the Great and the Roman emperor Caracalla. Achilles' cult was also to be found at other places, e. g. on the island of Astypalaea in the Sporades, in Sparta which had a sanctuary, in Elis and in Achilles' homeland Thessaly, as well as in the Magna Graecia cities of Tarentum, Locri and Croton, accounting for an almost Panhellenic cult to the hero.The cult of Achilles is illustrated in the 500 BCE Polyxena sarcophagus, which depicts the sacrifice of Polyxena near the tumulus of Achilles. Strabo (13.1.32) also suggested that such a cult of Achilles existed in Troad:The spread and intensity of the hero's veneration among the Greeks that had settled on the northern coast of the Pontus Euxinus, today's Black Sea, appears to have been remarkable. An archaic cult is attested for the Milesian colony of Olbia as well as for an island in the middle of the Black Sea, today identified with Snake Island (Ukrainian Зміїний, Zmiinyi, near Kiliya, Ukraine). Early dedicatory inscriptions from the Greek colonies on the Black Sea (graffiti and inscribed clay disks, these possibly being votive offerings, from Olbia, the area of Berezan Island and the Tauric Chersonese) attest the existence of a heroic cult of Achilles from the sixth century BC onwards. The cult was still thriving in the third century CE, when dedicatory stelae from Olbia refer to an Achilles Pontárchēs (Ποντάρχης, roughly "lord of the Sea," or "of the Pontus Euxinus"), who was invoked as a protector of the city of Olbia, venerated on par with Olympian gods such as the local Apollo Prostates, Hermes Agoraeus, or Poseidon.Pliny the Elder (23–79 AD) in his Natural History mentions a "port of the Achæi" and an "island of Achilles", famous for the tomb of that "man" (), situated somewhat nearby Olbia and the Dnieper-Bug Estuary; furthermore, at 125 Roman miles from this island, he places a peninsula "which stretches forth in the shape of a sword" obliquely, called Dromos Achilleos (Ἀχιλλέως δρόμος, Achilléōs drómos "the Race-course of Achilles") and considered the place of the hero's exercise or of games instituted by him. This last feature of Pliny's account is considered to be the iconic spit, called today Tendra (or Kosa Tendra and Kosa Djarilgatch), situated between the mouth of the Dnieper and Karkinit Bay, but which is hardly 125 Roman miles (c. 185 km) away from the Dnieper-Bug estuary, as Pliny states. (To the "Race-course" he gives a length of 80 miles, c. 120 km, whereas the spit measures c. 70 km today.)In the following chapter of his book, Pliny refers to the same island as Achillea and introduces two further names for it: Leuce or Macaron (from Greek [νῆσος] μακαρῶν "island of the blest"). The "present day" measures, he gives at this point, seem to account for an identification of Achillea or Leuce with today's Snake Island. Pliny's contemporary Pomponius Mela (c. 43 AD) tells that Achilles was buried on an island named Achillea, situated between the Borysthenes and the Ister, adding to the geographical confusion. Ruins of a square temple, measuring 30 meters to a side, possibly that dedicated to Achilles, were discovered by Captain Kritzikly () in 1823 on Snake Island. A second exploration in 1840 showed that the construction of a lighthouse had destroyed all traces of this temple. A fifth century BC black-glazed lekythos inscription, found on the island in 1840, reads: "Glaukos, son of Poseidon, dedicated me to Achilles, lord of Leuke." In another inscription from the fifth or fourth century BC, a statue is dedicated to Achilles, lord of Leuke, by a citizen of Olbia, while in a further dedication, the city of Olbia confirms its continuous maintenance of the island's cult, again suggesting its quality as a place of a supra-regional hero veneration.The heroic cult dedicated to Achilles on Leuce seems to go back to an account from the lost epic Aethiopis according to which, after his untimely death, Thetis had snatched her son from the funeral pyre and removed him to a mythical  (Leúkē Nêsos "White Island"). Already in the fifth century BC, Pindar had mentioned a cult of Achilles on a "bright island" (φαεννά νᾶσος, phaenná nâsos) of the Black Sea, while in another of his works, Pindar would retell the story of the immortalized Achilles living on a geographically indefinite Island of the Blest together with other heroes such as his father Peleus and Cadmus. Well known is the connection of these mythological Fortunate Isles (μακαρῶν νῆσοι, makárôn nêsoi) or the Homeric Elysium with the stream Oceanus which according to Greek mythology surrounds the inhabited world, which should have accounted for the identification of the northern strands of the Euxine with it. Guy Hedreen has found further evidence for this connection of Achilles with the northern margin of the inhabited world in a poem by Alcaeus, speaking of "Achilles lord of Scythia" and the opposition of North and South, as evoked by Achilles' fight against the Aethiopian prince Memnon, who in his turn would be removed to his homeland by his mother Eos after his death.The Periplus of the Euxine Sea (c. 130 AD) gives the following details:The Greek geographer Dionysius Periegetes, who likely lived during the first century CE, wrote that the island was called Leuce "because the wild animals which live there are white. It is said that there, in Leuce island, reside the souls of Achilles and other heroes, and that they wander through the uninhabited valleys of this island; this is how Jove rewarded the men who had distinguished themselves through their virtues, because through virtue they had acquired everlasting honour". Similarly, others relate the island's name to its white cliffs, snakes or birds dwelling there. Pausanias has been told that the island is "covered with forests and full of animals, some wild, some tame. In this island there is also Achilles' temple and his statue". Leuce had also a reputation as a place of healing. Pausanias reports that the Delphic Pythia sent a lord of Croton to be cured of a chest wound. Ammianus Marcellinus attributes the healing to waters (aquae) on the island.A number of important commercial port cities of the Greek waters were dedicated to Achilles. Herodotus, Pliny the Elder and Strabo reported on the existence of a town Achílleion (Ἀχίλλειον), built by settlers from Mytilene in the sixth century BC, close to the hero's presumed burial mound in the Troad. Later attestations point to an Achílleion in Messenia (according to Stephanus Byzantinus) and an Achílleios (Ἀχίλλειος) in Laconia. Nicolae Densuşianu recognized a connection to Achilles in the names of Aquileia and of the northern arm of the Danube delta, called Chilia (presumably from an older Achileii), though his conclusion, that Leuce had sovereign rights over the Black Sea, evokes modern rather than archaic sea-law.The kings of Epirus claimed to be descended from Achilles through his son, Neoptolemus. Alexander the Great, son of the Epirote princess Olympias, could therefore also claim this descent, and in many ways strove to be like his great ancestor. He is said to have visited the tomb of Achilles at Achilleion while passing Troy. In AD 216 the Roman Emperor Caracalla, while on his way to war against Parthia, emulated Alexander by holding games around Achilles' tumulus.Reception during antiquityIn Greek tragedy The Greek tragedian Aeschylus wrote a trilogy of plays about Achilles, given the title Achilleis by modern scholars. The tragedies relate the deeds of Achilles during the Trojan War, including his defeat of Hector and eventual death when an arrow shot by Paris and guided by Apollo punctures his heel. Extant fragments of the Achilleis and other Aeschylean fragments have been assembled to produce a workable modern play. The first part of the Achilleis trilogy, The Myrmidons, focused on the relationship between Achilles and chorus, who represent the Achaean army and try to convince Achilles to give up his quarrel with Agamemnon; only a few lines survive today. In Plato's Symposium, Phaedrus points out that Aeschylus portrayed Achilles as the lover and Patroclus as the beloved; Phaedrus argues that this is incorrect because Achilles, being the younger and more beautiful of the two, was the beloved, who loved his lover so much that he chose to die to avenge him.The tragedian Sophocles also wrote The Lovers of Achilles, a play with Achilles as the main character. Only a few fragments survive.Towards the end of the 5th century BCE, a more negative view of Achilles emerges in Greek drama; Euripides refers to Achilles in a bitter or ironic tone in Hecuba, Electra, and Iphigenia in Aulis.In Greek philosophyZenoThe philosopher Zeno of Elea centred one of his paradoxes on an imaginary footrace between "swift-footed" Achilles and a tortoise, by which he attempted to show that Achilles could not catch up to a tortoise with a head start, and therefore that motion and change were impossible. As a student of the monist Parmenides and a member of the Eleatic school, Zeno believed time and motion to be illusions.PlatoIn Hippias Minor, a dialogue attributed to Plato, an arrogant man named Hippias argues with Socrates. The two get into a discussion about lying. They decide that a person who is intentionally false must be "better" than a person who is unintentionally false, on the basis that someone who lies intentionally must understand the subject about which they are lying. Socrates uses various analogies, discussing athletics and the sciences to prove his point. The two also reference Homer extensively. Socrates and Hippias agree that Odysseus, who concocted a number of lies throughout the Odyssey and other stories in the Trojan War Cycle, was false intentionally. Achilles, like Odysseus, told numerous falsehoods. Hippias believes that Achilles was a generally honest man, while Socrates believes that Achilles lied for his own benefit. The two argue over whether it is better to lie on purpose or by accident. Socrates eventually abandons Homeric arguments and makes sports analogies to drive home the point: someone who does wrong on purpose is a better person than someone who does wrong unintentionally.In Roman and medieval literature The Romans, who traditionally traced their lineage to Troy, took a highly negative view of Achilles. Virgil refers to Achilles as a savage and a merciless butcher of men, while Horace portrays Achilles ruthlessly slaying women and children. Other writers, such as Catullus, Propertius, and Ovid, represent a second strand of disparagement, with an emphasis on Achilles' erotic career. This strand continues in Latin accounts of the Trojan War by writers such as Dictys Cretensis and Dares Phrygius and in Benoît de Sainte-Maure's Roman de Troie and Guido delle Colonne's Historia destructionis Troiae, which remained the most widely read and retold versions of the Matter of Troy until the 17th century.Achilles was described by the Byzantine chronicler Leo the Deacon, not as Hellene, but as Scythian, while according to the Byzantine author John Malalas, his army was made up of a tribe previously known as Myrmidons and later as Bulgars.In modern literature and artsLiterature Achilles appears in Dante's Inferno (composed 1308–1320). He is seen in Hell's second circle, that of lust. Achilles is portrayed as a former hero who has become lazy and devoted to the love of Patroclus, in William Shakespeare's Troilus and Cressida (1602). The French dramatist Thomas Corneille wrote a tragedy La Mort d'Achille (1673). Achilles is the subject of the poem Achilleis (1799), a fragment by Johann Wolfgang von Goethe. In 1899, the Polish playwright, painter and poet Stanisław Wyspiański published a national drama, based on Polish history, named Achilles. In 1921, Edward Shanks published The Island of Youth and Other Poems, concerned among others with Achilles. The 1983 novel Kassandra by Christa Wolf also treats the death of Achilles. Akhilles is killed by a poisoned Kentaur arrow shot by Kassandra in Marion Zimmer Bradley's novel The Firebrand (1987). Achilles is one of various 'narrators' in Colleen McCullough's novel The Song of Troy (1998). The Death of Achilles (Смерть Ахиллеса, 1998) is an historical detective novel by Russian writer Boris Akunin that alludes to various figures and motifs from the Iliad. The character Achilles in Ender's Shadow (1999), by Orson Scott Card, shares his namesake's cunning mind and ruthless attitude. Achilles is one of the main characters in Dan Simmons's novels Ilium (2003) and Olympos (2005). Achilles is a major supporting character in David Gemmell's Troy series of books (2005–2007). Achilles is the main character in David Malouf's novel Ransom (2009). The ghost of Achilles appears in Rick Riordan's The Last Olympian (2009). He warns Percy Jackson about the Curse of Achilles and its side effects. Achilles is a main character in Terence Hawkins' 2009 novel The Rage of Achilles. Achilles is a major character in Madeline Miller's debut novel, The Song of Achilles (2011), which won the 2012 Orange Prize for Fiction. The novel explores the relationship between Patroclus and Achilles from boyhood to the fateful events of the Iliad. Achilles appears in the light novel series Fate/Apocrypha (2012–2014) as the Rider of Red. Achilles is a main character in Pat Barker's 2018 novel The Silence of the Girls, much of which is narrated by his slave Briseis.Visual arts  Achilles with the Daughters of Lycomedes is a subject treated in paintings by Anthony van Dyck (before 1618; Museo del Prado, Madrid) and Nicolas Poussin (c. 1652; Museum of Fine Arts, Boston) among others. Peter Paul Rubens has authored a series of works on the life of Achilles, comprising the titles: Thetis dipping the infant Achilles into the river Styx, Achilles educated by the centaur Chiron, Achilles recognized among the daughters of Lycomedes, The wrath of Achilles, The death of Hector, Thetis receiving the arms of Achilles from Vulcanus, The death of Achilles (Museum Boijmans Van Beuningen, Rotterdam), and Briseis restored to Achilles (Detroit Institute of Arts; all c. 1630–1635) Pieter van Lint, "Achilles Discovered among the Daughters of Lycomedes", 1645, at the Israel Museum, Jerusalem Dying Achilles is a sculpture created by Christophe Veyrier (c. 1683; Victoria and Albert Museum, London). The Rage of Achilles is a fresco by Giovanni Battista Tiepolo (1757, Villa Valmarana Ai Nani, Vicenza). Eugène Delacroix painted a version of The Education of Achilles for the ceiling of the Paris Palais Bourbon (1833–1847), one of the seats of the French Parliament.  created a statue group Achilles and Penthesilea (1895; Vienna). Achilleus (1908) is a lithography by Max Slevogt.Music Achilles has been frequently the subject of operas, ballets and related genres. Operas titled Deidamia were composed by Francesco Cavalli (1644) and George Frideric Handel (1739). Achille et Polyxène (Paris 1687) is an opera begun by Jean-Baptiste Lully and finished by Pascal Collasse. Achille et Déidamie (Paris 1735) is an opera composed by André Campra. Achilles (London 1733) is a ballad opera, written by John Gay, parodied by Thomas Arne as Achilles in petticoats in 1773. Achille in Sciro is a libretto by Metastasio, composed by Domenico Sarro for the inauguration of the Teatro di San Carlo (Naples, 4 November 1737). An even earlier composition is from Antonio Caldara (Vienna 1736). Later operas on the same libretto were composed by Leonardo Leo (Turin 1739), Niccolò Jommelli (Vienna 1749 and Rome 1772), Giuseppe Sarti (Copenhagen 1759 and Florence 1779), Johann Adolph Hasse (Naples 1759), Giovanni Paisiello (St. Petersburg 1772), Giuseppe Gazzaniga (Palermo 1781) and many others. It has also been set to music as Il Trionfo della gloria. Achille (Vienna 1801) is an opera by Ferdinando Paër on a libretto by Giovanni de Gamerra. Achille à Scyros (Paris 1804) is a ballet by Pierre Gardel, composed by Luigi Cherubini. Achilles, oder Das zerstörte Troja ("Achilles, or Troy Destroyed", Bonn 1885) is an oratorio by the German composer Max Bruch. Achilles auf Skyros (Stuttgart 1926) is a ballet by the Austrian-British composer and musicologist Egon Wellesz. Achilles' Wrath is a concert piece by Sean O'Loughlin. Achilles Last Stand a track on the 1976 Led Zeppelin album Presence. Achilles, Agony and Ecstasy in Eight Parts is the first song on the 1992 Manowar album The Triumph of Steel. Achilles Come Down is a song on the 2017 Gang of Youths album Go Farther in Lightness.Film and televisionIn films Achilles has been portrayed in the following films and television series: The 1924 film Helena by Carlo Aldini The 1954 film Ulysses by Piero Lulli The 1956 film Helen of Troy by Stanley Baker The 1961 film The Trojan Horse by Arturo Dominici The 1962 film The Fury of Achilles by Gordon Mitchell The 1997 television miniseries The Odyssey by Richard Trewett The 2003 television miniseries Helen of Troy by Joe Montana The 2004 film Troy by Brad Pitt The 2018 TV series Troy: Fall of a City by David GyasiArchitecture In 1890, Elisabeth of Bavaria, Empress of Austria, had a summer palace built in Corfu. The building is named the Achilleion, after Achilles. Its paintings and statuary depict scenes from the Trojan War, with particular focus on Achilles. The Wellington Monument is a statue representing Achilles erected as a memorial to Arthur Wellesley, the first duke of Wellington, and his victories in the Peninsular War and the latter stages of the Napoleonic Wars.Namesakes  The name of Achilles has been used for at least nine Royal Navy warships since 1744 – both as  and with the French spelling . A 60-gun ship of that name served at the Battle of Belleisle in 1761 while a 74-gun ship served at the Battle of Trafalgar. Other battle honours include Walcheren 1809. An armored cruiser of that name served in the Royal Navy during the First World War.  was a  which served with the Royal New Zealand Navy in World War II. It became famous for its part in the Battle of the River Plate, alongside  and . In addition to earning the battle honour 'River Plate', HMNZS Achilles also served at Guadalcanal 1942–1943 and Okinawa in 1945. After returning to the Royal Navy, the ship was sold to the Indian Navy in 1948, but when she was scrapped parts of the ship were saved and preserved in New Zealand. A species of lizard, Anolis achilles, which has widened heel plates, is named for Achilles.GalleryReferencesFurther reading  Ileana Chirassi Colombo (1977), "Heroes Achilleus – Theos Apollon." In Il Mito Greco, edd. Bruno Gentili and Giuseppe Paione. Rome: Edizione dell'Ateneo e Bizzarri. Anthony Edwards (1985a), "Achilles in the Underworld: Iliad, Odyssey, and Æthiopis". Greek, Roman, and Byzantine Studies. 26: pp. 215–227. Anthony Edwards (1985b), "Achilles in the Odyssey: Ideologies of Heroism in the Homeric Epic". Beiträge zur klassischen Philologie. 171.  Graves, Robert, The Greek Myths, Harmondsworth, London, England, Penguin Books, 1960. Graves, Robert, The Greek Myths: The Complete and Definitive Edition. Penguin Books Limited. 2017.    Hélène Monsacré (1984), Les larmes d'Achille. Le héros, la femme et la souffrance dans la poésie d'Homère, Paris: Albin Michel. Gregory Nagy (1984), The Name of Achilles: Questions of Etymology and 'Folk Etymology, Illinois Classical Studies. 19. Gregory Nagy (1999), The Best of The Acheans: Concepts of the Hero in Archaic Greek Poetry. Johns Hopkins University Press (revised edition, online).  Dale S. Sinos (1991), The Entry of Achilles into Greek Epic, PhD thesis, Johns Hopkins University. Ann Arbor, Michigan: University Microfilms International. Jonathan S. Burgess (2009), The Death and Afterlife of Achilles. Baltimore: Johns Hopkins University Press. Abrantes, M.C. (2016), Themes of the Trojan Cycle: Contribution to the study of the greek mythological tradition (Coimbra).External links  Trojan War Resources Gallery of the Ancient Art: Achilles  Poem by Florence Earle CoatesGreek mythological heroesKings of the MyrmidonsAchaean LeadersThessalians in the Trojan WarMetamorphoses charactersMythological rapistsDemigods in classical mythologyLGBT themes in Greek mythology Deeds of ApolloMedea
Abraham Lincoln (; February 12, 1809 – April 15, 1865) was an American lawyer and statesman who served as the 16th president of the United States from 1861 until his assassination in 1865. Lincoln led the nation through the American Civil War and succeeded in preserving the Union, abolishing slavery, bolstering the federal government, and modernizing the U.S. economy.Lincoln was born into poverty in a log cabin in Kentucky and was raised on the frontier primarily in Indiana. He was self-educated and became a lawyer, Whig Party leader, Illinois state legislator, and U.S. Congressman from Illinois. In 1849, he returned to his law practice but became vexed by the opening of additional lands to slavery as a result of the Kansas–Nebraska Act. He reentered politics in 1854, becoming a leader in the new Republican Party, and he reached a national audience in the 1858 debates against Stephen Douglas. Lincoln ran for President in 1860, sweeping the North in victory. Pro-slavery elements in the South equated his success with the North's rejection of their right to practice slavery, and southern states began seceding from the Union. To secure its independence, the new Confederate States fired on Fort Sumter, a U.S. fort in the South, and Lincoln called up forces to suppress the rebellion and restore the Union.Lincoln, a moderate Republican, had to navigate a contentious array of factions with friends and opponents from both the Democratic and Republican parties. His allies, the War Democrats and the Radical Republicans, demanded harsh treatment of the Southern Confederates. Anti-war Democrats (called "Copperheads") despised Lincoln, and irreconcilable pro-Confederate elements plotted his assassination. He managed the factions by exploiting their mutual enmity, carefully distributing political patronage, and by appealing to the American people. His Gettysburg Address appealed to nationalistic, republican, egalitarian, libertarian, and democratic sentiments. Lincoln scrutinized the strategy and tactics in the war effort, including the selection of generals and the naval blockade of the South's trade. He suspended habeas corpus in Maryland, and he averted British intervention by defusing the Trent Affair. He engineered the end to slavery with his Emancipation Proclamation, including his order that the Army and Navy liberate, protect, and recruit former slaves. He also encouraged border states to outlaw slavery, and promoted the Thirteenth Amendment to the United States Constitution, which outlawed slavery across the country.Lincoln managed his own successful re-election campaign. He sought to heal the war-torn nation through reconciliation. On April 14, 1865, just days after the war's end at Appomattox, he was attending a play at Ford's Theatre in Washington, D.C., with his wife Mary when he was fatally shot by Confederate sympathizer John Wilkes Booth. Lincoln is remembered as a martyr and hero of the United States and is often ranked as the greatest president in American history.Family and childhoodEarly lifeAbraham Lincoln was born on February 12, 1809, the second child of Thomas Lincoln and Nancy Hanks Lincoln, in a log cabin on Sinking Spring Farm near Hodgenville, Kentucky. He was a descendant of Samuel Lincoln, an Englishman who migrated from Hingham, Norfolk, to its namesake, Hingham, Massachusetts, in 1638. The family then migrated west, passing through New Jersey, Pennsylvania, and Virginia. Lincoln's paternal grandparents, his namesake Captain Abraham Lincoln and wife Bathsheba (née Herring) moved the family from Virginia to Jefferson County, Kentucky. The captain was killed in an Indian raid in 1786. His children, including eight-year-old Thomas, Abraham's father, witnessed the attack. Thomas then worked at odd jobs in Kentucky and Tennessee before the family settled in Hardin County, Kentucky, in the early 1800s.The heritage of Lincoln's mother Nancy remains unclear, but it is widely assumed that she was the daughter of Lucy Hanks. Thomas and Nancy married on June 12, 1806, in Washington County, and moved to Elizabethtown, Kentucky. They had three children: Sarah, Abraham, and Thomas, who died as infant.Thomas Lincoln bought or leased farms in Kentucky before losing all but  of his land in court disputes over property titles. In 1816, the family moved to Indiana where the land surveys and titles were more reliable. Indiana was a "free" (non-slaveholding) territory, and they settled in an "unbroken forest" in Hurricane Township, Perry County, Indiana. In 1860, Lincoln noted that the family's move to Indiana was "partly on account of slavery", but mainly due to land title difficulties.In Kentucky and Indiana, Thomas worked as a farmer, cabinetmaker, and carpenter. At various times, he owned farms, livestock, and town lots, paid taxes, sat on juries, appraised estates, and served on county patrols. Thomas and Nancy were members of a Separate Baptists church, which forbade alcohol, dancing, and slavery.Overcoming financial challenges, Thomas in 1827 obtained clear title to  in Indiana, an area which became the Little Pigeon Creek Community.Mother's deathOn October 5, 1818, Nancy Lincoln succumbed to milk sickness, leaving 11-year-old Sarah in charge of a household including her father, 9-year-old Abraham, and Nancy's 19-year-old orphan cousin, Dennis Hanks. Ten years later, on January 20, 1828, Sarah died while giving birth to a stillborn son, devastating Lincoln.On December 2, 1819, Thomas married Sarah Bush Johnston, a widow from Elizabethtown, Kentucky, with three children of her own. Abraham became close to his stepmother and called her "Mother". Lincoln disliked the hard labor associated with farm life. His family even said he was lazy, for all his "reading, scribbling, writing, ciphering, writing Poetry, etc.". His stepmother acknowledged he did not enjoy "physical labor", but loved to read.Education and move to IllinoisLincoln was largely self-educated. His formal schooling was from itinerant teachers. It included two short stints in Kentucky, where he learned to read but probably not to write, at age seven, and in Indiana, where he went to school sporadically due to farm chores, for a total of less than 12 months in aggregate by the age of 15. He persisted as an avid reader and retained a lifelong interest in learning. Family, neighbors, and schoolmates recalled that his reading included the King James Bible, Aesop's Fables, John Bunyan's The Pilgrim's Progress, Daniel Defoe's Robinson Crusoe, and The Autobiography of Benjamin Franklin.As a teen, Lincoln took responsibility for chores and customarily gave his father all earnings from work outside the home until he was 21. Lincoln was tall, strong, and athletic, and became adept at using an ax. He was an active wrestler during his youth and trained in the rough catch-as-catch-can style (also known as catch wrestling). He became county wrestling champion at the age of 21. He gained a reputation for strength and audacity after winning a wrestling match with the renowned leader of ruffians known as "the Clary's Grove Boys".In March 1830, fearing another milk sickness outbreak, several members of the extended Lincoln family, including Abraham, moved west to Illinois, a free state, and settled in Macon County. Abraham then became increasingly distant from Thomas, in part due to his father's lack of education. In 1831, as Thomas and other family prepared to move to a new homestead in Coles County, Illinois, Abraham struck out on his own. He made his home in New Salem, Illinois, for six years. Lincoln and some friends took goods by flatboat to New Orleans, Louisiana, where he was first exposed to slavery.In 1865, Lincoln was asked how he came to acquire his rhetorical skills. He answered that in the practice of law he frequently came across the word "demonstrate" but had insufficient understanding of the term. So, he left Springfield for his father's home to study until he "could give any proposition in the six books of Euclid [here, referencing Euclid's Elements] at sight."Marriage and childrenLincoln's first romantic interest was Ann Rutledge, whom he met when he moved to New Salem. By 1835, they were in a relationship but not formally engaged. She died on August 25, 1835, most likely of typhoid fever. In the early 1830s, he met Mary Owens from Kentucky.Late in 1836, Lincoln agreed to a match with Owens if she returned to New Salem. Owens arrived that November and he courted her for a time; however, they both had second thoughts. On August 16, 1837, he wrote Owens a letter saying he would not blame her if she ended the relationship, and she never replied.In 1839, Lincoln met Mary Todd in Springfield, Illinois, and the following year they became engaged. She was the daughter of Robert Smith Todd, a wealthy lawyer and businessman in Lexington, Kentucky. A wedding set for January 1, 1841, was canceled at Lincoln's request, but they reconciled and married on November 4, 1842, in the Springfield mansion of Mary's sister. While anxiously preparing for the nuptials, he was asked where he was going and replied, "To hell, I suppose." In 1844, the couple bought a house in Springfield near his law office. Mary kept house with the help of a hired servant and a relative.Lincoln was an affectionate husband and father of four sons, though his work regularly kept him away from home. The oldest, Robert Todd Lincoln, was born in 1843 and was the only child to live to maturity. Edward Baker Lincoln (Eddie), born in 1846, died February 1, 1850, probably of tuberculosis. Lincoln's third son, "Willie" Lincoln was born on December 21, 1850, and died of a fever at the White House on February 20, 1862. The youngest, Thomas "Tad" Lincoln, was born on April 4, 1853, and survived his father but died of heart failure at age 18 on July 16, 1871. Lincoln "was remarkably fond of children" and the Lincolns were not considered to be strict with their own. In fact, Lincoln's law partner William H. Herndon would grow irritated when Lincoln would bring his children to the law office. Their father, it seemed, was often too absorbed in his work to notice his children's behavior. Herndon recounted, "I have felt many and many a time that I wanted to wring their little necks, and yet out of respect for Lincoln I kept my mouth shut. Lincoln did not note what his children were doing or had done."The deaths of their sons, Eddie and Willie, had profound effects on both parents. Lincoln suffered from "melancholy", a condition now thought to be clinical depression. Later in life, Mary struggled with the stresses of losing her husband and sons, and Robert committed her for a time to an asylum in 1875.Early career and militia serviceIn 1832, Lincoln joined with a partner, Denton Offutt, in the purchase of a general store on credit in New Salem. Although the economy was booming, the business struggled and Lincoln eventually sold his share. That March he entered politics, running for the Illinois General Assembly, advocating navigational improvements on the Sangamon River. He could draw crowds as a raconteur, but he lacked the requisite formal education, powerful friends, and money, and lost the election.Lincoln briefly interrupted his campaign to serve as a captain in the Illinois Militia during the Black Hawk War. In his first campaign speech after returning, he observed a supporter in the crowd under attack, grabbed the assailant by his "neck and the seat of his trousers", and tossed him. Lincoln finished eighth out of 13 candidates (the top four were elected), though he received 277 of the 300 votes cast in the New Salem precinct.Lincoln served as New Salem's postmaster and later as county surveyor, but continued his voracious reading, and decided to become a lawyer. Rather than studying in the office of an established attorney, as was the custom, Lincoln borrowed legal texts from attorneys John Todd Stuart and Thomas Drummond, purchased books including Blackstone's Commentaries and Chitty's Pleadings, and read law on his own. He later said of his legal education that "I studied with nobody."Illinois state legislature (1834–1842)Lincoln's second state house campaign in 1834, this time as a Whig, was a success over a powerful Whig opponent. Then followed his four terms in the Illinois House of Representatives for Sangamon County. He championed construction of the Illinois and Michigan Canal, and later was a Canal Commissioner. He voted to expand suffrage beyond white landowners to all white males, but adopted a "free soil" stance opposing both slavery and abolition. In 1837, he declared, "[The] Institution of slavery is founded on both injustice and bad policy, but the promulgation of abolition doctrines tends rather to increase than abate its evils." He echoed Henry Clay's support for the American Colonization Society which advocated a program of abolition in conjunction with settling freed slaves in Liberia.He was admitted to the Illinois bar in 1836, and moved to Springfield and began to practice law under John T. Stuart, Mary Todd's cousin. Lincoln emerged as a formidable trial combatant during cross-examinations and closing arguments. He partnered several years with Stephen T. Logan, and in 1844 began his practice with William Herndon, "a studious young man".U.S. House of Representatives (1847–1849)True to his record, Lincoln professed to friends in 1861 to be "an old line Whig, a disciple of Henry Clay". Their party favored economic modernization in banking, tariffs to fund internal improvements including railroads, and urbanization.In 1843, Lincoln sought the Whig nomination for Illinois' 7th district seat in the U.S. House of Representatives; he was defeated by John J. Hardin though he prevailed with the party in limiting Hardin to one term. Lincoln not only pulled off his strategy of gaining the nomination in 1846 but also won the election. He was the only Whig in the Illinois delegation, but as dutiful as any participated in almost all votes and made speeches that toed the party line. He was assigned to the Committee on Post Office and Post Roads and the Committee on Expenditures in the War Department. Lincoln teamed with Joshua R. Giddings on a bill to abolish slavery in the District of Columbia with compensation for the owners, enforcement to capture fugitive slaves, and a popular vote on the matter. He dropped the bill when it eluded Whig support.Political views On foreign and military policy, Lincoln spoke against the Mexican–American War, which he imputed to President James K. Polk's desire for "military glory—that attractive rainbow, that rises in showers of blood". He supported the Wilmot Proviso, a failed proposal to ban slavery in any U.S. territory won from Mexico.Lincoln emphasized his opposition to Polk by drafting and introducing his Spot Resolutions. The war had begun with a Mexican slaughter of American soldiers in territory disputed by Mexico, and Polk insisted that Mexican soldiers had "invaded our territory and shed the blood of our fellow-citizens on our own soil". Lincoln demanded that Polk show Congress the exact spot on which blood had been shed and prove that the spot was on American soil. The resolution was ignored in both Congress and the national papers, and it cost Lincoln political support in his district. One Illinois newspaper derisively nicknamed him "spotty Lincoln". Lincoln later regretted some of his statements, especially his attack on presidential war-making powers.Lincoln had pledged in 1846 to serve only one term in the House. Realizing Clay was unlikely to win the presidency, he supported General Zachary Taylor for the Whig nomination in the 1848 presidential election. Taylor won and Lincoln hoped in vain to be appointed Commissioner of the General Land Office. The administration offered to appoint him secretary or governor of the Oregon Territory as consolation. This distant territory was a Democratic stronghold, and acceptance of the post would have disrupted his legal and political career in Illinois, so he declined and resumed his law practice.Prairie lawyerIn his Springfield practice, Lincoln handled "every kind of business that could come before a prairie lawyer". Twice a year he appeared for 10 consecutive weeks in county seats in the Midstate county courts; this continued for 16 years. Lincoln handled transportation cases in the midst of the nation's western expansion, particularly river barge conflicts under the many new railroad bridges. As a riverboat man, Lincoln initially favored those interests, but ultimately represented whoever hired him. He later represented a bridge company against a riverboat company in Hurd v. Rock Island Bridge Company, a landmark case involving a canal boat that sank after hitting a bridge. In 1849, he received a patent for a flotation device for the movement of boats in shallow water. The idea was never commercialized, but it made Lincoln the only president to hold a patent.Lincoln appeared before the Illinois Supreme Court in 175 cases; he was sole counsel in 51 cases, of which 31 were decided in his favor. From 1853 to 1860, one of his largest clients was the Illinois Central Railroad. His legal reputation gave rise to the nickname "Honest Abe".Lincoln argued in an 1858 criminal trial, defending William "Duff" Armstrong, who was on trial for the murder of James Preston Metzker. The case is famous for Lincoln's use of a fact established by judicial notice to challenge the credibility of an eyewitness. After an opposing witness testified to seeing the crime in the moonlight, Lincoln produced a Farmers' Almanac showing the moon was at a low angle, drastically reducing visibility. Armstrong was acquitted.Leading up to his presidential campaign, Lincoln elevated his profile in an 1859 murder case, with his defense of Simeon Quinn "Peachy" Harrison who was a third cousin; Harrison was also the grandson of Lincoln's political opponent, Rev. Peter Cartwright. Harrison was charged with the murder of Greek Crafton who, as he lay dying of his wounds, confessed to Cartwright that he had provoked Harrison. Lincoln angrily protested the judge's initial decision to exclude Cartwright's testimony about the confession as inadmissible hearsay. Lincoln argued that the testimony involved a dying declaration and was not subject to the hearsay rule. Instead of holding Lincoln in contempt of court as expected, the judge, a Democrat, reversed his ruling and admitted the testimony into evidence, resulting in Harrison's acquittal.Republican politics (1854–1860)Emergence as Republican leaderThe debate over the status of slavery in the territories failed to alleviate tensions between the slave-holding South and the free North, with the failure of the Compromise of 1850, a legislative package designed to address the issue. In his 1852 eulogy for Clay, Lincoln highlighted the latter's support for gradual emancipation and opposition to "both extremes" on the slavery issue. As the slavery debate in the Nebraska and Kansas territories became particularly acrimonious, Illinois Senator Stephen A. Douglas proposed popular sovereignty as a compromise; the measure would allow the electorate of each territory to decide the status of slavery. The legislation alarmed many Northerners, who sought to prevent the resulting spread of slavery, but Douglas's Kansas–Nebraska Act narrowly passed Congress in May 1854.Lincoln did not comment on the act until months later in his "Peoria Speech" in October 1854. Lincoln then declared his opposition to slavery which he repeated en route to the presidency. He said the Kansas Act had a "declared indifference, but as I must think, a covert real zeal for the spread of slavery. I cannot but hate it. I hate it because of the monstrous injustice of slavery itself. I hate it because it deprives our republican example of its just influence in the world ..." Lincoln's attacks on the Kansas–Nebraska Act marked his return to political life.Nationally, the Whigs were irreparably split by the Kansas–Nebraska Act and other efforts to compromise on the slavery issue. Reflecting on the demise of his party, Lincoln wrote in 1855, "I think I am a Whig, but others say there are no Whigs, and that I am an abolitionist...I do no more than oppose the extension of slavery." The new Republican Party was formed as a northern party dedicated to antislavery, drawing from the antislavery wing of the Whig Party, and combining Free Soil, Liberty, and antislavery Democratic Party members, Lincoln resisted early Republican entreaties, fearing that the new party would become a platform for extreme abolitionists. Lincoln held out hope for rejuvenating the Whigs, though he lamented his party's growing closeness with the nativist Know Nothing movement.In 1854, Lincoln was elected to the Illinois legislature but declined to take his seat. The year's elections showed the strong opposition to the Kansas–Nebraska Act, and in the aftermath, Lincoln sought election to the United States Senate. At that time, senators were elected by the state legislature. After leading in the first six rounds of voting, he was unable to obtain a majority. Lincoln instructed his backers to vote for Lyman Trumbull. Trumbull was an antislavery Democrat, and had received few votes in the earlier ballots; his supporters, also antislavery Democrats, had vowed not to support any Whig. Lincoln's decision to withdraw enabled his Whig supporters and Trumbull's antislavery Democrats to combine and defeat the mainstream Democratic candidate, Joel Aldrich Matteson.1856 campaign Violent political confrontations in Kansas continued, and opposition to the Kansas–Nebraska Act remained strong throughout the North. As the 1856 elections approached, Lincoln joined the Republicans and attended the Bloomington Convention, which formally established the Illinois Republican Party. The convention platform endorsed Congress's right to regulate slavery in the territories and backed the admission of Kansas as a free state. Lincoln gave the final speech of the convention supporting the party platform and called for the preservation of the Union. At the June 1856 Republican National Convention, though Lincoln received support to run as vice president, John C. Frémont and William Dayton comprised the ticket, which Lincoln supported throughout Illinois. The Democrats nominated former Secretary of State James Buchanan and the Know-Nothings nominated former Whig President Millard Fillmore. Buchanan prevailed, while Republican William Henry Bissell won election as Governor of Illinois, and Lincoln became a leading Republican in Illinois.Dred Scott v. Sandford Dred Scott was a slave whose master took him from a slave state to a free territory under the Missouri Compromise. After Scott was returned to the slave state he petitioned a federal court for his freedom. His petition was denied in Dred Scott v. Sandford (1857). Supreme Court Chief Justice Roger B. Taney in the decision wrote that blacks were not citizens and derived no rights from the Constitution. While many Democrats hoped that Dred Scott would end the dispute over slavery in the territories, the decision sparked further outrage in the North. Lincoln denounced it as the product of a conspiracy of Democrats to support the Slave Power. He argued the decision was at variance with the Declaration of Independence; he said that while the founding fathers did not believe all men equal in every respect, they believed all men were equal "in certain inalienable rights, among which are life, liberty, and the pursuit of happiness".Lincoln–Douglas debates and Cooper Union speechIn 1858, Douglas was up for re-election in the U.S. Senate, and Lincoln hoped to defeat him. Many in the party felt that a former Whig should be nominated in 1858, and Lincoln's 1856 campaigning and support of Trumbull had earned him a favor. Some eastern Republicans supported Douglas for his opposition to the Lecompton Constitution and admission of Kansas as a slave state. Many Illinois Republicans resented this eastern interference. For the first time, Illinois Republicans held a convention to agree upon a Senate candidate, and Lincoln won the nomination with little opposition.Lincoln accepted the nomination with great enthusiasm and zeal. After his nomination he delivered his House Divided Speech, with the biblical reference Mark 3:25, "A house divided against itself cannot stand. I believe this government cannot endure permanently half slave and half free. I do not expect the Union to be dissolved—I do not expect the house to fall—but I do expect it will cease to be divided. It will become all one thing, or all the other." The speech created a stark image of the danger of disunion. The stage was then set for the election of the Illinois legislature which would, in turn, select Lincoln or Douglas. When informed of Lincoln's nomination, Douglas stated, "[Lincoln] is the strong man of the party ... and if I beat him, my victory will be hardly won."The Senate campaign featured seven debates between Lincoln and Douglas. These were the most famous political debates in American history; they had an atmosphere akin to a prizefight and drew crowds in the thousands. The principals stood in stark contrast both physically and politically. Lincoln warned that Douglas’ "Slave Power" was threatening the values of republicanism, and accused Douglas of distorting the Founding Fathers' premise that all men are created equal. Douglas emphasized his Freeport Doctrine, that local settlers were free to choose whether to allow slavery and accused Lincoln of having joined the abolitionists. Lincoln's argument assumed a moral tone, as he claimed Douglas represented a conspiracy to promote slavery. Douglas's argument was more legal, claiming that Lincoln was defying the authority of the U.S. Supreme Court in the Dred Scott decision.Though the Republican legislative candidates won more popular votes, the Democrats won more seats, and the legislature re-elected Douglas. Lincoln's articulation of the issues gave him a national political presence. In May 1859, Lincoln purchased the Illinois Staats-Anzeiger, a German-language newspaper that was consistently supportive; most of the state's 130,000 German Americans voted Democratically but the German-language paper mobilized Republican support. In the aftermath of the 1858 election, newspapers frequently mentioned Lincoln as a potential Republican presidential candidate, rivaled by William H. Seward, Salmon P. Chase, Edward Bates, and Simon Cameron. While Lincoln was popular in the Midwest, he lacked support in the Northeast and was unsure whether to seek office. In January 1860, Lincoln told a group of political allies that he would accept the nomination if offered, and in the following months' several local papers endorsed his candidacy.Over the coming months, Lincoln was tireless, making nearly fifty speeches along the campaign trail. By the quality and simplicity of his rhetoric, he quickly became the champion of the Republican party. However, despite his overwhelming support in the Midwestern United States, he was less appreciated in the east. Horace Greeley, editor of the New York Tribune, at that time wrote up an unflattering account of Lincoln's compromising position on slavery and his reluctance to challenge the court's Dred-Scott ruling, which was promptly used against him by his political rivals.On February 27, 1860, powerful New York Republicans invited Lincoln to give a speech at Cooper Union, in which he argued that the Founding Fathers of the United States had little use for popular sovereignty and had repeatedly sought to restrict slavery. He insisted that morality required opposition to slavery, and rejected any "groping for some middle ground between the right and the wrong". Many in the audience thought he appeared awkward and even ugly. But Lincoln demonstrated intellectual leadership that brought him into contention. Journalist Noah Brooks reported, "No man ever before made such an impression on his first appeal to a New York audience."Historian David Herbert Donald described the speech as a "superb political move for an unannounced candidate, to appear in one rival's (Seward) own state at an event sponsored by the second rival's (Chase) loyalists, while not mentioning either by name during its delivery". In response to an inquiry about his ambitions, Lincoln said, "The taste is in my mouth a little."1860 presidential electionOn May 9–10, 1860, the Illinois Republican State Convention was held in Decatur. Lincoln's followers organized a campaign team led by David Davis, Norman Judd, Leonard Swett, and Jesse DuBois, and Lincoln received his first endorsement. Exploiting his embellished frontier legend (clearing land and splitting fence rails), Lincoln's supporters adopted the label of "The Rail Candidate". In 1860, Lincoln described himself: "I am in height, six feet, four inches, nearly; lean in flesh, weighing, on an average, one hundred and eighty pounds; dark complexion, with coarse black hair, and gray eyes." Michael Martinez wrote about the effective imaging of Lincoln by his campaign. At times he was presented as the plain-talking "Rail Splitter" and at other times he was "Honest Abe", unpolished but trustworthy.On May 18, at the Republican National Convention in Chicago, Lincoln won the nomination on the third ballot, beating candidates such as Seward and Chase. A former Democrat, Hannibal Hamlin of Maine, was nominated for vice president to balance the ticket. Lincoln's success depended on his campaign team, his reputation as a moderate on the slavery issue, and his strong support for internal improvements and the tariff.Pennsylvania put him over the top, led by the state's iron interests who were reassured by his tariff support. Lincoln's managers had focused on this delegation while honoring Lincoln's dictate to "Make no contracts that will bind me".As the Slave Power tightened its grip on the national government, most Republicans agreed with Lincoln that the North was the aggrieved party. Throughout the 1850s, Lincoln had doubted the prospects of civil war, and his supporters rejected claims that his election would incite secession. When Douglas was selected as the candidate of the Northern Democrats, delegates from eleven slave states walked out of the Democratic convention; they opposed Douglas's position on popular sovereignty, and selected incumbent Vice President John C. Breckinridge as their candidate. A group of former Whigs and Know Nothings formed the Constitutional Union Party and nominated John Bell of Tennessee. Lincoln and Douglas competed for votes in the North, while Bell and Breckinridge primarily found support in the South.Prior to the Republican convention, the Lincoln campaign began cultivating a nationwide youth organization, the Wide Awakes, which it used to generate popular support throughout the country to spearhead voter registration drives, thinking that new voters and young voters tended to embrace new parties. People of the Northern states knew the Southern states would vote against Lincoln and rallied supporters for Lincoln.As Douglas and the other candidates campaigned, Lincoln gave no speeches, relying on the enthusiasm of the Republican Party. The party did the leg work that produced majorities across the North and produced an abundance of campaign posters, leaflets, and newspaper editorials. Republican speakers focused first on the party platform, and second on Lincoln's life story, emphasizing his childhood poverty. The goal was to demonstrate the power of "free labor", which allowed a common farm boy to work his way to the top by his own efforts. The Republican Party's production of campaign literature dwarfed the combined opposition; a Chicago Tribune writer produced a pamphlet that detailed Lincoln's life and sold 100,000–200,000 copies. Though he did not give public appearances, many sought to visit him and write him. In the runup to the election, he took an office in the Illinois state capitol to deal with the influx of attention. He also hired John George Nicolay as his personal secretary, who would remain in that role during the presidency.On November 6, 1860, Lincoln was elected the 16th president. He was the first Republican president and his victory was entirely due to his support in the North and West. No ballots were cast for him in 10 of the 15 Southern slave states, and he won only two of 996 counties in all the Southern states, an omen of the impending Civil War. Lincoln received 1,866,452 votes, or 39.8% of the total in a four-way race, carrying the free Northern states, as well as California and Oregon. His victory in the electoral college was decisive: Lincoln had 180 votes to 123 for his opponents.Presidency (1861–1865)Secession and inaugurationThe South was outraged by Lincoln's election, and in response secessionists implemented plans to leave the Union before he took office in March 1861. On December 20, 1860, South Carolina took the lead by adopting an ordinance of secession; by February 1, 1861, Florida, Mississippi, Alabama, Georgia, Louisiana, and Texas followed. Six of these states declared themselves to be a sovereign nation, the Confederate States of America, and adopted a constitution. The upper South and border states (Delaware, Maryland, Virginia, North Carolina, Tennessee, Kentucky, Missouri, and Arkansas) initially rejected the secessionist appeal. President Buchanan and President-elect Lincoln refused to recognize the Confederacy, declaring secession illegal. The Confederacy selected Jefferson Davis as its provisional president on February 9, 1861.Attempts at compromise followed but Lincoln and the Republicans rejected the proposed Crittenden Compromise as contrary to the Party's platform of free-soil in the territories. Lincoln said, "I will suffer death before I consent ... to any concession or compromise which looks like buying the privilege to take possession of this government to which we have a constitutional right."Lincoln tacitly supported the Corwin Amendment to the Constitution, which passed Congress and was awaiting ratification by the states when Lincoln took office. That doomed amendment would have protected slavery in states where it already existed. A few weeks before the war, Lincoln sent a letter to every governor informing them Congress had passed a joint resolution to amend the Constitution.En route to his inauguration, Lincoln addressed crowds and legislatures across the North. He gave a particularly emotional farewell address upon leaving Springfield; he would never again return to Springfield alive. The president-elect evaded suspected assassins in Baltimore. On February 23, 1861, he arrived in disguise in Washington, D.C., which was placed under substantial military guard. Lincoln directed his inaugural address to the South, proclaiming once again that he had no inclination to abolish slavery in the Southern states: Lincoln cited his plans for banning the expansion of slavery as the key source of conflict between North and South, stating "One section of our country believes slavery is right and ought to be extended, while the other believes it is wrong and ought not to be extended. This is the only substantial dispute." The president ended his address with an appeal to the people of the South: "We are not enemies, but friends. We must not be enemies ... The mystic chords of memory, stretching from every battlefield, and patriot grave, to every living heart and hearthstone, all over this broad land, will yet swell the chorus of the Union, when again touched, as surely they will be, by the better angels of our nature." The failure of the Peace Conference of 1861 signaled that legislative compromise was impossible. By March 1861, no leaders of the insurrection had proposed rejoining the Union on any terms. Meanwhile, Lincoln and the Republican leadership agreed that the dismantling of the Union could not be tolerated. In his second inaugural address, Lincoln looked back on the situation at the time and said: "Both parties deprecated war, but one of them would make war rather than let the Nation survive, and the other would accept war rather than let it perish, and the war came."Civil WarMajor Robert Anderson, commander of the Union's Fort Sumter in Charleston, South Carolina, sent a request for provisions to Washington, and Lincoln's order to meet that request was seen by the secessionists as an act of war. On April 12, 1861, Confederate forces fired on Union troops at Fort Sumter and began the fight. Historian Allan Nevins argued that the newly inaugurated Lincoln made three miscalculations: underestimating the gravity of the crisis, exaggerating the strength of Unionist sentiment in the South, and overlooking Southern Unionist opposition to an invasion.William Tecumseh Sherman talked to Lincoln during inauguration week and was "sadly disappointed" at his failure to realize that "the country was sleeping on a volcano" and that the South was preparing for war. Donald concludes that, "His repeated efforts to avoid collision in the months between inauguration and the firing on Ft. Sumter showed he adhered to his vow not to be the first to shed fraternal blood. But he also vowed not to surrender the forts. The only resolution of these contradictory positions was for the confederates to fire the first shot; they did just that."On April 15, Lincoln called on the states to send a total of 75,000 volunteer troops to recapture forts, protect Washington, and "preserve the Union", which, in his view, remained intact despite the seceding states. This call forced states to choose sides. Virginia seceded and was rewarded with the designation of Richmond as the Confederate capital, despite its exposure to Union lines. North Carolina, Tennessee, and Arkansas followed over the following two months. Secession sentiment was strong in Missouri and Maryland, but did not prevail; Kentucky remained neutral. The Fort Sumter attack rallied Americans north of the Mason-Dixon line to defend the nation.As States sent Union regiments south, on April 19, Baltimore mobs in control of the rail links attacked Union troops who were changing trains. Local leaders' groups later burned critical rail bridges to the capital and the Army responded by arresting local Maryland officials. Lincoln suspended the writ of habeas corpus where needed for the security of troops trying to reach Washington. John Merryman, one Maryland official hindering the U.S. troop movements, petitioned Supreme Court Chief Justice Roger B. Taney to issue a writ of habeas corpus. In June Taney, ruling only for the lower circuit court in ex parte Merryman, issued the writ which he felt could only be suspended by Congress. Lincoln persisted with the policy of suspension in select areas.Union military strategyLincoln took executive control of the war and shaped the Union military strategy. He responded to the unprecedented political and military crisis as commander-in-chief by exercising unprecedented authority. He expanded his war powers, imposed a blockade on Confederate ports, disbursed funds before appropriation by Congress, suspended habeas corpus, and arrested and imprisoned thousands of suspected Confederate sympathizers. Lincoln gained the support of Congress and the northern public for these actions. Lincoln also had to reinforce Union sympathies in the border slave states and keep the war from becoming an international conflict.It was clear from the outset that bipartisan support was essential to success, and that any compromise alienated factions on both sides of the aisle, such as the appointment of Republicans and Democrats to command positions. Copperheads criticized Lincoln for refusing to compromise on slavery. The Radical Republicans criticized him for moving too slowly in abolishing slavery. On August 6, 1861, Lincoln signed the Confiscation Act that authorized judicial proceedings to confiscate and free slaves who were used to support the Confederates. The law had little practical effect, but it signaled political support for abolishing slavery.In August 1861, General John C. Frémont, the 1856 Republican presidential nominee, without consulting Washington, issued a martial edict freeing slaves of the rebels. Lincoln canceled the illegal proclamation as politically motivated and lacking military necessity. As a result, Union enlistments from Maryland, Kentucky, and Missouri increased by over 40,000.Internationally, Lincoln wanted to forestall foreign military aid to the Confederacy. He relied on his combative Secretary of State William Seward while working closely with Senate Foreign Relations Committee chairman Charles Sumner. In the 1861 Trent Affair which threatened war with Great Britain, the U.S. Navy illegally intercepted a British mail ship, the Trent, on the high seas and seized two Confederate envoys; Britain protested vehemently while the U.S. cheered. Lincoln ended the crisis by releasing the two diplomats. Biographer James G. Randall dissected Lincoln's successful techniques:Lincoln painstakingly monitored the telegraph reports coming into the War Department. He tracked all phases of the effort, consulting with governors, and selecting generals based on their success, their state, and their party. In January 1862, after complaints of inefficiency and profiteering in the War Department, Lincoln replaced War Secretary Simon Cameron with Edwin Stanton. Stanton centralized the War Department's activities, auditing and canceling contracts, saving the federal government $17,000,000. Stanton was a staunch Unionist, pro-business, conservative Democrat who gravitated toward the Radical Republican faction. He worked more often and more closely with Lincoln than any other senior official. "Stanton and Lincoln virtually conducted the war together", say Thomas and Hyman.Lincoln's war strategy embraced two priorities: ensuring that Washington was well-defended and conducting an aggressive war effort for a prompt, decisive victory. Twice a week, Lincoln met with his cabinet in the afternoon. Occasionally Mary prevailed on him to take a carriage ride, concerned that he was working too hard. For his edification Lincoln relied upon a book by his chief of staff General Henry Halleck entitled Elements of Military Art and Science; Halleck was a disciple of the European strategist Antoine-Henri Jomini. Lincoln began to appreciate the critical need to control strategic points, such as the Mississippi River. Lincoln saw the importance of Vicksburg and understood the necessity of defeating the enemy's army, rather than simply capturing territory.General McClellanAfter the Union rout at Bull Run and Winfield Scott's retirement, Lincoln appointed Major General George B. McClellan general-in-chief. McClellan then took months to plan his Virginia Peninsula Campaign. McClellan's slow progress frustrated Lincoln, as did his position that no troops were needed to defend Washington. McClellan, in turn, blamed the failure of the campaign on Lincoln's reservation of troops for the capitol.In 1862, Lincoln removed McClellan for the general's continued inaction. He elevated Henry Halleck in July and appointed John Pope as head of the new Army of Virginia. Pope satisfied Lincoln's desire to advance on Richmond from the north, thus protecting Washington from counterattack. But Pope was then soundly defeated at the Second Battle of Bull Run in the summer of 1862, forcing the Army of the Potomac back to defend Washington.Despite his dissatisfaction with McClellan's failure to reinforce Pope, Lincoln restored him to command of all forces around Washington. Two days after McClellan's return to command, General Robert E. Lee's forces crossed the Potomac River into Maryland, leading to the Battle of Antietam. That battle, a Union victory, was among the bloodiest in American history; it facilitated Lincoln's Emancipation Proclamation in January.McClellan then resisted the president's demand that he pursue Lee's withdrawing army, while General Don Carlos Buell likewise refused orders to move the Army of the Ohio against rebel forces in eastern Tennessee. Lincoln replaced Buell with William Rosecrans; and after the 1862 midterm elections he replaced McClellan with Ambrose Burnside. The appointments were both politically neutral and adroit on Lincoln's part.Burnside, against presidential advice, launched an offensive across the Rappahannock River and was defeated by Lee at Fredericksburg in December. Desertions during 1863 came in the thousands and only increased after Fredericksburg, so Lincoln replaced Burnside with Joseph Hooker.In the 1862 midterm elections the Republicans suffered severe losses due to rising inflation, high taxes, rumors of corruption, suspension of habeas corpus, military draft law, and fears that freed slaves would come North and undermine the labor market. The Emancipation Proclamation gained votes for Republicans in rural New England and the upper Midwest, but cost votes in the Irish and German strongholds and in the lower Midwest, where many Southerners had lived for generations.In the spring of 1863 Lincoln was sufficiently optimistic about upcoming military campaigns to think the end of the war could be near; the plans included attacks by Hooker on Lee north of Richmond, Rosecrans on Chattanooga, Grant on Vicksburg, and a naval assault on Charleston.Hooker was routed by Lee at the Battle of Chancellorsville in May, then resigned and was replaced by George Meade. Meade followed Lee north into Pennsylvania and beat him in the Gettysburg Campaign, but then failed to follow up despite Lincoln's demands. At the same time, Grant captured Vicksburg and gained control of the Mississippi River, splitting the far western rebel states.Emancipation ProclamationThe Federal government's power to end slavery was limited by the Constitution, which before 1865 delegated the issue to the individual states. Lincoln argued that slavery would be rendered obsolete if its expansion into new territories were prevented. He sought to persuade the states to agree to compensation for emancipating their slaves in return for their acceptance of abolition. Lincoln rejected Fremont's two emancipation attempts in August 1861, as well as one by Major General David Hunter in May 1862, on the grounds that it was not within their power, and would upset loyal border states.In June 1862, Congress passed an act banning slavery on all federal territory, which Lincoln signed. In July, the Confiscation Act of 1862 was enacted, providing court procedures to free the slaves of those convicted of aiding the rebellion; Lincoln approved the bill despite his belief that it was unconstitutional. He felt such action could be taken only within the war powers of the commander-in-chief, which he planned to exercise. Lincoln at this time reviewed a draft of the Emancipation Proclamation with his cabinet.Privately, Lincoln concluded that the Confederacy's slave base had to be eliminated. Copperheads argued that emancipation was a stumbling block to peace and reunification; Republican editor Horace Greeley of the New York Tribune agreed. In a letter of August 22, 1862, Lincoln said that while he personally wished all men could be free, regardless of that, his first obligation as president was to preserve the Union:The Emancipation Proclamation, issued on September 22, 1862, and effective January 1, 1863, affirmed the freedom of slaves in 10 states not then under Union control, with exemptions specified for areas under such control. Lincoln's comment on signing the Proclamation was: "I never, in my life, felt more certain that I was doing right, than I do in signing this paper." He spent the next 100 days preparing the army and the nation for emancipation, while Democrats rallied their voters by warning of the threat that freed slaves posed to northern whites.With the abolition of slavery in the rebel states now a military objective, Union armies advancing south liberated three million slaves.Enlisting former slaves became official policy. By the spring of 1863, Lincoln was ready to recruit black troops in more than token numbers. In a letter to Tennessee military governor Andrew Johnson encouraging him to lead the way in raising black troops, Lincoln wrote, "The bare sight of 50,000 armed and drilled black soldiers on the banks of the Mississippi would end the rebellion at once". By the end of 1863, at Lincoln's direction, General Lorenzo Thomas had recruited 20 regiments of blacks from the Mississippi Valley.The Proclamation included Lincoln's earlier plans for colonies for newly freed slaves, though that undertaking ultimately failed.Gettysburg Address (1863)Lincoln spoke at the dedication of the Gettysburg battlefield cemetery on November 19, 1863. In 272 words, and three minutes, Lincoln asserted that the nation was born not in 1789, but in 1776, "conceived in Liberty, and dedicated to the proposition that all men are created equal". He defined the war as dedicated to the principles of liberty and equality for all. He declared that the deaths of so many brave soldiers would not be in vain, that slavery would end, and the future of democracy would be assured, that "government of the people, by the people, for the people, shall not perish from the earth".Defying his prediction that "the world will little note, nor long remember what we say here", the Address became the most quoted speech in American history.General GrantGrant's victories at the Battle of Shiloh and in the Vicksburg campaign impressed Lincoln. Responding to criticism of Grant after Shiloh, Lincoln had said, "I can't spare this man. He fights." With Grant in command, Lincoln felt the Union Army could advance in multiple theaters, while also including black troops. Meade's failure to capture Lee's army after Gettysburg and the continued passivity of the Army of the Potomac persuaded Lincoln to promote Grant to supreme commander. Grant then assumed command of Meade's army.Lincoln was concerned that Grant might be considering a presidential candidacy in 1864. He arranged for an intermediary to inquire into Grant's political intentions, and once assured that he had none, Lincoln promoted Grant to the newly revived rank of Lieutenant General, a rank which had been unoccupied since George Washington. Authorization for such a promotion "with the advice and consent of the Senate" was provided by a new bill which Lincoln signed the same day he submitted Grant's name to the Senate. His nomination was confirmed by the Senate on March 2, 1864.Grant in 1864 waged the bloody Overland Campaign, which exacted heavy losses on both sides. When Lincoln asked what Grant's plans were, the persistent general replied, "I propose to fight it out on this line if it takes all summer." Grant's army moved steadily south. Lincoln traveled to Grant's headquarters at City Point, Virginia, to confer with Grant and William Tecumseh Sherman. Lincoln reacted to Union losses by mobilizing support throughout the North. Lincoln authorized Grant to target infrastructure—plantations, railroads, and bridges—hoping to weaken the South's morale and fighting ability. He emphasized defeat of the Confederate armies over destruction (which was considerable) for its own sake. Lincoln's engagement became distinctly personal on one occasion in 1864 when Confederate general Jubal Early raided Washington, D.C. Legend has it that while Lincoln watched from an exposed position, Union Captain (and future Supreme Court Justice) Oliver Wendell Holmes Jr. shouted at him, "Get down, you damn fool, before you get shot!"As Grant continued to weaken Lee's forces, efforts to discuss peace began. Confederate Vice President Stephens led a group meeting with Lincoln, Seward, and others at Hampton Roads. Lincoln refused to negotiate with the Confederacy as a coequal; his objective to end the fighting was not realized. On April 1, 1865, Grant nearly encircled Petersburg in a siege. The Confederate government evacuated Richmond and Lincoln visited the conquered capital. On April 9, Lee surrendered to Grant at Appomattox, officially ending the war.Re-electionLincoln ran for reelection in 1864, while uniting the main Republican factions, along with War Democrats Edwin M. Stanton and Andrew Johnson. Lincoln used conversation and his patronage powers—greatly expanded from peacetime—to build support and fend off the Radicals' efforts to replace him. At its convention, the Republicans selected Johnson as his running mate. To broaden his coalition to include War Democrats as well as Republicans, Lincoln ran under the label of the new Union Party.Grant's bloody stalemates damaged Lincoln's re-election prospects, and many Republicans feared defeat. Lincoln confidentially pledged in writing that if he should lose the election, he would still defeat the Confederacy before turning over the White House; Lincoln did not show the pledge to his cabinet, but asked them to sign the sealed envelope. The pledge read as follows:The Democratic platform followed the "Peace wing" of the party and called the war a "failure"; but their candidate, McClellan, supported the war and repudiated the platform. Meanwhile, Lincoln emboldened Grant with more troops and Republican party support. Sherman's capture of Atlanta in September and David Farragut's capture of Mobile ended defeatism. The Democratic Party was deeply split, with some leaders and most soldiers openly for Lincoln. The National Union Party was united by Lincoln's support for emancipation. State Republican parties stressed the perfidy of the Copperheads. On November 8, Lincoln carried all but three states, including 78 percent of Union soldiers.On March 4, 1865, Lincoln delivered his second inaugural address. In it, he deemed the war casualties to be God's will. Historian Mark Noll places the speech "among the small handful of semi-sacred texts by which Americans conceive their place in the world;" it is inscribed in the Lincoln Memorial. Lincoln said:ReconstructionReconstruction preceded the war's end, as Lincoln and his associates considered the reintegration of the nation, and the fates of Confederate leaders and freed slaves. When a general asked Lincoln how the defeated Confederates were to be treated, Lincoln replied, "Let 'em up easy." Lincoln was determined to find meaning in the war in its aftermath, and did not want to continue to outcast the southern states. His main goal was to keep the union together, so he proceeded by focusing not on whom to blame, but on how to rebuild the nation as one. Lincoln led the moderates in Reconstruction policy and was opposed by the Radicals, under Rep. Thaddeus Stevens, Sen. Charles Sumner and Sen. Benjamin Wade, who otherwise remained Lincoln's allies. Determined to reunite the nation and not alienate the South, Lincoln urged that speedy elections under generous terms be held. His Amnesty Proclamation of December 8, 1863, offered pardons to those who had not held a Confederate civil office and had not mistreated Union prisoners, if they were willing to sign an oath of allegiance.As Southern states fell, they needed leaders while their administrations were restored. In Tennessee and Arkansas, Lincoln respectively appointed Johnson and Frederick Steele as military governors. In Louisiana, Lincoln ordered General Nathaniel P. Banks to promote a plan that would reestablish statehood when 10 percent of the voters agreed, and only if the reconstructed states abolished slavery. Democratic opponents accused Lincoln of using the military to ensure his and the Republicans' political aspirations. The Radicals denounced his policy as too lenient, and passed their own plan, the 1864 Wade–Davis Bill, which Lincoln vetoed. The Radicals retaliated by refusing to seat elected representatives from Louisiana, Arkansas, and Tennessee.Lincoln's appointments were designed to harness both moderates and Radicals. To fill Chief Justice Taney's seat on the Supreme Court, he named the Radicals' choice, Salmon P. Chase, who Lincoln believed would uphold his emancipation and paper money policies.After implementing the Emancipation Proclamation, Lincoln increased pressure on Congress to outlaw slavery throughout the nation with a constitutional amendment. He declared that such an amendment would "clinch the whole matter" and by December 1863 an amendment was brought to Congress. This first attempt fell short of the required two-thirds majority in the House of Representatives. Passage became part of Lincoln's reelection platform, and after his successful reelection, the second attempt in the House passed on January 31, 1865. With ratification, it became the Thirteenth Amendment to the United States Constitution on December 6, 1865.Lincoln believed the federal government had limited responsibility to the millions of freedmen. He signed Senator Charles Sumner's Freedmen's Bureau bill that set up a temporary federal agency designed to meet the immediate needs of former slaves. The law opened land for a lease of three years with the ability to purchase title for the freedmen. Lincoln announced a Reconstruction plan that involved short-term military control, pending readmission under the control of southern Unionists.Historians agree that it is impossible to predict exactly how Reconstruction would have proceeded had Lincoln lived. Biographers James G. Randall and Richard Current, according to David Lincove, argue that:Eric Foner argues that:Native American policyLincoln's experience with Indians followed the death of his grandfather Abraham by Indian assailants, in the presence of his father and uncles. Lincoln claimed Indians were antagonistic toward his father, Thomas Lincoln, and his young family. Although Lincoln was a veteran of the Black Hawk War, which was fought in Wisconsin and Illinois in 1832, he saw no significant action. During his presidency, Lincoln's policy toward Indians was driven by politics. He used the Indian Bureau as a source of patronage, making appointments to his loyal followers in Minnesota and Wisconsin. He faced difficulties guarding Western settlers, railroads, and telegraphs, from Indian attacks.On August 17, 1862, the Dakota uprising in Minnesota, supported by the Yankton Indians, killed hundreds of white settlers, forced 30,000 from their homes, and deeply alarmed the Lincoln administration. Some believed it was a conspiracy by the Confederacy to launch a war on the Northwestern front. Lincoln sent General John Pope, the former head of the Army of Virginia, to Minnesota as commander of the new Department of the Northwest. Lincoln ordered thousands of Confederate prisoners of war sent by railroad to put down the Dakota Uprising. When the Confederates protested forcing Confederate prisoners to fight Indians, Lincoln revoked the policy. Pope fought against the Indians mercilessly, even advocating their extinction. He ordered Indian farms and food supplies be destroyed, and Indian warriors be killed. Aiding Pope, Minnesota Congressman Col. Henry H. Sibley led militiamen and regular troops to defeat the Dakota at Wood Lake. By October 9, Pope considered the uprising to be ended; hostilities ceased on December 26. An unusual military court was set up to prosecute captured natives, with Lincoln effectively acting as the route of appeal.Lincoln personally reviewed each of 303 execution warrants for Santee Dakota convicted of killing innocent farmers; he commuted the sentences of all but 39 (one was later reprieved). Lincoln sought to be lenient, but still send a message. He also faced significant public pressure, including threats of mob justice should any of the Dakota be spared. Former Governor of Minnesota Alexander Ramsey told Lincoln, in 1864, that he would have gotten more presidential election support had he executed all 303 of the Indians. Lincoln responded, "I could not afford to hang men for votes."Other enactmentsIn the selection and use of his cabinet, Lincoln employed the strengths of his opponents in a manner that emboldened his presidency. Lincoln commented on his thought process, "We need the strongest men of the party in the Cabinet. We needed to hold our own people together. I had looked the party over and concluded that these were the very strongest men. Then I had no right to deprive the country of their services."  Goodwin described the group in her biography as a Team of Rivals.Lincoln adhered to the Whig theory of a presidency focused on executing laws while deferring to Congress' responsibility for legislating. Lincoln vetoed only four bills, including the Wade-Davis Bill with its harsh Reconstruction program. The 1862 Homestead Act made millions of acres of Western government-held land available for purchase at low cost. The 1862 Morrill Land-Grant Colleges Act provided government grants for agricultural colleges in each state. The Pacific Railway Acts of 1862 and 1864 granted federal support for the construction of the United States' First Transcontinental Railroad, which was completed in 1869. The passage of the Homestead Act and the Pacific Railway Acts was enabled by the absence of Southern congressmen and senators who had opposed the measures in the 1850s.There were two measures passed to raise revenues for the Federal government: tariffs (a policy with long precedent), and a Federal income tax. In 1861, Lincoln signed the second and third Morrill Tariffs, following the first enacted by Buchanan. He also signed the Revenue Act of 1861, creating the first U.S. income tax—a flat tax of 3 percent on incomes above $800 ($ in current dollar terms). The Revenue Act of 1862 adopted rates that increased with income.Lincoln presided over the expansion of the federal government's economic influence in other areas. The National Banking Act created the system of national banks. The US issued paper currency for the first time, known as greenbacks—printed in green on the reverse side. In 1862, Congress created the Department of Agriculture.In response to rumors of a renewed draft, the editors of the New York World and the Journal of Commerce published a false draft proclamation that created an opportunity for the editors and others to corner the gold market. Lincoln attacked the media for such behavior, and ordered a military seizure of the two papers which lasted for two days.Lincoln is largely responsible for the Thanksgiving holiday. Thanksgiving had become a regional holiday in New England in the 17th century. It had been sporadically proclaimed by the federal government on irregular dates. The prior proclamation had been during James Madison's presidency 50 years earlier. In 1863, Lincoln declared the final Thursday in November of that year to be a day of Thanksgiving.In June 1864, Lincoln approved the Yosemite Grant enacted by Congress, which provided unprecedented federal protection for the area now known as Yosemite National Park.Judicial appointmentsSupreme Court appointmentsLincoln's philosophy on court nominations was that "we cannot ask a man what he will do, and if we should, and he should answer us, we should despise him for it. Therefore we must take a man whose opinions are known." Lincoln made five appointments to the Supreme Court. Noah Haynes Swayne was an anti-slavery lawyer who was committed to the Union. Samuel Freeman Miller supported Lincoln in the 1860 election and was an avowed abolitionist. David Davis was Lincoln's campaign manager in 1860 and had served as a judge in the Illinois court circuit where Lincoln practiced. Democrat Stephen Johnson Field, a previous California Supreme Court justice, provided geographic and political balance. Finally, Lincoln's Treasury Secretary, Salmon P. Chase, became Chief Justice. Lincoln believed Chase was an able jurist, would support Reconstruction legislation, and that his appointment united the Republican Party.Other judicial appointmentsLincoln appointed 27 judges to the United States district courts but no judges to the United States circuit courts during his time in office.States admitted to the UnionWest Virginia was admitted to the Union on June 20, 1863. Nevada, which became the third state in the far-west of the continent, was admitted as a free state on October 31, 1864.AssassinationJohn Wilkes Booth was a well-known actor and a Confederate spy from Maryland; though he never joined the Confederate army, he had contacts with the Confederate secret service. After attending an April 11, 1865 speech in which Lincoln promoted voting rights for blacks, Booth hatched a plot to assassinate the President. When Booth learned of the Lincolns' intent to attend a play with General Grant, he planned to assassinate Lincoln and Grant at Ford's Theatre. Lincoln and his wife attended the play Our American Cousin on the evening of April 14, just five days after the Union victory at the Battle of Appomattox Courthouse. At the last minute, Grant decided to go to New Jersey to visit his children instead of attending the play.At 10:15 in the evening, Booth entered the back of Lincoln's theater box, crept up from behind, and fired at the back of Lincoln's head, mortally wounding him. Lincoln's guest Major Henry Rathbone momentarily grappled with Booth, but Booth stabbed him and escaped. After being attended by Doctor Charles Leale and two other doctors, Lincoln was taken across the street to Petersen House. After remaining in a coma for eight hours, Lincoln died at 7:22 in the morning on April 15. Stanton saluted and said, "Now he belongs to the ages." Lincoln's body was placed in a flag-wrapped coffin, which was loaded into a hearse and escorted to the White House by Union soldiers. President Johnson was sworn in the next morning.Two weeks later, Booth, refusing to surrender, was tracked to a farm in Virginia, and was mortally shot by Sergeant Boston Corbett and died on April 26. Secretary of War Stanton had issued orders that Booth be taken alive, so Corbett was initially arrested for court martial. After a brief interview, Stanton declared him a patriot and dismissed the charge.Funeral and burial The late President lay in state, first in the East Room of the White House, and then in the Capitol Rotunda from April 19 through April 21. The caskets containing Lincoln's body and the body of his son Willie traveled for three weeks on the Lincoln Special funeral train. The train followed a circuitous route from Washington D.C. to Springfield, Illinois, stopping at many cities for memorials attended by hundreds of thousands. Many others gathered along the tracks as the train passed with bands, bonfires, and hymn singing or in silent grief. Poet Walt Whitman composed "When Lilacs Last in the Dooryard Bloom'd" to eulogize him, one of four poems he wrote about Lincoln. African Americans were especially moved; they had lost 'their Moses'. In a larger sense, the reaction was in response to the deaths of so many men in the war. Historians emphasized the widespread shock and sorrow, but noted that some Lincoln haters celebrated his death. Lincoln's body was buried at Oak Ridge Cemetery in Springfield and now lies within the Lincoln Tomb.Religious and philosophical beliefsAs a young man, Lincoln was a religious skeptic. He was deeply familiar with the Bible, quoting and praising it. He was private about his position on organized religion and respected the beliefs of others. He never made a clear profession of Christian beliefs. Through his entire public career, Lincoln had a proneness for quoting Scripture. His three most famous speeches—the House Divided Speech, the Gettysburg Address, and his second inaugural—each contain direct allusions to Providence and quotes from Scripture.In the 1840s, Lincoln subscribed to the Doctrine of Necessity, a belief that the human mind was controlled by a higher power. With the death of his son Edward in 1850 he more frequently expressed a dependence on God. He never joined a church, although he frequently attended First Presbyterian Church with his wife beginning in 1852.In the 1850s, Lincoln asserted his belief in "providence" in a general way, and rarely used the language or imagery of the evangelicals; he regarded the republicanism of the Founding Fathers with an almost religious reverence. The death of son Willie in February 1862 may have caused him to look toward religion for solace. After Willie's death, he questioned the divine necessity of the war's severity. He wrote at this time that God "could have either saved or destroyed the Union without a human contest. Yet the contest began. And having begun, He could give the final victory to either side any day. Yet the contest proceeds."Lincoln did believe in an all-powerful God that shaped events and by 1865 was expressing those beliefs in major speeches. By the end of the war, he increasingly appealed to the Almighty for solace and to explain events, writing on April 4, 1864, to a newspaper editor in Kentucky: I claim not to have controlled events, but confess plainly that events have controlled me. Now, at the end of three years struggle the nation's condition is not what either party, or any man devised, or expected. God alone can claim it. Whither it is tending seems plain. If God now wills the removal of a great wrong, and wills also that we of the North as well as you of the South, shall pay fairly for our complicity in that wrong, impartial history will find therein new cause to attest and revere the justice and goodness of God.This spirituality can best be seen in his second inaugural address, considered by some scholars as the greatest such address in American history, and by Lincoln himself as his own greatest speech, or one of them at the very least. Lincoln explains therein that the cause, purpose, and result of the war was God's will. Lincoln's frequent use of religious imagery and language toward the end of his life may have reflected his own personal beliefs or might have been a device to reach his audiences, who were mostly evangelical Protestants. On the day Lincoln was assassinated, he reportedly told his wife he desired to visit the Holy Land.HealthLincoln is believed to have had depression, smallpox, and malaria. He took blue mass pills, which contained mercury, to treat constipation. It is unknown to what extent he may have suffered from mercury poisoning.Several claims have been made that Lincoln's health was declining before the assassination. These are often based on photographs of Lincoln appearing to show weight loss and muscle wasting. It is also suspected that he might have had a rare genetic disease such as Marfan syndrome or multiple endocrine neoplasia type 2B.LegacyRepublican values Lincoln's redefinition of republican values has been stressed by historians such as John Patrick Diggins, Harry V. Jaffa, Vernon Burton, Eric Foner, and Herman J. Belz. Lincoln called the Declaration of Independence—which emphasized freedom and equality for all—the "sheet anchor" of republicanism beginning in the 1850s. He did this at a time when the Constitution, which "tolerated slavery", was the focus of most political discourse. Diggins notes, "Lincoln presented Americans a theory of history that offers a profound contribution to the theory and destiny of republicanism itself" in the 1860 Cooper Union speech. Instead of focusing on the legality of an argument, he focused on the moral basis of republicanism.His position on war was founded on a legal argument regarding the Constitution as essentially a contract among the states, and all parties must agree to pull out of the contract. Furthermore, it was a national duty to ensure the republic stands in every state. Many soldiers and religious leaders from the north, though, felt the fight for liberty and freedom of slaves was ordained by their moral and religious beliefs.As a Whig activist, Lincoln was a spokesman for business interests, favoring high tariffs, banks, infrastructure improvements, and railroads, in opposition to Jacksonian democrats. William C. Harris found that Lincoln's "reverence for the Founding Fathers, the Constitution, the laws under it, and the preservation of the Republic and its institutions strengthened his conservatism." James G. Randall emphasizes his tolerance and moderation "in his preference for orderly progress, his distrust of dangerous agitation, and his reluctance toward ill digested schemes of reform." Randall concludes that "he was conservative in his complete avoidance of that type of so-called 'radicalism' which involved abuse of the South, hatred for the slaveholder, thirst for vengeance, partisan plotting, and ungenerous demands that Southern institutions be transformed overnight by outsiders."Reunification of the statesIn Lincoln's first inaugural address, he explored the nature of democracy. He denounced secession as anarchy, and explained that majority rule had to be balanced by constitutional restraints. He said "A majority held in restraint by constitutional checks and limitations, and always changing easily with deliberate changes of popular opinions and sentiments, is the only true sovereign of a free people."The successful reunification of the states had consequences for how people viewed the country. The term "the United States" has historically been used sometimes in the plural ("these United States") and other times in the singular. The Civil War was a significant force in the eventual dominance of the singular usage by the end of the 19th century.Historical reputation In surveys of U.S. scholars ranking presidents conducted since 1948, the top three presidents are Lincoln, Washington, and Franklin Delano Roosevelt, although the order varies. Between 1999 and 2011, Lincoln, John F. Kennedy, and Ronald Reagan have been the top-ranked presidents in eight surveys, according to Gallup. A 2004 study found that scholars in the fields of history and politics ranked Lincoln number one, while legal scholars placed him second after George Washington.Lincoln's assassination left him a national martyr. He was viewed by abolitionists as a champion of human liberty. Republicans linked Lincoln's name to their party. Many, though not all, in the South considered Lincoln as a man of outstanding ability. Historians have said he was "a classical liberal" in the 19th-century sense. Allen C. Guelzo states that Lincoln was a "classical liberal democrat—an enemy of artificial hierarchy, a friend to trade and business as ennobling and enabling, and an American counterpart to Mill, Cobden, and Bright", whose portrait Lincoln hung in his White House office.Schwartz argues that Lincoln's American reputation grew slowly from the late 19th century until the Progressive Era (1900–1920s), when he emerged as one of America's most venerated heroes, even among white Southerners. The high point came in 1922 with the dedication of the Lincoln Memorial on the National Mall in Washington, D.C.Union nationalism, as envisioned by Lincoln, "helped lead America to the nationalism of Theodore Roosevelt, Woodrow Wilson, and Franklin Delano Roosevelt." In the New Deal era, liberals honored Lincoln not so much as the self-made man or the great war president, but as the advocate of the common man who they claimed would have supported the welfare state.Sociologist Barry Schwartz argues that in the 1930s and 1940s the memory of Abraham Lincoln was practically sacred and provided the nation with "a moral symbol inspiring and guiding American life." During the Great Depression, he argues, Lincoln served "as a means for seeing the world's disappointments, for making its sufferings not so much explicable as meaningful". Franklin D. Roosevelt, preparing America for war, used the words of the Civil War president to clarify the threat posed by Germany and Japan. Americans asked, "What would Lincoln do?" However, Schwartz also finds that since World War II Lincoln's symbolic power has lost relevance, and this "fading hero is symptomatic of fading confidence in national greatness." He suggested that postmodernism and multiculturalism have diluted greatness as a concept.In the Cold War years, Lincoln's image shifted to a symbol of freedom who brought hope to those oppressed by Communist regimes. By the late 1960s, some African-American intellectuals, led by Lerone Bennett Jr., rejected Lincoln's role as the Great Emancipator. Bennett won wide attention when he called Lincoln a white supremacist in 1968. He noted that Lincoln used ethnic slurs and told jokes that ridiculed blacks. Bennett argued that Lincoln opposed social equality, and proposed sending freed slaves to another country. Defenders, such as authors Dirck and Cashin, retorted that he was not as bad as most politicians of his day; and that he was a "moral visionary" who deftly advanced the abolitionist cause, as fast as politically possible. The emphasis shifted away from Lincoln the emancipator to an argument that blacks had freed themselves from slavery, or at least were responsible for pressuring the government on emancipation.By the 1970s, Lincoln had become a hero to political conservatives, apart from neo-Confederates such as Mel Bradford who denounced his treatment of the white South, for his intense nationalism, support for business, his insistence on stopping the spread of human bondage, his acting in terms of Lockean and Burkean principles on behalf of both liberty and tradition, and his devotion to the principles of the Founding Fathers. Lincoln became a favorite exemplar for liberal intellectuals across the world.Historian Barry Schwartz wrote in 2009 that Lincoln's image suffered "erosion, fading prestige, benign ridicule" in the late 20th century. On the other hand, Donald opined in his 1996 biography that Lincoln was distinctly endowed with the personality trait of negative capability, defined by the poet John Keats and attributed to extraordinary leaders who were "content in the midst of uncertainties and doubts, and not compelled toward fact or reason".In the 21st century, President Barack Obama named Lincoln his favorite president and insisted on using the Lincoln Bible for his inaugural ceremonies. Lincoln has often been portrayed by Hollywood, almost always in a flattering light.Memory and memorialsLincoln's portrait appears on two denominations of United States currency, the penny and the $5 bill. His likeness also appears on many postage stamps. While he is usually portrayed bearded, he did not grow a beard until 1860 at the suggestion of 11-year-old Grace Bedell. He was the first of five presidents to do so.He has been memorialized in many town, city, and county names, including the capital of Nebraska. The United States Navy   is named after Lincoln, the second Navy ship to bear his name.Lincoln Memorial is one of the most visited monuments in the nation's capital, and is one of the top five visited National Park Service sites in the country. Ford's Theatre, among the top sites in Washington, D.C., is across the street from Petersen House (where he died). Memorials in Springfield, Illinois include Abraham Lincoln Presidential Library and Museum, Lincoln's home, as well as his tomb. A portrait carving of Lincoln appears with those of three other presidents on Mount Rushmore, which receives about 3 million visitors a year.See also Outline of Abraham Lincoln Grace Bedell Lincoln Tower List of civil rights leaders List of photographs of Abraham Lincoln Lincoln (film): 2012 film by Steven Spielberg. Linconia, a proposed colony in Central America named for LincolnNotesReferencesBibliography                       Ellenberg's essay is adapted from his 2021 book, Shape: The Hidden Geometry of Information, Biology, Strategy, Democracy, and Everything Else, Penguin Press. ISBN 9781984879059External linksOfficial Abraham Lincoln Presidential Library and Museum The Lincoln Presidential Library's ongoing digitization of all documents written by or to Abraham Lincoln during his lifetime Collected Works of Abraham Lincoln – complete collected works as edited by Basler et al. (1958) – an online edition available through University of Michigan Library Digital Collections White House biographyOrganizations Abraham Lincoln Association  Abraham Lincoln Bicentennial FoundationMedia coverageOther Abraham Lincoln: A Resource Guide from the Library of Congress "Life Portrait of Abraham Lincoln", from C-SPAN's American presidents: Life Portraits, June 28, 1999 "Writings of Abraham Lincoln" from C-SPAN's American Writers: A Journey Through History Abraham Lincoln: Original Letters and Manuscripts – Shapell Manuscript Foundation Lincoln/Net: Abraham Lincoln Historical Digitization Project – Northern Illinois University Libraries Teaching Abraham Lincoln  – National Endowment for the Humanities    In Popular Song: Our Noble Chief Has Passed Away by Cooper/Thomas Abraham Lincoln Recollections and Newspaper Articles Collection , McLean County Museum of History Digitized items in the Alfred Whital Stern Collection of Lincolniana in the Rare Book and Special Collections Division in the Library of Congress 1809 births1865 deaths1865 murders in the United States19th-century American politicians19th-century presidents of the United StatesAmerican abolitionistsAmerican colonization movementAmerican lawyers admitted to the practice of law by reading lawAmerican military personnel of the Indian WarsAmerican militia officersAmerican nationalistsAmerican people of English descentAmerican political party foundersIllinois postmastersAmerican surveyorsAssassinated presidents of the United StatesBurials at Oak Ridge CemeteryCandidates in the 1860 United States presidential electionCandidates in the 1864 United States presidential electionHall of Fame for Great Americans inducteesIllinois Central Railroad peopleIllinois RepublicansIllinois WhigsIllinois lawyersAbrahamMale murder victimsMembers of the Illinois House of RepresentativesMembers of the United States House of Representatives from IllinoisPeople associated with the assassination of Abraham LincolnPeople from Coles County, IllinoisPeople from LaRue County, KentuckyPeople from Macon County, IllinoisPeople from Spencer County, IndianaPeople murdered in Washington, D.C.People of Illinois in the American Civil WarPeople with mood disordersPoliticians from Springfield, IllinoisPresidents of the United StatesRepublican Party (United States) presidential nomineesRepublican Party presidents of the United StatesUnion political leadersWhig Party members of the United States House of Representatives
Aristotle (;  Aristotélēs, ; 384–322 BC) was a Greek philosopher and polymath during the Classical period in Ancient Greece. Taught by Plato, he was the founder of the Lyceum, the Peripatetic school of philosophy, and the Aristotelian tradition. His writings cover many subjects including physics, biology, zoology, metaphysics, logic, ethics, aesthetics, poetry, theatre, music, rhetoric, psychology, linguistics, economics, politics, meteorology, geology and government. Aristotle provided a complex synthesis of the various philosophies existing prior to him. It was above all from his teachings that the West inherited its intellectual lexicon, as well as problems and methods of inquiry. As a result, his philosophy has exerted a unique influence on almost every form of knowledge in the West and it continues to be a subject of contemporary philosophical discussion.Little is known about his life. Aristotle was born in the city of Stagira in Northern Greece. His father, Nicomachus, died when Aristotle was a child, and he was brought up by a guardian. At seventeen or eighteen years of age he joined Plato's Academy in Athens and remained there until the age of thirty-seven (c. 347 BC). Shortly after Plato died, Aristotle left Athens and, at the request of Philip II of Macedon, tutored Alexander the Great beginning in 343 BC. He established a library in the Lyceum which helped him to produce many of his hundreds of books on papyrus scrolls. Though Aristotle wrote many elegant treatises and dialogues for publication, only around a third of his original output has survived, none of it intended for publication.Aristotle's views profoundly shaped medieval scholarship. The influence of physical science extended from Late Antiquity and the Early Middle Ages into the Renaissance, and were not replaced systematically until the Enlightenment and theories such as classical mechanics were developed. Some of Aristotle's zoological observations found in his biology, such as on the hectocotyl (reproductive) arm of the octopus, were disbelieved until the 19th century. He also influenced Judeo-Islamic philosophies (800–1400) during the Middle Ages, as well as Christian theology, especially the Neoplatonism of the Early Church and the scholastic tradition of the Catholic Church. Aristotle was revered among medieval Muslim scholars as "The First Teacher", and among medieval Christians like Thomas Aquinas as simply "The Philosopher", while the poet Dante called him “the master of those who know". His works contain the earliest known formal study of logic, and were studied by medieval scholars such as Peter Abelard and John Buridan.Aristotle's influence on logic continued well into the 19th century. In addition, his ethics, though always influential, gained renewed interest with the modern advent of virtue ethics.Aristotle has been called "the father of logic", "the father of biology", "the father of political science", "the father of zoology", "the father of embryology", "the father of natural law", "the father of scientific method", "the father of rhetoric", "the father of psychology", "the father of realism", "the father of criticism", "the father of individualism", "the father of teleology", and "the father of meteorology".LifeIn general, the details of Aristotle's life are not well-established. The biographies written in ancient times are often speculative and historians only agree on a few salient points.Aristotle, whose name means "the best purpose" in Ancient Greek, was born in 384 BC in Stagira, Chalcidice, about 55 km (34 miles) east of modern-day Thessaloniki. His father, Nicomachus, was the personal physician to King Amyntas of Macedon. While he was young, Aristotle learned about biology and medical information, which was taught by his father. Both of Aristotle's parents died when he was about thirteen, and Proxenus of Atarneus became his guardian. Although little information about Aristotle's childhood has survived, he probably spent some time within the Macedonian palace, making his first connections with the Macedonian monarchy.At the age of seventeen or eighteen, Aristotle moved to Athens to continue his education at Plato's Academy. He probably experienced the Eleusinian Mysteries as he wrote when describing the sights one viewed at the Eleusinian Mysteries, "to experience is to learn" [παθείν μαθεĩν]. Aristotle remained in Athens for nearly twenty years before leaving in 348/47 BC. The traditional story about his departure records that he was disappointed with the academy's direction after control passed to Plato's nephew Speusippus, although it is possible that he feared the anti-Macedonian sentiments in Athens at that time and left before Plato died. Aristotle then accompanied Xenocrates to the court of his friend Hermias of Atarneus in Asia Minor. After the death of Hermias, Aristotle travelled with his pupil Theophrastus to the island of Lesbos, where together they researched the botany and zoology of the island and its sheltered lagoon. While in Lesbos, Aristotle married Pythias, either Hermias's adoptive daughter or niece. She bore him a daughter, whom they also named Pythias. In 343 BC, Aristotle was invited by Philip II of Macedon to become the tutor to his son Alexander.Aristotle was appointed as the head of the royal academy of Macedon. During Aristotle's time in the Macedonian court, he gave lessons not only to Alexander but also to two other future kings: Ptolemy and Cassander. Aristotle encouraged Alexander toward eastern conquest, and Aristotle's own attitude towards Persia was unabashedly ethnocentric. In one famous example, he counsels Alexander to be "a leader to the Greeks and a despot to the barbarians, to look after the former as after friends and relatives, and to deal with the latter as with beasts or plants". By 335 BC, Aristotle had returned to Athens, establishing his own school there known as the Lyceum. Aristotle conducted courses at the school for the next twelve years. While in Athens, his wife Pythias died and Aristotle became involved with Herpyllis of Stagira, who bore him a son whom he named after his father, Nicomachus. If the Suda  an uncritical compilation from the Middle Ages  is accurate, he may also have had an erômenos, Palaephatus of Abydus.This period in Athens, between 335 and 323 BC, is when Aristotle is believed to have composed many of his works. He wrote many dialogues, of which only fragments have survived. Those works that have survived are in treatise form and were not, for the most part, intended for widespread publication; they are generally thought to be lecture aids for his students. His most important treatises include Physics, Metaphysics, Nicomachean Ethics, Politics, On the Soul and Poetics. Aristotle studied and made significant contributions to "logic, metaphysics, mathematics, physics, biology, botany, ethics, politics, agriculture, medicine, dance, and theatre."Near the end of his life, Alexander and Aristotle became estranged over Alexander's relationship with Persia and Persians. A widespread tradition in antiquity suspected Aristotle of playing a role in Alexander's death, but the only evidence of this is an unlikely claim made some six years after the death. Following Alexander's death, anti-Macedonian sentiment in Athens was rekindled. In 322 BC, Demophilus and Eurymedon the Hierophant reportedly denounced Aristotle for impiety, prompting him to flee to his mother's family estate in Chalcis, on Euboea, at which occasion he was said to have stated: "I will not allow the Athenians to sin twice against philosophy" – a reference to Athens's trial and execution of Socrates. He died on Euboea of natural causes later that same year, having named his student Antipater as his chief executor and leaving a will in which he asked to be buried next to his wife.Speculative philosophyLogicWith the Prior Analytics, Aristotle is credited with the earliest study of formal logic, and his conception of it was the dominant form of Western logic until 19th-century advances in mathematical logic. Kant stated in the Critique of Pure Reason that with Aristotle logic reached its completion.OrganonWhat is today called Aristotelian logic with its types of syllogism (methods of logical argument), Aristotle himself would have labelled "analytics". The term "logic" he reserved to mean dialectics. Most of Aristotle's work is probably not in its original form, because it was most likely edited by students and later lecturers. The logical works of Aristotle were compiled into a set of six books called the Organon around 40 BC by Andronicus of Rhodes or others among his followers. The books are: Categories On Interpretation Prior Analytics Posterior Analytics Topics On Sophistical RefutationsThe order of the books (or the teachings from which they are composed) is not certain, but this list was derived from analysis of Aristotle's writings. It goes from the basics, the analysis of simple terms in the Categories, the analysis of propositions and their elementary relations in On Interpretation, to the study of more complex forms, namely, syllogisms (in the Analytics) and dialectics (in the Topics and Sophistical Refutations). The first three treatises form the core of the logical theory stricto sensu: the grammar of the language of logic and the correct rules of reasoning. The Rhetoric is not conventionally included, but it states that it relies on the Topics.MetaphysicsThe word "metaphysics" appears to have been coined by the first century AD editor who assembled various small selections of Aristotle's works to the treatise we know by the name Metaphysics. Aristotle called it "first philosophy", and distinguished it from mathematics and natural science (physics) as the contemplative (theoretikē) philosophy which is "theological" and studies the divine. He wrote in his Metaphysics (1026a16):Substance Aristotle examines the concepts of substance (ousia) and essence (to ti ên einai, "the what it was to be") in his Metaphysics (Book VII), and he concludes that a particular substance is a combination of both matter and form, a philosophical theory called hylomorphism. In Book VIII, he distinguishes the matter of the substance as the substratum, or the stuff of which it is composed. For example, the matter of a house is the bricks, stones, timbers, etc., or whatever constitutes the potential house, while the form of the substance is the actual house, namely 'covering for bodies and chattels' or any other differentia that let us define something as a house. The formula that gives the components is the account of the matter, and the formula that gives the differentia is the account of the form.Immanent realism Like his teacher Plato, Aristotle's philosophy aims at the universal. Aristotle's ontology places the universal (katholou) in particulars (kath' hekaston), things in the world, whereas for Plato the universal is a separately existing form which actual things imitate. For Aristotle, "form" is still what phenomena are based on, but is "instantiated" in a particular substance.Plato argued that all things have a universal form, which could be either a property or a relation to other things. When one looks at an apple, for example, one sees an apple, and one can also analyse a form of an apple. In this distinction, there is a particular apple and a universal form of an apple. Moreover, one can place an apple next to a book, so that one can speak of both the book and apple as being next to each other. Plato argued that there are some universal forms that are not a part of particular things. For example, it is possible that there is no particular good in existence, but "good" is still a proper universal form. Aristotle disagreed with Plato on this point, arguing that all universals are instantiated at some period of time, and that there are no universals that are unattached to existing things. In addition, Aristotle disagreed with Plato about the location of universals. Where Plato spoke of the world of forms, a place where all universal forms subsist, Aristotle maintained that universals exist within each thing on which each universal is predicated. So, according to Aristotle, the form of apple exists within each apple, rather than in the world of the forms.Potentiality and actuality With regard to the change (kinesis) and its causes now, as he defines in his Physics and On Generation and Corruption 319b–320a, he distinguishes the coming to be from: growth and diminution, which is change in quantity; locomotion, which is change in space; and alteration, which is change in quality.The coming to be is a change where nothing persists of which the resultant is a property. In that particular change he introduces the concept of potentiality (dynamis) and actuality (entelecheia) in association with the matter and the form. Referring to potentiality, this is what a thing is capable of doing or being acted upon if the conditions are right and it is not prevented by something else. For example, the seed of a plant in the soil is potentially (dynamei) a plant, and if it is not prevented by something, it will become a plant. Potentially beings can either 'act' (poiein) or 'be acted upon' (paschein), which can be either innate or learned. For example, the eyes possess the potentiality of sight (innate – being acted upon), while the capability of playing the flute can be possessed by learning (exercise – acting). Actuality is the fulfilment of the end of the potentiality. Because the end (telos) is the principle of every change, and for the sake of the end exists potentiality, therefore actuality is the end. Referring then to the previous example, it can be said that an actuality is when a plant does one of the activities that plants do.In summary, the matter used to make a house has potentiality to be a house and both the activity of building and the form of the final house are actualities, which is also a final cause or end. Then Aristotle proceeds and concludes that the actuality is prior to potentiality in formula, in time and in substantiality. With this definition of the particular substance (i.e., matter and form), Aristotle tries to solve the problem of the unity of the beings, for example, "what is it that makes a man one"? Since, according to Plato there are two Ideas: animal and biped, how then is man a unity? However, according to Aristotle, the potential being (matter) and the actual one (form) are one and the same.EpistemologyAristotle's immanent realism means his epistemology is based on the study of things that exist or happen in the world, and rises to knowledge of the universal, whereas for Plato epistemology begins with knowledge of universal Forms (or ideas) and descends to knowledge of particular imitations of these. Aristotle uses induction from examples alongside deduction, whereas Plato relies on deduction from a priori principles.Natural philosophyAristotle's "natural philosophy" spans a wide range of natural phenomena including those now covered by physics, biology and other natural sciences. In Aristotle's terminology, "natural philosophy" is a branch of philosophy examining the phenomena of the natural world, and includes fields that would be regarded today as physics, biology and other natural sciences. Aristotle's work encompassed virtually all facets of intellectual inquiry. Aristotle makes philosophy in the broad sense coextensive with reasoning, which he also would describe as "science". However, his use of the term science carries a different meaning than that covered by the term "scientific method". For Aristotle, "all science (dianoia) is either practical, poetical or theoretical" (Metaphysics 1025b25). His practical science includes ethics and politics; his poetical science means the study of fine arts including poetry; his theoretical science covers physics, mathematics and metaphysics.PhysicsFive elementsIn his On Generation and Corruption, Aristotle related each of the four elements proposed earlier by Empedocles, Earth, Water, Air, and Fire, to two of the four sensible qualities, hot, cold, wet, and dry. In the Empedoclean scheme, all matter was made of the four elements, in differing proportions. Aristotle's scheme added the heavenly Aether, the divine substance of the heavenly spheres, stars and planets.MotionAristotle describes two kinds of motion: "violent" or "unnatural motion", such as that of a thrown stone, in the Physics (254b10), and "natural motion", such as of a falling object, in On the Heavens (300a20). In violent motion, as soon as the agent stops causing it, the motion stops also: in other words, the natural state of an object is to be at rest, since Aristotle does not address friction. With this understanding, it can be observed that, as Aristotle stated, heavy objects (on the ground, say) require more force to make them move; and objects pushed with greater force move faster. This would imply the equation ,incorrect in modern physics.Natural motion depends on the element concerned: the aether naturally moves in a circle around the heavens, while the 4 Empedoclean elements move vertically up (like fire, as is observed) or down (like earth) towards their natural resting places.In the Physics (215a25), Aristotle effectively states a quantitative law, that the speed, v, of a falling body is proportional (say, with constant c) to its weight, W, and inversely proportional to the density, ρ, of the fluid in which it is falling: Aristotle implies that in a vacuum the speed of fall would become infinite, and concludes from this apparent absurdity that a vacuum is not possible. Opinions have varied on whether Aristotle intended to state quantitative laws. Henri Carteron held the "extreme view" that Aristotle's concept of force was basically qualitative, but other authors reject this.Archimedes corrected Aristotle's theory that bodies move towards their natural resting places; metal boats can float if they displace enough water; floating depends in Archimedes' scheme on the mass and volume of the object, not, as Aristotle thought, its elementary composition.Aristotle's writings on motion remained influential until the Early Modern period. John Philoponus (in the Middle Ages) and Galileo are said to have shown by experiment that Aristotle's claim that a heavier object falls faster than a lighter object is incorrect. A contrary opinion is given by Carlo Rovelli, who argues that Aristotle's physics of motion is correct within its domain of validity, that of objects in the Earth's gravitational field immersed in a fluid such as air. In this system, heavy bodies in steady fall indeed travel faster than light ones (whether friction is ignored, or not), and they do fall more slowly in a denser medium.Newton's "forced" motion corresponds to Aristotle's "violent" motion with its external agent, but Aristotle's assumption that the agent's effect stops immediately it stops acting (e.g., the ball leaves the thrower's hand) has awkward consequences: he has to suppose that surrounding fluid helps to push the ball along to make it continue to rise even though the hand is no longer acting on it, resulting in the Medieval theory of impetus.Four causesAristotle suggested that the reason for anything coming about can be attributed to four different types of simultaneously active factors. His term aitia is traditionally translated as "cause", but it does not always refer to temporal sequence; it might be better translated as "explanation", but the traditional rendering will be employed here. Material cause describes the material out of which something is composed. Thus the material cause of a table is wood. It is not about action. It does not mean that one domino knocks over another domino. The formal cause is its form, i.e., the arrangement of that matter. It tells one what a thing is, that a thing is determined by the definition, form, pattern, essence, whole, synthesis or archetype. It embraces the account of causes in terms of fundamental principles or general laws, as the whole (i.e., macrostructure) is the cause of its parts, a relationship known as the whole-part causation. Plainly put, the formal cause is the idea in the mind of the sculptor that brings the sculpture into being. A simple example of the formal cause is the mental image or idea that allows an artist, architect, or engineer to create a drawing. The efficient cause is "the primary source", or that from which the change under consideration proceeds. It identifies 'what makes of what is made and what causes change of what is changed' and so suggests all sorts of agents, non-living or living, acting as the sources of change or movement or rest. Representing the current understanding of causality as the relation of cause and effect, this covers the modern definitions of "cause" as either the agent or agency or particular events or states of affairs. In the case of two dominoes, when the first is knocked over it causes the second also to fall over. In the case of animals, this agency is a combination of how it develops from the egg, and how its body functions. The final cause (telos) is its purpose, the reason why a thing exists or is done, including both purposeful and instrumental actions and activities. The final cause is the purpose or function that something is supposed to serve. This covers modern ideas of motivating causes, such as volition. In the case of living things, it implies adaptation to a particular way of life.OpticsAristotle describes experiments in optics using a camera obscura in Problems, book 15. The apparatus consisted of a dark chamber with a small aperture that let light in. With it, he saw that whatever shape he made the hole, the sun's image always remained circular. He also noted that increasing the distance between the aperture and the image surface magnified the image.Chance and spontaneityAccording to Aristotle, spontaneity and chance are causes of some things, distinguishable from other types of cause such as simple necessity. Chance as an incidental cause lies in the realm of accidental things, "from what is spontaneous". There is also more a specific kind of chance, which Aristotle names "luck", that only applies to people's moral choices.AstronomyIn astronomy, Aristotle refuted Democritus's claim that the Milky Way was made up of "those stars which are shaded by the earth from the sun's rays," pointing out correctly that if "the size of the sun is greater than that of the earth and the distance of the stars from the earth many times greater than that of the sun, then... the sun shines on all the stars and the earth screens none of them."Geology/Natural SciencesAristotle was one of the first people to record any geological observations. He stated that geological change was too slow to be observed in one person's lifetime.The geologist Charles Lyell noted that Aristotle described such change, including "lakes that had dried up" and "deserts that had become watered by rivers", giving as examples the growth of the Nile delta since the time of Homer, and "the upheaving of one of the Aeolian islands, previous to a volcanic eruption."'Aristotle also made many observations about the hydrologic cycle and meteorology (including his major writings "Meteorologica"). For example, he made some of the earliest observations about desalination: he observed early – and correctly – that when seawater is heated, freshwater evaporates and that the oceans are then replenished by the cycle of rainfall and river runoff ("I have proved by experiment that salt water evaporated forms fresh and the vapor does not when it condenses condense into sea water again.")BiologyEmpirical researchAristotle was the first person to study biology systematically, and biology forms a large part of his writings. He spent two years observing and describing the zoology of Lesbos and the surrounding seas, including in particular the Pyrrha lagoon in the centre of Lesbos. His data in History of Animals, Generation of Animals, Movement of Animals, and Parts of Animals are assembled from his own observations, statements given by people with specialized knowledge such as beekeepers and fishermen, and less accurate accounts provided by travellers from overseas. His apparent emphasis on animals rather than plants is a historical accident: his works on botany have been lost, but two books on plants by his pupil Theophrastus have survived.Aristotle reports on the sea-life visible from observation on Lesbos and the catches of fishermen. He describes the catfish, electric ray, and frogfish in detail, as well as cephalopods such as the octopus and paper nautilus. His description of the hectocotyl arm of cephalopods, used in sexual reproduction, was widely disbelieved until the 19th century. He gives accurate descriptions of the four-chambered fore-stomachs of ruminants, and of the ovoviviparous embryological development of the hound shark.He notes that an animal's structure is well matched to function, so, among birds, the heron, which lives in marshes with soft mud and lives by catching fish, has a long neck and long legs, and a sharp spear-like beak, whereas ducks that swim have short legs and webbed feet. Darwin, too, noted these sorts of differences between similar kinds of animal, but unlike Aristotle used the data to come to the theory of evolution. Aristotle's writings can seem to modern readers close to implying evolution, but while Aristotle was aware that new mutations or hybridizations could occur, he saw these as rare accidents. For Aristotle, accidents, like heat waves in winter, must be considered distinct from natural causes. He was thus critical of Empedocles's materialist theory of a "survival of the fittest" origin of living things and their organs, and ridiculed the idea that accidents could lead to orderly results. To put his views into modern terms, he nowhere says that different species can have a common ancestor, or that one kind can change into another, or that kinds can become extinct.Scientific styleAristotle did not do experiments in the modern sense. He used the ancient Greek term pepeiramenoi to mean observations, or at most investigative procedures like dissection. In Generation of Animals, he finds a fertilized hen's egg of a suitable stage and opens it to see the embryo's heart beating inside.Instead, he practiced a different style of science: systematically gathering data, discovering patterns common to whole groups of animals, and inferring possible causal explanations from these. This style is common in modern biology when large amounts of data become available in a new field, such as genomics. It does not result in the same certainty as experimental science, but it sets out testable hypotheses and constructs a narrative explanation of what is observed. In this sense, Aristotle's biology is scientific.From the data he collected and documented, Aristotle inferred quite a number of rules relating the life-history features of the live-bearing tetrapods (terrestrial placental mammals) that he studied. Among these correct predictions are the following. Brood size decreases with (adult) body mass, so that an elephant has fewer young (usually just one) per brood than a mouse. Lifespan increases with gestation period, and also with body mass, so that elephants live longer than mice, have a longer period of gestation, and are heavier. As a final example, fecundity decreases with lifespan, so long-lived kinds like elephants have fewer young in total than short-lived kinds like mice.Classification of living thingsAristotle distinguished about 500 species of animals, arranging these in the History of Animals in a graded scale of perfection, a nonreligious version of the scala naturae, with man at the top. His system had eleven grades of animal, from highest potential to lowest, expressed in their form at birth: the highest gave live birth to hot and wet creatures, the lowest laid cold, dry mineral-like eggs. Animals came above plants, and these in turn were above minerals. see also: He grouped what the modern zoologist would call vertebrates as the hotter "animals with blood", and below them the colder invertebrates as "animals without blood". Those with blood were divided into the live-bearing (mammals), and the egg-laying (birds, reptiles, fish). Those without blood were insects, crustacea (non-shelled – cephalopods, and shelled) and the hard-shelled molluscs (bivalves and gastropods). He recognised that animals did not exactly fit into a linear scale, and noted various exceptions, such as that sharks had a placenta like the tetrapods. To a modern biologist, the explanation, not available to Aristotle, is convergent evolution. Philosophers of science have generally concluded that Aristotle was not interested in taxonomy, but zoologists who studied this question recently think otherwise. He believed that purposive final causes guided all natural processes; this teleological view justified his observed data as an expression of formal design.PsychologySoulAristotle's psychology, given in his treatise On the Soul (peri psychēs), posits three kinds of soul ("psyches"): the vegetative soul, the sensitive soul, and the rational soul. Humans have a rational soul. The human soul incorporates the powers of the other kinds: Like the vegetative soul it can grow and nourish itself; like the sensitive soul it can experience sensations and move locally. The unique part of the human, rational soul is its ability to receive forms of other things and to compare them using the nous (intellect) and logos (reason).For Aristotle, the soul is the form of a living being. Because all beings are composites of form and matter, the form of living beings is that which endows them with what is specific to living beings, e.g. the ability to initiate movement (or in the case of plants, growth and chemical transformations, which Aristotle considers types of movement). In contrast to earlier philosophers, but in accordance with the Egyptians, he placed the rational soul in the heart, rather than the brain. Notable is Aristotle's division of sensation and thought, which generally differed from the concepts of previous philosophers, with the exception of Alcmaeon.MemoryAccording to Aristotle in On the Soul, memory is the ability to hold a perceived experience in the mind and to distinguish between the internal "appearance" and an occurrence in the past. In other words, a memory is a mental picture (phantasm) that can be recovered. Aristotle believed an impression is left on a semi-fluid bodily organ that undergoes several changes in order to make a memory. A memory occurs when stimuli such as sights or sounds are so complex that the nervous system cannot receive all the impressions at once. These changes are the same as those involved in the operations of sensation, Aristotelian , and thinking.Aristotle uses the term 'memory' for the actual retaining of an experience in the impression that can develop from sensation, and for the intellectual anxiety that comes with the impression because it is formed at a particular time and processing specific contents. Memory is of the past, prediction is of the future, and sensation is of the present. Retrieval of impressions cannot be performed suddenly. A transitional channel is needed and located in past experiences, both for previous experience and present experience.Because Aristotle believes people receive all kinds of sense perceptions and perceive them as impressions, people are continually weaving together new impressions of experiences. To search for these impressions, people search the memory itself. Within the memory, if one experience is offered instead of a specific memory, that person will reject this experience until they find what they are looking for. Recollection occurs when one retrieved experience naturally follows another. If the chain of "images" is needed, one memory will stimulate the next. When people recall experiences, they stimulate certain previous experiences until they reach the one that is needed. Recollection is thus the self-directed activity of retrieving the information stored in a memory impression. Only humans can remember impressions of intellectual activity, such as numbers and words. Animals that have perception of time can retrieve memories of their past observations. Remembering involves only perception of the things remembered and of the time passed.Aristotle believed the chain of thought, which ends in recollection of certain impressions, was connected systematically in relationships such as similarity, contrast, and contiguity, described in his laws of association. Aristotle believed that past experiences are hidden within the mind. A force operates to awaken the hidden material to bring up the actual experience. According to Aristotle, association is the power innate in a mental state, which operates upon the unexpressed remains of former experiences, allowing them to rise and be recalled.DreamsAristotle describes sleep in On Sleep and Wakefulness. Sleep takes place as a result of overuse of the senses or of digestion, so it is vital to the body. While a person is asleep, the critical activities, which include thinking, sensing, recalling and remembering, do not function as they do during wakefulness. Since a person cannot sense during sleep they cannot have desire, which is the result of sensation. However, the senses are able to work during sleep, albeit differently, unless they are weary.Dreams do not involve actually sensing a stimulus. In dreams, sensation is still involved, but in an altered manner. Aristotle explains that when a person stares at a moving stimulus such as the waves in a body of water, and then looks away, the next thing they look at appears to have a wavelike motion. When a person perceives a stimulus and the stimulus is no longer the focus of their attention, it leaves an impression. When the body is awake and the senses are functioning properly, a person constantly encounters new stimuli to sense and so the impressions of previously perceived stimuli are ignored. However, during sleep the impressions made throughout the day are noticed as there are no new distracting sensory experiences. So, dreams result from these lasting impressions. Since impressions are all that are left and not the exact stimuli, dreams do not resemble the actual waking experience. During sleep, a person is in an altered state of mind. Aristotle compares a sleeping person to a person who is overtaken by strong feelings toward a stimulus. For example, a person who has a strong infatuation with someone may begin to think they see that person everywhere because they are so overtaken by their feelings. Since a person sleeping is in a suggestible state and unable to make judgements, they become easily deceived by what appears in their dreams, like the infatuated person. This leads the person to believe the dream is real, even when the dreams are absurd in nature. In De Anima iii 3, Aristotle ascribes the ability to create, to store, and to recall images in the absence of perception to the faculty of imagination, phantasia.One component of Aristotle's theory of dreams disagrees with previously held beliefs. He claimed that dreams are not foretelling and not sent by a divine being. Aristotle reasoned naturalistically that instances in which dreams do resemble future events are simply coincidences. Aristotle claimed that a dream is first established by the fact that the person is asleep when they experience it. If a person had an image appear for a moment after waking up or if they see something in the dark it is not considered a dream because they were awake when it occurred. Secondly, any sensory experience that is perceived while a person is asleep does not qualify as part of a dream. For example, if, while a person is sleeping, a door shuts and in their dream they hear a door is shut, this sensory experience is not part of the dream. Lastly, the images of dreams must be a result of lasting impressions of waking sensory experiences.Practical philosophyAristotle's practical philosophy covers areas such as ethics, politics, economics, and rhetoric.EthicsAristotle considered ethics to be a practical rather than theoretical study, i.e., one aimed at becoming good and doing good rather than knowing for its own sake. He wrote several treatises on ethics, including most notably, the Nicomachean Ethics.Aristotle taught that virtue has to do with the proper function (ergon) of a thing. An eye is only a good eye in so much as it can see, because the proper function of an eye is sight. Aristotle reasoned that humans must have a function specific to humans, and that this function must be an activity of the psuchē (soul) in accordance with reason (logos). Aristotle identified such an optimum activity (the virtuous mean, between the accompanying vices of excess or deficiency) of the soul as the aim of all human deliberate action, eudaimonia, generally translated as "happiness" or sometimes "well-being". To have the potential of ever being happy in this way necessarily requires a good character (ēthikē aretē), often translated as moral or ethical virtue or excellence.Aristotle taught that to achieve a virtuous and potentially happy character requires a first stage of having the fortune to be habituated not deliberately, but by teachers, and experience, leading to a later stage in which one consciously chooses to do the best things. When the best people come to live life this way their practical wisdom (phronesis) and their intellect (nous) can develop with each other towards the highest possible human virtue, the wisdom of an accomplished theoretical or speculative thinker, or in other words, a philosopher.PoliticsIn addition to his works on ethics, which address the individual, Aristotle addressed the city in his work titled Politics. Aristotle considered the city to be a natural community. Moreover, he considered the city to be prior in importance to the family which in turn is prior to the individual, "for the whole must of necessity be prior to the part". He famously stated that "man is by nature a political animal" and argued that humanity's defining factor among others in the animal kingdom is its rationality. Aristotle conceived of politics as being like an organism rather than like a machine, and as a collection of parts none of which can exist without the others. Aristotle's conception of the city is organic, and he is considered one of the first to conceive of the city in this manner.The common modern understanding of a political community as a modern state is quite different from Aristotle's understanding. Although he was aware of the existence and potential of larger empires, the natural community according to Aristotle was the city (polis) which functions as a political "community" or "partnership" (koinōnia). The aim of the city is not just to avoid injustice or for economic stability, but rather to allow at least some citizens the possibility to live a good life, and to perform beautiful acts: "The political partnership must be regarded, therefore, as being for the sake of noble actions, not for the sake of living together." This is distinguished from modern approaches, beginning with social contract theory, according to which individuals leave the state of nature because of "fear of violent death" or its "inconveniences."In Protrepticus, the character 'Aristotle' states:As Plato's disciple Aristotle was rather skeptical concerning democracy and, following Plato's vague ideas, he developed a coherent theory of integrating various forms of power into a so-called mixed state:To illustrate this approach, Aristotle proposed a first-of-its-kind mathematical model of voting, albeit textually described, where the democratic principle of "one voter–one vote" is combined with the oligarchic "merit-weighted voting"; for relevant quotes and their translation into mathematical formulas see.EconomicsAristotle made substantial contributions to economic thought, especially to thought in the Middle Ages. In Politics, Aristotle addresses the city, property, and trade. His response to criticisms of private property, in Lionel Robbins's view, anticipated later proponents of private property among philosophers and economists, as it related to the overall utility of social arrangements. Aristotle believed that although communal arrangements may seem beneficial to society, and that although private property is often blamed for social strife, such evils in fact come from human nature. In Politics, Aristotle offers one of the earliest accounts of the origin of money. Money came into use because people became dependent on one another, importing what they needed and exporting the surplus. For the sake of convenience, people then agreed to deal in something that is intrinsically useful and easily applicable, such as iron or silver.Aristotle's discussions on retail and interest was a major influence on economic thought in the Middle Ages. He had a low opinion of retail, believing that contrary to using money to procure things one needs in managing the household, retail trade seeks to make a profit. It thus uses goods as a means to an end, rather than as an end unto itself. He believed that retail trade was in this way unnatural. Similarly, Aristotle considered making a profit through interest unnatural, as it makes a gain out of the money itself, and not from its use.Aristotle gave a summary of the function of money that was perhaps remarkably precocious for his time. He wrote that because it is impossible to determine the value of every good through a count of the number of other goods it is worth, the necessity arises of a single universal standard of measurement. Money thus allows for the association of different goods and makes them "commensurable". He goes on to state that money is also useful for future exchange, making it a sort of security. That is, "if we do not want a thing now, we shall be able to get it when we do want it".Rhetoric and poeticsAristotle's Rhetoric proposes that a speaker can use three basic kinds of appeals to persuade his audience: ethos (an appeal to the speaker's character), pathos (an appeal to the audience's emotion), and logos (an appeal to logical reasoning). He also categorizes rhetoric into three genres: epideictic (ceremonial speeches dealing with praise or blame), forensic (judicial speeches over guilt or innocence), and deliberative (speeches calling on an audience to make a decision on an issue). Aristotle also outlines two kinds of rhetorical proofs: enthymeme (proof by syllogism) and paradeigma (proof by example).Aristotle writes in his Poetics that epic poetry, tragedy, comedy, dithyrambic poetry, painting, sculpture, music, and dance are all fundamentally acts of mimesis ("imitation"), each varying in imitation by medium, object, and manner. He applies the term mimesis both as a property of a work of art and also as the product of the artist's intention and contends that the audience's realisation of the mimesis is vital to understanding the work itself. Aristotle states that mimesis is a natural instinct of humanity that separates humans from animals and that all human artistry "follows the pattern of nature". Because of this, Aristotle believed that each of the mimetic arts possesses what Stephen Halliwell calls "highly structured procedures for the achievement of their purposes." For example, music imitates with the media of rhythm and harmony, whereas dance imitates with rhythm alone, and poetry with language. The forms also differ in their object of imitation. Comedy, for instance, is a dramatic imitation of men worse than average; whereas tragedy imitates men slightly better than average. Lastly, the forms differ in their manner of imitation – through narrative or character, through change or no change, and through drama or no drama.While it is believed that Aristotle's Poetics originally comprised two books – one on comedy and one on tragedy – only the portion that focuses on tragedy has survived. Aristotle taught that tragedy is composed of six elements: plot-structure, character, style, thought, spectacle, and lyric poetry. The characters in a tragedy are merely a means of driving the story; and the plot, not the characters, is the chief focus of tragedy. Tragedy is the imitation of action arousing pity and fear, and is meant to effect the catharsis of those same emotions. Aristotle concludes Poetics with a discussion on which, if either, is superior: epic or tragic mimesis. He suggests that because tragedy possesses all the attributes of an epic, possibly possesses additional attributes such as spectacle and music, is more unified, and achieves the aim of its mimesis in shorter scope, it can be considered superior to epic. Aristotle was a keen systematic collector of riddles, folklore, and proverbs; he and his school had a special interest in the riddles of the Delphic Oracle and studied the fables of Aesop.Views on womenAristotle's analysis of procreation describes an active, ensouling masculine element bringing life to an inert, passive female element. On this ground, proponents of feminist metaphysics have accused Aristotle of misogyny and sexism. However, Aristotle gave equal weight to women's happiness as he did to men's, and commented in his Rhetoric that the things that lead to happiness need to be in women as well as men.InfluenceMore than 2300 years after his death, Aristotle remains one of the most influential people who ever lived. He contributed to almost every field of human knowledge then in existence, and he was the founder of many new fields. According to the philosopher Bryan Magee, "it is doubtful whether any human being has ever known as much as he did". Among countless other achievements, Aristotle was the founder of formal logic, pioneered the study of zoology, and left every future scientist and philosopher in his debt through his contributions to the scientific method. Taneli Kukkonen, writing in The Classical Tradition, observes that his achievement in founding two sciences is unmatched, and his reach in influencing "every branch of intellectual enterprise" including Western ethical and political theory, theology, rhetoric and literary analysis is equally long. As a result, Kukkonen argues, any analysis of reality today "will almost certainly carry Aristotelian overtones ... evidence of an exceptionally forceful mind." Jonathan Barnes wrote that "an account of Aristotle's intellectual afterlife would be little less than a history of European thought".On his successor, TheophrastusAristotle's pupil and successor, Theophrastus, wrote the History of Plants, a pioneering work in botany. Some of his technical terms remain in use, such as carpel from carpos, fruit, and pericarp, from pericarpion, seed chamber.Theophrastus was much less concerned with formal causes than Aristotle was, instead pragmatically describing how plants functioned.On later Greek philosophersThe immediate influence of Aristotle's work was felt as the Lyceum grew into the Peripatetic school. Aristotle's notable students included Aristoxenus, Dicaearchus, Demetrius of Phalerum, Eudemos of Rhodes, Harpalus, Hephaestion, Mnason of Phocis, Nicomachus, and Theophrastus. Aristotle's influence over Alexander the Great is seen in the latter's bringing with him on his expedition a host of zoologists, botanists, and researchers. He had also learned a great deal about Persian customs and traditions from his teacher. Although his respect for Aristotle was diminished as his travels made it clear that much of Aristotle's geography was clearly wrong, when the old philosopher released his works to the public, Alexander complained "Thou hast not done well to publish thy acroamatic doctrines; for in what shall I surpass other men if those doctrines wherein I have been trained are to be all men's common property?"On Hellenistic scienceAfter Theophrastus, the Lyceum failed to produce any original work. Though interest in Aristotle's ideas survived, they were generally taken unquestioningly. It is not until the age of Alexandria under the Ptolemies that advances in biology can be again found.The first medical teacher at Alexandria, Herophilus of Chalcedon, corrected Aristotle, placing intelligence in the brain, and connected the nervous system to motion and sensation. Herophilus also distinguished between veins and arteries, noting that the latter pulse while the former do not. Though a few ancient atomists such as Lucretius challenged the teleological viewpoint of Aristotelian ideas about life, teleology (and after the rise of Christianity, natural theology) would remain central to biological thought essentially until the 18th and 19th centuries. Ernst Mayr states that there was "nothing of any real consequence in biology after Lucretius and Galen until the Renaissance."On Byzantine scholarsGreek Christian scribes played a crucial role in the preservation of Aristotle by copying all the extant Greek language manuscripts of the corpus. The first Greek Christians to comment extensively on Aristotle were Philoponus, Elias, and David in the sixth century, and Stephen of Alexandria in the early seventh century. John Philoponus stands out for having attempted a fundamental critique of Aristotle's views on the eternity of the world, movement, and other elements of Aristotelian thought. Philoponus questioned Aristotle's teaching of physics, noting its flaws and introducing the theory of impetus to explain his observations.After a hiatus of several centuries, formal commentary by Eustratius and Michael of Ephesus reappeared in the late eleventh and early twelfth centuries, apparently sponsored by Anna Comnena.On the medieval Islamic worldAristotle was one of the most revered Western thinkers in early Islamic theology. Most of the still extant works of Aristotle, as well as a number of the original Greek commentaries, were translated into Arabic and studied by Muslim philosophers, scientists and scholars. Averroes, Avicenna and Alpharabius, who wrote on Aristotle in great depth, also influenced Thomas Aquinas and other Western Christian scholastic philosophers. Alkindus greatly admired Aristotle's philosophy, and Averroes spoke of Aristotle as the "exemplar" for all future philosophers. Medieval Muslim scholars regularly described Aristotle as the "First Teacher". The title "teacher" was first given to Aristotle by Muslim scholars, and was later used by Western philosophers (as in the famous poem of Dante) who were influenced by the tradition of Islamic philosophy.On medieval EuropeWith the loss of the study of ancient Greek in the early medieval Latin West, Aristotle was practically unknown there from c. AD 600 to c. 1100 except through the Latin translation of the Organon made by Boethius. In the twelfth and thirteenth centuries, interest in Aristotle revived and Latin Christians had translations made, both from Arabic translations, such as those by Gerard of Cremona, and from the original Greek, such as those by James of Venice and William of Moerbeke. After the Scholastic Thomas Aquinas wrote his Summa Theologica, working from Moerbeke's translations and calling Aristotle "The Philosopher", the demand for Aristotle's writings grew, and the Greek manuscripts returned to the West, stimulating a revival of Aristotelianism in Europe that continued into the Renaissance. These thinkers blended Aristotelian philosophy with Christianity, bringing the thought of Ancient Greece into the Middle Ages. Scholars such as Boethius, Peter Abelard, and John Buridan worked on Aristotelian logic.The medieval English poet Chaucer describes his student as being happy by havingA cautionary medieval tale held that Aristotle advised his pupil Alexander to avoid the king's seductive mistress, Phyllis, but was himself captivated by her, and allowed her to ride him. Phyllis had secretly told Alexander what to expect, and he witnessed Phyllis proving that a woman's charms could overcome even the greatest philosopher's male intellect. Artists such as Hans Baldung produced a series of illustrations of the popular theme.The Italian poet Dante says of Aristotle in The Divine Comedy:Besides Dante's fellow poets, the classical figure that most influenced the Comedy is Aristotle. Dante built up the philosophy of the Comedy with the works of Aristotle as a foundation, just as the scholastics used Aristotle as the basis for their thinking. Dante knew Aristotle directly from Latin translations of his works and indirectly quotations in the works of Albert Magnus. Dante even acknowledges Aristotle's influence explicitly in the poem, specifically when Virgil justifies the Inferno's structure by citing the Nicomachean Ethics.On medieval JudaismMoses Maimonides (considered to be the foremost intellectual figure of medieval Judaism) adopted Aristotelianism from the Islamic scholars and based his Guide for the Perplexed on it and that became the basis of Jewish scholastic philosophy. Maimonides also considered Aristotle to be the greatest philosopher that ever lived, and styled him as the "chief of the philosophers". Also, in his letter to Samuel ibn Tibbon, Maimonides observes that there is no need for Samuel to study the writings of philosophers who preceded Aristotle because the works of the latter are "sufficient by themselves and [superior] to all that were written before them. His intellect, Aristotle's is the extreme limit of human intellect, apart from him upon whom the divine emanation has flowed forth to such an extent that they reach the level of prophecy, there being no level higher".On Early Modern scientistsIn the Early Modern period, scientists such as William Harvey in England and Galileo Galilei in Italy reacted against the theories of Aristotle and other classical era thinkers like Galen, establishing new theories based to some degree on observation and experiment. Harvey demonstrated the circulation of the blood, establishing that the heart functioned as a pump rather than being the seat of the soul and the controller of the body's heat, as Aristotle thought. Galileo used more doubtful arguments to displace Aristotle's physics, proposing that bodies all fall at the same speed whatever their weight.On 18th/19th-century thinkersThe 19th-century German philosopher Friedrich Nietzsche has been said to have taken nearly all of his political philosophy from Aristotle. Aristotle rigidly separated action from production, and argued for the deserved subservience of some people ("natural slaves"), and the natural superiority (virtue, arete) of others. It was Martin Heidegger, not Nietzsche, who elaborated a new interpretation of Aristotle, intended to warrant his deconstruction of scholastic and philosophical tradition.The English mathematician George Boole fully accepted Aristotle's logic, but decided "to go under, over, and beyond" it with his system of algebraic logic in his 1854 book The Laws of Thought. This gives logic a mathematical foundation with equations, enables it to solve equations as well as check validity, and allows it to handle a wider class of problems by expanding propositions of any number of terms, not just two.Charles Darwin regarded Aristotle as the most important contributor to the subject of biology. In an 1882 letter he wrote that "Linnaeus and Cuvier have been my two gods, though in very different ways, but they were mere schoolboys to old Aristotle". Also, in later editions of the book "On the Origin of Species', Darwin traced evolutionary ideas as far back as Aristotle; the text he cites is a summary by Aristotle of the ideas of the earlier Greek philosopher Empedocles.James Joyce's favoured philosopher was Aristotle, whom he considered to be "the greatest thinker of all times". Samuel Taylor Coleridge said: Everybody is born either a Platonist or an Aristotelian. Ayn Rand acknowledged Aristotle as her greatest influence and remarked that in the history of philosophy she could only recommend "three A's"—Aristotle, Aquinas, and Ayn Rand. She also regarded Aristotle as the greatest of all philosophers.Karl Marx considered Aristotle to be the "greatest thinker of antiquity", and called him a "giant thinker", a "genius", and "the great scholar".Modern rejection and rehabilitationDuring the 20th century, Aristotle's work was widely criticized. The philosopher Bertrand Russellargued that "almost every serious intellectual advance has had to begin with an attack on some Aristotelian doctrine". Russell called Aristotle's ethics "repulsive", and labelled his logic "as definitely antiquated as Ptolemaic astronomy". Russell stated that these errors made it difficult to do historical justice to Aristotle, until one remembered what an advance he made upon all of his predecessors.The Dutch historian of science Eduard Jan Dijksterhuis wrote that Aristotle and his predecessors showed the difficulty of science by "proceed[ing] so readily to frame a theory of such a general character" on limited evidence from their senses. In 1985, the biologist Peter Medawar could still state in "pure seventeenth century" tones that Aristotle had assembled "a strange and generally speaking rather tiresome farrago of hearsay, imperfect observation, wishful thinking and credulity amounting to downright gullibility". Hobbes rejected one of the most famous theses of Aristotle's politics, namely that human beings are naturally suited to life in a polis and do not fully realize their natures until they exercise the role of citizen.By the start of the 21st century, however, Aristotle was taken more seriously: Kukkonen noted that "In the best 20th-century scholarship Aristotle comes alive as a thinker wrestling with the full weight of the Greek philosophical tradition." Alasdair MacIntyre has attempted to reform what he calls the Aristotelian tradition in a way that is anti-elitist and capable of disputing the claims of both liberals and Nietzscheans. Kukkonen observed, too, that "that most enduring of romantic images, Aristotle tutoring the future conqueror Alexander" remained current, as in the 2004 film Alexander, while the "firm rules" of Aristotle's theory of drama have ensured a role for the Poetics in Hollywood.Biologists continue to be interested in Aristotle's thinking. Armand Marie Leroi has reconstructed Aristotle's biology, while Niko Tinbergen's four questions, based on Aristotle's four causes, are used to analyse animal behaviour; they examine function, phylogeny, mechanism, and ontogeny.Surviving worksCorpus AristotelicumThe works of Aristotle that have survived from antiquity through medieval manuscript transmission are collected in the Corpus Aristotelicum. These texts, as opposed to Aristotle's lost works, are technical philosophical treatises from within Aristotle's school. Reference to them is made according to the organization of Immanuel Bekker's Royal Prussian Academy edition (Aristotelis Opera edidit Academia Regia Borussica, Berlin, 1831–1870), which in turn is based on ancient classifications of these works.Loss and preservationAristotle wrote his works on papyrus scrolls, the common writing medium of that era. His writings are divisible into two groups: the "exoteric", intended for the public, and the "esoteric", for use within the Lyceum school. Aristotle's "lost" works stray considerably in characterization from the surviving Aristotelian corpus. Whereas the lost works appear to have been originally written with a view to subsequent publication, the surviving works mostly resemble lecture notes not intended for publication. Cicero's description of Aristotle's literary style as "a river of gold" must have applied to the published works, not the surviving notes. A major question in the history of Aristotle's works is how the exoteric writings were all lost, and how the ones now possessed came to be found. The consensus is that Andronicus of Rhodes collected the esoteric works of Aristotle's school which existed in the form of smaller, separate works, distinguished them from those of Theophrastus and other Peripatetics, edited them, and finally compiled them into the more cohesive, larger works as they are known today.LegacyDepictionsPaintingsAristotle has been depicted by major artists including Lucas Cranach the Elder, Justus van Gent, Raphael, Paolo Veronese, Jusepe de Ribera, Rembrandt, and Francesco Hayez over the centuries. Among the best-known depictions is Raphael's fresco The School of Athens, in the Vatican's Apostolic Palace, where the figures of Plato and Aristotle are central to the image, at the architectural vanishing point, reflecting their importance. Rembrandt's Aristotle with a Bust of Homer, too, is a celebrated work, showing the knowing philosopher and the blind Homer from an earlier age: as the art critic Jonathan Jones writes, "this painting will remain one of the greatest and most mysterious in the world, ensnaring us in its musty, glowing, pitch-black, terrible knowledge of time."SculpturesEponymsThe Aristotle Mountains in Antarctica are named after Aristotle. He was the first person known to conjecture, in his book Meteorology, the existence of a landmass in the southern high-latitude region and called it Antarctica. Aristoteles is a crater on the Moon bearing the classical form of Aristotle's name.See also Aristotelian SocietyAristotle's Biology Conimbricenses PerfectionismReferencesNotesCitationsSourcesFurther readingThe secondary literature on Aristotle is vast. The following is only a small selection. Ackrill, J. L. (1997). Essays on Plato and Aristotle, Oxford University Press.     These translations are available in several places online; see External links. Bakalis, Nikolaos. (2005). Handbook of Greek Philosophy: From Thales to the Stoics Analysis and Fragments, Trafford Publishing, .  Bolotin, David (1998). An Approach to Aristotle's Physics: With Particular Attention to the Role of His Manner of Writing. Albany: SUNY Press. A contribution to our understanding of how to read Aristotle's scientific works. Burnyeat, Myles F. et al. (1979). Notes on Book Zeta of Aristotle's Metaphysics. Oxford: Sub-faculty of Philosophy.   Code, Alan (1995). Potentiality in Aristotle's Science and Metaphysics, Pacific Philosophical Quarterly 76.   De Groot, Jean (2014). Aristotle's Empiricism: Experience and Mechanics in the 4th century BC, Parmenides Publishing, . Frede, Michael (1987). Essays in Ancient Philosophy. Minneapolis: University of Minnesota Press.  Gendlin, Eugene T. (2012). Line by Line Commentary on Aristotle's De Anima , Volume 1: Books I & II; Volume 2: Book III. The Focusing Institute. Gill, Mary Louise (1989). Aristotle on Substance: The Paradox of Unity. Princeton University Press.      Jori, Alberto (2003). Aristotele, Bruno Mondadori (Prize 2003 of the "International Academy of the History of Science"), .  Knight, Kelvin (2007). Aristotelian Philosophy: Ethics and Politics from Aristotle to MacIntyre, Polity Press. Lewis, Frank A. (1991). Substance and Predication in Aristotle. Cambridge University Press. Lord, Carnes (1984). Introduction to The Politics, by Aristotle. Chicago University Press. Loux, Michael J. (1991). Primary Ousia: An Essay on Aristotle's Metaphysics Ζ and Η. Ithaca, NY: Cornell University Press. Maso, Stefano (Ed.), Natali, Carlo (Ed.), Seel, Gerhard (Ed.) (2012) Reading Aristotle: Physics VII. 3: What is Alteration? Proceedings of the International ESAP-HYELE Conference, Parmenides Publishing. .   [Reprinted in J. Barnes, M. Schofield, and R.R.K. Sorabji, eds.(1975). Articles on Aristotle Vol 1. Science. London: Duckworth 14–34.]   Reeve, C. D. C. (2000). Substantial Knowledge: Aristotle's Metaphysics. Hackett.   Scaltsas, T. (1994). Substances and Universals in Aristotle's Metaphysics. Cornell University Press. Strauss, Leo (1964). "On Aristotle's Politics", in The City and Man, Rand McNally.External links   At the Internet Encyclopedia of Philosophy:  At the Internet Classics Archive From the Stanford Encyclopedia of Philosophy:   Collections of works  At Massachusetts Institute of Technology      Perseus Project at Tufts University At the University of Adelaide   P. Remacle The 11-volume 1837 Bekker edition of Aristotle's Works in Greek (PDFDJVU) 384 BC births322 BC deaths4th-century BC mathematicians4th-century BC philosophers4th-century BC writersAcademic philosophersActing theoristsAncient Greek biologistsAncient Greek economistsAncient Greek epistemologistsAncient Greek ethicistsAncient Greek logiciansAncient Greek mathematiciansAncient Greek metaphilosophersAncient Greek metaphysiciansAncient Greek philosophersAncient Greek philosophers of languageAncient Greek philosophers of mindAncient Greek physicistsAncient Greek political philosophersAncient Greek philosophers of artAncient literary criticsAncient StagiritesAphoristsAristotelian philosophersAttic Greek writersAncient Greek cosmologistsCritical thinkingCultural criticsFounders of philosophical traditionsGreek male writersGreek geologistsGreek meteorologistsGreek social commentatorsHumor researchersIrony theoristsMetic philosophers in Classical AthensMoral philosophersNatural philosophersOntologistsPeripatetic philosophersPhilosophers and tutors of Alexander the GreatPhilosophers of ancient ChalcidicePhilosophers of culturePhilosophers of educationPhilosophers of ethics and moralityPhilosophers of historyPhilosophers of lawPhilosophers of literaturePhilosophers of logicPhilosophers of lovePhilosophers of psychologyPhilosophers of sciencePhilosophers of timePhilosophers of sexualityPhilosophers of technologyPhilosophical logicPhilosophical theistsPhilosophy academicsPhilosophy writersRhetoric theoristsSocial criticsSocial philosophersStudents of PlatoTrope theoristsVirtue ethicistsVirtue ethicsWestern cultureWestern philosophyZoologists
An American in Paris is a jazz-influenced orchestral piece by American composer George Gershwin first performed in 1928. It was inspired by the time that Gershwin had spent in Paris and evokes the sights and energy of the French capital during the Années folles.Gershwin scored the piece for the standard instruments of the symphony orchestra plus celesta, saxophones, and automobile horns. He brought back four Parisian taxi horns for the New York premiere of the composition, which took place on December 13, 1928, in Carnegie Hall, with Walter Damrosch conducting the New York Philharmonic. It was Damrosch who had commissioned Gershwin to write his Concerto in F following the earlier success of Rhapsody in Blue (1924). He completed the orchestration on November 18, less than four weeks before the work's premiere. He collaborated on the original program notes with critic and composer Deems Taylor.BackgroundAlthough the story is likely apocryphal, Gershwin is said to have been attracted by Maurice Ravel's unusual chords, and Gershwin went on his first trip to Paris in 1926 ready to study with Ravel. After his initial student audition with Ravel turned into a sharing of musical theories, Ravel said he could not teach him, saying, "Why be a second-rate Ravel when you can be a first-rate Gershwin?"Gershwin strongly encouraged Ravel to come to the United States for a tour. To this end, upon his return to New York, Gershwin joined the efforts of Ravel's friend Robert Schmitz, a pianist Ravel had met during the war, to urge Ravel to tour the U.S. Schmitz was the head of Pro Musica, promoting Franco-American musical relations, and was able to offer Ravel a $10,000 fee for the tour, an enticement Gershwin knew would be important to Ravel.Gershwin greeted Ravel in New York in March 1928 during a party held for Ravel's birthday by Éva Gauthier. Ravel's tour reignited Gershwin's desire to return to Paris, which he and his brother Ira did after meeting Ravel. Ravel's high praise of Gershwin in an introductory letter to Nadia Boulanger caused Gershwin to seriously consider taking much more time to study abroad in Paris. Yet after he played for her, she told him she could not teach him. Boulanger gave Gershwin basically the same advice she gave all her accomplished master students: "What could I give you that you haven't already got?" This did not set Gershwin back, as his real intent abroad was to complete a new work based on Paris and perhaps a second rhapsody for piano and orchestra to follow his Rhapsody in Blue. Paris at this time hosted many expatriate writers, among them Ezra Pound, W. B. Yeats, Ernest Hemingway, and artist Pablo Picasso.CompositionGershwin based An American in Paris on a melodic fragment called "Very Parisienne", written in 1926 on his first visit to Paris as a gift to his hosts, Robert and Mabel Schirmer. Gershwin called it "a rhapsodic ballet"; it is written freely and in a much more modern idiom than his prior works.Gershwin explained in Musical America, "My purpose here is to portray the impressions of an American visitor in Paris as he strolls about the city, listens to the various street noises, and absorbs the French atmosphere."The piece is structured into five sections, which culminate in a loose ABA format. Gershwin's first A episode introduces the two main "walking" themes in the "Allegretto grazioso" and develops a third theme in the "Subito con brio". The style of this A section is written in the typical French style of composers Claude Debussy and Les Six. This A section featured duple meter, singsong rhythms, and diatonic melodies with the sounds of oboe, English horn, and taxi horns. The B section's "Andante ma con ritmo deciso" introduces the American Blues and spasms of homesickness. The "Allegro" that follows continues to express homesickness in a faster twelve-bar blues. In the B section, Gershwin uses common time, syncopated rhythms, and bluesy melodies with the sounds of trumpet, saxophone, and snare drum. "Moderato con grazia" is the last A section that returns to the themes set in A. After recapitulating the "walking" themes, Gershwin overlays the slow blues theme from section B in the final "Grandioso".ResponseGershwin did not particularly like Walter Damrosch's interpretation at the world premiere of An American in Paris. He stated that Damrosch's sluggish, dragging tempo caused him to walk out of the hall during a matinee performance of this work. The audience, according to Edward Cushing, responded with "a demonstration of enthusiasm impressively genuine in contrast to the conventional applause which new music, good and bad, ordinarily arouses."Critics believed that An American in Paris was better crafted than Gershwin's Concerto in F. Some did not think it belonged in a program with classical composers César Franck, Richard Wagner, or Guillaume Lekeu on its premiere. Gershwin responded to the critics:InstrumentationAn American in Paris was originally scored for 3 flutes (3rd doubling on piccolo), 2 oboes, English horn, 2 clarinets in B-flat, bass clarinet in B-flat, 2 bassoons, contrabassoon, 4 horns in F, 3 trumpets in B-flat, 3 trombones, tuba, timpani, snare drum, bass drum, triangle, wood block, ratchet, cymbals, low and high tom-toms, xylophone, glockenspiel, celesta, 4 taxi horns labeled as A, B, C, and D with circles around them, alto saxophone, tenor saxophone, baritone saxophone (all saxophones doubling soprano saxophones), and strings. Although most modern audiences have heard the taxi horns using the notes A, B, C, and D, it had been Gershwin's intention to use the notes A4, B4, D5, and A4. It is likely that in labeling the taxi horns as A, B, C, and D with circles, he was referring to the four horns, and not the notes that they played.A major revision of the work by composer and arranger F. Campbell-Watson simplified the instrumentation by reducing the saxophones to only three instruments: alto, tenor and baritone. The soprano saxophone doublings were eliminated to avoid changing instruments, and the contrabassoon was also deleted. This became the standard performing edition until 2000, when Gershwin specialist Jack Gibbons made his own restoration of the original orchestration of An American in Paris, working directly from Gershwin's original manuscript, including the restoration of Gershwin's soprano saxophone parts removed in Campbell-Watson's revision. Gibbons' restored orchestration of An American in Paris was performed at London's Queen Elizabeth Hall on July 9, 2000, by the City of Oxford Orchestra conducted by Levon Parikian.William Daly arranged the score for piano solo; this was published by New World Music in 1929.Preservation statusOn September 22, 2013, it was announced that a musicological critical edition of the full orchestral score would be eventually released. The Gershwin family, working in conjunction with the Library of Congress and the University of Michigan, were working to make scores available to the public that represent Gershwin's true intent. It was unknown whether the critical score would include the four minutes of material Gershwin later deleted from the work (such as the restatement of the blues theme after the faster 12 bar blues section), or if the score would document changes in the orchestration during Gershwin's composition process.The score to An American in Paris was scheduled to be issued first in a series of scores to be released. The entire project was expected to take 30 to 40 years to complete, but An American in Paris was planned to be an early volume in the series.Two urtext editions of the work were published by the German publisher B-Note Music in 2015. The changes made by Campbell-Watson were withdrawn in both editions. In the extended urtext, 120 bars of music were re-integrated. Conductor Walter Damrosch had cut them shortly before the first performance.On September 9, 2017, The Cincinnati Symphony Orchestra gave the world premiere of the long-awaited critical edition of the piece prepared by Mark Clague, director of the Gershwin initiative at the University of Michigan. This performance was of the original 1928 orchestration,  an alteration usually attributed to F. Campbell-Watson.RecordingsAn American in Paris has been frequently recorded. The first recording was made for the Victor Talking Machine Company in 1929 with Nathaniel Shilkret conducting the Victor Symphony Orchestra, drawn from members of the Philadelphia Orchestra. Gershwin was on hand to "supervise" the recording; however, Shilkret was reported to be in charge and eventually asked the composer to leave the recording studio. Then, a little later, Shilkret discovered there was no one to play the brief celesta solo during the slow section, so he hastily asked Gershwin if he might play the solo; Gershwin said he could and so he briefly participated in the actual recording. This recording is believed to use the taxi horns in the way that Gershwin had intended using the notes A-flat, B-flat, a higher D, and a lower A.The radio broadcast of the September 8, 1937, Hollywood Bowl George Gershwin Memorial Concert, in which An American in Paris, also conducted by Shilkret, was second on the program, was recorded and was released in 1998 in a two-CD set.Arthur Fiedler and the Boston Pops Orchestra recorded the work for RCA Victor, including one of the first stereo recordings of the music.In 1945, Arturo Toscanini conducting the NBC Symphony Orchestra recorded the piece for RCA Victor, one of the few commercial recordings Toscanini made of music by an American composer.The Seattle Symphony also recorded a version in 1990 of Gershwin's original score, before he made numerous edits resulting in the score as we hear it today.Harry James released a version of the blues section on his 1953 album One Night Stand, recorded live at the Aragon Ballroom in Chicago (Columbia GL 522 and CL 522).Use in filmIn 1951, Metro-Goldwyn-Mayer released the musical film, An American in Paris, featuring Gene Kelly and Leslie Caron. Winning the 1951 Best Picture Oscar, and numerous other awards, the film was directed by Vincente Minnelli, featured many tunes of Gershwin, and concluded with an extensive, elaborate dance sequence built around the An American in Paris symphonic poem (arranged for the film by Johnny Green), costing $500,000.ReferencesFurther reading Rimler, Walter. George Gershwin – An Intimate Portrait. Urbana, University of Illinois Press, 2009. chapter 6: Paris, pp. 28–33.External links   Scores, marked by Leonard Bernstein, Andre Kostelanetz, Erich Leinsdorf; New York Philharmonic archives 1944 recording by the New York Philharmonic conducted by Artur Rodziński , New York Philharmonic, Leonard Bernstein, 1959.  1928 compositionsCompositions by George GershwinGrammy Hall of Fame Award recipientsMusic about ParisMusic commissioned by the New York PhilharmonicSymphonic poems
The Academy Award for Best Production Design recognizes achievement for art direction in film. The category's original name was Best Art Direction, but was changed to its current name in 2012 for the 85th Academy Awards. This change resulted from the Art Director's branch of the Academy of Motion Picture Arts and Sciences (AMPAS) being renamed the Designer's branch. Since 1947, the award is shared with the set decorator(s). It is awarded to the best interior design in a film.The films below are listed with their production year (for example, the 2000 Academy Award for Best Art Direction is given to a film from 1999). In the lists below, the winner of the award for each year is shown first, followed by the other nominees in alphabetical order.SuperlativesWinners and nominees1920s1930s1940s1950s1960s1970s1980s1990s2000s2010s2020sSee also BAFTA Award for Best Production Design Critics' Choice Movie Award for Best Production DesignNotesReferencesBest Production DesignAwards for best art direction
The Academy Awards, popularly known as the Oscars, are awards for artistic and technical merit in the film industry. They are regarded by many as the most prestigious and significant awards in the entertainment industry worldwide. Given annually by the Academy of Motion Picture Arts and Sciences (AMPAS), the awards are an international recognition of excellence in cinematic achievements, as assessed by the Academy's voting membership. The various category winners are awarded a copy of a golden statuette as a trophy, officially called the "Academy Award of Merit", although more commonly referred to by its nickname, the "Oscar". The statuette depicts a knight rendered in the Art Deco style.The award was originally sculpted by George Stanley from a design sketch by Cedric Gibbons. AMPAS first presented it in 1929 at a private dinner hosted by Douglas Fairbanks in The Hollywood Roosevelt Hotel in what would become known as the 1st Academy Awards. The Academy Awards ceremony was first broadcast by radio in 1930 and was televised for the first time in 1953. It is the oldest worldwide entertainment awards ceremony and is now televised live worldwide. It is also the oldest of the four major annual American entertainment awards; its equivalents – the Emmy Awards for television, the Tony Awards for theater, and the Grammy Awards for music – are modeled after the Academy Awards. A total of 3,140 Oscar statuettes have been awarded since its inception in 1929. They are widely cited as the most prestigious and renowned competitive awards in the field of entertainment.The 93rd Academy Awards ceremony, honoring the best films of 2020 and early 2021, was held on April 25, 2021, after it was postponed from its original February 28, 2021, schedule due to the impact of the COVID-19 pandemic on cinema. As with the two previous ceremonies, there was no host. The ceremony was broadcast on ABC. It took place at the Dolby Theatre in Los Angeles, California for the 19th consecutive year, along with satellite location taking place at the Union Station also in Los Angeles.HistoryThe first Academy Awards presentation was held on May 16, 1929, at a private dinner function at The Hollywood Roosevelt Hotel with an audience of about 270 people.The post-awards party was held at the Mayfair Hotel. The cost of guest tickets for that night's ceremony was $5 ($ at 2020 prices). Fifteen statuettes were awarded, honoring artists, directors and other participants in the film-making industry of the time, for their works during the 1927–28 period. The ceremony ran for 15 minutes.Winners were announced to the media three months earlier. That was changed for the second ceremony in 1930. Since then, for the rest of the first decade, the results were given to newspapers for publication at 11:00 pm on the night of the awards. This method was used until 1940 when the Los Angeles Times announced the winners before the ceremony began; as a result, the Academy has, since 1941, used a sealed envelope to reveal the names of the winners.MilestonesThe first Best Actor awarded was Emil Jannings, for his performances in The Last Command and The Way of All Flesh. He had to return to Europe before the ceremony, so the Academy agreed to give him the prize earlier; this made him the first Academy Award winner in history. At that time, winners were recognized for the entirety of their work done in a certain category during the qualifying period; for example, Jannings received the award for two movies in which he starred during that period, and Janet Gaynor later won a single Oscar for performances in three films. With the fourth ceremony, however, the system changed, and professionals were honored for a specific performance in a single film. For the first six ceremonies, the eligibility period spanned two calendar years.At the 29th ceremony, held in 1957, the Best Foreign Language Film category, now known as Best International Feature Film, was introduced. Until then, foreign-language films had been honored with the Special Achievement Award.Perhaps the most widely seen streaker in history was 34-year-old Robert Opel, who streaked across the stage of The Dorothy Chandler Pavilion in Los Angeles flashing a peace sign on national US television at the 46th Academy Awards in 1974. Bemused host David Niven quipped, "Isn't it fascinating to think that probably the only laugh that man will ever get in his life is by stripping off and showing his shortcomings?" Later, evidence arose suggesting that Opel's appearance was facilitated as a publicity stunt by the show's producer Jack Haley Jr. Robert Metzler, the show's business manager, believed that the incident had been planned in some way; during the dress rehearsal Niven had asked Metzler's wife to borrow a pen so he could write down the famous line, which was thus not the ad-lib it appeared to be.The 74th Academy Awards, held in 2002, presented the first Academy Award for Best Animated Feature.From 1973 to 2020, all Academy Awards ceremonies have ended with the Academy Award for Best Picture. For 2021, this tradition was broken as the ceremony ended with the Academy Award for Best Actor.Traditionally, the previous year's winner for Best Actor and Best Supporting Actor present the awards for Best Actress and Best Supporting Actress, while the previous year's winner for Best Actress and Best Supporting Actress present the awards for Best Actor and Best Supporting Actor.Parasite became the first foreign-language film to win Best Picture at the February 9, 2020, award ceremony.Tom Hanks announced at the 2020 Oscar Ceremony, the opening of the Academy Museum of Motion Pictures on December 14, 2020.<ref>Barnes, Brooks (February 19, 2020).  "Motion Picture Academy Museum Will Open in December."   The New York Times. Retrieved March 15, 2020.</ref> The museum development started in 2017 under Kerry Brougher, but is now led by Bill Kramer. The industry curated exhibits will be geared toward the history of motion picture, the art & science of film making, exhibiting trailblazing directors, actors, film-makers, sound editors and more, and will house famous artifacts from acclaimed movies like Dorothy's Ruby Red Slippers.Because of COVID-19, Academy president David Rubin and CEO Dawn Hudson announced that for the 2021 Oscar Ceremony, streaming movies not shown in theaters would be eligible, though at some point the requirement that movies be shown in theaters would return.Oscar statuetteAcademy Award of Merit (Oscar statuette)The best known award is the Academy Award of Merit, more popularly known as the Oscar statuette. Made of gold-plated bronze on a black metal base, it is 13.5 in (34.3 cm) tall, weighs 8.5 lb (3.856 kg), and depicts a knight rendered in Art Deco style holding a sword standing on a reel of film with five spokes. The five spokes represent the original branches of the Academy: Actors, Writers, Directors, Producers, and Technicians.Sculptor George Stanley (who also did the Muse Fountain at the Hollywood Bowl) sculpted Cedric Gibbons' design. The statuettes presented at the initial ceremonies were gold-plated solid bronze. Within a few years, the bronze was abandoned in favor of Britannia metal, a pewter-like alloy which is then plated in copper, nickel silver, and finally, 24-karat gold. Due to a metal shortage during World War II, Oscars were made of painted plaster for three years. Following the war, the Academy invited recipients to redeem the plaster figures for gold-plated metal ones. The only addition to the Oscar since it was created is a minor streamlining of the base. The original Oscar mold was cast in 1928 at the C.W. Shumway & Sons Foundry in Batavia, Illinois, which also contributed to casting the molds for the Vince Lombardi Trophy and Emmy Award's statuettes. From 1983 to 2015, approximately 50 Oscars in a tin alloy with gold plating were made each year in Chicago by Illinois manufacturer R.S. Owens & Company. It would take between three and four weeks to manufacture 50 statuettes. In 2016, the Academy returned to bronze as the core metal of the statuettes, handing manufacturing duties to Walden, New York-based Polich Tallix Fine Art Foundry. While based on a digital scan of an original 1929 Oscar, the statuettes retain their modern-era dimensions and black pedestal. Cast in liquid bronze from 3D-printed ceramic molds and polished, they are then electroplated in 24-karat gold by Brooklyn, New York–based Epner Technology. The time required to produce 50 such statuettes is roughly three months. R.S. Owens is expected to continue producing other awards for the Academy and service existing Oscars that need replating.NamingThe Academy officially adopted the name "Oscar" for the trophies in 1939. However, the origin of the nickname is disputed.One biography of Bette Davis, who was a president of the Academy in 1941, claims she named the award after her first husband, band leader Harmon Oscar Nelson. A frequently mentioned originator is Margaret Herrick, the Academy executive secretary, who, when she first saw the award in 1931, said the statuette reminded her of "Uncle Oscar", a nickname for her cousin Oscar Pierce.Columnist Sidney Skolsky, who was present during Herrick's naming in 1931, wrote that "Employees have affectionately dubbed their famous statuette 'Oscar.'" The Academy credits Skolsky with "the first confirmed newspaper reference" to Oscar in his column on March 16, 1934, which was written about that year's 6th Academy Awards. The 1934 awards appeared again in another early media mention of Oscar: a Time magazine story. In the ceremonies that year, Walt Disney was the first to thank the Academy for his "Oscar" during his acceptance speech.EngravingTo prevent information identifying the Oscar winners from leaking ahead of the ceremony, Oscar statuettes presented at the ceremony have blank baseplates. Until 2010, winners returned their statuettes to the Academy and had to wait several weeks to have their names inscribed on their respective Oscars. Since 2010, winners have had the option of having engraved nameplates applied to their statuettes at an inscription-processing station at the Governor's Ball, a party held immediately after the Oscar ceremony. The R.S. Owens company has engraved nameplates made before the ceremony, bearing the name of every potential winner. The nameplates for the non-winning nominees are later recycled.Ownership of Oscar statuettesPrior to 1950, Oscar statuettes were (and remain) the property of the recipient.  Since then the statuettes have been legally encumbered by the requirement that the statuette be first offered for sale back to the Academy for US$1. If a winner refuses to agree to this stipulation, then the Academy keeps the statuette. Academy Awards predating this agreement have been sold in public auctions and private deals for six-figure sums.In 1989, Michael Todd's grandson tried to sell Todd's Best Picture Oscar for his 1956 production of Around the World in 80 Days to a movie prop collector.  The Academy earned enforcement of its statuette contract by gaining a permanent injunction against the sale.In 1992, Harold Russell consigned his 1946 Oscar for Best Supporting Actor for The Best Years of Our Lives to auction to raise money for his wife's medical expenses.  Though his decision caused controversy, the first-ever Oscar to be sold passed   to a private collector on August 6, 1992 for $60,500 ($ today). Russell defended his action, saying, "I don't know why anybody would be critical. My wife's health is much more important than sentimental reasons. The movie will be here, even if Oscar isn't."In December 2011, Orson Welles' 1941 Oscar for Citizen Kane (Academy Award for Best Original Screenplay) was put up for auction, after his heirs won a 2004 court decision contending that Welles did not sign any agreement to return the statue to the Academy. On December 20, 2011, it sold in an online auction for US$861,542 ($ today).Some buyers have subsequently returned the statuettes to the Academy, which keeps them in its treasury.Other awards presented by the AcademyIn addition to the Academy Award of Merit (Oscar award), there are nine honorary (non-competitive) awards presented by the Academy from time to time (except for the Academy Honorary Award, the Technical Achievement Award, and the Student Academy Awards, which are presented annually): Governors Awards: The Academy Honorary Award (annual) (which may or may not be in the form of an Oscar statuette);  The Irving G. Thalberg Memorial Award (since 1938) (in the form of a bust of Thalberg); The Jean Hersholt Humanitarian Award (since 1957) (in the form of an Oscar statuette);  The Academy Scientific and Technical Awards: Academy Award of Merit (non-competitive) (in the form of an Oscar statuette); Scientific and Engineering Award (in the form of a bronze tablet); Technical Achievement Award (annual) (in the form of a certificate); The John A. Bonner Medal of Commendation (since 1978) (in the form of a medal); The Gordon E. Sawyer Award (since 1982); and The Academy Student Academy Awards (annual).The Academy also awards Nicholl Fellowships in Screenwriting.NominationSince 2004, Academy Award nomination results have been announced to the public in mid-January. Prior to that, the results were announced in early February. In 2021, the nominees are announced in March.VotersThe Academy of Motion Picture Arts and Sciences (AMPAS), a professional honorary organization, maintains a voting membership of over 7,000 .Academy membership is divided into different branches, with each representing a different discipline in film production. Actors constitute the largest voting bloc, numbering 1,311 members (22 percent) of the Academy's composition. Votes have been certified by the auditing firm PricewaterhouseCoopers (and its predecessor Price Waterhouse) since the 7th Academy Awards in 1935. The firm mails the ballots of eligible nominees to members of the Academy in December to reflect the previous eligible year with a due date sometime in January of the next year, then tabulates the votes in a process that takes thousands of hours.All AMPAS members must be invited to join by the Board of Governors, on behalf of Academy Branch Executive Committees. Membership eligibility may be achieved by a competitive nomination or a member may submit a name based on other significant contributions to the field of motion pictures.New membership proposals are considered annually. The Academy does not publicly disclose its membership, although as recently as 2007 press releases have announced the names of those who have been invited to join. The 2007 release also stated that it has just under 6,000 voting members. While the membership had been growing, stricter policies have kept its size steady since then.In 2012, the results of a study conducted by the Los Angeles Times were published describing the demographic breakdown of approximately 88% of AMPAS' voting membership. Of the 5,100+ active voters confirmed, 94% were Caucasian, 77% were male, and 54% were found to be over the age of 60. 33% of voting members are former nominees (14%) and winners (19%).In May 2011, the Academy sent a letter advising its 6,000 or so voting members that an online system for Oscar voting would be implemented in 2013.RulesAccording to Rules 2 and 3 of the official Academy Awards Rules, a film must open in the previous calendar year, from midnight at the start of January 1 to midnight at the end of December 31, in Los Angeles County, California, and play for seven consecutive days, to qualify (except for the Best International Feature Film, Best Documentary Feature, and awards in short film categories). Additionally, the film must be shown at least three times on each day of its qualifying run, with at least one of the daily showings starting between 6 pm and 10 pm local time.For example, the 2009 Best Picture winner, The Hurt Locker, was originally first released in 2008, but did not qualify for the 2008 awards, as it did not play its Oscar-qualifying run in Los Angeles until mid-2009, thus qualifying for the 2009 awards. Foreign films must include English subtitles, and each country can submit only one film for consideration in the International Feature Film category per year.Rule 2 states that a film must be feature-length, defined as a minimum of 40 minutes, except for short-subject awards, and it must exist either on a 35 mm or 70 mm film print or in 24 frame/s or 48 frame/s progressive scan digital cinema format with a minimum projector resolution of 2048 by 1080 pixels. Since the 90th Academy Awards, presented in 2018, multi-part and limited series have been ineligible for the Best Documentary Feature award. This followed the win of O.J.: Made in America, an eight-hour presentation that was screened in a limited release before being broadcast in five parts on ABC and ESPN, in that category in 2017. The Academy's announcement of the new rule made no direct mention of that film.The Best International Feature Film award does not require a U.S. release. It requires the film to be submitted as its country's official selection.The Best Documentary Feature award requires either week-long releases in both Los Angeles County and New York City  during the previous calendar year, or a qualifying award at a competitive film festival from the Documentary Feature Qualifying Festival list (regardless of any public exhibition or distribution), or submission in the International Feature Film category as its country's official selection. The qualifying theatrical runs must meet the same requirements as those for non-documentary films regarding numbers and times of screenings. Additionally, a film must have been reviewed by a critic from The New York Times, Time Out New York, the Los Angeles Times, or LA Weekly.Producers must submit an Official Screen Credits online form before the deadline; in case it is not submitted by the defined deadline, the film will be ineligible for Academy Awards in any year. The form includes the production credits for all related categories. Then, each form is checked and put in a Reminder List of Eligible Releases.Awards in short film categories (Best Documentary Short Subject, Best Animated Short Film, and Best Live Action Short Film) have noticeably different eligibility rules from most other competitive awards. First, the qualifying period for release does not coincide with a calendar year, instead of covering one year starting on October 1 and ending on September 30 of the calendar year before the ceremony. Second, there are multiple methods of qualification. The main method is a week-long theatrical release in either Los Angeles County or New York City during the eligibility period. Films also can qualify by winning specified awards at one of several competitive film festivals designated by the Academy, also without regard to prior public distribution. Finally, a film that is selected as a gold, silver, or bronze medal winner in an appropriate category of the immediately previous Student Academy Awards is also eligible (Documentary category for that award, and Animation, Narrative, Alternative, or International for the other awards). The requirements for the qualifying theatrical run are also different from those for other awards. Only one screening per day is required. For the Documentary award, the screening must start between noon and 10 pm local time; for other awards, no specific start time is required, but the film must appear in regular theater listings with dates and screening times.In late December, ballots, and copies of the Reminder List of Eligible Releases are mailed to around 6,000 active members. For most categories, members from each of the branches vote to determine the nominees only in their respective categories (i.e. only directors vote for directors, writers for writers, actors for actors, etc.). In the special case of Best Picture, all voting members are eligible to select the nominees. In all major categories, a variant of the single transferable vote is used, with each member casting a ballot with up to five nominees (ten for Best Picture) ranked preferentially. In certain categories, including International Feature Film, Documentary and Animated Feature, nominees are selected by special screening committees made up of members from all branches.In most categories, the winner is selected from among the nominees by plurality voting of all members. Since 2009, the Best Picture winner has been chosen by instant runoff voting. Since 2013, re-weighted range voting has been used to select the nominees for the Best Visual Effects.Film companies will spend as much as several million dollars on marketing to awards voters for a movie in the running for Best Picture, in attempts to improve chances of receiving Oscars and other movie awards conferred in Oscar season. The Academy enforces rules to limit overt campaigning by its members to try to eliminate excesses and prevent the process from becoming undignified. It has an awards czar on staff who advises members on allowed practices and levies penalties on offenders. For example, a producer of the 2009 Best Picture nominee The Hurt Locker was disqualified as a producer in the category when he contacted associates urging them to vote for his film and not another that was seen as the front-runner (The Hurt Locker eventually won).Academy Screening RoomThe Academy Screening Room or Academy Digital Screening Room is a secure streaming platform which allows voting members of the Academy to view all eligible films (except, initially, those in the International category) in one place. It was introduced in 2019, for the 2020 Oscars, though DVD screeners and Academy in-person screenings were still provided. For films to be included on the platform, the North American distributor must pay $12,500, including a watermarking fee, and a digital copy of the film to be prepared for streaming by the Academy. The platform can be accessed through an app on Apple TV. The watermarking process involved several video security firms, creating a forensic watermark and restricting the ability to take screenshots or screen recordings.In 2021, for the 2022 Oscars, the Academy banned all physical screeners and in-person screenings, restricting official membership viewing to the Academy Screening Room. Films eligible in the Documentary and International categories were made available in different sections of the platform. Distributors can also pay an extra fee to add video featurettes to promote their films on the platform. The in-person screenings were said to be cancelled because of the COVID-19 pandemic. Eligible films do not have to be added to the platform, but the Academy advertises them to voting members when they are.Awards ceremoniesTelecastThe major awards are presented at a live televised ceremony, commonly in late February or early March following the relevant calendar year, and six weeks after the announcement of the nominees. It is the culmination of the film awards season, which usually begins during November or December of the previous year. This is an elaborate extravaganza, with the invited guests walking up the red carpet in the creations of the most prominent fashion designers of the day. Black tie dress is the most common outfit for men, although fashion may dictate not wearing a bow-tie, and musical performers sometimes do not adhere to this. (The artists who recorded the nominees for Best Original Song quite often perform those songs live at the awards ceremony, and the fact that they are performing is often used to promote the television broadcast.)The Academy Awards is the world's longest-running awards show televised live from the U.S. to all-time zones in North America and worldwide, and gathers billions of viewers elsewhere throughout the world. The Oscars were first televised in 1953 by NBC, which continued to broadcast the event until 1960, when ABC took over, televising the festivities (including the first color broadcast of the event in 1966) through 1970. NBC regained the rights for five years  then ABC resumed broadcast duties in 1976 and its current contract with the Academy runs through 2028. The Academy has also produced condensed versions of the ceremony for broadcast in international markets (especially those outside of the Americas) in more desirable local timeslots. The ceremony was broadcast live internationally for the first time via satellite since 1970, but only two South American countries, Chile and Brazil, purchased the rights to air the broadcast. By that time, the television rights to the Academy Awards had been sold in 50 countries. A decade later, the rights were already being sold to 60 countries, and by 1984, the TV rights to the Awards were licensed in 76 countries.The ceremonies were moved up from late March/early April to late February, since 2004, to help disrupt and shorten the intense lobbying and ad campaigns associated with Oscar season in the film industry. Another reason was because of the growing TV ratings success coinciding with the NCAA Basketball Tournament, which would cut into the Academy Awards audience. (In 1976 and 1977, ABC's regained Oscars were moved from Tuesday to Monday and went directly opposite NBC's NCAA title game.) The earlier date is also to the advantage of ABC, as it now usually occurs during the highly profitable and important February sweeps period. Some years, the ceremony is moved into the first Sunday of March to avoid a clash with the Winter Olympic Games. Another reason for the move to late February and early March is also to avoid the awards ceremony occurring so close to the religious holidays of Passover and Easter, which for decades had been a grievance from members and the general public. Advertising is somewhat restricted, however, as traditionally no movie studios or competitors of official Academy Award sponsors may advertise during the telecast. The production of the Academy Awards telecast currently holds the distinction of winning the most Emmys in history, with 47 wins and 195 nominations overall since that award's own launch in 1949.After many years of being held on Mondays at 9:00 pm Eastern/6:00 p.m Pacific, since the 1999 ceremonies, it was moved to Sundays at 8:30 pm ET/5:30 pm PT. The reasons given for the move were that more viewers would tune in on Sundays, that Los Angeles rush-hour traffic jams could be avoided, and an earlier start time would allow viewers on the East Coast to go to bed earlier. For many years the film industry opposed a Sunday broadcast because it would cut into the weekend box office. In 2010, the Academy contemplated moving the ceremony even further back into January, citing TV viewers' fatigue with the film industry's long awards season. However, such an accelerated schedule would dramatically decrease the voting period for its members, to the point where some voters would only have time to view the contending films streamed on their computers (as opposed to traditionally receiving the films and ballots in the mail). Furthermore, a January ceremony on Sunday would clash with National Football League playoff games. In 2018, the Academy announced that the ceremony would be moved from late February to mid February beginning with the 92nd Academy Awards in 2020.Originally scheduled for April 8, 1968, the 40th Academy Awards ceremony was postponed for two days, because of the assassination of Dr. Martin Luther King, Jr. On March 30, 1981, the 53rd Academy Awards was postponed for one day, after the shooting of President Ronald Reagan and others in Washington, D.C.In 1993, an In Memoriam segment was introduced, honoring those who had made a significant contribution to cinema who had died in the preceding 12 months, a selection compiled by a small committee of Academy members. This segment has drawn criticism over the years for the omission of some names. Criticism was also levied for many years regarding another aspect, with the segment having a "popularity contest" feel as the audience varied their applause to those who had died by the subject's cultural impact; the applause has since been muted during the telecast, and the audience is discouraged from clapping during the segment and giving silent reflection instead. This segment was later followed by a commercial break.In terms of broadcast length, the ceremony generally averages three and a half hours. The first Oscars, in 1929, lasted 15 minutes. At the other end of the spectrum, the 2002 ceremony lasted four hours and twenty-three minutes. In 2010, the organizers of the Academy Awards announced winners' acceptance speeches must not run past 45 seconds. This, according to organizer Bill Mechanic, was to ensure the elimination of what he termed "the single most hated thing on the show" – overly long and embarrassing displays of emotion. In 2016, in a further effort to streamline speeches, winners' dedications were displayed on an on-screen ticker. During the 2018 ceremony, host Jimmy Kimmel acknowledged how long the ceremony had become, by announcing that he would give a brand-new jet ski to whoever gave the shortest speech of the night (a reward won by Mark Bridges when accepting his Best Costume Design award for Phantom Thread). The Wall Street Journal analyzed the average minutes spent across the 2014–2018 telecasts as follows: 14 on song performances; 25 on the hosts' speeches; 38 on prerecorded clips; and 78 on the awards themselves, broken into 24 on the introduction and announcement, 24 on winners walking to the stage, and 30 on their acceptance speeches.Although still dominant in ratings, the viewership of the Academy Awards has steadily dropped; the 88th Academy Awards were the lowest-rated in the past eight years (although with increases in male and 18–49 viewership), while the show itself also faced mixed reception. Following the show, Variety reported that ABC was, in negotiating an extension to its contract to broadcast the Oscars, seeking to have more creative control over the broadcast itself. Currently and nominally, AMPAS is responsible for most aspects of the telecast, including the choice of production staff and hosting, although ABC is allowed to have some input on their decisions. In August 2016, AMPAS extended its contract with ABC through 2028: the contract neither contains any notable changes nor gives ABC any further creative control over the telecast.TV ratingsHistorically, the telecast's viewership is higher when box-office hits are favored to win the Best Picture award. More than 57.25 million viewers tuned to the telecast for the 70th Academy Awards in 1998, the year of Titanic, which generated a box office haul during its initial 1997–98 run of US$600.8 million in the US, a box office record that would remain unsurpassed for years. The 76th Academy Awards ceremony, in which The Lord of the Rings: The Return of the King (pre-telecast box office earnings of US$368 million) received 11 Awards including Best Picture, drew 43.56 million viewers. The most watched ceremony based on Nielsen ratings to date, however, was the 42nd Academy Awards (Best Picture Midnight Cowboy) which drew a 43.4% household rating on April 7, 1970.By contrast, ceremonies honoring films that have not performed well at the box office tend to show weaker ratings, despite how much critical acclaim those films have received. The 78th Academy Awards which awarded low-budget independent film Crash (with a pre-Oscar gross of US$53.4 million) generated an audience of 38.64 million with a household rating of 22.91%. In 2008, the 80th Academy Awards telecast was watched by 31.76 million viewers on average with an 18.66% household rating, the lowest-rated and least-watched ceremony at the time, in spite of celebrating 80 years of the Academy Awards. The Best Picture winner of that particular ceremony was another independent film (No Country for Old Men).Whereas the 92nd Academy Awards drew an average of 23.6 million viewers, the 93rd Academy Awards drew an even lower viewership of 10.4 million. That is the lowest viewership recorded by Nielsen since it started recording audience totals in 1974.ArchiveThe Academy Film Archive holds copies of every Academy Awards ceremony since the 1949 Oscars and material on many prior ceremonies, along with ancillary material related to more recent shows. Copies are held in a variety of film, video, and digital formats.VenuesIn 1929, the first Academy Awards were presented at a banquet dinner at The Hollywood Roosevelt Hotel. From 1930 to 1943, the ceremony alternated between two venues: the Ambassador Hotel on Wilshire Boulevard and the Biltmore Hotel in downtown Los Angeles.Grauman's Chinese Theatre in Hollywood then hosted the awards from 1944 to 1946, followed by the Shrine Auditorium in Los Angeles from 1947 to 1948. The 21st Academy Awards in 1949 were held at the Academy Award Theatre at what had been the Academy's headquarters on Melrose Avenue in Hollywood.From 1950 to 1960, the awards were presented at Hollywood's Pantages Theatre. With the advent of television, the awards from 1953 to 1957 took place simultaneously in Hollywood and New York, first at the NBC International Theatre (1953) and then at the NBC Century Theatre, after which the ceremony took place solely in Los Angeles. The Oscars moved to the Santa Monica Civic Auditorium in Santa Monica, California, in 1961. By 1969, the Academy decided to move the ceremonies back to Downtown Los Angeles, this time to the Dorothy Chandler Pavilion at the Los Angeles County Music Center. In the late 1990s and early 2000s, the ceremony returned to the Shrine.In 2002, Hollywood's Dolby Theatre (previously known as the Kodak Theatre) became the presentation's current venue.Awards of Merit categoriesCurrent categoriesIn the first year of the awards, the Best Directing award was split into two categories (Drama and Comedy). At times, the Best Original Score award has also been split into separate categories (Drama and Comedy/Musical). From the 1930s through the 1960s, the Art Direction (now Production Design), Cinematography, and Costume Design awards were likewise split into two categories (black-and-white films and color films). Prior to 2012, the Production Design award was called Art Direction, while the Makeup and Hairstyling award was called Makeup.In August 2018, the Academy announced that several categories would not be televised live, but rather be recorded during commercial breaks and aired later in the ceremony.Following dissent from Academy members, they announced that they would indeed air all 24 categories live. This followed several proposals (among them, the introduction of a Popular Film category) that the Academy had announced but did not implement.Discontinued categoriesProposed categoriesThe Board of Governors meets each year and considers new award categories. To date, the following categories have been proposed: Best Casting: rejected in 1999 Best Popular Film: proposed in 2018 for presentation at the 2019 ceremony; postponed until the 2020 ceremony at the earliest (yet to be implemented) Best Stunt Coordination: rejected every year from 1991 to 2012 Best Title Design: rejected in 1999Special categoriesThe Special Academy Awards are voted on by special committees, rather than by the Academy membership as a whole. They are not always presented on an annual basis.Current special categories Academy Honorary Award: since 1929 Academy Scientific and Technical Award (three different awards): since 1931 Gordon E. Sawyer Award: since 1981 Jean Hersholt Humanitarian Award: since 1957  Irving G. Thalberg Memorial Award: since 1938  Academy Special Achievement Award: from 1972 to 1995, and again for 2017Discontinued special categories Academy Juvenile Award: 1934 to 1960CriticismAccusations of commercialismDue to the positive exposure and prestige of the Academy Awards, many studios spend millions of dollars and hire publicists specifically to promote their films during what is typically called the "Oscar season". This has generated accusations of the Academy Awards being influenced more by marketing than by quality. William Friedkin, an Academy Award-winning film director and former producer of the ceremony, expressed this sentiment at a conference in New York in 2009, describing it as "the greatest promotion scheme that any industry ever devised for itself".Tim Dirks, editor of AMC's filmsite.org, has written of the Academy Awards:A recent technique that has been claimed to be used during the Oscar season is the whisper campaign. These campaigns are intended to spread negative perceptions of other movies nominated and are believed to be perpetrated by those that were involved in creating the movie. Examples of whisper campaigns include the allegations against Zero Dark Thirty suggesting that it justifies torture and the claim that Lincoln distorts history.Accusations of biasTypical criticism of the Academy Awards for Best Picture is that among the winners and nominees there is an over-representation of romantic historical epics, biographical dramas, romantic dramedies and family melodramas, most of which are released in the U.S. in the last three months of the calendar year. The Oscars have been infamously known for selecting specific genres of movies to be awarded. The term "Oscar bait" was coined to describe such movies. This has led, at times, to more specific criticisms that the Academy is disconnected from the audience, e.g., by favoring "Oscar bait" over audience favorites or favoring historical melodramas over critically acclaimed movies that depict current life issues.Allegations of a lack of diversityThe Academy Awards have long received criticism over its lack of diversity among the nominees. This criticism is based on the statistics from every Academy Awards since 1929, which shows us that only 6.4% of academy award nominees have been non-white and since 1991, 11.2% of nominees have been non-white, with the rate of winners being even more polarizing. Due to a variety of reasons, including marketability and historical bans on interracial couples, a number of high-profile Oscars have been given to yellowface portrayals, as well as performances of Asian characters rewritten for white characters. The 88th awards ceremony became the target of a boycott, popularized on social media with the hashtag #OscarsSoWhite, based on activists' perception that its all-white acting nominee list reflected bias. In response, the Academy initiated "historic" changes in membership by the year 2020.Symbolism or sentimentalizationActing prizes in certain years have been criticized for not recognizing superior performances so much as being awarded for personal popularity, to make up for a "snub" for a work that proved in time to be more popular or renowned than the one awarded, or presented as a "career honor" to recognize a distinguished nominee's entire body of work.Recognition of streaming media filmFollowing the 91st Academy Awards in February 2019 in which the Netflix-broadcast film Roma had been nominated for ten awards including the Best Picture category, Steven Spielberg and other members of the Academy discussed changing the requirements through the Board of Governors for films as to exclude those from Netflix and other media streaming services. Spielberg had been concerned that Netflix as a movie production and distribution studio could spend much more than typical Oscar-winning films and have much wider and earlier distribution than other Best Picture-nominated films, while still being able to meet the minimal theatrical-run status to qualify for an Oscar. The United States Department of Justice, having heard of this potential rule change, wrote a letter to the Academy in March 2019, cautioning them that placing additional restrictions on films that originate from streaming media services without proper justification could raise anti-trust concerns against the Academy. Following its April 2019 board meeting, the Academy Board of Governors agreed to retain the current rules that allow for streaming media films to be eligible for Oscars as long as they enjoy limited theatrical runs.Refusals of the awardSome winners critical of the Academy Awards have boycotted the ceremonies and refused to accept their Oscars. The first to do so was screenwriter Dudley Nichols (Best Writing in 1935 for The Informer). Nichols boycotted the 8th Academy Awards ceremony because of conflicts between the Academy and the Writers' Guild. Nichols eventually accepted the 1935 award three years later, at the 1938 ceremony. Nichols was nominated for three further Academy Awards during his career.George C. Scott became the second person to refuse his award (Best Actor in 1970 for Patton) at the 43rd Academy Awards ceremony. Scott described it as a "meat parade", saying, "I don't want any part of it."The third person to refuse the award was Marlon Brando, who refused his award (Best Actor for 1972's The Godfather), citing the film industry's discrimination and mistreatment of Native Americans. At the 45th Academy Awards ceremony, Brando asked actress and civil rights activist Sacheen Littlefeather to read a 15-page speech in his place, detailing his criticisms, for which there was booing and cheering by the audience.DisqualificationsSix films have had nominations revoked before the official award ceremony: The Circus (1928) – The film was voluntarily removed by the Academy from competitive categories, to award Charlie Chaplin a special award. Hondo (1953) – Removed from the Best Story ballot after letters from the producer and nominee questioned its inclusion in the category. High Society (1955) – Withdrawn from screenwriting ballot after being mistaken for the 1956 movie of the same title. The Godfather (1972) – Initially nominated for eleven awards, its nomination for Best Original Score was revoked after it was discovered that its main theme was very similar to music that the score's composer had written for an earlier film. None of its other nominations were revoked, and it received three Oscars, including Best Picture. A Place in the World (1992) – Removed from the Best Foreign Language Film ballot after it was discovered that the country which submitted the film exercised insufficient artistic control. Alone Yet Not Alone (2014) – The film's title song, "Alone Yet Not Alone", was removed from the Best Original Song ballot after Bruce Broughton was found to have improperly contacted other members of the academy's musical branch; this was the first time that a film was removed from a ballot for ethical reasons.One film was disqualified after winning the award, and had the winner return the Oscar: Young Americans (1969) – Initially won the award for Best Documentary Feature, but was later revoked after it was revealed that it had opened theatrically prior to the eligibility period.One film had its nomination revoked after the award ceremony when it had not won the Oscar:Tuba Atlantic (2011) – Its nomination for Best Live Action Short Film was revoked when it was discovered that the film had aired on television in 2010, before its theatrical release.Gender segregationSome advocates of gender equality and non-binary people have criticized the separation of male and female acting categories in the Academy Awards, Emmy Awards and Tony Awards. Though some commentators worry that gender discrimination would cause men to dominate unsegregated categories, other categories are unsegregated. The Grammy Awards went gender-neutral in 2012, while the Daytime Emmy Awards introduced a single Outstanding Younger Performer in a Drama Series category in 2019 to replace their two gender-specific younger actor and actress categories.Associated eventsThe following events are closely associated with the annual Academy Awards: BAFTA Awards César Awards David di Donatello Awards Nominees luncheon Governors Awards The 25th Independent Spirit Awards (2010), usually held in Santa Monica, California the Saturday before the Oscars, marked the first time it was moved to a Friday and a change of venue to L.A. Live The annual "Night Before", traditionally held at the Beverly Hills Hotel, begun in 2002 and generally known as the party of the season, benefits the Motion Picture & Television Fund, which operates a retirement home for SAG actors in the San Fernando Valley Elton John AIDS Foundation Academy Award Party airs the awards live at the nearby Pacific Design Center The Governors Ball is the Academy's official after-party, including dinner (until 2011), and is adjacent to the awards-presentation venue The Vanity Fair after-party, historically at the former Morton's restaurant, has been at the Sunset Tower since 2009 Ariel Award in Mexico Goya Award in SpainPresenter and performer giftsIt has become a tradition to give out gift bags to the presenters and performers at the Oscars. In recent years, these gifts have also been extended to award nominees and winners. The value of each of these gift bags can reach into the tens of thousands of dollars. In 2014, the value was reported to be as high as US$80,000. The value has risen to the point where the U.S. Internal Revenue Service issued a statement regarding the gifts and their taxable status.Oscar gift bags have included vacation packages to Hawaii and Mexico and Japan, a private dinner party for the recipient and friends at a restaurant, videophones, a four-night stay at a hotel, watches, bracelets, spa treatments, bottles of vodka, maple salad dressing, weight-loss gummie candy and up to $25,000 worth of cosmetic treatments and rejuvenation procedures such as lip fillers and chemical peels from New York City facial plastic surgeon Konstantin Vasyukevich. Some of the gifts have even had a "risque" element to them; in 2014, the adult products retailer Adam & Eve had a "Secret Room Gifting Suite". Celebrities visiting the gifting suite included Judith Hoag, Carolyn Hennesy, Kate Linder, Chris Mulkey, Jim O'Heir, and John Salley.Television ratings and advertisement pricesFrom 2006 onwards, results are Live+SD; all previous years are live viewing.TrademarkThe term "Oscar" is a registered trademark of the AMPAS; however, in the Italian language, it is used generically to refer to any award or award ceremony, regardless of which field.Court: Oscar may be generic term in Italian | Reuters See also List of film awards List of Academy Award records List of actors with Academy Award nominations List of superlative Academy Award winners and nomineesFootnotesReferencesFurther reading Brokaw, Lauren (2010). "Wanna see an Academy Awards invite? We got it along with all the major annual events surrounding the Oscars". Los Angeles: The Daily Truffle.      Wright, Jon (2007). The Lunacy of Oscar: The Problems with Hollywood's Biggest Night''. Thomas Publishing, Inc.External links  of the Academy of Motion Picture Arts and Sciences  Official Academy Awards Database (searchable) 1929 establishments in CaliforniaPerforming arts trophiesAmerican annual television specialsAmerican film awardsAnnual events in Los Angeles County, CaliforniaAwards established in 1929Cinema of Southern CaliforniaEvents in Los AngelesHollywood history and cultureAmerican live television shows
Actresses (Catalan: Actrius) is a 1997 Catalan language Spanish drama film produced and directed by Ventura Pons and based on the award-winning stage play E.R. by Josep Maria Benet i Jornet. The film has no male actors, with all roles played by females. The film was produced in 1996.SynopsisIn order to prepare herself to play a role commemorating the life of legendary actress Empar Ribera, young actress (Mercè Pons) interviews three established actresses who had been the Ribera's pupils: the international diva Glòria Marc (Núria Espert), the television star Assumpta Roca (Rosa Maria Sardà), and dubbing director Maria Caminal (Anna Lizaran).Cast Núria Espert as Glòria Marc Rosa Maria Sardà as Assumpta Roca Anna Lizaran as Maria Caminal Mercè Pons as EstudiantRecognitionScreeningsActrius screened in 2001 at the Grauman's Egyptian Theatre in an American Cinematheque retrospective of the works of its director. The film had first screened at the same location in 1998. It was also shown at the 1997 Stockholm International Film Festival.ReceptionIn Movie - Film - Review, Christopher Tookey wrote that though the actresses were "competent in roles that may have some reference to their own careers", the film "is visually unimaginative, never escapes its stage origins, and is almost totally lacking in revelation or surprising incident". Noting that there were "occasional, refreshing moments of intergenerational bitchiness", they did not "justify comparisons to All About Eve", and were "insufficiently different to deserve critical parallels with Rashomon". He also wrote that The Guardian called the film a "slow, stuffy chamber-piece", and that The Evening Standard stated the film's "best moments exhibit the bitchy tantrums seething beneath the threesome's composed veneers". MRQE wrote "This cinematic adaptation of a theatrical work is true to the original, but does not stray far from a theatrical rendering of the story."Awards and nominations 1997, won 'Best Catalan Film' at Butaca Awards for Ventura Pons 1997, won 'Best Catalan Film Actress' at Butaca Awards, shared by Núria Espert, Rosa Maria Sardà, Anna Lizaran, and Mercè Pons 1998, nominated for 'Best Screenplay' at Goya Awards, shared by Josep Maria Benet i Jornet and Ventura PonsReferencesExternal links   as archived 17 February 2009 (Spanish)1997 films1997 drama filmsSpanish filmsCatalan-language filmsFilms set in BarcelonaFilms directed by Ventura PonsSpanish drama films
Animalia is an illustrated children's book by Graeme Base. It was originally published in 1986, followed by a tenth anniversary edition in 1996, and a 25th anniversary edition in 2012. Over four million copies have been sold worldwide.   A special numbered and signed anniversary edition was also published in 1996, with an embossed gold jacket.SynopsisAnimalia is an alliterative alphabet book and contains twenty-six illustrations, one for each letter of the alphabet. Each illustration features an animal from the animal kingdom (A is for alligator and armadillo, B is for butterfly, etc.) along with a short poem utilizing the letter of the page for many of the words. The illustrations contain many other objects beginning with that letter that the reader can try to identify (however, there are not necessarily "a thousand things, or maybe more", as the author states). As an additional challenge, the author has hidden a picture of himself as a child in every picture.Here are some of the things in each picture that are truly different (the alligator in the A section is wearing an apron featuring the alphabet, which the book is about, and this section also features the author's home country, Australia):Note: This list is incomplete.A1. Astronaut2. Album3. Admiral4. Archdiocese5. Actor6. Actress7. Aborigine8. Athlete9. Acrobat10. Apple11. Acorn12. Apricot13. Avocado14. Adder15. Albatross16. Antelope (this is actually a pronghorn, which is not a true antelope, so it belongs in the P section)17. Anteater18. Aardvark19. Anvil20. Afghan hound21. Affenpinscher22. Airedale terrier23. Aqueduct24. Ant25. Abacus26. Asparagus27. Artichoke28. Accordion29. Anchor30. Anemone 31. Axe32. Angel 33. Algebra34. Atlas35. Apron36. Alien37. Ambulance38. AntennaB36. Bumblebee37. Bobolink38. Bear39. Bonnet40. Barbed wire41. Brambles42. Bulrushes43. Baboon44. Bassoon45. Brontosaurus46. Budgerigar47. Bomb48. Brain49. Brick50. Basket51. Basketball52. Basketball hoop53. Baseball54. Baseball bat55. Backgammon56. Ballpoint pen57. Bagpipes58. Bicycle59. Barrel60. Bell61. Boot62. Button63. Blueberries64. Belt65. Bugle66. Bull67. Bucket68. Bellows69. Boomerang70. Bathtub71. Bone72. Brush73. Bottle74. Banana75. Brush76. Binoculars77. Barracuda78. Buddha79. Battery80. Broom81. Bat (animal)82. Boy83. BungalowC82. Crab83. Chair84. Crane85. Caterpillar86. Canoe87. Computer88. Collar89. Camera90. Concertina91. Cap92. Cheetah93. Chain94. Cassette95. Crocodile96. Cone97. Cube98. Cylinder99. Cymbal100. Cucumber101. Celery102. Cabbage103. Cheese104. Corn105. Carrot106. Cards107. Calculator108. Candle109. Cherry110. Cake111. Coconut112. Cup113. Cocoa114. Can115. Calendar116. Chef117. Castle118. Church119. Cemetery120. Cross of Christ121. Caravan122. Circus123. Clown124. Cricket (game)125. Convict126. Cannon127. Cow128. Chimpanzee129. Cobra130. Cage131. Canary132. Check133. Crossword puzzle134. Crutch135. Cord136. Crown137. Crate138. Cork 139. Cog140. Comb141. Clarinet142. Clam143. Chieftain144. Cactus145. Cliff146. Chateau147. Concorde148. Chandelier149. Cottage150. Cigar151. Candy cane152. Cauldron153. CentipedeD154. Dustpan155. Duster156. Dynamite157. Drill158. Drawers159. Draughts160. Doughnut161. Diamond162. Dice163. Dutch doll164. Dentures165. Date (fruit)166. Date (time)167. Doily168. Dish169. Dollar170. Dolphin171. Decagon172. Devil173. Dormouse174. Diagonal175. Decade176. Doctrine177. Dumbbell178. Dragonfly179. Dwarf180. Dachshund181. Doberman pinscher182. Dalmatian183. Dodo184. Diplodocus185. Dimetrodon186. Dove187. Desperado188. Donkey189. Dam190. Drain191. Dinghy192. Drowning193. Drawbridge194. Deer195. Destroyer196. Dromedary197. Double-decker bus198. Daffodil199. Daisy200. Dirigible201. Dominos202. Dagger203. Dart204. Duck205. Dingo206. Dolly207. Deputy208. DogE208. Eclipse209. Éclair210. Elderberries211. Envelope212. Emu213. Eleven214. Edison215. Einstein216. Embryo217. Earwig218. Echidna219. Elf220. Eskimo221. Eagle222. Edelweiss223. Earring224. Emerald225. Exclamation point226. EyeglassesF226. Flounder227. Film228. Fly229. Foxglove230. Fern231. Fairy232. Fire233. Firewood234. Frankenstein235. Fork236. Forest237. Falcon238. Fungus239. Flier240. Flute241. Fan242. FoghornG243. Graph244. Glockenspiel245. Gerbil246. Geranium247. Gladiolus248. Gladiator249. Gremlin250. Golf club251. Golf ball252. Gibbon253. Guitar254. Galoshes255. Grail256. Greyhound257. Gong258. Gazelle259. Griffin260. Gargoyle261. Graffiti262. Grasshopper263. Globe264. Galleon265. Gorgon266. Gnome267. Gramophone268. Goat269. Goggles270. Goose271. Giraffe272. Gazebo273. Guard274. Gift275. Garage276. Garbage277. Garbage can278. Gallows279. Guillotine280. Ghost281. Giant282. Goal283. Glider284. Gage285. GarterH285. Hexagon286. Hose287. Hare288. Hyena289. Hawk290. Hammock291. Hook292. Hippo293. Hunter294. Hill295. Hang glider296. Herald297. Helicopter298. Hamburger299. Hydrant300. Hourglass301. Hamster302. Hedgehog 303. Horn304. Heart305. Hen306. Hand grenade307. Humpty-Dumpty308. Holly309. Holy Bible310. Hatch311. Haddock312. Hammer313. Hieroglyphics314. Handkerchief315. Handcuffs316. Hatchet317. Hornet318. HalberdI318. Island319. Icicle320. Ice cream321. Iron322. Iceberg323. Icarus324. Imprisoned325. Ingot326. InkJ324. Judge325. Javelin326. Jester327. Jack-in-the-box328. Jack-in-the-pulpit329. Japan330. Jet331. Jasmine332. Jaguar333. JeansK333. Kite334. Knapsack335. Knitting336. Kiwi337. Kilt338. Kitten339. Knight340. Kipper341. Knife342. Keys343. Keychain344. Kitchen345. Kettle346. Kayak347. Knocker348. Ketch349. Keel350. Keypad351. KerbL350. Ladder351. Lyre352. Lantern353. Lobster354. Llama355. Lettuce356. Leprechaun357. Lockbox358. Ladle359. Lemon360. Lute361. Lollipop362. Lamp363. Lily364. LassoM365. Map366. Mammoth367. Mermaid368. Moose369. Magpie370. Mosque371. Mandolin372. Monkey marionette373. Marble374. Metronome375. Moth376. Million377. Millimeter378. Millipede379. Mushroom380. Match381. Matchbox382. Molecule383. Mug384. Milk385. Medal386. Monocle387. Magnet388. Maggot389. Mask390. Microphone391. Microscope392. Moon393. Mole394. Monster395. Monitor396. MoustacheN394. Noah395. Narwhal396. Neptune397. Newspaper398. Nightingale399. Nest400. Net401. Nun402. Nut403. Nutcracker404. North405. Ninety-nine406. Napkin407. Nautilus408. Nurse409. NonagonO410. Orange411. Otter412. Orangutan413. Observatory414. Octagon415. Owl416. Obelisk417. Oak418. Oil drill419. Organ420. Oven421. OrchestraP421. Purse422. Physician423. Poodle424. Parasol425. Pig426. Perambulator427. Periwinkle428. Politician429. Pin430. Philosopher431. Parchment432. Polka dot433. Pigtail434. Pit drum435. Pharaoh436. Pied Piper437. Pyjamas438. Plume439. Police440. Prisoner441. Pygmy442. Punch & Judy443. Pope444. Peace445. Pirate446. Patch447. Peg leg448. Prince449. Princess450. Pendant451. Palace452. Pagoda453. Parachute454. Pegasus455. Pisa (Leaning Tower)456. Parthenon457. Palm tree458. Pyramid459. Paris460. Peninsula461. Penguin462. Pool463. Pathway464. Procession465. Platypus466. Pan467. Pumpkin468. Pheasant469. Partridge470. Puffin471. Pelican472. Porcupine473. Panda474. Parcel475. Pliers476. Plow477. Pitchfork478. Pick479. Pine tree480. Pansy481. Poison ivy482. Periscope483. Porpoise484. Piano485. Popeye486. Phoenix487. Potato488. Plum489. Painter490. Palette491. Paint492. Paintbrush493. Peach494. Pear495. Pomegranate496. Pineapple497. Pussy-willows498. Pavilion499. Pulley500. Pump501. Plaque502. Prism503. Peas504. PearlQ505. Quartz506. Quicksand507. Quarter508. Quoits509. Queen510. Quilt511. Queensland512. QueueR 511. Rust512. Radar513. Raspberry514. Raccoon515. Rhododendron516. Roman numerals517. Ruby518. Ring519. Razor520. Roller skate521. Reindeer522. Roulette523. Rake524. Rifle525. Revolver526. Refrigerator527. Rabbit528. Rolling pin529. Register530. Rose531. Raven532. Ram533. Rat534. Rowboat535. Rooster536. Rattlesnake537. Robin538. Rocking horse539. Rocking chair540. Radius541. Rip542. Racket543. Recorder544. RocketS545. Sapphire546. Soup547. Stump548. Scorpion549. Sieve550. Sandcastle551. Sloop552. Schooner553. Shark554. Scarf555. Spider556. Spur557. Sheriff558. Sling559. Scab560. Sickle561. Scythe562. Slippers563. Sandwich564. Sunflower565. Snowshoes566. Skis567. Stretcher568. Spy569. Stitch570. Screwdriver571. Screw572. Shifter (Wrench)573. Shrug574. Spade575. Shovel576. Sledgehammer577. Scissors578. Shears579. Saw580. Scalpel581. Shack582. Scooter583. Satchel584. Sundae585. Straw586. Spaghetti587. Strawberry588. Spoon589. Saturn590. Seesaw591. Spring592. Sneeze593. Shepherd594. Staff595. Scarecrow596. Sloth597. Stork598. Spoonbill599. Safe600. Shrew601. Skipping rope602. Scroll603. Stamp604. Soccer605. Swimmer606. Snorkel607. Syringe608. Siphon609. Stethoscope610. Starfish611. Snail612. Slug613. Sphinx614. Sprocket615. Spinning wheel616. Spool617. Stool618. Space shuttle619. Satellite620. Sombrero621. Serape622. Saxophone623. Synthesizer624. Superman625. Shower626. Suitcase627. Shuttlecock628. Skittle (Bowling pin)629. Stilts630. Stalactite631. Stalagmite632. Steamroller633. Swings634. Slide635. Sword636. Sheathe637. Stiletto638. Scimitar639. Saber640. Spear641. Sleigh642. Snow643. Santa Claus644. Sack645. Sausage646. Stick figure647. Surfboard648. Surfer649. Seal650. Skull651. Spine652. Shamrock653. Spectacles654. Scapula655. Slingshot656. Snipe657. Swallow658. Sardines659. Swan660. Skunk661. Stepladder662. Sofa663. Scarab beetle664. Stereo665. Star of David666. Sparrow667. Squirrel668. Sextant669. Squid670. Seahorse671. Salute672. Sardines673. SemaphoreT672. Top hat673. Tulip674. Tricycle675. Toad676. Thermos677. Turtle678. Tear679. Trombone680. Trumpet681. Tuba682. Tractor683. Trailer684. Tunnel685. Tepee686. Totem pole687. Target688. Tuxedo689. Tunic690. Telescope691. Teapot692. Television693. Trophy694. Tap695. Teddy bear696. Tambourine697. Torch698. Toy tank699. Tomato700. Thermometer701. Tweezers702. Threader703. Typewriter704. Turntable705. Telephone706. TapirU707. UFO708. Ursa Major709. Ursa Minor710. United Kingdom711. Uncle Sam712. Ukulele713. Underwear714. UmiakV715. Volkswagen716. Vase717. Van718. VCR719. Violin720. Vacuum cleaner721. Voodoo doll722. Vane723. Valve724. Volcano725. Viaduct726. Vicar727. Viking728. Vampire729. Valley730. VegetablesW730. Weevil731. Wristwatch732. Witch733. Wave734. Wizard735. Wand736. Wheat737. Wall738. Wreck739. Wharf740. Whale741. Walrus742. Whirlpool743. Werewolf744. Wolf745. Wishbone746. Well747. Washerwoman748. Washhouse749. Washing machine750. Wagon751. Whip752. Windmill753. Wombat754. Wallaby755. Weeping willow756. Waterfall757. Weapons758. WaterX757. Xylophone758. Xerophytes759. Xmas tree760. X-ray761. X (sign language)Y762. Yoke763. Yolk764. Yeti765. Yeoman766. Yo-yo767. Yard768. YearZ769. Zulu770. Zodiac771. Zipper772. Zinnia773. Zither774. Zebu775. Zorro776. Zero777. ZebraRelated productsJulia MacRae Books published an Animalia colouring book in 2008.   H. N. Abrams also published a wall calendar colouring book version for children the same year.H. N. Abrams published The Animalia Wall Frieze, a fold-out over 26 feet in length, in which the author created new riddles for each letter.The Great American Puzzle Factory created a 300-piece jigsaw puzzle based on the book's cover.AdaptationsA television series was also created, based on the book, which airs in the United States, Australia, Canada, the United Kingdom, Norway and Venezuela. It also airs on Minimax for the Czech Republic and Slovakia. And recently in Greece on the channel ET1. The Australian Children's Television Foundation released a teaching resource DVD-ROM in 2011 to accompany the TV series with teaching aids for classroom use.In 2010, The Base Factory and AppBooks released Animalia as an application for iPad and iPhone/iPod Touch.AwardsAnimalia won the Young Australian's Best Book Award in 1987 for Best Picture Story Book.The Children's Book Council of Australia designated Animalia a 1987 Picture Book of the Year: Honour Book.Kid's Own Australian Literature Awards named Animalia the 1988 Picture Book Winner.ReferencesExternal links Graeme Base's official website A Learning Time activity guide for Animalia created by The Little Big Book ClubAlphabet books1986 children's booksPicture books by Graeme BasePuzzle booksAustralian children's booksPuffin Books books
International Atomic Time (TAI, from the French name ) is a high-precision atomic coordinate time standard based on the notional passage of proper time on Earth's geoid. It is a continuous scale of time, without leap seconds. It is the principal realisation of Terrestrial Time (with a fixed offset of epoch). It is also the basis for Coordinated Universal Time (UTC), which is used for civil timekeeping all over the Earth's surface. UTC deviates from TAI by a number of whole seconds. , when another leap second was put into effect, UTC is currently exactly 37 seconds behind TAI. The 37 seconds result from the initial difference of 10 seconds at the start of 1972, plus 27 leap seconds in UTC since 1972.TAI may be reported using traditional means of specifying days, carried over from non-uniform time standards based on the rotation of the Earth. Specifically, both Julian days and the Gregorian calendar are used. TAI in this form was synchronised with Universal Time at the beginning of 1958, and the two have drifted apart ever since, due to the changing motion of the Earth.OperationTAI is a weighted average of the time kept by over 400 atomic clocks in over 50 national laboratories worldwide. The majority of the clocks involved are caesium clocks; the International System of Units (SI) definition of the second is based on caesium. The clocks are compared using GPS signals and two-way satellite time and frequency transfer.  Due to the signal averaging TAI is an order of magnitude more stable than its best constituent clock.The participating institutions each broadcast, in real time, a frequency signal with timecodes, which is their estimate of TAI.  Time codes are usually published in the form of UTC, which differs from TAI by a well-known integer number of seconds.  These time scales are denoted in the form UTC(NPL) in the UTC form, where NPL identifies the National Physical Laboratory, UK. The TAI form may be denoted TAI(NPL).  The latter is not to be confused with TA(NPL), which denotes an independent atomic time scale, not synchronised to TAI or to anything else.The clocks at different institutions are regularly compared against each other.  The International Bureau of Weights and Measures (BIPM, France), combines these measurements to retrospectively calculate the weighted average that forms the most stable time scale possible.  This combined time scale is published monthly in "Circular T", and is the canonical TAI.  This time scale is expressed in the form of tables of differences UTC − UTC(k) (equivalent to TAI − TAI(k)) for each participating institution k.  The same circular also gives tables of TAI − TA(k), for the various unsynchronised atomic time scales.Errors in publication may be corrected by issuing a revision of the faulty Circular T or by errata in a subsequent Circular T.  Aside from this, once published in Circular T, the TAI scale is not revised.  In hindsight, it is possible to discover errors in TAI and to make better estimates of the true proper time scale.  Since the published circulars are definitive, better estimates do not create another version of TAI; it is instead considered to be creating a better realisation of Terrestrial Time (TT).HistoryEarly atomic time scales consisted of quartz clocks with frequencies calibrated by a single atomic clock; the atomic clocks were not operated continuously. Atomic timekeeping services started experimentally in 1955, using the first caesium atomic clock at the National Physical Laboratory, UK (NPL). It was used as a basis for calibrating the quartz clocks at the Royal Greenwich Observatory and to establish a time scale, called Greenwich Atomic (GA). The United States Naval Observatory began the A.1 scale on 13 September 1956, using an Atomichron commercial atomic clock, followed by the NBS-A scale at the National Bureau of Standards, Boulder, Colorado on 9 October 1957.The International Time Bureau (BIH) began a time scale, Tm or AM, in July 1955, using both local caesium clocks and comparisons to distant clocks using the phase of VLF radio signals. The BIH scale, A.1, and NBS-A were defined by an epoch at the beginning of 1958 The procedures used by the BIH evolved, and the name for the time scale changed: "A3" in 1964 and "TA(BIH)" in 1969.The SI second was defined in terms of the caesium atom in 1967. From 1971 to 1975 the General Conference on Weights and Measures and the International Committee for Weights and Measures made a series of decisions which designated the BIPM time scale International Atomic Time (TAI).In the 1970s, it became clear that the clocks participating in TAI were ticking at different rates due to gravitational time dilation, and the combined TAI scale, therefore, corresponded to an average of the altitudes of the various clocks. Starting from the Julian Date 2443144.5 (1 January 1977 00:00:00), corrections were applied to the output of all participating clocks, so that TAI would correspond to proper time at the geoid (mean sea level).  Because the clocks were, on average, well above sea level, this meant that TAI slowed by about one part in a trillion. The former uncorrected time scale continues to be published under the name EAL (Échelle Atomique Libre, meaning Free Atomic Scale).The instant that the gravitational correction started to be applied serves as the epoch for Barycentric Coordinate Time (TCB), Geocentric Coordinate Time (TCG), and Terrestrial Time (TT), which represent three fundamental time scales in the solar system.  All three of these time scales were defined to read JD 2443144.5003725 (1 January 1977 00:00:32.184) exactly at that instant. TAI was henceforth a realisation of TT, with the equation TT(TAI) = TAI + 32.184 s.The continued existence of TAI was questioned in a 2007 letter from the BIPM to the ITU-R which stated, "In the case of a redefinition of UTC without leap seconds, the CCTF would consider discussing the possibility of suppressing TAI, as it would remain parallel to the continuous UTC."Relation to UTCUTC is a discontinuous time scale. It is occasionally adjusted by leap seconds. Between these adjustments, it is composed of segments that are mapped to atomic time. From its beginning in 1961 through December 1971, the adjustments were made regularly in fractional leap seconds so that UTC approximated UT2.  Afterward, these adjustments were made only in whole seconds to approximate UT1. This was a compromise arrangement in order to enable a publicly broadcast time scale. The less frequent whole-second adjustments meant that the time scale would be more stable and easier to synchronize internationally. The fact that it continues to approximate UT1 means that tasks such as navigation which require a source of Universal Time continue to be well served by the public broadcast of UTC.See also Clock synchronization Network Time Protocol Precision Time Protocol Time and frequency transferNotesReferencesFootnotesBibliographyExternal links Bureau International des Poids et Mesures: TAI Time and Frequency Section - National Physical Laboratory, UK IERS website  NIST Web Clock FAQs History of time scales NIST-F1 Cesium Fountain Atomic Clock  Japan Standard Time Project, NICT, Japan  Standard of time definition: UTC, GPS, LORAN and TAITime scales
Altruism is the principle and moral practice of concern for happiness of other human beings or other animals, resulting in a quality of life both material and spiritual. It is a traditional virtue in many cultures and a core aspect of various religious and secular worldviews. However, the object(s) of concern vary among cultures and religions. In an extreme case, altruism may become a synonym of selflessness, which is the opposite of selfishness.The word "altruism" was popularized (and possibly coined) by the French philosopher Auguste Comte in French, as altruisme, for an antonym of egoism. He derived it from the Italian altrui, which in turn was derived from Latin alteri, meaning "other people" or "somebody else".Altruism in biological observations in field populations of the day organisms is an individual performing an action which is at a cost to themselves (e.g., pleasure and quality of life, time, probability of survival or reproduction), but benefits, either directly or indirectly, another individual, without the expectation of reciprocity or compensation for that action. Steinberg suggests a definition for altruism in the clinical setting, that is "intentional and voluntary actions that aim to enhance the welfare of another person in the absence of any quid pro quo external rewards". In one sense, the opposite of altruism is spite; a spiteful action harms another with no self-benefit.Altruism can be distinguished from feelings of loyalty or concern for the common good.  The latter are predicated upon social relationships, whilst altruism does not consider relationships. Much debate exists as to whether "true" altruism is possible in human psychology. The theory of psychological egoism suggests that no act of sharing, helping or sacrificing can be described as truly altruistic, as the actor may receive an intrinsic reward in the form of personal gratification. The validity of this argument depends on whether intrinsic rewards qualify as "benefits".The term altruism may also refer to an ethical doctrine that claims that individuals are morally obliged to benefit others. Used in this sense, it is usually contrasted with egoism, which claims individuals are morally obligated to serve themselves first. Effective altruism is the use of evidence and reason to determine the most effective ways to benefit others.The notion of altruismThe concept has a long history in philosophical and ethical thought. The term was originally coined in the 19th century by the founding sociologist and philosopher of science, Auguste Comte, and has become a major topic for psychologists (especially evolutionary psychology researchers), evolutionary biologists, and ethologists. Whilst ideas about altruism from one field can affect the other fields, the different methods and focuses of these fields always lead to different perspectives on altruism. In simple terms, altruism is caring about the welfare of other people and acting to help them.Scientific viewpointsAnthropologyMarcel Mauss's essay The Gift contains a passage called "Note on alms". This note describes the evolution of the notion of alms (and by extension of altruism) from the notion of sacrifice. In it, he writes:Alms are the fruits of a moral notion of the gift and of fortune on the one hand, and of a notion of sacrifice, on the other. Generosity is an obligation, because Nemesis avenges the poor and the gods for the superabundance of happiness and wealth of certain people who should rid themselves of it. This is the ancient morality of the gift, which has become a principle of justice. The gods and the spirits accept that the share of wealth and happiness that has been offered to them and had been hitherto destroyed in useless sacrifices should serve the poor and children.Evolutionary explanationsIn the science of ethology (the study of animal behaviour), and more generally in the study of social evolution, altruism refers to behaviour by an individual that increases the fitness of another individual while decreasing the fitness of the actor. In evolutionary psychology this may be applied to a wide range of human behaviors such as charity, emergency aid, help to coalition partners, tipping, courtship gifts, production of public goods, and environmentalism.Theories of apparently altruistic behavior were accelerated by the need to produce theories compatible with evolutionary origins. Two related strands of research on altruism have emerged from traditional evolutionary analyses and from evolutionary game theory a mathematical model and analysis of behavioural strategies.Some of the proposed mechanisms are:  Kin selection. That animals and humans are more altruistic towards close kin than to distant kin and non-kin has been confirmed in numerous studies across many different cultures. Even subtle cues indicating kinship may unconsciously increase altruistic behavior. One kinship cue is facial resemblance. One study found that slightly altering photographs so that they more closely resembled the faces of study participants increased the trust the participants expressed regarding depicted persons. Another cue is having the same family name, especially if rare, and this has been found to increase helpful behavior. Another study found more cooperative behavior the greater the number of perceived kin in a group. Using kinship terms in political speeches increased audience agreement with the speaker in one study. This effect was especially strong for firstborns, who are typically close to their families. Vested interests. People are likely to suffer if their friends, allies, and similar social ingroups suffer or even disappear. Helping such group members may therefore eventually benefit the altruist. Making ingroup membership more noticeable increases cooperativeness. Extreme self-sacrifice towards the ingroup may be adaptive if a hostile outgroup threatens to kill the entire ingroup. Reciprocal altruism. See also Reciprocity (evolution). Direct reciprocity. Research shows that it can be beneficial to help others if there is a chance that they can and will reciprocate the help. The effective tit for tat strategy is one game theoretic example. Many people seem to be following a similar strategy by cooperating if and only if others cooperate in return.One consequence is that people are more cooperative if it is more likely that individuals will interact again in the future. People tend to be less cooperative if they perceive that the frequency of helpers in the population is lower. They tend to help less if they see non-cooperativeness by others and this effect tend to be stronger than the opposite effect of seeing cooperative behaviors. Simply changing the cooperative framing of a proposal may increase cooperativeness such as calling it a "Community Game" instead of a "Wall Street Game".A tendency towards reciprocity implies that people will feel obligated to respond if someone helps them. This has been used by charities that give small gifts to potential donors hoping thereby to induce reciprocity. Another method is to announce publicly that someone has given a large donation. The tendency to reciprocate can even generalize so people become more helpful toward others in general after being helped. On the other hand, people will avoid or even retaliate against those perceived not to be cooperating. People sometimes mistakenly fail to help when they intended to, or their helping may not be noticed, which may cause unintended conflicts. As such, it may be an optimal strategy to be slightly forgiving of and have a slightly generous interpretation of non-cooperation.People are more likely to cooperate on a task if they can communicate with one another first. This may be due to better assessments of cooperativeness or due to exchange of promises. They are more cooperative if they can gradually build trust, instead of being asked to give extensive help immediately. Direct reciprocity and cooperation in a group can be increased by changing the focus and incentives from intra-group competition to larger scale competitions such as between groups or against the general population. Thus, giving grades and promotions based only on an individual's performance relative to a small local group, as is common, may reduce cooperative behaviors in the group. Indirect reciprocity. The avoidance of poor reciprocators and cheaters causes a person's reputation to become very important. A person with a good reputation for reciprocity has a higher chance of receiving help even from persons they have had no direct interactions with previously. Strong reciprocity. A form of reciprocity where some individuals seem to spend more resources on cooperating and punishing than would be most beneficial as predicted by several established theories of altruism. A number of theories have been proposed as explanations as well as criticisms regarding its existence. Pseudo-reciprocity. An organism behaves altruistically and the recipient does not reciprocate but has an increased chance of acting in a way that is selfish but also as a byproduct benefits the altruist. Costly signaling and the handicap principle. Since altruism takes away resources from the altruist it can be an "honest signal" of resource availability and the abilities needed to gather resources. This may signal to others that the altruist is a valuable potential partner. It may also be a signal of interactive and cooperative intentions since those not interacting further in the future gain nothing from the costly signaling. It is unclear if costly signaling can indicate a long-term cooperative personality but people have increased trust for those who help. Costly signaling is pointless if everyone has the same traits, resources, and cooperative intentions but become a potentially more important signal if the population increasingly varies on these characteristics.Hunters widely sharing the meat has been seen as a costly signal of ability and research has found that good hunters have higher reproductive success and more adulterous relations even if they themselves receive no more of the hunted meat than anyone else. Similarly, holding large feasts and giving large donations has been seen as ways of demonstrating one's resources. Heroic risk-taking has also been interpreted as a costly signal of ability.Both indirect reciprocity and costly signaling depend on the value of reputation and tend to make similar predictions. One is that people will be more helping when they know that their helping behavior will be communicated to people they will interact with later, is publicly announced, is discussed, or is simply being observed by someone else. This have been documented in many studies. The effect is sensitive to subtle cues such as people being more helpful when there were stylized eyespots instead of a logo on a computer screen. Weak reputational cues such as eyespots may become unimportant if there are stronger cues present and may lose their effect with continued exposure unless reinforced with real reputational effects. Public displays such as public weeping for dead celebrities and participation in demonstrations may be influenced by a desire to be seen as altruistic. People who know that they are publicly monitored sometimes even wastefully donate money they know are not needed by recipient which may be because of reputational concerns.Women have been found to find altruistic men to be attractive partners. When looking for a long-term partner, altruism may be a preferred trait as it may indicate that he is also willing to share resources with her and her children. It has been shown that men perform altruistic acts in the early stages of a romantic relationship or simply when in the presence of an attractive woman. While both sexes state that kindness is the most preferable trait in a partner there is some evidence that men place less value on this than women and that women may not be more altruistic in presence of an attractive man. Men may even avoid altruistic women in short-term relationships which may be because they expect less success.People may compete for social benefit from a burnished reputation, which may cause competitive altruism. On the other hand, in some experiments a proportion of people do not seem to care about reputation and they do not help more even if this is conspicuous. This may possibly be due to reasons such as psychopathy or that they are so attractive that they need not be seen to be altruistic. The reputational benefits of altruism occur in the future as compared to the immediate costs of altruism in the present. While humans and other organisms generally place less value on future costs/benefits as compared to those in the present, some have shorter time horizons than others and these people tend to be less cooperative.Explicit extrinsic rewards and punishments have been found to sometimes actually have the opposite effect on behaviors compared to intrinsic rewards. This may be because such extrinsic, top-down incentives may replace (partially or in whole) intrinsic and reputational incentives, motivating the person to focus on obtaining the extrinsic rewards, which overall may make the behaviors less desirable. Another effect is that people would like altruism to be due to a personality characteristic rather than due to overt reputational concerns and simply pointing out that there are reputational benefits of an action may actually reduce them. This may possibly be used as derogatory tactic against altruists, especially by those who are non-cooperators. A counterargument is that doing good due to reputational concerns is better than doing no good at all. Group selection. It has controversially been argued by some evolutionary scientists such as David Sloan Wilson that natural selection can act at the level of non-kin groups to produce adaptations that benefit a non-kin group even if these adaptations are detrimental at the individual level. Thus, while altruistic persons may under some circumstances be outcompeted by less altruistic persons at the individual level, according to group selection theory the opposite may occur at the group level where groups consisting of the more altruistic persons may outcompete groups consisting of the less altruistic persons. Such altruism may only extend to ingroup members while there may instead prejudice and antagonism against outgroup members (See also in-group favoritism). Group selection theory has been criticized by many other evolutionary scientists.Such explanations do not imply that humans are always consciously calculating how to increase their inclusive fitness when they are doing altruistic acts. Instead, evolution has shaped psychological mechanisms, such as emotions, that promote altruistic behaviors.Every single instance of altruistic behavior need not always increase inclusive fitness; altruistic behaviors would have been selected for if such behaviors on average increased inclusive fitness in the ancestral environment. This need not imply that on average 50% or more of altruistic acts were beneficial for the altruist in the ancestral environment; if the benefits from helping the right person were very high it would be beneficial to err on the side of caution and usually be altruistic even if in most cases there were no benefits.The benefits for the altruist may be increased and the costs reduced by being more altruistic towards certain groups. Research has found that people are more altruistic to kin than to no-kin, to friends than to strangers, to those attractive than to those unattractive, to non-competitors than to competitors, and to members ingroups than to members of outgroup.The study of altruism was the initial impetus behind George R. Price's development of the Price equation, which is a mathematical equation used to study genetic evolution. An interesting example of altruism is found in the cellular slime moulds, such as Dictyostelium mucoroides. These protists live as individual amoebae until starved, at which point they aggregate and form a multicellular fruiting body in which some cells sacrifice themselves to promote the survival of other cells in the fruiting body.Selective investment theory proposes that close social bonds, and associated emotional, cognitive, and neurohormonal mechanisms, evolved in order to facilitate long-term, high-cost altruism between those closely depending on one another for survival and reproductive success.Such cooperative behaviors have sometimes been seen as arguments for left-wing politics such by the Russian zoologist and anarchist Peter Kropotkin in his 1902 book Mutual Aid: A Factor of Evolution and Moral Philosopher Peter Singer in his book A Darwinian Left.NeurobiologyJorge Moll and Jordan Grafman, neuroscientists at the National Institutes of Health and LABS-D'Or Hospital Network (J.M.) provided the first evidence for the neural bases of altruistic giving in normal healthy volunteers, using functional magnetic resonance imaging. In their research, published in the Proceedings of the National Academy of Sciences USA in October 2006, they showed that both pure monetary rewards and charitable donations activated the mesolimbic reward pathway, a primitive part of the brain that usually responds to food and sex. However, when volunteers generously placed the interests of others before their own by making charitable donations, another brain circuit was selectively activated: the subgenual cortex/septal region. These structures are intimately related to social attachment and bonding in other species. Altruism, the experiment suggested, was not a superior moral faculty that suppresses basic selfish urges but rather was basic to the brain, hard-wired and pleasurable. One brain region, the subgenual anterior cingulate cortex/basal forebrain, contributes to learning altruistic behavior, especially in those with trait empathy. The same study has shown a connection between giving to charity and the promotion of social bonding.In fact, in an experiment published in March 2007 at the University of Southern California neuroscientist Antonio R. Damasio and his colleagues showed that subjects with damage to the ventromedial prefrontal cortex lack the ability to empathically feel their way to moral answers, and that when confronted with moral dilemmas, these brain-damaged patients coldly came up with "end-justifies-the-means" answers, leading Damasio to conclude that the point was not that they reached immoral conclusions, but that when they were confronted by a difficult issue – in this case as whether to shoot down a passenger plane hijacked by terrorists before it hits a major city – these patients appear to reach decisions without the anguish that afflicts those with normally functioning brains. According to Adrian Raine, a clinical neuroscientist also at the University of Southern California, one of this study's implications is that society may have to rethink how it judges immoral people: "Psychopaths often feel no empathy or remorse. Without that awareness, people relying exclusively on reasoning seem to find it harder to sort their way through moral thickets. Does that mean they should be held to different standards of accountability?"In another study, in the 1990s, Dr. Bill Harbaugh, a University of Oregon economist, concluded people are motivated to give for reasons of personal prestige and in a similar fMRI scanner test in 2007 with his psychologist colleague Dr. Ulrich Mayr, reached the same conclusions of Jorge Moll and Jordan Grafman about giving to charity, although they were able to divide the study group into two groups: "egoists" and "altruists". One of their discoveries was that, though rarely, even some of the considered "egoists" sometimes gave more than expected because that would help others, leading to the conclusion that there are other factors in cause in charity, such as a person's environment and values.PsychologyThe International Encyclopedia of the Social Sciences defines psychological altruism as "a motivational state with the goal of increasing another's welfare". Psychological altruism is contrasted with psychological egoism, which refers to the motivation to increase one's own welfare.There has been some debate on whether or not humans are truly capable of psychological altruism. Some definitions specify a self-sacrificial nature to altruism and a lack of external rewards for altruistic behaviors. However, because altruism ultimately benefits the self in many cases, the selflessness of altruistic acts is brought to question. The social exchange theory postulates that altruism only exists when benefits to the self outweigh costs to the self. Daniel Batson is a psychologist who examined this question and argues against the social exchange theory. He identified four major motives: to ultimately benefit the self (egoism), to ultimately benefit the other person (altruism), to benefit a group (collectivism), or to uphold a moral principle (principlism). Altruism that ultimately serves selfish gains is thus differentiated from selfless altruism, but the general conclusion has been that empathy-induced altruism can be genuinely selfless. The empathy-altruism hypothesis basically states that psychological altruism does exist and is evoked by the empathic desire to help someone who is suffering. Feelings of empathic concern are contrasted with feelings of personal distress, which compel people to reduce their own unpleasant emotions and increase their own positive ones through helping someone in need. Empathy is thus not selfless, since altruism works either as the way to avoid those negative, unpleasant feelings and have positive, pleasant feelings triggered by others' need for help, or as the way to incentive the gain of social reward or through fear to avoid social punishment by helping. People with empathic concern help others in distress even when exposure to the situation could be easily avoided, whereas those lacking in empathic concern avoid helping unless it is difficult or impossible to avoid exposure to another's suffering. Helping behavior is seen in humans at about two years old, when a toddler is capable of understanding subtle emotional cues.In psychological research on altruism, studies often observe altruism as demonstrated through prosocial behaviors such as helping, comforting, sharing, cooperation, philanthropy, and community service. Research has found that people are most likely to help if they recognize that a person is in need and feel personal responsibility for reducing the person's distress. Research also suggests that the number of bystanders witnessing distress or suffering affects the likelihood of helping (the Bystander effect). Greater numbers of bystanders decrease individual feelings of responsibility. However, a witness with a high level of empathic concern is likely to assume personal responsibility entirely regardless of the number of bystanders.Many studies have observed the effects of volunteerism (as a form of altruism) on happiness and health and have consistently found a strong connection between volunteerism and current and future health and well-being. In a study of older adults, those who volunteered were higher on life satisfaction and will to live, and lower in depression, anxiety, and somatization. Volunteerism and helping behavior have not only been shown to improve mental health, but physical health and longevity as well, attributable to the activity and social integration it encourages. One study examined the physical health of mothers who volunteered over a 30-year period and found that 52% of those who did not belong to a volunteer organization experienced a major illness while only 36% of those who did volunteer experienced one. A study on adults ages 55+ found that during the four-year study period, people who volunteered for two or more organizations had a 63% lower likelihood of dying. After controlling for prior health status, it was determined that volunteerism accounted for a 44% reduction in mortality. Merely being aware of kindness in oneself and others is also associated with greater well-being. A study that asked participants to count each act of kindness they performed for one week significantly enhanced their subjective happiness. It is important to note that, while research supports the idea that altruistic acts bring about happiness, it has also been found to work in the opposite direction—that happier people are also kinder. The relationship between altruistic behavior and happiness is bidirectional. Studies have found that generosity increases linearly from sad to happy affective states.Studies have also been careful to note that feeling over-taxed by the needs of others has conversely negative effects on health and happiness. For example, one study on volunteerism found that feeling overwhelmed by others' demands had an even stronger negative effect on mental health than helping had a positive one (although positive effects were still significant). Additionally, while generous acts make people feel good about themselves, it is also important for people to appreciate the kindness they receive from others. Studies suggest that gratitude goes hand-in-hand with kindness and is also very important for our well-being. A study on the relationship happiness to various character strengths showed that "a conscious focus on gratitude led to reductions in negative affect and increases in optimistic appraisals, positive affect, offering emotional support, sleep quality, and well-being".Pathological altruismPathological altruism is when altruism is taken to an unhealthy extreme, and either harms the altruistic person, or well-intentioned actions cause more harm than good.The term "pathological altruism" was popularised by the book Pathological Altruism.Examples include depression and burnout seen in healthcare professionals, an unhealthy focus on others to the detriment of one's own needs, hoarding of animals, and ineffective philanthropic and social programs that ultimately worsen the situations they are meant to aid.Sociology"Sociologists have long been concerned with how to build the good society" ("Altruism, Morality, and Social Solidarity". American Sociological Association.). The structure of our societies and how individuals come to exhibit charitable, philanthropic, and other pro-social, altruistic actions for the common good is a largely researched topic within the field. The American Sociology Association (ASA) acknowledges public sociology saying, "The intrinsic scientific, policy, and public relevance of this field of investigation in helping to construct 'good societies' is unquestionable" ("Altruism, Morality, and Social Solidarity" ASA). This type of sociology seeks contributions that aid grassroots and theoretical understandings of what motivates altruism and how it is organized, and promotes an altruistic focus in order to benefit the world and people it studies. How altruism is framed, organized, carried out, and what motivates it at the group level is an area of focus that sociologists seek to investigate in order to contribute back to the groups it studies and "build the good society". The motivation of altruism is also the focus of study; some publications link the occurrence of moral outrage to the punishment of perpetrators and compensation of victims. Studies have shown that generosity in laboratory and in online experiments is contagious – people imitate observed generosity of others.Religious viewpointsMost, if not all, of the world's religions promote altruism as a very important moral value. Buddhism, Christianity, Hinduism, Islam, Jainism, Judaism, and Sikhism, etc., place particular emphasis on altruistic morality.BuddhismAltruism figures prominently in Buddhism. Love and compassion are components of all forms of Buddhism, and are focused on all beings equally: love is the wish that all beings be happy, and compassion is the wish that all beings be free from suffering. "Many illnesses can be cured by the one medicine of love and compassion. These qualities are the ultimate source of human happiness, and the need for them lies at the very core of our being" (Dalai Lama).Still, the notion of altruism is modified in such a world-view, since the belief is that such a practice promotes our own happiness: "The more we care for the happiness of others, the greater our own sense of well-being becomes" (Dalai Lama).In the context of larger ethical discussions on moral action and judgment, Buddhism is characterized by the belief that negative (unhappy) consequences of our actions derive not from punishment or correction based on moral judgment, but from the law of karma, which functions like a natural law of cause and effect. A simple illustration of such cause and effect is the case of experiencing the effects of what one causes: if one causes suffering, then as a natural consequence one would experience suffering; if one causes happiness, then as a natural consequence one would experience happiness.JainismThe fundamental principles of Jainism revolve around the concept of altruism, not only for humans but for all sentient beings. Jainism preaches the view of Ahimsa – to live and let live, thereby not harming sentient beings, i.e. uncompromising reverence for all life. It also considers all living things to be equal. The first Tirthankara, Rishabhdev, introduced the concept of altruism for all living beings, from extending knowledge and experience to others to donation, giving oneself up for others, non-violence and compassion for all living things.Jainism prescribes a path of non-violence to progress the soul to this ultimate goal. A major characteristic of Jain belief is the emphasis on the consequences of not only physical but also mental behaviors. One's unconquered mind with anger, pride (ego), deceit, greed and uncontrolled sense organs are the powerful enemies of humans. Anger spoils good relations, pride destroys humility, deceit destroys peace and greed destroys everything. Jainism recommends conquering anger by forgiveness, pride by humility, deceit by straightforwardness and greed by contentment.Jains believe that to attain enlightenment and ultimately liberation, one must practice the following ethical principles (major vows) in thought, speech and action. The degree to which these principles are practiced is different for householders and monks. They are: Non-violence (Ahimsa); Truthfulness (Satya); Non-stealing (Asteya); Celibacy (Brahmacharya); Non-possession or non-materialism (Aparigraha);The "great vows" (Mahavrata) are prescribed for monks and "limited vows" (Anuvrata) are prescribed for householders. The house-holders are encouraged to practice the above-mentioned five vows. The monks have to observe them very strictly. With consistent practice, it will be possible to overcome the limitations gradually, accelerating the spiritual progress.The principle of nonviolence seeks to minimize karmas which limit the capabilities of the soul. Jainism views every soul as worthy of respect because it has the potential to become Siddha (God in Jainism). Because all living beings possess a soul, great care and awareness is essential in one's actions. Jainism emphasizes the equality of all life, advocating harmlessness towards all, whether the creatures are great or small. This policy extends even to microscopic organisms. Jainism acknowledges that every person has different capabilities and capacities to practice and therefore accepts different levels of compliance for ascetics and householders.ChristianitySt Thomas Aquinas interprets 'You should love your neighbour as yourself' as meaning that love for ourselves is the exemplar of love for others. Considering that "the love with which a man loves himself is the form and root of friendship" and quotes Aristotle that "the origin of friendly relations with others lies in our relations to ourselves", he concluded that though we are not bound to love others more than ourselves, we naturally seek the common good, the good of the whole, more than any private good, the good of a part. However, he thinks we should love God more than ourselves and our neighbours, and more than our bodily life—since the ultimate purpose of loving our neighbour is to share in eternal beatitude: a more desirable thing than bodily well-being. In coining the word Altruism, as stated above, Comte was probably opposing this Thomistic doctrine, which is present in some theological schools within Catholicism.Many biblical authors draw a strong connection between love of others and love of God. 1 John 4 states that for one to love God one must love his fellowman, and that hatred of one's fellowman is the same as hatred of God. Thomas Jay Oord has argued in several books that altruism is but one possible form of love. An altruistic action is not always a loving action. Oord defines altruism as acting for the other's good, and he agrees with feminists who note that sometimes love requires acting for one's own good when the other's demands undermine overall well-being.German philosopher Max Scheler distinguishes two ways in which the strong can help the weak. One way is a sincere expression of Christian love, "motivated by a powerful feeling of security, strength, and inner salvation, of the invincible fullness of one's own life and existence". Another way is merely "one of the many modern substitutes for love, ... nothing but the urge to turn away from oneself and to lose oneself in other people's business". At its worst, Scheler says, "love for the small, the poor, the weak, and the oppressed is really disguised hatred, repressed envy, an impulse to detract, etc., directed against the opposite phenomena: wealth, strength, power, largesse."IslamIn Islam, the concept "īthār" (إيثار) (altruism) is the notion of "preferring others to oneself". For Sufis, this means devotion to others through complete forgetfulness of one's own concerns, where concern for others is deemed as a demand made by Allah (i.e. God) on the human body, considered to be property of Allah alone. The importance of īthār lies in sacrifice for the sake of the greater good; Islam considers those practicing īthār as abiding by the highest degree of nobility.This is similar to the notion of chivalry, but unlike that European concept, in īthār attention is focused on everything in existence. A constant concern for Allah results in a careful attitude towards people, animals, and other things in this world.JudaismJudaism defines altruism as the desired goal of creation. The famous Rabbi Abraham Isaac Kook stated that love is the most important attribute in humanity. This is defined as bestowal, or giving, which is the intention of altruism. This can be altruism towards humanity that leads to altruism towards the creator or God. Kabbalah defines God as the force of giving in existence. Rabbi Moshe Chaim Luzzatto in particular focused on the 'purpose of creation' and how the will of God was to bring creation into perfection and adhesion with this upper force.Modern Kabbalah developed by Rabbi Yehuda Ashlag, in his writings about the future generation, focuses on how society could achieve an altruistic social framework. Ashlag proposed that such a framework is the purpose of creation, and everything that happens is to raise humanity to the level of altruism, love for one another. Ashlag focused on society and its relation to divinity.SikhismAltruism is essential to the Sikh religion. The central faith in Sikhism is that the greatest deed any one can do is to imbibe and live the godly qualities like love, affection, sacrifice, patience, harmony, truthfulness. The concept of seva, or selfless service to the community for its own sake, is an important concept in Sikhism.The fifth Guru, Arjun Dev, sacrificed his life to uphold "22 carats of pure truth, the greatest gift to humanity", the Guru Granth. The ninth Guru, Tegh Bahadur, sacrificed his head to protect weak and defenseless people against atrocity.In the late seventeenth century, Guru Gobind Singh (the tenth Guru in Sikhism), was at war with the Mughal rulers to protect the people of different faiths when a fellow Sikh, Bhai Kanhaiya, attended the troops of the enemy. He gave water to both friends and foes who were wounded on the battlefield. Some of the enemy began to fight again and some Sikh warriors were annoyed by Bhai Kanhaiya as he was helping their enemy. Sikh soldiers brought Bhai Kanhaiya before Guru Gobind Singh, and complained of his action that they considered counterproductive to their struggle on the battlefield. "What were you doing, and why?" asked the Guru. "I was giving water to the wounded because I saw your face in all of them", replied Bhai Kanhaiya. The Guru responded, "Then you should also give them ointment to heal their wounds. You were practicing what you were coached in the house of the Guru."Under the tutelage of the Guru, Bhai Kanhaiya subsequently founded a volunteer corps for altruism, which is still engaged today in doing good to others and in training new recruits for this service.HinduismIn Hinduism Selflessness (Atmatyag), Love (Prema), Kindness (Daya) and Forgiveness (Kshama) are considered as the highest acts of humanity or "Manushyattva". Giving alms to the beggers or poor people is considered as a divine act or "Punya" and Hindus believe it will free their souls from guilt or "Paapa" and will led them to heaven or "Swarga" in afterlife. Altruism is also the central act of various Hindu mythology and religious poems and songs.The founder of warkari samprdaya the great saint "Dhnyaneshwar Maharaj" (1275-1296) in his "Pasaydan" pray to the supreme lord "Vitthal" for the wellbeing of all living organisms of the universe.Swami Vivekananda, the legendary Hindu monk, has said -"Jive prem kare jeijon, Seijon sebiche Iswar" (Whoever loves any living being, is serving god.). Mass donation of clothes to poor people (Vastraseva), or blood donation camp or mass food donation (Annaseva) for poor people is common in various Hindu religious ceremonies.Swami Sivananda, an Advaita scholar, reiterates the views in his commentary synthesising Vedanta views on the Brahma Sutras, a Vedantic text. In his commentary on Chapter 3 of the Brahma Sutras, Sivananda notes that karma is insentient and short-lived, and ceases to exist as soon as a deed is executed. Hence, karma cannot bestow the fruits of actions at a future date according to one's merit. Furthermore, one cannot argue that karma generates apurva or punya, which gives fruit. Since apurva is non-sentient, it cannot act unless moved by an intelligent being such as a god. It cannot independently bestow reward or punishment.However the very well known and popular text, the Bhagavad Gita supports the doctrine of karma yoga (achieving oneness with God through action) & "Nishkam Karma" or action without expectation / desire for personal gain which can be said to encompass altruism. Altruistic acts are generally celebrated and very well received in Hindu literature and is central to Hindu morality.PhilosophyThere exists a wide range of philosophical views on humans' obligations or motivations to act altruistically. Proponents of ethical altruism maintain that individuals are morally obligated to act altruistically. The opposing view is ethical egoism, which maintains that moral agents should always act in their own self-interest. Both ethical altruism and ethical egoism contrast with utilitarianism, which maintains that each agent should act in order to maximise the efficacy of their function and the benefit to both themselves and their co-inhabitants.A related concept in descriptive ethics is psychological egoism, the thesis that humans always act in their own self-interest and that true altruism is impossible. Rational egoism is the view that rationality consists in acting in one's self-interest (without specifying how this affects one's moral obligations).Effective altruismEffective altruism is a philosophy and social movement that uses evidence and reasoning to determine the most effective ways to benefit others. Effective altruism encourages individuals to consider all causes and actions and to act in the way that brings about the greatest positive impact, based upon their values. It is the broad, evidence-based and cause-neutral approach that distinguishes effective altruism from traditional altruism or charity. Effective altruism is part of the larger movement towards evidence-based practices.While a substantial proportion of effective altruists have focused on the nonprofit sector, the philosophy of effective altruism applies more broadly to prioritizing the scientific projects, companies, and policy initiatives which can be estimated to save lives, help people, or otherwise have the biggest benefit. People associated with the movement include philosopher Peter Singer, Facebook co founder Dustin Moskovitz, Cari Tuna, Ben Delo, Oxford-based researchers William MacAskill and Toby Ord, and professional poker player Liv Boeree,GeneticsThe genes OXTR, CD38, COMT, DRD4, DRD5, IGF2, and GABRB2 have been found to be candidate genes for altruism.Digital AltruismDigital Altruism is the notion that some are willing to freely share information based on the principle of reciprocity and in the belief that in the end, everyone benefits from sharing information via the Internet.This term is coined by Dr. Dana Klisanin, the founder and CEO of Evolutionary Guidance Media R&D Inc., and is a recipient of the Early Career Award for Scientific Achievement in Media Psychology from the American Psychological Association's Division of Media Psychology.According to Klisanin, "the notion that "some are willing to freely reveal what they know" is interesting.Types of Digital AltruismThere are three types of digital altruism: (1) "everyday digital altruism," involving expedience, ease, moral engagement, and conformity; (2) "creative digital altruism," involving creativity, heightened moral engagement, and cooperation; and (3) "co-creative digital altruism" involving creativity, moral engagement, and meta cooperative efforts.See also Altruria, California Charitable organization Comedy of the commons Consideration Egotism Family economics Golden Rule Gene-centered view of evolution Humanity (virtue) Misanthropy Mutual aid Non nobis solum Prisoner's dilemma Random act of kindness Social preferences Social psychology Solidarity (sociology) Spite (game theory)NotesReferences      Comte, Auguste, Catechisme positiviste (1852) or Catechism of Positivism, tr. R. Congreve, (London: Kegan Paul, 1891)  Kropotkin, Peter, Mutual Aid: A Factor of Evolution (1902)  Nietzsche, Friedrich, Beyond Good and Evil Pierre-Joseph Proudhon, The Philosophy of Poverty (1847) Lysander Spooner, Natural Law Matt Ridley, The Origins of Virtue Oliner, Samuel P. and Pearl M. Towards a Caring Society: Ideas into Action. West Port, CT: Praeger, 1995.External linksRichard Kraut (2016) Altruism Stanford Encyclopedia of Philosophy Auguste ComteDefence mechanismsMoralityMoral psychologyPhilanthropySocial philosophyInterpersonal relationshipsVirtue
Alice O'Connor (born Alisa Zinovyevna Rosenbaum; , 1905 – March 6, 1982), better known by her pen name Ayn Rand (), was a Russian-born American writer and philosopher. She is known for her fiction and for developing a philosophical system she named Objectivism. Born and educated in Russia, she moved to the United States in 1926. She wrote a play that opened on Broadway in 1935. After two early novels that were initially unsuccessful, she achieved fame with her 1943 novel, The Fountainhead. In 1957, Rand published her best-known work, the novel Atlas Shrugged. Afterward, until her death in 1982, she turned to non-fiction to promote her philosophy, publishing her own periodicals and releasing several collections of essays.Rand advocated reason as the only means of acquiring knowledge; she rejected faith and religion. She supported rational and ethical egoism and rejected altruism. In politics, she condemned the initiation of force as immoral and opposed collectivism, statism, and anarchism. Instead, she supported laissez-faire capitalism, which she defined as the system based on recognizing individual rights, including private property rights. Although Rand opposed libertarianism, which she viewed as anarchism, she is often associated with the modern libertarian movement in the United States. In art, Rand promoted romantic realism. She was sharply critical of most philosophers and philosophical traditions known to her, except for Aristotle, Thomas Aquinas, and classical liberals.Rand's fiction received mixed reviews from literary critics. Although academic interest in her ideas has grown since her death, academic philosophers have generally ignored or rejected her philosophy because of her polemical approach and lack of methodological rigor. Her writings have politically influenced some libertarians and conservatives. The Objectivist movement attempts to spread her ideas, both to the public and in academic settings.LifeEarly lifeRand was born Alisa Zinovyevna Rosenbaum on February 2, 1905, to a Russian-Jewish bourgeois family living in Saint Petersburg. She was the eldest of three daughters of Zinovy Zakharovich Rosenbaum, a pharmacist, and Anna Borisovna (née Kaplan). Rand later said she found school unchallenging and began writing screenplays at age eight and novels at age ten. At the prestigious , her closest friend was Vladimir Nabokov's younger sister, Olga; the pair shared an intense interest in politics.She was twelve at the time of the February Revolution of 1917, during which Rand favored Alexander Kerensky over Tsar Nicholas II. The subsequent October Revolution and the rule of the Bolsheviks under Vladimir Lenin disrupted the life the family had enjoyed previously. Her father's business was confiscated, and the family fled to the Crimean Peninsula, which was initially under the control of the White Army during the Russian Civil War. While in high school there, Rand concluded she was an atheist and valued reason above any other virtue. After graduating in June 1921, she returned with her family to Petrograd (as Saint Petersburg was then named), where they faced desperate conditions, occasionally nearly starving.Following the Russian Revolution, universities were opened to women, allowing her to be in the first group of women to enroll at Petrograd State University. At 16, she began her studies in the department of social pedagogy, majoring in history. At the university, she was introduced to the writings of Aristotle and Plato; Rand came to see their differing views on reality and knowledge as the primary conflict within philosophy. She also studied the philosophical works of Friedrich Nietzsche.Along with many other bourgeois students, she was purged from the university shortly before graduating. After complaints from a group of visiting foreign scientists, many of the purged students were allowed to complete their work and graduate, which she did in October 1924. She then studied for a year at the State Technicum for Screen Arts in Leningrad. For an assignment, Rand wrote an essay about the Polish actress Pola Negri, which became her first published work.By this time, she had decided her professional surname for writing would be Rand, possibly because it is graphically similar to a vowelless excerpt  of her birth surname  in Cyrillic. She adopted the first name Ayn.Arrival in the United StatesIn late 1925, Rand was granted a visa to visit relatives in Chicago. She departed on January 17, 1926. Arriving in New York City on February 19, 1926, Rand was so impressed with the Manhattan skyline that she cried what she later called "tears of splendor". Intent on staying in the United States to become a screenwriter, she lived for a few months with her relatives. One of them owned a movie theater and allowed her to watch dozens of films free of charge. She then left for Hollywood, California.In Hollywood, a chance meeting with famed director Cecil B. DeMille led to work as an extra in his film The King of Kings and a subsequent job as a junior screenwriter. While working on The King of Kings, she met an aspiring young actor, Frank O'Connor; the two married on April 15, 1929. She became a permanent American resident in July 1929 and an American citizen on March 3, 1931. She made several attempts to bring her parents and sisters to the United States, but they were unable to obtain permission to emigrate.During these early years of her career, Rand wrote a number of screenplays, plays, and short stories that were not produced or published during her lifetime; some were published later in The Early Ayn Rand.Early fictionAlthough it was never produced, Rand's first literary success came with the sale of her screenplay Red Pawn to Universal Studios in 1932.  Her courtroom drama Night of January 16th, first produced by E. E. Clive in Hollywood in 1934, reopened successfully on Broadway in 1935. Each night, a jury was selected from members of the audience; based on its vote, one of two different endings would be performed.Her first published novel, the semi-autobiographical We the Living, was published in 1936. Set in Soviet Russia, it focused on the struggle between the individual and the state. Initial sales were slow, and the American publisher let it go out of print, although European editions continued to sell. She adapted the story as a stage play, but producer George Abbott's Broadway production was a failure and closed in less than a week. After the success of her later novels, Rand was able to release a revised version in 1959 that has since sold over three million copies. In a foreword to the 1959 edition, Rand wrote that We the Living "is as near to an autobiography as I will ever write. ... The plot is invented, the background is not ...".Rand wrote her novella Anthem during a break from writing her next major novel, The Fountainhead. It presents a vision of a dystopian future world in which totalitarian collectivism has triumphed to such an extent that even the word I has been forgotten and replaced with we. Published in England in 1938, Rand could not find an American publisher initially. As with We the Living, Rand's later success allowed her to get a revised version published in 1946, which has sold over 3.5 million copies.The Fountainhead and political activismDuring the 1940s, Rand became politically active. She and her husband worked as full-time volunteers for Republican Wendell Willkie's 1940 presidential campaign. This led to Rand's first public speaking experiences; she enjoyed fielding sometimes hostile questions from New York City audiences who had seen pro-Willkie newsreels. Her work brought her into contact with other intellectuals sympathetic to free-market capitalism. She became friends with journalist Henry Hazlitt, who introduced her to the Austrian School economist Ludwig von Mises. Despite her philosophical differences with them, Rand strongly endorsed the writings of both men throughout her career, and both of them expressed admiration for her. Mises once referred to her as "the most courageous man in America", a compliment that particularly pleased her because he said "man" instead of "woman". Rand became friends with libertarian writer Isabel Paterson. Rand questioned her about American history and politics long into the night during their many meetings, and gave Paterson ideas for her only non-fiction book, The God of the Machine.Rand's first major success as a writer came in 1943 with The Fountainhead, a romantic and philosophical novel that she wrote over seven years. The novel centers on an uncompromising young architect named Howard Roark and his struggle against what Rand described as "second-handers"—those who attempt to live through others, placing others above themselves. Twelve publishers rejected it before the Bobbs-Merrill Company finally accepted it at the insistence of editor Archibald Ogden, who threatened to quit if his employer did not publish it. While completing the novel, Rand was prescribed the amphetamine Benzedrine to fight fatigue. The drug helped her to work long hours to meet her deadline for delivering the novel, but afterwards she was so exhausted that her doctor ordered two weeks' rest. Her use of the drug for approximately three decades may have contributed to what some of her later associates described as volatile mood swings.The Fountainhead became a worldwide success, bringing Rand fame and financial security. In 1943, she sold the film rights to Warner Bros. and returned to Hollywood to write the screenplay. Producer Hal B. Wallis hired her afterwards as a screenwriter and script-doctor. Her work for him included the screenplays for the Oscar-nominated Love Letters and You Came Along. Rand worked on other projects, including a never-completed nonfiction treatment of her philosophy to be called The Moral Basis of Individualism.Rand extended her involvement with free-market and anti-communist activism while working in Hollywood. She became involved with the anti-Communist Motion Picture Alliance for the Preservation of American Ideals and wrote articles on the group's behalf. She also joined the anti-Communist American Writers Association. A visit by Paterson to meet with Rand's California associates led to a falling out between the two when Paterson made comments to valued political allies which Rand considered rude. In 1947, during the Second Red Scare, Rand testified as a "friendly witness" before the United States House Un-American Activities Committee that the 1944 film Song of Russia grossly misrepresented conditions in the Soviet Union, portraying life there as much better and happier than it was. She also wanted to criticize the lauded 1946 film The Best Years of Our Lives for what she interpreted as its negative presentation of the business world, but was not allowed to do so. When asked after the hearings about her feelings on the investigations' effectiveness, Rand described the process as "futile".After several delays, the film version of The Fountainhead was released in 1949. Although it used Rand's screenplay with minimal alterations, she "disliked the movie from beginning to end" and complained about its editing, the acting and other elements.Atlas Shrugged and ObjectivismFollowing the publication of The Fountainhead, Rand received numerous letters from readers, some of whom the book had influenced profoundly. In 1951, Rand moved from Los Angeles to New York City, where she gathered a group of these admirers around her. This group (jokingly designated "The Collective") included a future chair of the Federal Reserve Alan Greenspan, a young psychology student named Nathan Blumenthal (later Nathaniel Branden) and his wife Barbara, and Barbara's cousin Leonard Peikoff. Initially, the group was an informal gathering of friends who met with Rand at her apartment on weekends to discuss philosophy. Later, Rand began allowing them to read the drafts of her new novel, Atlas Shrugged, as she wrote the manuscript. In 1954, her close relationship with Nathaniel Branden turned into a romantic affair, with the knowledge of their spouses.Published in 1957, Atlas Shrugged was considered Rand's magnum opus. She described the novel's theme as "the role of the mind in man's existence—and, as a corollary, the demonstration of a new moral philosophy: the morality of rational self-interest". It advocates the core tenets of Rand's philosophy of Objectivism and expresses her concept of human achievement. The plot involves a dystopian United States in which the most creative industrialists, scientists, and artists respond to a welfare state government by going on strike and retreating to a hidden valley where they build an independent free economy. The novel's hero and leader of the strike, John Galt, describes it as "stopping the motor of the world" by withdrawing the minds of the individuals contributing most to the nation's wealth and achievements. With this fictional strike, Rand intended to illustrate that without the efforts of the rational and productive, the economy would collapse and society would fall apart. The novel includes elements of mystery, romance, and science fiction, and contains an extended exposition of Objectivism in a lengthy monologue delivered by Galt.Despite many negative reviews, Atlas Shrugged became an international bestseller; however, the reaction of intellectuals to the novel discouraged and depressed Rand. Atlas Shrugged was her last completed work of fiction marking the end of her career as a novelist and the beginning of her role as a popular philosopher.In 1958, Nathaniel Branden established the Nathaniel Branden Lectures, later incorporated as the Nathaniel Branden Institute (NBI), to promote Rand's philosophy. Collective members gave lectures for the NBI and wrote articles for Objectivist periodicals that Rand edited. She later published some of these articles in book form. Rand was unimpressed by many of the NBI students and held them to strict standards, sometimes reacting coldly or angrily to those who disagreed with her. Critics, including some former NBI students and Branden himself, later described the culture of the NBI as one of intellectual conformity and excessive reverence for Rand. Some described the NBI or the Objectivist movement as a cult or religion. Rand expressed opinions on a wide range of topics, from literature and music to sexuality and facial hair. Some of her followers mimicked her preferences, wearing clothes to match characters from her novels and buying furniture like hers. However, some former NBI students believed the extent of these behaviors was exaggerated, and the problem was concentrated among Rand's closest followers in New York.Later yearsThroughout the 1960s and 1970s, Rand developed and promoted her Objectivist philosophy through her nonfiction works and by giving talks to students at institutions such as Yale, Princeton, Columbia, Harvard, and the Massachusetts Institute of Technology. She began delivering annual lectures at the Ford Hall Forum, responding to questions from the audience. During these appearances, she often took controversial stances on the political and social issues of the day. These included: supporting abortion rights, opposing the Vietnam War and the military draft (but condemning many draft dodgers as "bums"), supporting Israel in the Yom Kippur War of 1973 against a coalition of Arab nations as "civilized men fighting savages", saying European colonists had the right to invade and take land inhabited by American Indians, and calling homosexuality "immoral" and "disgusting", while also advocating the repeal of all laws concerning it. She endorsed several Republican candidates for president of the United States, most strongly Barry Goldwater in 1964, whose candidacy she promoted in several articles for The Objectivist Newsletter.In 1964, Nathaniel Branden began an affair with the young actress Patrecia Scott, whom he later married. Nathaniel and Barbara Branden kept the affair hidden from Rand. When she learned of it in 1968, though her romantic relationship with Branden had already ended, Rand ended her relationship with both Brandens, and the NBI was closed. She published an article in The Objectivist repudiating Nathaniel Branden for dishonesty and other "irrational behavior in his private life". In subsequent years, Rand and several more of her closest associates parted company.Rand underwent surgery for lung cancer in 1974 after decades of heavy smoking. In 1976, she retired from writing her newsletter and, after her initial objections, allowed a social worker employed by her attorney to enroll her in Social Security and Medicare. During the late 1970s, her activities within the Objectivist movement declined, especially after the death of her husband on November 9, 1979. One of her final projects was work on a never-completed television adaptation of Atlas Shrugged.On March 6, 1982, Rand died of heart failure at her home in New York City. She was interred in the Kensico Cemetery, Valhalla, New York. At her funeral, a  floral arrangement in the shape of a dollar sign was placed near her casket. In her will, Rand named Leonard Peikoff as her beneficiary.Literary method and influencesRand described her approach to literature as "romantic realism". She wanted her fiction to present the world "as it could be and should be", rather than as it was. This approach led her to create highly stylized situations and characters. Her fiction typically has protagonists who are heroic individualists, depicted as fit and attractive. Her stories' villains support duty and collectivist moral ideals. Rand often describes them as unattractive and they sometimes have names that suggest negative traits, like Wesley Mouch in Atlas Shrugged.Rand considered plot a critical element of literature, and her stories typically have what biographer Anne Heller described as "tight, elaborate, fast-paced plotting". Romantic triangles are a common plot element in Rand's fiction; in most of her novels and plays, the main female character is romantically involved with at least two different men.InfluencesIn school Rand read works by Fyodor Dostoevsky, Victor Hugo, Edmond Rostand, and Friedrich Schiller, who became her favorites. She considered them to be among the "top rank" of Romantic writers because of their focus on moral themes and their skill at constructing plots. Hugo, in particular, was an important influence on her writing, especially her approach to plotting. In the introduction she wrote for an English-language edition of his novel Ninety-Three, Rand called him "the greatest novelist in world literature".Although Rand disliked most Russian literature, her depictions of her heroes show the influence of the Russian Symbolists and other nineteenth-century Russian writing, most notably the 1863 novel What Is to Be Done? by Nikolay Chernyshevsky. Rand's experience of the Russian Revolution and early Communist Russia influenced the portrayal of her villains. This is most apparent in We the Living, set in Russia. The ideas and rhetoric of Ellsworth Toohey in The Fountainhead and the destruction of the economy by the looters in Atlas Shrugged also reflect it.Rand's descriptive style echoes her early career writing scenarios and scripts for movies; her novels have many narrative descriptions that resemble early Hollywood movie scenarios. They often follow common film editing conventions, such as having a broad establishing shot description of a scene followed by close-up details, and her descriptions of women characters often take a "male gaze" perspective.PhilosophyRand called her philosophy "Objectivism", describing its essence as "the concept of man as a heroic being, with his own happiness as the moral purpose of his life, with productive achievement as his noblest activity, and reason as his only absolute". She considered Objectivism a systematic philosophy and laid out positions on metaphysics, epistemology, ethics, political philosophy, and aesthetics.In metaphysics, Rand supported philosophical realism and opposed anything she regarded as mysticism or supernaturalism, including all forms of religion. Rand believed in free will as a form of agent causation and rejected determinism.In epistemology, she considered all knowledge to be based on sense perception, the validity of which Rand considered axiomatic, and reason, which she described as "the faculty that identifies and integrates the material provided by man's senses". Rand rejected all claims of non-perceptual or a priori knowledge, including instinct,' 'intuition,' 'revelation,' or any form of 'just knowing. In her Introduction to Objectivist Epistemology, Rand presented a theory of concept formation and rejected the analytic–synthetic dichotomy.In ethics, Rand argued for rational and ethical egoism (rational self-interest), as the guiding moral principle. She said the individual should "exist for his own sake, neither sacrificing himself to others nor sacrificing others to himself". Rand referred to egoism as "the virtue of selfishness" in her book of that title. In it, she presented her solution to the is-ought problem by describing a meta-ethical theory that based morality in the needs of "man's survival qua man". She condemned ethical altruism as incompatible with the requirements of human life and happiness, and held the initiation of force was evil and irrational, writing in Atlas Shrugged that, "Force and mind are opposites."Rand's political philosophy emphasized individual rights—including property rights. She considered laissez-faire capitalism the only moral social system because in her view it was the only system based on protecting those rights. Rand opposed statism, which she understood included theocracy, absolute monarchy, Nazism, fascism, communism, democratic socialism, and dictatorship. She believed a constitutionally limited government should protect natural rights. Although her political views are often classified as conservative or libertarian, Rand preferred the term "radical for capitalism". She worked with conservatives on political projects, but disagreed with them over issues such as religion and ethics. Rand denounced libertarianism, which she associated with anarchism. She rejected anarchism as a naive theory based in subjectivism that could only lead to collectivism in practice.In aesthetics, Rand defined art as a "selective re-creation of reality according to an artist's metaphysical value-judgments". According to her, art allows philosophical concepts to be presented in a concrete form that can be grasped easily, thereby fulfilling a need of human consciousness. As a writer, the art form Rand focused on most closely was literature. She considered romanticism to be the approach that most accurately reflected the existence of human free will.Rand said her most important contributions to philosophy were her "theory of concepts, ethics, and discovery in politics that evil—the violation of rights—consists of the initiation of force". She believed epistemology was a foundational branch of philosophy and considered the advocacy of reason to be the single most significant aspect of her philosophy, stating: "I am not primarily an advocate of capitalism, but of egoism; and I am not primarily an advocate of egoism, but of reason. If one recognizes the supremacy of reason and applies it consistently, all the rest follows."CriticismsRand's ethics and politics are the most criticized areas of her philosophy. Numerous authors, including Robert Nozick and William F. O'Neill, in some of the earliest academic critiques of her ideas, said she failed in her attempt to solve the is–ought problem. Critics have called her definitions of egoism and altruism biased and inconsistent with normal usage. Critics from religious traditions oppose her rejection of altruism in addition to atheism. Essays criticizing Rand's egoistic views are included in a number of anthologies for teaching introductory ethics, which often include no essays presenting or defending them.Multiple critics, including Nozick, have said her attempt to justify individual rights based on egoism fails. Others, like Michael Huemer, have gone further, saying that her support of egoism and her support of individual rights are inconsistent positions. Some critics, like Roy Childs, have said that her opposition to the initiation of force should lead to support of anarchism, rather than limited government.Commentators, including Hazel Barnes, Albert Ellis, and Nathaniel Branden, have criticized Rand's focus on the importance of reason. Branden said this emphasis led her to denigrate emotions and create unrealistic expectations of how consistently rational human beings should be.Relationship to other philosophersExcept for Aristotle, Thomas Aquinas and classical liberals, Rand was sharply critical of most philosophers and philosophical traditions known to her. Acknowledging Aristotle as her greatest influence, Rand remarked that in the history of philosophy she could only recommend "three A's"—Aristotle, Aquinas, and Ayn Rand. In a 1959 interview with Mike Wallace, when asked where her philosophy came from, she responded: "Out of my own mind, with the sole acknowledgement of a debt to Aristotle, the only philosopher who ever influenced me. I devised the rest of my philosophy myself."In an article for the Claremont Review of Books, political scientist Charles Murray criticized her claim that her only "philosophical debt" was to Aristotle. He asserted her ideas were derivative of previous thinkers such as John Locke and Friedrich Nietzsche. Rand found early inspiration from Nietzsche, and scholars have found indications of this in Rand's private journals. In 1928, she alluded to his idea of the "superman" in notes for an unwritten novel whose protagonist was inspired by the murderer William Edward Hickman. There are other indications of Nietzsche's influence in passages from the first edition of We the Living (which Rand later revised), and in her overall writing style. By the time she wrote The Fountainhead, Rand had turned against Nietzsche's ideas, and the extent of his influence on her even during her early years is disputed.Rand considered her philosophical opposite to be Immanuel Kant, whom she referred to as "the most evil man in mankind's history"; she believed his epistemology undermined reason and his ethics opposed self-interest. Philosophers George Walsh and Fred Seddon have argued she misinterpreted Kant and exaggerated their differences.Rand's relationship with contemporary philosophers was mostly antagonistic. She was not an academic and did not participate in academic discourse. She was dismissive toward critics and wrote about ideas she disagreed with in a polemical manner without in-depth analysis. She was in turn viewed very negatively by many academic philosophers, who dismissed her as an unimportant figure who need not be given serious consideration.Reception and legacyCritical receptionThe first reviews Rand received were for Night of January 16th. Reviews of the Broadway production were largely positive, but Rand considered even positive reviews to be embarrassing because of significant changes made to her script by the producer. Although Rand believed that her novel We the Living was not widely reviewed, over 200 publications published approximately 125 different reviews. Overall, they were more positive than those she received for her later work. Her 1938 novella Anthem received little review attention, both for its first publication in England and for subsequent re-issues.Rand's first bestseller, The Fountainhead, received far fewer reviews than We the Living, and reviewers' opinions were mixed. Lorine Pruette's positive review in The New York Times, which called the author "a writer of great power" who wrote "brilliantly, beautifully and bitterly", was one that Rand greatly appreciated. There were other positive reviews, but Rand dismissed most of them for either misunderstanding her message or for being in unimportant publications. Some negative reviews said the novel was too long; others called the characters unsympathetic and Rand's style "offensively pedestrian".Atlas Shrugged was widely reviewed, and many of the reviews were strongly negative. Atlas Shrugged received positive reviews from a few publications, but Rand scholar Mimi Reisel Gladstein later wrote that "reviewers seemed to vie with each other in a contest to devise the cleverest put-downs", with reviews including comments that it was "written out of hate" and showed "remorseless hectoring and prolixity". Whittaker Chambers wrote what was later called the novel's most "notorious" review for the conservative magazine National Review. He accused Rand of supporting a godless system (which he related to that of the Soviets), claiming, "From almost any page of Atlas Shrugged, a voice can be heard ... commanding: 'To a gas chamber—go!.Rand's nonfiction received far fewer reviews than her novels. The tenor of the criticism for her first nonfiction book, For the New Intellectual, was similar to that for Atlas Shrugged. Philosopher Sidney Hook likened her certainty to "the way philosophy is written in the Soviet Union", and author Gore Vidal called her viewpoint "nearly perfect in its immorality". These reviews set the pattern for reaction to her ideas among liberal critics. Her subsequent books got progressively less review attention.On the 100th anniversary of Rand's birth in 2005, writing for The New York Times, Edward Rothstein referred to her written fiction as quaint utopian "retro fantasy" and programmatic neo-Romanticism of the misunderstood artist, while criticizing her characters' "isolated rejection of democratic society".Popular interestWith over 30 million copies sold , Rand's books continue to be read widely. A survey conducted for the Library of Congress and the Book-of-the-Month Club in 1991 asked club members to name the most influential book in their lives. Rand's Atlas Shrugged was the second most popular choice, after the Bible. Although Rand's influence has been greatest in the United States, there has been international interest in her work.Rand's contemporary admirers included fellow novelists, like Ira Levin, Kay Nolte Smith and L. Neil Smith; she has influenced later writers like Erika Holzer and Terry Goodkind. Other artists who have cited Rand as an important influence on their lives and thought include comic book artist Steve Ditko and musician Neil Peart of Rush, although he later distanced himself. Rand provided a positive view of business and subsequently many business executives and entrepreneurs have admired and promoted her work. John Allison of BB&T and Ed Snider of Comcast Spectacor have funded the promotion of Rand's ideas. Mark Cuban (owner of the Dallas Mavericks) as well as John P. Mackey (CEO of Whole Foods), among others, have said they consider Rand crucial to their success.Television shows including animated sitcoms, live-action comedies, dramas, and game shows, as well as movies and video games have referred to Rand and her works. Throughout her life she was the subject of many articles in popular magazines, as well as book-length critiques by authors such as the psychologist Albert Ellis and Trinity Foundation president John W. Robbins. Rand, or characters based on her, figure prominently in novels by prominent American authors, including Mary Gaitskill, Matt Ruff, Kay Nolte Smith, and Tobias Wolff. Nick Gillespie, former editor-in- chief of Reason, remarked that, "Rand's is a tortured immortality, one in which she's as likely to be a punch line as a protagonist. Jibes at Rand as cold and inhuman run through the popular culture." Two movies have been made about Rand's life. A 1997 documentary film, Ayn Rand: A Sense of Life, was nominated for the Academy Award for Best Documentary Feature. The Passion of Ayn Rand, a 1999 television adaptation of the book of the same name, won several awards. Rand's image also appears on a 1999 U.S. postage stamp illustrated by artist Nick Gaetano.Rand's works, most commonly Anthem or The Fountainhead, are sometimes assigned as secondary school reading. Since 2002, the Ayn Rand Institute has provided free copies of Rand's novels to teachers who promise to include the books in their curriculum. The Institute had distributed 4.5 million copies in the U.S. and Canada by the end of 2020. In 2017, Rand was added to the required reading list for the A Level Politics exam in the United Kingdom.Political influenceAlthough she rejected the labels "conservative" and "libertarian", Rand has had a continuing influence on right-wing politics and libertarianism. Rand is often considered one of the three most important women (along with Rose Wilder Lane and Isabel Paterson) in the early development of modern American libertarianism. David Nolan, one founder of the Libertarian Party, said that "without Ayn Rand, the libertarian movement would not exist". In his history of that movement, journalist Brian Doherty described her as "the most influential libertarian of the twentieth century to the public at large". Historian Jennifer Burns referred to her as "the ultimate gateway drug to life on the right".The political figures who cite Rand as an influence are usually conservatives (often members of the Republican Party), despite Rand taking some atypical positions for a conservative, like being pro-choice and an atheist. She faced intense opposition from William F. Buckley Jr. and other contributors to the conservative National Review magazine, which published numerous criticisms of her writings and ideas. Nevertheless, a 1987 article in The New York Times referred to her as the Reagan administration's "novelist laureate". Republican congressmen and conservative pundits have acknowledged her influence on their lives and have recommended her novels. She has influenced some conservative politicians outside the U.S., such as Sajid Javid in the United Kingdom, Siv Jensen in Norway, and Ayelet Shaked in Israel.The financial crisis of 2007–2008 spurred renewed interest in her works, especially Atlas Shrugged, which some saw as foreshadowing the crisis. Opinion articles compared real-world events with the novel's plot. Signs mentioning Rand and her fictional hero John Galt appeared at Tea Party protests. There was increased criticism of her ideas, especially from the political left. Critics blamed the economic crisis on her support of selfishness and free markets, particularly through her influence on Alan Greenspan. In 2015, Adam Weiner said that through Greenspan, "Rand had effectively chucked a ticking time bomb into the boiler room of the US economy". Lisa Duggan said that Rand's novels had "incalculable impact" in encouraging the spread of neoliberal political ideas. In 2021, Cass Sunstein said Rand's ideas could be seen in the tax and regulatory policies of the Trump administration, which he attributed to the "enduring influence" of Rand's fiction.Academic reactionDuring Rand's lifetime, her work received little attention from academic scholars. Since her death, interest in her work has increased gradually. In 2009, historian Jennifer Burns identified "three overlapping waves" of scholarly interest in Rand, including "an explosion of scholarship" since the year 2000. However, as of that same year, few universities included Rand or Objectivism as a philosophical specialty or research area, with many literature and philosophy departments dismissing her as a pop culture phenomenon rather than a subject for serious study. From 2002 to 2012, over 60 colleges and universities accepted grants from the charitable foundation of BB&T Corporation that required teaching Rand's ideas or works; in some cases, the grants were controversial or even rejected because of the requirement to teach about Rand. In 2020, media critic Eric Burns said that, "Rand is surely the most engaging philosopher of my lifetime",  but "nobody in the academe pays any attention to her, neither as an author nor a philosopher. That same year, the editor of a collection of critical essays about Rand said academics who disapproved of her ideas had long held "a stubborn resolve to ignore or ridicule" her work, but he believed more academic critics were engaging with her work in recent years.To her ideasIn 1967, John Hospers discussed Rand's ethical ideas in the second edition of his textbook, An Introduction to Philosophical Analysis. That same year, Hazel Barnes included a chapter critiquing Objectivism in her book An Existentialist Ethics. When the first full-length academic book about Rand's philosophy appeared in 1971, its author declared writing about Rand "a treacherous undertaking" that could lead to "guilt by association" for taking her seriously. A few articles about Rand's ideas appeared in academic journals before her death in 1982, many of them in The Personalist. One of these was "On the Randian Argument" by libertarian philosopher Robert Nozick, who criticized her meta-ethical arguments. Other philosophers, writing in the same publication, argued that Nozick misstated Rand's case. In an article responding to Nozick, Douglas Den Uyl and Douglas B. Rasmussen defended her positions, but described her style as "literary, hyperbolic and emotional".The Philosophic Thought of Ayn Rand, a 1984 collection of essays about Objectivism edited by Den Uyl and Rasmussen, was the first academic book about Rand's ideas published after her death. In one essay, political writer Jack Wheeler wrote that despite "the incessant bombast and continuous venting of Randian rage", Rand's ethics are "a most immense achievement, the study of which is vastly more fruitful than any other in contemporary thought". In 1987, Allan Gotthelf, George Walsh, and David Kelley co-founded the Ayn Rand Society, a group affiliated with the American Philosophical Association.In a 1995 entry about Rand in Contemporary Women Philosophers, Jenny A. Heyl described a divergence in how different academic specialties viewed Rand. She said that Rand's philosophy "is regularly omitted from academic philosophy. Yet, throughout literary academia, Ayn Rand is considered a philosopher." Writing in the 1998 edition of the Routledge Encyclopedia of Philosophy, political theorist Chandran Kukathas summarized the mainstream philosophical reception of her work in two parts. He said most commentators view her ethical argument as an unconvincing variant of Aristotle's ethics, and her political theory "is of little interest" because it is marred by an "ill-thought out and unsystematic" effort to reconcile her hostility to the state with her rejection of anarchism. The Journal of Ayn Rand Studies, a multidisciplinary, peer-reviewed academic journal devoted to the study of Rand and her ideas, was established in 1999. R. W. Bradford, Stephen D. Cox, and Chris Matthew Sciabarra were its founding co-editors.In a 2010 essay for the Cato Institute, libertarian philosopher Michael Huemer argued very few people find Rand's ideas convincing, especially her ethics. He attributed the attention she receives to her being a "compelling writer", especially as a novelist, noting that Atlas Shrugged outsells Rand's non-fiction works and the works of other philosophers of classical liberalism. In 2012, the Pennsylvania State University Press agreed to take over publication of The Journal of Ayn Rand Studies, and the University of Pittsburgh Press launched an "Ayn Rand Society Philosophical Studies" series based on the Society's proceedings. The Fall 2012 update to the entry about Rand in the Stanford Encyclopedia of Philosophy said that "only a few professional philosophers have taken her work seriously". That same year, political scientist Alan Wolfe dismissed Rand as a "nonperson" among academics, an attitude that writer Ben Murnane later described as "the traditional academic view" of Rand.To her fictionAcademic consideration of Rand as a literary figure during her life was even more limited than the discussion of her philosophy. Mimi Reisel Gladstein could not find any scholarly articles about Rand's novels when she began researching her in 1973, and only three such articles appeared during the rest of the 1970s. Since her death, scholars of English and American literature have continued largely to ignore her work, although attention to her literary work has increased since the 1990s. Several academic book series about important authors cover Rand and her works. These include Twayne's United States Authors (Ayn Rand by James T. Baker), Twayne's Masterwork Studies (The Fountainhead: An American Novel by Den Uyl and Atlas Shrugged: Manifesto of the Mind by Gladstein), and Re-reading the Canon (Feminist Interpretations of Ayn Rand, edited by Gladstein and Sciabarra), as well as in popular study guides like CliffsNotes and SparkNotes. In The Literary Encyclopedia entry for Rand written in 2001, John David Lewis declared that "Rand wrote the most intellectually challenging fiction of her generation." In 2019, Lisa Duggan described Rand's fiction as popular and influential on many readers, despite being easy to criticize for "her cartoonish characters and melodramatic plots, her rigid moralizing, her middle- to lowbrow aesthetic preferences ... and philosophical strivings".Objectivist movementAfter the closure of the Nathaniel Branden Institute, the Objectivist movement continued in other forms. In the 1970s, Leonard Peikoff began delivering courses on Objectivism. In 1979, Objectivist writer Peter Schwartz started a newsletter called The Intellectual Activist, which Rand endorsed. She also endorsed The Objectivist Forum, a bimonthly magazine founded by Objectivist philosopher Harry Binswanger, which ran from 1980 to 1987.In 1985, Peikoff worked with businessman Ed Snider to establish the Ayn Rand Institute, a nonprofit organization dedicated to promoting Rand's ideas and works. In 1990, after an ideological disagreement with Peikoff, philosopher David Kelley founded the Institute for Objectivist Studies, now known as The Atlas Society. In 2001, historian John McCaskey organized the Anthem Foundation for Objectivist Scholarship, which provides grants for scholarly work on Objectivism in academia.Selected worksFiction and drama: Night of January 16th (performed 1934, published 1968) We the Living (1936, revised 1959) Anthem (1938, revised 1946) The Unconquered (performed 1940, published 2014) The Fountainhead (1943) Atlas Shrugged (1957) The Early Ayn Rand (1984) Ideal (2015)Non-fiction: For the New Intellectual (1961) The Virtue of Selfishness (1964) Capitalism: The Unknown Ideal (1966, expanded 1967) The Romantic Manifesto (1969, expanded 1975) The New Left (1971, expanded 1975) Introduction to Objectivist Epistemology (1979, expanded 1990) Philosophy: Who Needs It (1982) Letters of Ayn Rand (1995) Journals of Ayn Rand (1997)NotesReferencesWorks cited                                                                            Reprinted from Esquire, July 1961.External links Frequently Asked Questions About Ayn Rand from the Ayn Rand Institute    Rand's papers at The Library of Congress Ayn Rand Lexicon – searchable database     "Writings of Ayn Rand" – from C-SPAN's American Writers: A Journey Through History 1905 births1982 deathsWriters from Saint PetersburgWriters from New York City20th-century American dramatists and playwrights20th-century American novelists20th-century American philosophers20th-century American women writers20th-century atheists20th-century essayists20th-century Russian philosophersActivists from New York (state)American abortion-rights activistsAmerican anti-communistsAmerican anti-fascistsJewish American atheistsAmerican atheist writersAmerican essayistsAmerican ethicistsAmerican people of Russian-Jewish descentAmerican political activistsAmerican political philosophersAmerican science fiction writersAmerican women activistsAmerican women dramatists and playwrightsAmerican women essayistsAmerican women novelistsAmerican women philosophersAmerican women screenwritersAmerican secularistsAmerican writers of Russian descentAristotelian philosophersAtheist philosophersCritics of MarxismEpistemologistsExophonic writersFemale critics of feminismAtheists of the Russian EmpireJews of the Russian EmpireJewish American dramatists and playwrightsJewish American novelistsJewish activistsJewish anti-communistsJewish anti-fascistsJewish philosophersJewish women writersMetaphysiciansNovelists from New York (state)ObjectivistsOld Right (United States)People of the New Deal arts projectsPeople with acquired American citizenshipPhilosophers from New York (state)Political philosophersPseudonymous women writersDramatists and playwrights of the Russian EmpireSaint Petersburg State University alumniScreenwriters from New York (state)Soviet emigrants to the United StatesWomen science fiction and fantasy writersBurials at Kensico Cemetery20th-century American screenwritersDeaths from organ failure20th-century pseudonymous writersCritics of ChristianitySocial critics
Alain Connes (; born 1 April 1947) is a French mathematician, and a theoretical physicist, known for his contributions to the study of operator algebras and noncommutative geometry. He is a professor at the Collège de France, IHÉS, Ohio State University and Vanderbilt University. He was awarded the Fields Medal in 1982.CareerConnes was an Invited Professor at the Conservatoire national des arts et métiers (2000).ResearchAlain Connes studies operator algebras. In his early work on von Neumann algebras in the 1970s, he succeeded in obtaining the almost complete classification of injective factors. He also formulated the Connes embedding problem. Following this, he made contributions in operator K-theory and index theory, which culminated in the Baum–Connes conjecture. He also introduced cyclic cohomology in the early 1980s as a first step in the study of noncommutative differential geometry. He was a member of Bourbaki.Connes has applied his work in areas of mathematics and theoretical physics, including number theory, differential geometry and particle physics.Awards and honoursConnes was awarded the Fields Medal in 1982, the Crafoord Prize in 2001 and the gold medal of the CNRS in 2004.  He was an invited speaker at the ICM in 1974 at Vancouver and in 1986 at Berkeley and a plenary speaker at the ICM in 1978 at Helsinki. He is a member of the French Academy of Sciences and several foreign academies and societies, including the Danish Academy of Sciences, Norwegian Academy of Sciences, Russian Academy of Sciences, and US National Academy of Sciences.Books Alain Connes and Matilde Marcolli, Noncommutative Geometry, Quantum Fields and Motives, Colloquium Publications, American Mathematical Society, 2007,   Alain Connes, Andre Lichnerowicz, and Marcel Paul Schutzenberger, Triangle of Thought, translated by Jennifer Gage, American Mathematical Society, 2001,  Jean-Pierre Changeux, and Alain Connes, Conversations on Mind, Matter, and Mathematics, translated by M. B. DeBevoise, Princeton University Press, 1998,  Alain Connes, Noncommutative Geometry, Academic Press, 1994,See also Bost–Connes system Cyclic category Cyclic homology Factor (functional analysis) Higgs boson C*-algebra Noncommutative quantum field theory M-theory Groupoid Spectral tripleCriticism of non-standard analysis Riemann hypothesisReferencesExternal links Alain Connes Official Web Site containing downloadable papers, and his book Non-commutative geometry, .  Alain Connes' Standard Model An interview with Alain Connes and a discussion about it   1947 birthsLiving people20th-century French mathematiciansForeign associates of the National Academy of Sciences21st-century French mathematiciansCollège de France facultyInstitute for Advanced Study visiting scholarsFields MedalistsMathematical analystsDifferential geometersÉcole Normale Supérieure alumniVanderbilt University facultyForeign Members of the Russian Academy of SciencesMembers of the French Academy of SciencesMembers of the Norwegian Academy of Science and LettersMembers of the Royal Danish Academy of Sciences and LettersClay Research Award recipients
Allan Dwan (born Joseph Aloysius Dwan; April 3, 1885 – December 28, 1981) was a pioneering Canadian-born American motion picture director, producer, and screenwriter.Early lifeBorn Joseph Aloysius Dwan in Toronto, Ontario, Canada, Dwan, was the younger son of commercial traveler of woolen clothing Joseph Michael Dwan (1857–1917) and his wife Mary Jane Dwan, née Hunt. The family moved to the United States when he was seven years old on December 4, 1892 by ferry from Windsor to Detroit, according to his naturalization petition of August 1939. His elder brother, Leo Garnet Dwan (1883–1964), became a physician.Allan Dwan studied engineering at the University of Notre Dame and then worked for a lighting company in Chicago. He had a strong interest in the fledgling motion picture industry, and when Essanay Studios offered him the opportunity to become a scriptwriter, he took the job. At that time, some of the East Coast movie makers began to spend winters in California where the climate allowed them to continue productions requiring warm weather. Soon, a number of movie companies worked there year-round, and in 1911, Dwan began working part-time in Hollywood. While still in New York, in 1917 he was the founding president of the East Coast chapter of the Motion Picture Directors Association.CareerDwan operated Flying A Studios in La Mesa, California from August 1911 to July 1912. Flying A was one of the first motion pictures studios in California history. On August 12, 2011, a plaque was unveiled on the Wolff building at Third Avenue and La Mesa Boulevard commemorating Dwan and the Flying A Studios origins in La Mesa, California.After making a series of westerns and comedies, Dwan directed fellow Canadian-American Mary Pickford in several very successful movies as well as her husband, Douglas Fairbanks, notably in the acclaimed 1922 Robin Hood. Dwan directed Gloria Swanson in eight feature films, and one short film made in the short-lived sound-on-film process Phonofilm. This short, also featuring Thomas Meighan and Henri de la Falaise, was produced as a joke, for the April 26, 1925 "Lambs' Gambol" for The Lambs, with the film showing Swanson crashing the all-male club.Following the introduction of the talkies, Dwan directed child-star Shirley Temple in Heidi (1937) and Rebecca of Sunnybrook Farm (1938).Dwan helped launch the career of two other successful Hollywood directors, Victor Fleming, who went on to direct The Wizard of Oz and Gone With the Wind, and Marshall Neilan, who became an actor, director, writer and producer. Over a long career spanning almost 50 years, Dwan directed 125 motion pictures, some of which were highly acclaimed, such as the 1949 box office hit, Sands of Iwo Jima. He directed his last movie in 1961.He died in Los Angeles at the age of 96, and is interred in the San Fernando Mission Cemetery, Mission Hills, California.Dwan has a star on the Hollywood Walk of Fame at 6263 Hollywood Boulevard.Daniel Eagan of Film Journal International described Dwan as one of the early pioneers of cinema, stating that his style "is so basic as to seem invisible, but he treats his characters with uncommon sympathy and compassion."Partial filmography as directorThe Gold Lust (1911)The Picket Guard (1913)The Restless Spirit (1913)Back to Life (1913)Bloodhounds of the North (1913)The Lie (1914)The Honor of the Mounted (1914) The Unwelcome Mrs. Hatch (1914)Remember Mary Magdalen (1914)Discord and Harmony (1914)The Embezzler (1914)The Lamb, the Woman, the Wolf (1914)The End of the Feud (1914)The Test (1914) (*writer)The Tragedy of Whispering Creek (1914)The Unlawful Trade (1914)The Forbidden Room (1914)The Hopes of Blind Alley (1914)Richelieu (1914) Wildflower (1914)A Small Town Girl (1915)David Harum (1915)A Girl of Yesterday (1915)The Pretty Sister of Jose (1915) Jordan Is a Hard Road (1915)Betty of Graystone (1916)The Habit of Happiness (1916)The Good Bad Man (1916)An Innocent Magdalene (1916)The Half-Breed (1916)Manhattan Madness (1916)Accusing Evidence (1916)Panthea (1917)A Modern Musketeer (1917)Bound in Morocco (1918)Headin' South (1918)Mr. Fix-It (1918)He Comes Up Smiling (1918)Cheating Cheaters (1919)The Dark Star (1919)Getting Mary Married (1919)Soldiers of Fortune (1919)In The Heart of a Fool (1920) also producerThe Forbidden Thing (1920) also producerA Splendid Hazard (1920)A Perfect Crime (1921) The Sin of Martha Queed (1921) A Broken Doll (1921)Robin Hood (1922)Zaza (1923)Big Brother (1923)Manhandled (1924)Argentine Love (1924)The Coast of Folly (1925)Night Life of New York (1925)Stage Struck (1925)Gloria Swanson Dialogue (1925) short film made in Phonofilm for The Lambs annual "Gambol" held at Metropolitan Opera HousePadlocked (1926)Sea Horses (1926)Summer Bachelors (1926)Tin Gods (1926)French Dressing (1927)The Joy Girl (1927)East Side, West Side (1927)The Big Noise (1928)Frozen Justice (1929)The Iron Mask (1929)Tide of Empire (1929)The Far Call (1929)What a Widow! (1930)Man to Man (1930)Chances (1931)Wicked (1931)While Paris Sleeps (1932)Counsel's Opinion (1933)Black Sheep (1935)Navy Wife (1935)High Tension (1936)15 Maiden Lane (1936)One Mile from Heaven (1937)Heidi (1937)Rebecca of Sunnybrook Farm (1938)Suez (1938) Josette (1938)The Three Musketeers (1939)The Gorilla (1939)Frontier Marshal (1939)Sailor's Lady (1940)Young People (1940)Trail of the Vigilantes (1940)Look Who's Laughing (1941) also producerRise and Shine (1941)Friendly Enemies (1942)Around the World (1943) also producerUp in Mabel's Room (1944)Abroad with Two Yanks (1944)Getting Gertie's Garter (1945) also screenwriterBrewster's Millions (1945)Rendezvous with Annie (1946)Driftwood (1947)Calendar Girl (1947)Northwest Outpost (1947) also associate producerThe Inside Story (1948)Angel in Exile (1948) (with Philip Ford)Sands of Iwo Jima (1949)Surrender (1950)Belle Le Grand (1951)Wild Blue Yonder (1951)I Dream of Jeanie (1952)Montana Belle (1952)Woman They Almost Lynched (1953) Sweethearts on Parade (1953)Silver Lode (1954)Passion (1954)Cattle Queen of Montana (1954)Tennessee's Partner (1955)Pearl of the South Pacific (1955)Escape to Burma (1955)Slightly Scarlet (1956)Hold Back the Night (1956)The Restless Breed (1957)The River's Edge (1957)Enchanted Island (1958)Most Dangerous Man Alive (1961)See alsoCanadian pioneers in early HollywoodReferencesFurther readingBrownlow, Kevin, The Parade's Gone By... (1968)  Bogdanovich, Peter, Allan Dwan: The Last Pioneer (1971)   Foster, Charles, Stardust and Shadows: Canadians in Early Hollywood (2000) Lombardi, Frederic, Allan Dwan and the Rise and Decline of the Hollywood Studios (2013)Print  E-bookExternal linksAllan Dwan profile, virtual-history.com; accessed June 16, 20141885 births1981 deaths20th-century American male writers20th-century American screenwritersAmerican film directorsAmerican film producersAmerican male screenwritersBurials at San Fernando Mission CemeteryCanadian emigrants to the United StatesFilm directors from TorontoWestern (genre) film directorsWriters from Toronto
Algeria, officially the People's Democratic Republic of Algeria, is a country in the Maghreb region of North Africa. The country is the largest country by total area in Africa and in the Arab world, and is bordered to the northeast by Tunisia; to the east by Libya; to the southeast by Niger; to the southwest by Mali, Mauritania, and Western Sahara; to the west by Morocco; and to the north by the Mediterranean Sea. It has a semi-arid geography, with most of the population living in the fertile north and the Sahara dominating the geography of the south. Algeria covers an area of , making it the world's tenth largest nation by area, and the largest nation in Africa. With a population of 44 million, Algeria is the ninth-most populous country in Africa, and the 32nd-most populous country in the world. The capital and largest city is Algiers, located in the far north on the Mediterranean coast.Pre-1962 Algeria has seen many empires and dynasties, including ancient Numidians, Phoenicians, Carthaginians, Romans, Vandals, Byzantines, Umayyads, Abbasids, Rustamids, Idrisids, Aghlabids, Fatimids, Zirids, Hammadids, Almoravids, Almohads, Zayyanids, Spaniards, Ottomans and finally, the French colonial empire. The vast majority of Algeria's population is Arab-Berber, practicing Islam, and using the official languages of Arabic and Berber. However, French serves as an administrative and educational language in some contexts. The main spoken language is Algerian Arabic.Algeria is a semi-presidential republic, with local constituencies consisting of 58 provinces and 1,541 communes. Algeria is a regional power in North Africa, and a middle power in global affairs. It has the highest Human Development Index of all non-island African countries and one of the largest economies on the continent, based largely on energy exports. Algeria has the world's sixteenth-largest oil reserves and the ninth-largest reserves of natural gas. Sonatrach, the national oil company, is the largest company in Africa, supplying large amounts of natural gas to Europe. Algeria's military is one of the largest in Africa, and has the largest defence budget on the continent. It is a member of the African Union, the Arab League, the OIC, OPEC, the United Nations, and the Arab Maghreb Union, of which it is a founding member.Name Other forms of the name are: , ; ; ; ; . It is officially the People's Democratic Republic of Algeria (; , , ; , abbreviated as RADP).EtymologyThe country's name derives from the city of Algiers which in turn derives from the Arabic  (, "The Islands"), a truncated form of the older  (, "Islands of the Mazghanna Tribe"), employed by medieval geographers such as al-Idrisi.HistoryPrehistory and ancient historyAround ~1.8-million-year-old stone artifacts from Ain Hanech (Algeria) were considered to represent the oldest archaeological materials in North Africa. Stone artifacts and cut-marked bones that were excavated from two nearby deposits at Ain Boucherit are estimated to be ~1.9 million years old, and even older stone artifacts to be as old as ~2.4 million years. Hence, the Ain Boucherit evidence shows that ancestral hominins inhabited the Mediterranean fringe in northern Africa much earlier than previously thought. The evidence strongly argues for early dispersal of stone tool manufacture and use from East Africa or a possible multiple-origin scenario of stone technology in both East and North Africa.Neanderthal tool makers produced hand axes in the Levalloisian and Mousterian styles (43,000 BC) similar to those in the Levant. Algeria was the site of the highest state of development of Middle Paleolithic Flake tool techniques. Tools of this era, starting about 30,000 BC, are called Aterian (after the archaeological site of Bir el Ater, south of Tebessa).The earliest blade industries in North Africa are called Iberomaurusian (located mainly in the Oran region). This industry appears to have spread throughout the coastal regions of the Maghreb between 15,000 and 10,000 BC. Neolithic civilization (animal domestication and agriculture) developed in the Saharan and Mediterranean Maghreb perhaps as early as 11,000 BC or as late as between 6000 and 2000 BC. This life, richly depicted in the Tassili n'Ajjer paintings, predominated in Algeria until the classical period. The mixture of peoples of North Africa coalesced eventually into a distinct native population that came to be called Berbers, who are the indigenous peoples of northern Africa.From their principal center of power at Carthage, the Carthaginians expanded and established small settlements along the North African coast; by 600 BC, a Phoenician presence existed at Tipasa, east of Cherchell, Hippo Regius (modern Annaba) and Rusicade (modern Skikda). These settlements served as market towns as well as anchorages.As Carthaginian power grew, its impact on the indigenous population increased dramatically. Berber civilisation was already at a stage in which agriculture, manufacturing, trade, and political organisation supported several states. Trade links between Carthage and the Berbers in the interior grew, but territorial expansion also resulted in the enslavement or military recruitment of some Berbers and in the extraction of tribute from others.By the early 4th century BC, Berbers formed the single largest element of the Carthaginian army. In the Revolt of the Mercenaries, Berber soldiers rebelled from 241 to 238 BC after being unpaid following the defeat of Carthage in the First Punic War. They succeeded in obtaining control of much of Carthage's North African territory, and they minted coins bearing the name Libyan, used in Greek to describe natives of North Africa. The Carthaginian state declined because of successive defeats by the Romans in the Punic Wars.In 146 BC the city of Carthage was destroyed. As Carthaginian power waned, the influence of Berber leaders in the hinterland grew. By the 2nd century BC, several large but loosely administered Berber kingdoms had emerged. Two of them were established in Numidia, behind the coastal areas controlled by Carthage. West of Numidia lay Mauretania, which extended across the Moulouya River in modern-day Morocco to the Atlantic Ocean. The high point of Berber civilisation, unequalled until the coming of the Almohads and Almoravids more than a millennium later, was reached during the reign of Masinissa in the 2nd century BC.After Masinissa's death in 148 BC, the Berber kingdoms were divided and reunited several times. Masinissa's line survived until 24 AD, when the remaining Berber territory was annexed to the Roman Empire.For several centuries Algeria was ruled by the Romans, who founded many colonies in the region. Like the rest of North Africa, Algeria was one of the breadbaskets of the empire, exporting cereals and other agricultural products. Saint Augustine was the bishop of Hippo Regius (modern-day Annaba, Algeria), located in the Roman province of Africa. The Germanic Vandals of Geiseric moved into North Africa in 429, and by 435 controlled coastal Numidia. They did not make any significant settlement on the land, as they were harassed by local tribes. In fact, by the time the Byzantines arrived Leptis Magna was abandoned and the Msellata region was occupied by the indigenous Laguatan who had been busy facilitating an Amazigh political, military and cultural revival. Furthermore, during the rule of the Romans, Byzantines, Vandals, Carthaginians, and Ottomans the Berber people were the only or one of the few in North Africa who remained independent. The Berber people were so resistant that even during the Muslim conquest of North Africa they still had control and possession over their mountains.The collapse of the Western Roman Empire led to the establishment of a native Kingdom based in Altava (modern day Algeria) known as the Mauro-Roman Kingdom. It was succeeded by another Kingdom based in Altava, the Kingdom of Altava. During the reign of Kusaila its territory extended from the region of modern-day Fez in the west to the western Aurès and later Kairaouan and the interior of Ifriqiya in the east.Middle AgesAfter negligible resistance from the locals, Muslim Arabs of the Umayyad Caliphate conquered Algeria in the early 8th century.  Large numbers of the indigenous Berber people converted to Islam. Christians, Berber and Latin speakers remained in the great majority in Tunisia until the end of the 9th century and Muslims only became a vast majority some time in the 10th. After the fall of the Umayyad Caliphate, numerous local dynasties emerged, including the Rustamids, Aghlabids, Fatimids, Zirids, Hammadids, Almoravids, Almohads and the Abdalwadid. The Christians left in three waves: after the initial conquest, in the 10th century and the 11th. The last were evacuated to Sicily by the Normans and the few remaining died out in the 14th century.During the Middle Ages, North Africa was home to many great scholars, saints and sovereigns including Judah Ibn Quraysh, the first grammarian to mention Semitic and Berber languages, the great Sufi masters Sidi Boumediene (Abu Madyan) and Sidi El Houari, and the Emirs Abd Al Mu'min and Yāghmūrasen. It was during this time that the Fatimids or children of Fatima, daughter of Muhammad, came to the Maghreb. These "Fatimids" went on to found a long lasting dynasty stretching across the Maghreb, Hejaz and the Levant, boasting a secular inner government, as well as a powerful army and navy, made up primarily of Arabs and Levantines extending from Algeria to their capital state of Cairo. The Fatimid caliphate began to collapse when its governors the Zirids seceded. In order to punish them the Fatimids sent the Arab Banu Hilal and Banu Sulaym against them. The resultant war is recounted in the epic Tāghribāt. In Al-Tāghrībāt the Amazigh Zirid Hero Khālīfā Al-Zānatī asks daily, for duels, to defeat the Hilalan hero Ābu Zayd al-Hilalī and many other Arab knights in a string of victories. The Zirids, however, were ultimately defeated ushering in an adoption of Arab customs and culture. The indigenous Amazigh tribes, however, remained largely independent, and depending on tribe, location and time controlled varying parts of the Maghreb, at times unifying it (as under the Fatimids). The Fatimid Islamic state, also known as Fatimid Caliphate made an Islamic empire that included North Africa, Sicily, Palestine, Jordan, Lebanon, Syria, Egypt, the Red Sea coast of Africa, Tihamah, Hejaz and Yemen. Caliphates from Northern Africa traded with the other empires of their time, as well as forming part of a confederated support and trade network with other Islamic states during the Islamic Era.The Amazighs historically consisted of several tribes. The two main branches were the Botr and Barnès tribes, who were divided into tribes, and again into sub-tribes. Each region of the Maghreb contained several tribes (for example, Sanhadja, Houara, Zenata, Masmouda, Kutama, Awarba, and Berghwata). All these tribes made independent territorial decisions.Several Amazigh dynasties emerged during the Middle Ages in the Maghreb and other nearby lands. Ibn Khaldun provides a table summarising the Amazigh dynasties of the Maghreb region, the Zirid, Ifranid, Maghrawa, Almoravid, Hammadid, Almohad, Merinid, Abdalwadid, Wattasid, Meknassa and Hafsid dynasties. Both of the Hammadid and Zirid empires as well as the Fatimids established their rule in all of the Maghreb countries. The Zirids ruled land in what is now Algeria, Tunisia, Morocco, Libya, Spain, Malta and Italy. The Hammadids captured and held important regions such as Ouargla, Constantine, Sfax, Susa, Algiers, Tripoli and Fez establishing their rule in every country in the Maghreb region. The Fatimids which was created and established by the Kutama Berbers  conquered all of North Africa as well as Sicily and parts of the Middle East.A few examples of medieval Berber dynasties which originated in Modern Algeria  Ifranid Dynasty Maghrawa Dynasty Zirid dynasty Hammadid dynasty Fatimid Caliphate  Kingdom of TlemcenFollowing the Berber revolt numerous independent states emerged across the Maghreb. In Algeria the Rustamid Kingdom was established. The Rustamid realm stretched from Tafilalt in Morocco to the Nafusa mountains in Libya including south, central and western Tunisia therefore including territory in all of the modern day Maghreb countries, in the south the Rustamid realm expanded to the modern borders of Mali and included territory in Mauritania.Once extending their control over all of the Maghreb, part of Spain and briefly over Sicily, originating from modern Algeria, the Zirids only controlled modern Ifriqiya by the 11th century. The Zirids recognized nominal suzerainty of the Fatimid caliphs of Cairo. El Mu'izz the Zirid ruler decided to end this recognition and declared his independence. The Zirids also fought against other Zenata Kingdoms, for example the Maghrawa, a Berber dynasty originating from Algeria and which at one point was a dominant power in the Maghreb ruling over much of Morocco and western Algeria including Fez, Sijilmasa, Aghmat, Oujda, most of the Sous and Draa and reaching as far as M’sila and the Zab in Algeria.As the Fatimid state was at the time too weak to attempt a direct invasion, they found another means of revenge. Between the Nile and the Red Sea were living Bedouin nomad tribes expelled from Arabia for their disruption and turbulency. The Banu Hilal and the Banu Sulaym for example, who regularly disrupted farmers in the Nile Valley since the nomads would often loot their farms. The then Fatimid vizier decided to destroy what he couldn't control, and broke a deal with the chiefs of these Beduouin tribes. The Fatimids even gave them money to leave.Whole tribes set off with women, children, elders, animals and camping equipment. Some stopped on the way, especially in Cyrenaica, where they are still one of the essential elements of the settlement but most arrived in Ifriqiya by the Gabes region, arriving 1051. The Zirid ruler tried to stop this rising tide, but with each encounter, the last under the walls of Kairouan, his troops were defeated and the Arabs remained masters of the battlefield. They Arabs usually didn't take control over the cities, instead looting them and destroying them.The invasion kept going, and in 1057 the Arabs spread on the high plains of Constantine where they encircled the Qalaa of Banu Hammad (capital of the Hammadid Emirate), as they had done in Kairouan a few decades ago. From there they gradually gained the upper Algiers and Oran plains. Some of these territories were forcibly taken back by the Almohads in the second half of the 12th century. The influx of Bedouin tribes was a major factor in the linguistic, cultural Arabization of the Maghreb and in the spread of nomadism in areas where agriculture had previously been dominant. Ibn Khaldun noted that the lands ravaged by Banu Hilal tribes had become completely arid desert.The Almohads originating from modern day Morocco, although founded by a man originating from Algeria known as Abd al-Mu'min would soon take control over the Maghreb. During the time of the Almohad Dynasty Abd al-Mu'min's tribe, the Koumïa, were the main supporters of the throne and the most important body of the empire. Defeating the weakening Almoravid Empire and taking control over Morocco in 1147, they pushed into Algeria in 1152, taking control over Tlemcen, Oran, and Algiers, wrestling control from the Hilian Arabs, and by the same year they defeated Hammadids who controlled Eastern Algeria.Following their decisive defeat in the Battle of Las Navas de Tolosa in 1212 the Almohads began collapsing, and in 1235 the governor of modern-day Western Algeria, Yaghmurasen Ibn Zyan declared his independence and established the Kingdom of Tlemcen and the Zayyanid dynasty. Warring with the Almohad forces attempting to restore control over Algeria for 13 years, they defeated the Almohads in 1248 after killing their Caliph in a successful ambush near Oujda. The Zayyanids retained their control over Algeria for 3 centuries. Much of the eastern territories of Algeria were under the authority of the Hafsid dynasty, although the Emirate of Bejaia encompassing the Algerian territories of the Hafsids would occasionally be independent from central Tunisian control. At their peak the Zayyanid kingdom included all of Morocco as its vassal to the west and in the east reached as far as Tunis which they captured during the reign of Abu Tashfin.After several conflicts with local Barbary pirates sponsored by the Zayyanid sultans, Spain decided to invade Algeria and defeat the native Kingdom of Tlemcen. In 1505, they invaded and captured Mers el Kébir, and in 1509 after a bloody siege, they conquered Oran. Following their decisive victories over the Algerians in the western-coastal areas of Algeria, the Spanish decided to get bolder, and invaded more Algerian cities. In 1510, they led a series of sieges and attacks, taking over Bejaia in a large siege, and leading a semi-successful siege against Algiers. They also besieged Tlemcen. In 1511, they took control over Cherchell and Jijel, and attacked Mostaganem where although they weren't able to conquer the city, they were able to force a tribute on them.Ottoman era In 1516, the Ottoman privateer brothers Aruj and Hayreddin Barbarossa, who operated successfully under the Hafsids, moved their base of operations to Algiers. They succeeded in conquering Jijel and Algiers from the Spaniards with help from the locals who saw them as liberators from the Christians, but the brothers eventually assassinated the local noble Salim al-Tumi and took control over the city and the surrounding regions. When Aruj was killed in 1518 during his invasion of Tlemcen, Hayreddin succeeded him as military commander of Algiers. The Ottoman sultan gave him the title of beylerbey and a contingent of some 2,000 janissaries. With the aid of this force and native Algerians, Hayreddin conquered the whole area between Constantine and Oran (although the city of Oran remained in Spanish hands until 1792).The next beylerbey was Hayreddin's son Hasan, who assumed the position in 1544. He was a Kouloughli or of mixed origins, as his mother was an Algerian Mooresse. Until 1587 Beylerbeylik of Algiers was governed by Beylerbeys who served terms with no fixed limits. Subsequently, with the institution of a regular administration, governors with the title of pasha ruled for three-year terms. The pasha was assisted by an autonomous janissary unit, known in Algeria as the Ojaq who were led by an agha. Discontent among the ojaq rose in the mid-1600s because they were not paid regularly, and they repeatedly revolted against the pasha. As a result, the agha charged the pasha with corruption and incompetence and seized power in 1659.Plague had repeatedly struck the cities of North Africa. Algiers lost from 30,000 to 50,000 inhabitants to the plague in 1620–21, and suffered high fatalities in 1654–57, 1665, 1691 and 1740–42.The Barbary pirates preyed on Christian and other non-Islamic shipping in the western Mediterranean Sea. The pirates often took the passengers and crew on the ships and sold them or used them as slaves. They also did a brisk business in ransoming some of the captives. According to Robert Davis, from the 16th to 19th century, pirates captured 1 million to 1.25 million Europeans as slaves. They often made raids, called Razzias, on European coastal towns to capture Christian slaves to sell at slave markets in North Africa and other parts of the Ottoman Empire. In 1544, for example, Hayreddin Barbarossa captured the island of Ischia, taking 4,000 prisoners, and enslaved some 9,000 inhabitants of Lipari, almost the entire population. In 1551, the Ottoman governor of Algiers, Turgut Reis, enslaved the entire population of the Maltese island of Gozo. Barbary pirates often attacked the Balearic Islands. The threat was so severe that residents abandoned the island of Formentera. The introduction of broad-sail ships from the beginning of the 17th century allowed them to branch out into the Atlantic.In July 1627 two pirate ships from Algiers under the command of Dutch pirate Jan Janszoon sailed as far as Iceland, raiding and capturing slaves. Two weeks earlier another pirate ship from Salé in Morocco had also raided in Iceland. Some of the slaves brought to Algiers were later ransomed back to Iceland, but some chose to stay in Algeria. In 1629, pirate ships from Algeria raided the Faroe Islands.In 1671, the taifa of raises, or the company of corsair captains rebelled, killed the agha, and placed one of its own in power. The new leader received the title of Dey. After 1689, the right to select the dey passed to the divan, a council of some sixty nobles. It was at first dominated by the ojaq; but by the 18th century, it had become the dey's instrument. In 1710, the dey persuaded the sultan to recognise him and his successors as regent, replacing the pasha in that role. Although Algiers remained nominally part of the Ottoman Empire, in reality they acted independently from the rest of the Empire, and often had wars with other Ottoman subjects and territories such as the Beylik of Tunis.The dey was in effect a constitutional autocrat. The dey was elected for a life term, but in the 159 years (1671–1830) that the system was in place, fourteen of the twenty-nine deys were assassinated. Despite usurpation, military coups and occasional mob rule, the day-to-day operation of the Deylikal government was remarkably orderly. Although the regency patronised the tribal chieftains, it never had the unanimous allegiance of the countryside, where heavy taxation frequently provoked unrest. Autonomous tribal states were tolerated, and the regency's authority was seldom applied in the Kabylia, although in 1730 the Regency was able to take control over the Kingdom of Kuku in western Kabylia. Many cities in the northern parts of the Algerian desert paid taxes to Algiers or one of its Beys, although they otherwise retained complete autonomy from central control, while the deeper parts of the Sahara were completely independent from Algiers.Barbary raids in the Mediterranean continued to attack Spanish merchant shipping, and as a result, the Spanish Navy bombarded Algiers in 1783 and 1784. For the attack in 1784, the Spanish fleet was to be joined by ships from such traditional enemies of Algiers as Naples, Portugal and the Knights of Malta. Over 20,000 cannonballs were fired, much of the city and its fortifications were destroyed and most of the Algerian fleet was sunk.In 1792, Algiers took back Oran and Mers el Kébir, the two last Spanish strongholds in Algeria. In the same year, they conquered the Moroccan Rif and Oujda, which they then abandoned in 1795.In the 19th century, Algerian pirates forged affiliations with Caribbean powers, paying a "licence tax" in exchange for safe harbour of their vessels.Attacks by Algerian pirates on American merchantmen resulted in the First and Second Barbary Wars, which ended the attacks on U.S. ships. A year later, a combined Anglo-Dutch fleet, under the command of Lord Exmouth bombarded Algiers to stop similar attacks on European fishermen. These efforts proved successful, although Algerian piracy would continue until the French conquest in 1830.French colonization (1830–1962) Under the pretext of a slight to their consul, the French invaded and captured Algiers in 1830. Historian Ben Kiernan wrote on the French conquest of Algeria: "By 1875, the French conquest was complete. The war had killed approximately 825,000 indigenous Algerians since 1830." French losses from 1831 to 1851 were 92,329 dead in the hospital and only 3,336 killed in action. The population of Algeria, which stood at about 2.9 million in 1872, reached nearly 11 million in 1960. French policy was predicated on "civilising" the country. The slave trade and piracy in Algeria ceased following the French conquest. The conquest of Algeria by the French took some time and resulted in considerable bloodshed. A combination of violence and disease epidemics caused the indigenous Algerian population to decline by nearly one-third from 1830 to 1872. On 17 September 1860, Napoleon III declared "Our first duty is to take care of the happiness of the three million Arabs, whom the fate of arms has brought under our domination."During this time, only Kabylia resisted, the Kabylians were not colonized until after the Mokrani Revolt in 1871. From 1848 until independence, France administered the whole Mediterranean region of Algeria as an integral part and département of the nation. One of France's longest-held overseas territories, Algeria became a destination for hundreds of thousands of European immigrants, who became known as colons and later, as Pied-Noirs. Between 1825 and 1847, 50,000 French people emigrated to Algeria. These settlers benefited from the French government's confiscation of communal land from tribal peoples, and the application of modern agricultural techniques that increased the amount of arable land. Many Europeans settled in Oran and Algiers, and by the early 20th century they formed a majority of the population in both cities.During the late 19th and early 20th century, the European share was almost a fifth of the population. The French government aimed at making Algeria an assimilated part of France, and this included substantial educational investments especially after 1900. The indigenous cultural and religious resistance heavily opposed this tendency, but in contrast to the other colonised countries' path in central Asia and Caucasus, Algeria kept its individual skills and a relatively human-capital intensive agriculture.During the Second World War, Algeria came under Vichy control before being liberated by the Allies in Operation Torch, which saw the first large-scale deployment of American troops in the North African campaign.Gradually, dissatisfaction among the Muslim population, which lacked political and economic status under the colonial system, gave rise to demands for greater political autonomy and eventually independence from France. In May 1945, the uprising against the occupying French forces was suppressed through what is now known as the Sétif and Guelma massacre. Tensions between the two population groups came to a head in 1954, when the first violent events of what was later called the Algerian War began after the publication of the Declaration of 1 November 1954. Historians have estimated that between 30,000 and 150,000 Harkis and their dependants were killed by the Front de Libération Nationale (FLN) or by lynch mobs in Algeria. The FLN used hit and run attacks in Algeria and France as part of its war, and the French conducted severe reprisals.The war led to the death of hundreds of thousands of Algerians and hundreds of thousands of injuries. Historians, like Alistair Horne and Raymond Aron, state that the actual number of Algerian Muslim war dead was far greater than the original FLN and official French estimates but was less than the 1 million deaths claimed by the Algerian government after independence. Horne estimated Algerian casualties during the span of eight years to be around 700,000. The war uprooted more than 2 million Algerians.The war against French rule concluded in 1962, when Algeria gained complete independence following the March 1962 Evian agreements and the July 1962 self-determination referendum.The first three decades of independence (1962–1991)The number of European Pied-Noirs who fled Algeria totaled more than 900,000 between 1962 and 1964. The exodus to mainland France accelerated after the Oran massacre of 1962, in which hundreds of militants entered European sections of the city, and began attacking civilians.Algeria's first president was the Front de Libération Nationale (FLN) leader Ahmed Ben Bella. Morocco's claim to portions of western Algeria led to the Sand War in 1963. Ben Bella was overthrown in 1965 by Houari Boumédiène, his former ally and defence minister. Under Ben Bella, the government had become increasingly socialist and authoritarian; Boumédienne continued this trend. But, he relied much more on the army for his support, and reduced the sole legal party to a symbolic role. He collectivised agriculture and launched a massive industrialisation drive. Oil extraction facilities were nationalised. This was especially beneficial to the leadership after the international 1973 oil crisis.In the 1960s and 1970s under President Houari Boumediene, Algeria pursued a program of industrialisation within a state-controlled socialist economy. Boumediene's successor, Chadli Bendjedid, introduced some liberal economic reforms. He promoted a policy of Arabisation in Algerian society and public life. Teachers of Arabic, brought in from other Muslim countries, spread conventional Islamic thought in schools and sowed the seeds of a return to Orthodox Islam.The Algerian economy became increasingly dependent on oil, leading to hardship when the price collapsed during the 1980s oil glut. Economic recession caused by the crash in world oil prices resulted in Algerian social unrest during the 1980s; by the end of the decade, Bendjedid introduced a multi-party system. Political parties developed, such as the Islamic Salvation Front (FIS), a broad coalition of Muslim groups.Civil War (1991–2002) and aftermathIn December 1991 the Islamic Salvation Front dominated the first of two rounds of legislative elections. Fearing the election of an Islamist government, the authorities intervened on 11 January 1992, cancelling the elections. Bendjedid resigned and a High Council of State was installed to act as the Presidency. It banned the FIS, triggering a civil insurgency between the Front's armed wing, the Armed Islamic Group, and the national armed forces, in which more than 100,000 people are thought to have died. The Islamist militants conducted a violent campaign of civilian massacres. At several points in the conflict, the situation in Algeria became a point of international concern, most notably during the crisis surrounding Air France Flight 8969, a hijacking perpetrated by the Armed Islamic Group. The Armed Islamic Group declared a ceasefire in October 1997.Algeria held elections in 1999, considered biased by international observers and most opposition groups which were won by President Abdelaziz Bouteflika. He worked to restore political stability to the country and announced a "Civil Concord" initiative, approved in a referendum, under which many political prisoners were pardoned, and several thousand members of armed groups were granted exemption from prosecution under a limited amnesty, in force until 13 January 2000. The AIS disbanded and levels of insurgent violence fell rapidly. The Groupe Salafiste pour la Prédication et le Combat (GSPC), a splinter group of the Armed Islamic Group, continued a terrorist campaign against the Government.Bouteflika was re-elected in the April 2004 presidential election after campaigning on a programme of national reconciliation. The programme comprised economic, institutional, political and social reform to modernise the country, raise living standards, and tackle the causes of alienation. It also included a second amnesty initiative, the Charter for Peace and National Reconciliation, which was approved in a referendum in September 2005. It offered amnesty to most guerrillas and Government security forces.In November 2008, the Algerian Constitution was amended following a vote in Parliament, removing the two-term limit on Presidential incumbents. This change enabled Bouteflika to stand for re-election in the 2009 presidential elections, and he was re-elected in April 2009. During his election campaign and following his re-election, Bouteflika promised to extend the programme of national reconciliation and a $150-billion spending programme to create three million new jobs, the construction of one million new housing units, and to continue public sector and infrastructure modernisation programmes.A continuing series of protests throughout the country started on 28 December 2010, inspired by similar protests across the Middle East and North Africa. On 24 February 2011, the government lifted Algeria's 19-year-old state of emergency. The government enacted legislation dealing with political parties, the electoral code, and the representation of women in elected bodies. In April 2011, Bouteflika promised further constitutional and political reform. However, elections are routinely criticised by opposition groups as unfair and international human rights groups say that media censorship and harassment of political opponents continue.On 2 April 2019, Bouteflika resigned from the presidency after mass protests against his candidacy for a fifth term in office.In December 2019, Abdelmadjid Tebboune became Algeria's president, after winning the first round of the presidential election with a record abstention rate – the highest of all presidential elections since Algeria's democracy in 1989. Tebboune is close to the military and he is also accused of being loyal to the deposed president.Geography Since the 2011 breakup of Sudan, and the creation of South Sudan, Algeria has been the largest country in Africa, and the Mediterranean Basin. Its southern part includes a significant portion of the Sahara. To the north, the Tell Atlas form with the Saharan Atlas, further south, two parallel sets of reliefs in approaching eastbound, and between which are inserted vast plains and highlands. Both Atlas tend to merge in eastern Algeria. The vast mountain ranges of Aures and Nememcha occupy the entire northeastern Algeria and are delineated by the Tunisian border. The highest point is Mount Tahat ().Algeria lies mostly between latitudes 19° and 37°N (a small area is north of 37°N and south of 19°N), and longitudes 9°W and 12°E. Most of the coastal area is hilly, sometimes even mountainous, and there are a few natural harbours. The area from the coast to the Tell Atlas is fertile. South of the Tell Atlas is a steppe landscape ending with the Saharan Atlas; farther south, there is the Sahara desert.The Hoggar Mountains (), also known as the Hoggar, are a highland region in central Sahara, southern Algeria. They are located about  south of the capital, Algiers, and just east of Tamanghasset. Algiers, Oran, Constantine, and Annaba are Algeria's main cities.Climate and hydrology In this region, midday desert temperatures can be hot year round. After sunset, however, the clear, dry air permits rapid loss of heat, and the nights are cool to chilly. Enormous daily ranges in temperature are recorded.Rainfall is fairly plentiful along the coastal part of the Tell Atlas, ranging from  annually, the amount of precipitation increasing from west to east. Precipitation is heaviest in the northern part of eastern Algeria, where it reaches as much as  in some years.Farther inland, the rainfall is less plentiful. Algeria also has ergs, or sand dunes, between mountains. Among these, in the summer time when winds are heavy and gusty, temperatures can go up to .Fauna and flora The varied vegetation of Algeria includes coastal, mountainous and grassy desert-like regions which all support a wide range of wildlife. Many of the creatures comprising the Algerian wildlife live in close proximity to civilisation. The most commonly seen animals include the wild boars, jackals, and gazelles, although it is not uncommon to spot fennecs (foxes), and jerboas. Algeria also has a small African leopard and Saharan cheetah population, but these are seldom seen. A species of deer, the Barbary stag, inhabits the dense humid forests in the north-eastern areas. The fennec fox is the national animal of Algeria.A variety of bird species makes the country an attraction for bird watchers. The forests are inhabited by boars and jackals. Barbary macaques are the sole native monkey. Snakes, monitor lizards, and numerous other reptiles can be found living among an array of rodents throughout the semi arid regions of Algeria. Many animals are now extinct, including the Barbary lions, Atlas bears and crocodiles.In the north, some of the native flora includes Macchia scrub, olive trees, oaks, cedars and other conifers. The mountain regions contain large forests of evergreens (Aleppo pine, juniper, and evergreen oak) and some deciduous trees. Fig, eucalyptus, agave, and various palm trees grow in the warmer areas. The grape vine is indigenous to the coast. In the Sahara region, some oases have palm trees. Acacias with wild olives are the predominant flora in the remainder of the Sahara. Algeria had a 2018 Forest Landscape Integrity Index mean score of 5.22/10, ranking it 106th globally out of 172 countries.Camels are used extensively; the desert also abounds with venomous and nonvenomous snakes, scorpions, and numerous insects.Government and politics Elected politicians have relatively little sway over Algeria. Instead, a group of unelected civilian and military "décideurs" ("deciders"), known as "le pouvoir" ("the power"), actually rule the country, even deciding who should be president. The most powerful man might have been Mohamed Mediène, the head of military intelligence, before he was brought down during the 2019 protests. In recent years, many of these generals have died, retired, or been imprisoned. After the death of General Larbi Belkheir, previous president Bouteflika put loyalists in key posts, notably at Sonatrach, and secured constitutional amendments that made him re-electable indefinitely, until he was brought down in 2019 during protests.The head of state is the President of Algeria, who is elected for a five-year term. The president was formerly limited to two five-year terms, but a constitutional amendment passed by the Parliament on 11 November 2008 removed this limitation. The most recent presidential election was planned to be in April 2019, but widespread protests erupted on 22 February against the president's decision to participate in the election, which resulted in President Bouteflika announcing his resignation on 3 April. Abdelmadjid Tebboune, an independent candidate, was elected as president after the election eventually took place on 12 December 2019. Protestors refused to recognise Tebboune as president, citing demands for comprehensive reform of the political system. Algeria has universal suffrage at 18 years of age. The President is the head of the army, the Council of Ministers and the High Security Council. He appoints the Prime Minister who is also the head of government.The Algerian parliament is bicameral; the lower house, the People's National Assembly, has 462 members who are directly elected for five-year terms, while the upper house, the Council of the Nation, has 144 members serving six-year terms, of which 96 members are chosen by local assemblies and 48 are appointed by the president. According to the constitution, no political association may be formed if it is "based on differences in religion, language, race, gender, profession, or region". In addition, political campaigns must be exempt from the aforementioned subjects.Parliamentary elections were last held in May 2017. In the elections, the FLN lost 44 of its seats, but remained the largest party with 164 seats, the military-backed National Rally for Democracy won 100, and the Muslim Brotherhood-linked Movement of the Society for Peace won 33.Foreign relationsAlgeria is included in the European Union's European Neighbourhood Policy (ENP) which aims at bringing the EU and its neighbours closer.Giving incentives and rewarding best performers, as well as offering funds in a faster and more flexible manner, are the two main principles underlying the European Neighbourhood Instrument (ENI) that came into force in 2014. It has a budget of €15.4 billion and provides the bulk of funding through a number of programmes.In 2009, the French government agreed to compensate victims of nuclear tests in Algeria. Defence Minister Herve Morin stated that "It's time for our country to be at peace with itself, at peace thanks to a system of compensation and reparations," when presenting the draft law on the payouts. Algerian officials and activists believe that this is a good first step and hope that this move would encourage broader reparation.Tensions between Algeria and Morocco in relation to the Western Sahara have been an obstacle to tightening the Arab Maghreb Union, nominally established in 1989, but which has carried little practical weight. On 24 August 2021, Algeria announced the break of diplomatic relations with Morocco.MilitaryThe military of Algeria consists of the People's National Army (ANP), the Algerian National Navy (MRA), and the Algerian Air Force (QJJ), plus the Territorial Air Defence Forces. It is the direct successor of the National Liberation Army (Armée de Libération Nationale or ALN), the armed wing of the nationalist National Liberation Front which fought French colonial occupation during the Algerian War of Independence (1954–62).Total military personnel include 147,000 active, 150,000 reserve, and 187,000 paramilitary staff (2008 estimate). Service in the military is compulsory for men aged 19–30, for a total of 12 months. The military expenditure was 4.3% of the gross domestic product (GDP) in 2012. Algeria has the second largest military in North Africa with the largest defence budget in Africa ($10 billion). Most of Algeria's weapons are imported from Russia, with whom they are a close ally.In 2007, the Algerian Air Force signed a deal with Russia to purchase 49 MiG-29SMT and 6 MiG-29UBT at an estimated cost of $1.9 billion. Russia is also building two 636-type diesel submarines for Algeria.Human rightsAlgeria has been categorised by Freedom House as "not free" since it began publishing such ratings in 1972, with the exception of 1989, 1990, and 1991, when the country was labelled "partly free." In December 2016, the Euro-Mediterranean Human Rights Monitor issued a report regarding violation of media freedom in Algeria. It clarified that the Algerian government imposed restriction on freedom of the press; expression; and right to peaceful demonstration, protest and assembly as well as intensified censorship of the media and websites. Due to the fact that the journalists and activists criticise the ruling government, some media organisations' licenses are cancelled.Independent and autonomous trade unions face routine harassment from the government, with many leaders imprisoned and protests suppressed. In 2016, a number of unions, many of which were involved in the 2010–2012 Algerian Protests, have been deregistered by the government.Homosexuality is illegal in Algeria. Public homosexual behavior is punishable by up to two years in prison. Despite this, about 26% of Algerians think that homosexuality should be accepted, according to the survey conducted by the BBC News Arabic-Arab Barometer in 2019. Algeria showed largest LGBT acceptance compared to other Arab countries where the survey was conducted.Human Rights Watch has accused the Algerian authorities of using the COVID-19 pandemic as an excuse to prevent pro-democracy movements and protests in the country, leading to the arrest of youths as part of social distancing.Administrative divisionsAlgeria is divided into 58 provinces (wilayas), 553 districts (daïras) and 1,541 municipalities (baladiyahs). Each province, district, and municipality is named after its seat, which is usually the largest city.The administrative divisions have changed several times since independence. When introducing new provinces, the numbers of old provinces are kept, hence the non-alphabetical order. With their official numbers, currently (since 1983) they areEconomyAlgeria's currency is the dinar (DZD). The economy remains dominated by the state, a legacy of the country's socialist post-independence development model. In recent years, the Algerian government has halted the privatization of state-owned industries and imposed restrictions on imports and foreign involvement in its economy. These restrictions are just starting to be lifted off recently although questions about Algeria's slowly-diversifying economy remain.Algeria has struggled to develop industries outside hydrocarbons in part because of high costs and an inert state bureaucracy. The government's efforts to diversify the economy by attracting foreign and domestic investment outside the energy sector have done little to reduce high youth unemployment rates or to address housing shortages. The country is facing a number of short-term and medium-term problems, including the need to diversify the economy, strengthen political, economic and financial reforms, improve the business climate and reduce inequalities amongst regions.A wave of economic protests in February and March 2011 prompted the Algerian government to offer more than $23 billion in public grants and retroactive salary and benefit increases. Public spending has increased by 27% annually during the past 5 years. The 2010–14 public-investment programme will cost US$286 billion, 40% of which will go to human development.Thanks to strong hydrocarbon revenues, Algeria has a cushion of $173 billion in foreign currency reserves and a large hydrocarbon stabilisation fund. In addition, Algeria's external debt is extremely low at about 2% of GDP. The economy remains very dependent on hydrocarbon wealth, and, despite high foreign exchange reserves (US$178 billion, equivalent to three years of imports), current expenditure growth makes Algeria's budget more vulnerable to the risk of prolonged lower hydrocarbon revenues.Algeria has not joined the WTO, despite several years of negotiations but is a member of the Greater Arab Free Trade Area and the African Continental Free Trade Area, and has an association agreement with the European UnionOil and natural resourcesAlgeria, whose economy is reliant on petroleum, has been an OPEC member since 1969. Its crude oil production stands at around 1.1 million barrels/day, but it is also a major gas producer and exporter, with important links to Europe. Hydrocarbons have long been the backbone of the economy, accounting for roughly 60% of budget revenues, 30% of GDP, and 87.7% of export earnings. Algeria has the 10th-largest reserves of natural gas in the world and is the sixth-largest gas exporter. The U.S. Energy Information Administration reported that in 2005, Algeria had  of proven natural-gas reserves. It also ranks 16th in oil reserves.Non-hydrocarbon growth for 2011 was projected at 5%. To cope with social demands, the authorities raised expenditure, especially on basic food support, employment creation, support for SMEs, and higher salaries. High hydrocarbon prices have improved the current account and the already large international reserves position.Income from oil and gas rose in 2011 as a result of continuing high oil prices, though the trend in production volume is downwards. Production from the oil and gas sector in terms of volume, continues to decline, dropping from 43.2 million tonnes to 32 million tonnes between 2007 and 2011. Nevertheless, the sector accounted for 98% of the total volume of exports in 2011, against 48% in 1962, and 70% of budgetary receipts, or US$71.4 billion.The Algerian national oil company is Sonatrach, which plays a key role in all aspects of the oil and natural gas sectors in Algeria. All foreign operators must work in partnership with Sonatrach, which usually has majority ownership in production-sharing agreements.Access to biocapacity in Algeria is lower than world average. In 2016, Algeria had 0.53 global hectares of biocapacity per person within its territory, much less than the world average of 1.6 global hectares per person. In 2016, Algeria used 2.4 global hectares of biocapacity per person – their ecological footprint of consumption. This means they use just under 4.5 times as much biocapacity as Algeria contains. As a result, Algeria is running a biocapacity deficit.Research and alternative energy sourcesAlgeria has invested an estimated 100 billion dinars towards developing research facilities and paying researchers. This development program is meant to advance alternative energy production, especially solar and wind power. Algeria is estimated to have the largest solar energy potential in the Mediterranean, so the government has funded the creation of a solar science park in Hassi R'Mel. Currently, Algeria has 20,000 research professors at various universities and over 780 research labs, with state-set goals to expand to 1,000. Besides solar energy, areas of research in Algeria include space and satellite telecommunications, nuclear power and medical research.Labour marketThe overall rate of unemployment was 10% in 2011, but remained higher among young people, with a rate of 21.5% for those aged between 15 and 24. The government strengthened in 2011 the job programs introduced in 1988, in particular in the framework of the program to aid those seeking work (Dispositif d'Aide à l'Insertion Professionnelle).Despite a decline in total unemployment, youth and women unemployment is high. Unemployment particularly affects the young, with a jobless rate of 21.5% among the 15–24 age group.TourismThe development of the tourism sector in Algeria had previously been hampered by a lack of facilities, but since 2004 a broad tourism development strategy has been implemented resulting in many hotels of a high modern standard being built.There are several UNESCO World Heritage Sites in Algeria including Al Qal'a of Beni Hammad, the first capital of the Hammadid empire; Tipasa, a Phoenician and later Roman town; and Djémila and Timgad, both Roman ruins; M'Zab Valley, a limestone valley containing a large urbanized oasis; and the Casbah of Algiers, an important citadel. The only natural World Heritage Site is the Tassili n'Ajjer, a mountain range.TransportThe Algerian road network is the densest in Africa; its length is estimated at  of highways, with more than 3,756 structures and a paving rate of 85%. This network will be complemented by the East-West Highway, a major infrastructure project currently under construction. It is a 3-way,  highway, linking Annaba in the extreme east to the Tlemcen in the far west. Algeria is also crossed by the Trans-Sahara Highway, which is now completely paved. This road is supported by the Algerian government to increase trade between the six countries crossed: Algeria, Mali, Niger, Nigeria, Chad, and Tunisia.DemographicsAlgeria has a population of an estimated 44 million, of which the vast majority are Arab-Berber ethnically. At the outset of the 20th century, its population was approximately four million. About 90% of Algerians live in the northern, coastal area; the inhabitants of the Sahara desert are mainly concentrated in oases, although some 1.5 million remain nomadic or partly nomadic. 28.1% of Algerians are under the age of 15.Between 90,000 and 165,000 Sahrawis from Western Sahara live in the Sahrawi refugee camps, in the western Algerian Sahara desert. There are also more than 4,000 Palestinian refugees, who are well integrated and have not asked for assistance from the United Nations High Commissioner for Refugees (UNHCR). In 2009, 35,000 Chinese migrant workers lived in Algeria.The largest concentration of Algerian migrants outside Algeria is in France, which has reportedly over 1.7 million Algerians of up to the second generation.Ethnic groupsIndigenous Berbers as well as Phoenicians, Romans, Vandals, Byzantine Greeks, Arabs, Turks, various Sub-Saharan Africans, and French have contributed to the history of Algeria. Descendants of Andalusian refugees are also present in the population of Algiers and other cities. Moreover, Spanish was spoken by these Aragonese and Castillian Morisco descendants deep into the 18th century, and even Catalan was spoken at the same time by Catalan Morisco descendants in the small town of Grish El-Oued.Despite the dominance of the Berber ethnicity in Algeria, the majority of Algerians identify with an Arabic-based identity, especially after the Arab nationalism rising in the 20th century.    Berbers and Berber-speaking Algerians are divided into many groups with varying languages. The largest of these are the Kabyles, who live in the Kabylie region east of Algiers, the Chaoui of Northeast Algeria, the Tuaregs in the southern desert and the Shenwa people of North Algeria.During the colonial period, there was a large (10% in 1960) European population who became known as Pied-Noirs. They were primarily of French, Spanish and Italian origin. Almost all of this population left during the war of independence or immediately after its end.LanguagesModern Standard Arabic and Berber are the official languages. Algerian Arabic (Darja) is the language used by the majority of the population. Colloquial Algerian Arabic is heavily infused with borrowings from French and Berber.Berber has been recognised as a "national language" by the constitutional amendment of 8 May 2002. Kabyle, the predominant Berber language, is taught and is partially co-official (with a few restrictions) in parts of Kabylie. In February 2016, the Algerian constitution passed a resolution that made Berber an official language alongside Arabic.Although French has no official status in Algeria, it has one of the largest Francophone populations in the world, and French is widely used in government, media (newspapers, radio, local television), and both the education system (from primary school onwards) and academia due to Algeria's colonial history. It can be regarded as a lingua franca of Algeria. In 2008, 11.2 million Algerians could read and write in French. An Abassa Institute study in April 2000 found that 60% of households could speak and understand French, or 18 million people out of a total of 30 million at the time. Following a period during which the Algerian government tried to phase out French, in recent decades the government has changed course and reinforced the study of French, and some television programs are broadcast in the language.Algeria emerged as a bilingual state after 1962. Colloquial Algerian Arabic is spoken by about 72% of the population and Berber by 27–30%.ReligionIslam is the predominant religion in Algeria, with its adherents, mostly Sunnis, accounting for 99% of the population according to a 2021 CIA World Factbook estimate, and 97.9% according to Pew Research in 2020. There are about 290,000 Ibadis in the M'zab Valley in the region of Ghardaia. Estimates of the Christian population range from 20,000 to 200,000 Algerian citizens who are Christians predominantly belong to Protestant groups, which have seen increased pressure from the government in recent years including many forced closures.There has been an increase in the number of people identifying as non-religious. The June 2019 Arab Barometer-BBC News report found that the percentage of Algerians identifying as non-religious has grown from around 8% in 2013 to around 15% in 2018. The Arab Barometer December 2019, found that the growth in the percentage of Algerians identifying as non-religious is largely driven by young Algerians, with roughly 25% describing themselves as non-religious.Algeria has given the Muslim world a number of prominent thinkers, including Emir Abdelkader, Abdelhamid Ben Badis, Mouloud Kacem Naît Belkacem, Malek Bennabi and Mohamed Arkoun.HealthIn 2018, Algeria had the highest numbers of physicians in the Maghreb region (1.72 per 1,000 people), nurses (2.23 per 1,000 people), and dentists (0.31 per 1,000 people). Access to "improved water sources" was around 97.4% of the population in urban areas and 98.7% of the population in the rural areas. Some 99% of Algerians living in urban areas, and around 93.4% of those living in rural areas, had access to "improved sanitation". According to the World Bank, Algeria is making progress toward its goal of "reducing by half the number of people without sustainable access to improved drinking water and basic sanitation by 2015". Given Algeria's young population, policy favours preventive health care and clinics over hospitals. In keeping with this policy, the government maintains an immunisation program. However, poor sanitation and unclean water still cause tuberculosis, hepatitis, measles, typhoid fever, cholera and dysentery. The poor generally receive health care free of charge.Health records have been maintained in Algeria since 1882 and began adding Muslims living in the south to their vital record database in 1905 during French rule.EducationSince the 1970s, in a centralised system that was designed to significantly reduce the rate of illiteracy, the Algerian government introduced a decree by which school attendance became compulsory for all children aged between 6 and 15 years who have the ability to track their learning through the 20 facilities built since independence, now the literacy rate is around 92.6%. Since 1972, Arabic is used as the language of instruction during the first nine years of schooling. From the third year, French is taught and it is also the language of instruction for science classes. The students can also learn English, Italian, Spanish and German. In 2008, new programs at the elementary appeared, therefore the compulsory schooling does not start at the age of six anymore, but at the age of five. Apart from the 122 private schools, the Universities of the State are free of charge. After nine years of primary school, students can go to the high school or to an educational institution. The school offers two programs: general or technical. At the end of the third year of secondary school, students pass the exam of the baccalaureate, which allows once it is successful to pursue graduate studies in universities and institutes.Education is officially compulsory for children between the ages of six and 15. In 2008, the illiteracy rate for people over 10 was 22.3%, 15.6% for men and 29.0% for women. The province with the lowest rate of illiteracy was Algiers Province at 11.6%, while the province with the highest rate was Djelfa Province at 35.5%.Algeria has 26 universities and 67 institutions of higher education, which must accommodate a million Algerians and 80,000 foreign students in 2008. The University of Algiers, founded in 1879, is the oldest, it offers education in various disciplines (law, medicine, science and letters). Twenty-five of these universities and almost all of the institutions of higher education were founded after the independence of the country.Even if some of them offer instruction in Arabic like areas of law and the economy, most of the other sectors as science and medicine continue to be provided in French and English. Among the most important universities, there are the University of Sciences and Technology Houari Boumediene, the University of Mentouri Constantine, and University of Oran Es-Senia. The University of Abou Bekr Belkaïd in Tlemcen and University of Batna Hadj Lakhdar occupy the 26th and 45th row in Africa. Algeria was ranked 121st in the Global Innovation Index in 2020, down from 113rd in 2019.CitiesBelow is a list of the most populous Algerian cities:CultureModern Algerian literature, split between Arabic, Tamazight and French, has been strongly influenced by the country's recent history. Famous novelists of the 20th century include Mohammed Dib, Albert Camus, Kateb Yacine and Ahlam Mosteghanemi while Assia Djebar is widely translated. Among the important novelists of the 1980s were Rachid Mimouni, later vice-president of Amnesty International, and Tahar Djaout, murdered by an Islamist group in 1993 for his secularist views.Malek Bennabi and Frantz Fanon are noted for their thoughts on decolonization; Augustine of Hippo was born in Tagaste (modern-day Souk Ahras); and Ibn Khaldun, though born in Tunis, wrote the Muqaddima while staying in Algeria. The works of the Sanusi family in pre-colonial times, and of Emir Abdelkader and Sheikh Ben Badis in colonial times, are widely noted. The Latin author Apuleius was born in Madaurus (Mdaourouch), in what later became Algeria.Contemporary Algerian cinema is various in terms of genre, exploring a wider range of themes and issues. There has been a transition from cinema which focused on the war of independence to films more concerned with the everyday lives of Algerians.MediaArtAlgerian painters, like Mohamed Racim or Baya, attempted to revive the prestigious Algerian past prior to French colonisation, at the same time that they have contributed to the preservation of the authentic values of Algeria. In this line, Mohamed Temam, Abdelkhader Houamel have also returned through this art, scenes from the history of the country, the habits and customs of the past and the country life. Other new artistic currents including the one of M'hamed Issiakhem, Mohammed Khadda and Bachir Yelles, appeared on the scene of Algerian painting, abandoning figurative classical painting to find new pictorial ways, in order to adapt Algerian paintings to the new realities of the country through its struggle and its aspirations. Mohammed Khadda and M'hamed Issiakhem have been notable in recent years.Literature The historic roots of Algerian literature go back to the Numidian and Roman African era, when Apuleius wrote The Golden Ass, the only Latin novel to survive in its entirety. This period had also known Augustine of Hippo, Nonius Marcellus and Martianus Capella, among many others. The Middle Ages have known many Arabic writers who revolutionised the Arab world literature, with authors like Ahmad al-Buni, Ibn Manzur and Ibn Khaldoun, who wrote the Muqaddimah while staying in Algeria, and many others.Albert Camus was an Algerian-born French Pied-Noir author. In 1957, he was awarded the Nobel Prize in literature.Today Algeria contains, in its literary landscape, big names having not only marked the Algerian literature, but also the universal literary heritage in Arabic and French.As a first step, Algerian literature was marked by works whose main concern was the assertion of the Algerian national entity, there is the publication of novels as the Algerian trilogy of Mohammed Dib, or even Nedjma of Kateb Yacine novel which is often regarded as a monumental and major work. Other known writers will contribute to the emergence of Algerian literature whom include Mouloud Feraoun, Malek Bennabi, Malek Haddad, Moufdi Zakaria, Abdelhamid Ben Badis, Mohamed Laïd Al-Khalifa, Mouloud Mammeri, Frantz Fanon, and Assia Djebar.In the aftermath of the independence, several new authors emerged on the Algerian literary scene, they will attempt through their works to expose a number of social problems, among them there are Rachid Boudjedra, Rachid Mimouni, Leila Sebbar, Tahar Djaout and Tahir Wattar.Currently, a part of Algerian writers tends to be defined in a literature of shocking expression, due to the terrorism that occurred during the 1990s, the other party is defined in a different style of literature who staged an individualistic conception of the human adventure. Among the most noted recent works, there is the writer, the swallows of Kabul and the attack of Yasmina Khadra, the oath of barbarians of Boualem Sansal, memory of the flesh of Ahlam Mosteghanemi and the last novel by Assia Djebar nowhere in my father's House.MusicChaâbi music is a typically Algerian musical genre characterized by specific rhythms and of Qacidate (popular poems) in Arabic dialect. The undisputed master of this music is El Hadj M'Hamed El Anka. The Constantinois Malouf style is saved by musician from whom Mohamed Tahar Fergani is a performer.Folk music styles include Bedouin music, characterized by the poetic songs based on long kacida (poems); Kabyle music, based on a rich repertoire that is poetry and old tales passed through generations; Shawiya music, a folklore from diverse areas of the Aurès Mountains. Rahaba music style is unique to the Aures. Souad Massi is a rising Algerian folk singer. Other Algerian singers of the diaspora include Manel Filali in Germany and Kenza Farah in France. Tergui music is sung in Tuareg languages generally, Tinariwen had a worldwide success. Finally, the staïfi music is born in Sétif and remains a unique style of its kind.Modern music is available in several facets, Raï music is a style typical of western Algeria. Rap, a relatively recent style in Algeria, is experiencing significant growth.CinemaThe Algerian state's interest in film-industry activities can be seen in the annual budget of DZD 200 million (EUR 1.3 million) allocated to production, specific measures and an ambitious programme plan implemented by the Ministry of Culture in order to promote national production, renovate the cinema stock and remedy the weak links in distribution and exploitation.The financial support provided by the state, through the Fund for the Development of the Arts, Techniques and the Film Industry (FDATIC) and the Algerian Agency for Cultural Influence (AARC), plays a key role in the promotion of national production. Between 2007 and 2013, FDATIC subsidised 98 films (feature films, documentaries and short films). In mid-2013, AARC had already supported a total of 78 films, including 42 feature films, 6 short films and 30 documentaries.According to the European Audiovisual Observatory's LUMIERE database, 41 Algerian films were distributed in Europe between 1996 and 2013; 21 films in this repertoire were Algerian-French co-productions. Days of Glory (2006) and Outside the Law (2010) recorded the highest number of admissions in the European Union, 3,172,612 and 474,722, respectively.Algeria won the Palme d'Or for Chronicle of the Years of Fire (1975), two Oscars for Z (1969), and other awards for the Italian-Algerian movie The Battle of Algiers.CuisineAlgerian cuisine is rich and diverse. The country was considered as the "granary of Rome". It offers a component of dishes and varied dishes, depending on the region and according to the seasons. The cuisine uses cereals as the main products, since they are always produced with abundance in the country. There is not a dish where cereals are not present.Algerian cuisine varies from one region to another, according to seasonal vegetables. It can be prepared using meat, fish and vegetables. Among the dishes known, couscous, chorba, rechta, chakhchoukha, berkoukes, shakshouka, mthewem, chtitha, mderbel, dolma, brik or bourek, garantita, lham'hlou, etc. Merguez sausage is widely used in Algeria, but it differs, depending on the region and on the added spices.Cakes are marketed and can be found in cities either in Algeria, in Europe or North America. However, traditional cakes are also made at home, following the habits and customs of each family. Among these cakes, there are Tamina, Baklawa, Chrik, Garn logzelles, Griouech, Kalb el-louz, Makroud, Mbardja, Mchewek, Samsa, Tcharak, Baghrir, Khfaf, Zlabia, Aarayech, Ghroubiya and Mghergchette. Algerian pastry also contains Tunisian or French cakes. Marketed and home-made bread products include varieties such as Kessra or Khmira or Harchaya, chopsticks and so-called washers Khoubz dar or Matloue. Other traditional meals sold often as street food include mhadjeb or mahjouba, karantika, doubara, chakhchoukha, hassouna, and t'chicha.SportsVarious games have existed in Algeria since antiquity. In the Aures, people played several games such as El Kherba or El khergueba (chess variant). Playing cards, checkers and chess games are part of Algerian culture. Racing (fantasia) and rifle shooting are part of cultural recreation of the Algerians.The first Algerian and African gold medalist is Boughera El Ouafi in 1928 Olympics of Amsterdam in the Marathon. The second Algerian Medalist was Alain Mimoun in 1956 Summer Olympics in Melbourne. Several men and women were champions in athletics in the 1990s including Noureddine Morceli, Hassiba Boulmerka, Nouria Merah-Benida, and Taoufik Makhloufi, all specialized in middle-distance running.Football is the most popular sport in Algeria. Several names are engraved in the history of the sport, including Lakhdar Belloumi, Rachid Mekhloufi, Hassen Lalmas, Rabah Madjer, Riyad Mahrez, Salah Assad and Djamel Zidane. The Algeria national football team qualified for the 1982 FIFA World Cup, 1986 FIFA World Cup, 2010 FIFA World Cup and 2014 FIFA World Cup. In addition, several football clubs have won continental and international trophies as the club ES Sétif or JS Kabylia. The Algerian Football Federation is an association of Algeria football clubs organizing national competitions and international matches of the selection of Algeria national football team.See also Index of Algeria-related articles Outline of AlgeriaExplanatory notesCitationsGeneral bibliography  Ageron, Charles-Robert (1991). Modern Algeria – A History from 1830 to the Present. Translated from French and edited by Michael Brett. London: Hurst. . Aghrout, Ahmed; Bougherira, Redha M. (2004). Algeria in Transition – Reforms and Development Prospects. Routledge. . Bennoune, Mahfoud (1988). The Making of Contemporary Algeria – Colonial Upheavals and Post-Independence Development, 1830–1987. Cambridge: Cambridge University Press. . Fanon, Frantz (1966; 2005 paperback). The Wretched of the Earth. Grove Press. ASIN B0007FW4AW, . Horne, Alistair (1977). A Savage War of Peace: Algeria 1954–1962. Viking Adult. ,  (2006 reprint) Laouisset, Djamel (2009). A Retrospective Study of the Algerian Iron and Steel Industry. New York City: Nova Publishers. . Roberts, Hugh (2003). The Battlefield – Algeria, 1988–2002. Studies in a Broken Polity. London: Verso Books. . Ruedy, John (1992). Modern Algeria – The Origins and Development of a Nation. Bloomington: Indiana University Press. . Stora, Benjamin (2001). Algeria, 1830–2000 – A Short History. Ithaca, New York: Cornell University Press. . Sidaoui, Riadh (2009). "Islamic Politics and the Military – Algeria 1962–2008". Religion and Politics – Islam and Muslim Civilisation. Farnham: Ashgate Publishing. .External links People's Democratic Republic of Algeria Official government website  Portal of the First Ministry Portal of the First Ministry  Algeria. The World Factbook. Central Intelligence Agency.   Algeria profile from the BBC News  ency education ency education   Key Development Forecasts for Algeria from International Futures EU Neighbourhood Info Centre: Algeria North African countriesMaghrebi countriesSaharan countriesArab republicsRepublicsArabic-speaking countries and territoriesBerber-speaking countries and territoriesFrench-speaking countries and territoriesG15 nationsMember states of OPECMember states of the African UnionMember states of the Arab LeagueMember states of the Organisation of Islamic CooperationMember states of the Union for the MediterraneanCurrent member states of the United NationsStates and territories established in 19621962 establishments in Algeria1962 establishments in AfricaCountries in Africa
This is a list of characters in Ayn Rand's 1957 novel Atlas Shrugged.Major charactersThe following are major characters from the novel.ProtagonistsDagny TaggartDagny Taggart is the protagonist of the novel. She is vice-president in Charge of Operations for Taggart Transcontinental, under her brother, James Taggart. Given James' incompetence, Dagny is responsible for all the workings of the railroad.Francisco d'AnconiaFrancisco d'Anconia is one of the central characters in Atlas Shrugged, an owner by inheritance of the world's largest copper mining operation. He is a childhood friend, and the first love, of Dagny Taggart. A child prodigy of exceptional talents, Francisco was dubbed the "climax" of the d'Anconia line, an already prestigious family of skilled industrialists. He was a classmate of John Galt and Ragnar Danneskjöld and student of both Hugh Akston and Robert Stadler. He began working while still in school, proving that he could have made a fortune without the aid of his family's wealth and power. Later, Francisco bankrupts the d'Anconia business to put it out of others' reach. His full name is given as "Francisco Domingo Carlos Andres Sebastián d'Anconia".John GaltJohn Galt is the primary male hero of Atlas Shrugged. He initially appears as an unnamed menial worker for Taggart Transcontinental, who often dines with Eddie Willers in the employees' cafeteria, and leads Eddie to reveal important information about Dagny Taggart and Taggart Transcontinental. Only Eddie's side of their conversations is given in the novel. Later in the novel, the reader discovers this worker's true identity.Before working for Taggart Transcontinental, Galt worked as an engineer for the Twentieth Century Motor Company, where he secretly invented a generator of usable electric energy from ambient static electricity, but abandoned his prototype, and his employment, when dissatisfied by an easily corrupted novel system of payment. This prototype was found by Dagny Taggart and Hank Rearden. Galt himself remains concealed throughout much of the novel, working a job and living by himself, where he unites the most skillful inventors and business leaders under his leadership. Much of the book's third division is given to his broadcast speech, which presents the author's philosophy of Objectivism.Henry "Hank" ReardenHenry (known as "Hank") Rearden is one of the central characters in Atlas Shrugged. He owns the most important steel company in the United States, and invents Rearden Metal, an alloy stronger, lighter, cheaper and tougher than steel. He lives in Philadelphia with his wife Lillian, his brother Philip, and his elderly mother. Rearden represents a type of self-made man and eventually divorces Lillian, abandons his steel mills following a bloody assault by government-planted workers, and joins John Galt's strike.Eddie WillersEdwin "Eddie" Willers is the Special Assistant to the Vice-President in Charge of Operations at Taggart Transcontinental. His father and grandfather worked for the Taggarts, and himself likewise. He is completely loyal to Dagny and to Taggart Transcontinental. Willers does not possess the creative ability of Galt's associates, but matches them in moral courage and is capable of appreciating and making use of their creations. After Dagny shifts her attention and loyalty to saving the captive Galt, Willers maintains the railroad until its collapse.Ragnar DanneskjöldOne of Galt's first followers, and world-famous as a pirate, who seizes relief ships sent from the United States to the People's States of Europe. He works to  ensure that once those espousing Galt's philosophy are restored to their rightful place in society, they have enough capital to rebuild the world. Kept in the background for much of the book, Danneskjöld makes a personal appearance to encourage Rearden to persevere in his increasingly difficult situation, and gives him a bar of gold as compensation for the income taxes he has paid over the last several years. Danneskjöld is married to the actress Kay Ludlow; their relationship is kept hidden from the outside world, which only knows of Ludlow as a retired film star. Considered a misfit by Galt's other adherents, he views his actions as a means to speed the world along in understanding Galt's perspective.According to Barbara Branden, who was closely associated with Rand at the time the book was written, there were sections written describing Danneskjöld's adventures at sea, cut from the final published text. In a 1974 comment at a lecture, Ayn Rand admitted that Danneskjöld's name was a tribute to Victor Hugo's novel, , wherein the hero becomes the first of the Counts of Danneskjöld. In the published book, Danneskjöld is always seen through the eyes of others (Dagny Taggart or Hank Rearden), except for a brief paragraph in the very last chapter.AntagonistsJames TaggartThe President of Taggart Transcontinental and the book's most important antagonist. Taggart is an expert influence peddler but incapable of making operational decisions on his own. He relies on his sister, Dagny Taggart, to actually run the railroad, but nonetheless opposes her in almost every endeavor because of his various anti-capitalist moral and political beliefs. In a sense, he is the antithesis of Dagny. This contradiction leads to the recurring absurdity of his life: the desire to overcome those on whom his life depends, and the horror that he will succeed at this. In the final chapters of the novel, he suffers a complete mental breakdown upon realizing that he can no longer deceive himself in this respect.Lillian ReardenThe unsupportive wife of Hank Rearden, who dislikes his habits and (secretly at first) seeks to ruin Rearden to prove her own value. Lillian achieves this, when she passes information to James Taggart about her husband's affair with his sister. This information is used to blackmail Rearden to sign a Gift Certificate which delivers all the property rights of Rearden Metal to others. Lillian thereafter uses James Taggart for sexual satisfaction, until Hank abandons her.Dr. Floyd FerrisFerris is a biologist who works as "co-ordinator" at the State Science Institute. He uses his position there to deride reason and productive achievement, and publishes a book entitled Why Do You Think You Think? He clashes on several occasions with Hank Rearden, and twice attempts to blackmail Rearden into giving up Rearden Metal. He is also one of the group of looters who tries to get Rearden to agree to the Steel Unification Plan. Ferris hosts the demonstration of the Project X weapon, and is the creator of the Ferris Persuader, a torture machine. When John Galt is captured by the looters, Ferris uses the device on Galt, but it breaks down before extracting the information Ferris wants from Galt. Ferris represents the group which uses brute force on the heroes to achieve the ends of the looters.Dr. Robert StadlerA former professor at Patrick Henry University, and along with colleague Hugh Akston, mentor to Francisco d'Anconia, John Galt and Ragnar Danneskjöld. He has since become a sell-out, one who had great promise but squandered it for social approval, to the detriment of the free. He works at the State Science Institute where all his inventions are perverted for use by the military, including a sound-based weapon known as Project X (Xylophone). He is killed when Cuffy Meigs (see below) drunkenly overloads the circuits of Project X, causing it to destroy itself and every structure and living thing in a 100-mile radius. The character was, in part, modeled on J. Robert Oppenheimer, whom Rand had interviewed for an earlier project, and his part in the creation of nuclear weapons.` To his former student Galt, Stadler represents the epitome of human evil, as the "man who knew better" but chose not to act for the good.Wesley MouchThe incompetent and treacherous lobbyist whom Hank Rearden reluctantly employs in Washington, who rises to prominence and authority throughout the novel through trading favours and disloyalty. In return for betraying Hank by helping broker the Equalization of Opportunity Bill (which, by restricting the number of businesses each person may own to one, forces Hank to divest most of his companies), he is given a senior position at the Bureau of Economic Planning and National Resources. Later in the novel he becomes its Top Co-ordinator, a position that eventually becomes Economic Dictator of the country. Mouch's mantra, whenever a problem arises from his prior policy, is to say, "I can't help it.  I need wider powers."Secondary charactersThe following secondary characters also appear in the novel.Hugh Akston is identified as "One of the last great advocates of reason." He was a renowned philosopher and the head of the Department of Philosophy at Patrick Henry University, where he taught Francisco d'Anconia, John Galt, and Ragnar Danneskjöld. He was, along with Robert Stadler, a father figure to these three. Akston's name is so hallowed that a young lady, on hearing that Francisco had studied under him, is shocked. She thought he must have been one of those great names from an earlier century. He now works as a cook in a roadside diner, and proves extremely skillful at the job. When Dagny tracks him down, and before she discovers his true identity, he rejects her enthusiastic offer to manage the dining car services for Taggart Transcontinental. He is based on Aristotle.Jeff Allen is a tramp who stows away on a Taggart train during one of Dagny's cross-country trips. Instead of throwing him out, she allows him to ride as her guest. It is from Allen that she learns the full story behind the collapse of the Twentieth Century Motor Company (Rand's extensive metaphor for the inherent flaws of communism), as well as a hint of John Galt's true background.Calvin Atwood is owner of Atwood Light and Power Company and joins Galt's strike.Mayor Bascom is the mayor of Rome, Wisconsin, who reveals part of the history of the Twentieth Century Motor Company.Dr. Blodgett is the scientist who pulls the lever to demonstrate Project X.Orren Boyle is the head of Associated Steel, antithesis of Hank Rearden and a friend of James Taggart. He is an investor in the San Sebastián Mines. He disappears from the story after having a nervous breakdown following the failed 'unification' of the steel industry.Laura Bradford is an actress and Kip Chalmers' mistress. She is one of the passengers on his train, and dies in the Taggart Tunnel disaster.Bill Brent is the chief dispatcher for the Colorado Division of Taggart Transcontinental, who tries to prevent the Taggart Tunnel disaster.Cherryl Brooks is a dime store shopgirl who marries James Taggart after a chance encounter in her store the night the John Galt Line was falsely deemed his greatest success. She marries him thinking he is the heroic person behind Taggart Transcontinental. Cherryl is at first harsh towards Dagny, having believed Jim Taggart's descriptions of his sister, until she questions employees of the railroad. Upon learning that her scorn had been misdirected, Cherryl puts off apologizing to Dagny out of shame, but eventually admits to Dagny that when she married Jim, she thought he had the heroic qualities that she had looked up to - she thought she was marrying someone like Dagny. Shortly after making this admission, she commits suicide by jumping over a stone parapet and into the river, unable to live with her evil husband and seeing no way to escape him.Millie Bush was "a mean, ugly little eight-year-old" girl voted to receive gold braces to straighten her teeth by the Marxist "family" committee who determined how pay was allocated at The Twentieth Century Motor Company. Her teeth are later knocked out by a man denied an allowance by the committee to purchase the things he valued.Emma Chalmers, Kip Chalmers' mother, gains some influence after his death. Known as "Kip's Ma," she starts a soybean-growing project in Louisiana and commandeers thousands of railroad freight cars to move the harvest. As a result, the year's wheat crop from Minnesota never reaches the rest of the country, but instead rots in storage; also, the soybean crop is lost, having been reaped too early.Kip Chalmers is a Washington man who has decided to run for election as Legislator from California. On the way to a campaign rally, the Taggart Transcontinental train that is carrying him encounters a split rail, resulting in the destruction of its diesel engine. His demands lead to a coal-burning steam engine being attached to his train in its stead and used to pull it through an eight-mile tunnel. The result is the suffocation of all passengers and the destruction of the Taggart Tunnel.Dan Conway is the middle-aged president of the Phoenix-Durango railroad. Running a railroad is just about the only thing he knows. When the Anti-dog-eat-dog Rule is used to drive his business out of Colorado, he loses the will to fight, and resigns himself to a quiet life of books and fishing. He is not one of those who joined John Galt's strike, his resignation being a personal choice of his own. Ken Danagger owns Danagger Coal in Pennsylvania. He helps Hank Rearden illegally make Rearden Metal, then later decides to quit and join Galt's strike moments before Dagny arrives to try to persuade him otherwise.Quentin Daniels is an enterprising engineer hired by Dagny Taggart to reconstruct John Galt's motor. Partway through this process, Quentin withdraws his effort for the same reasons John Galt himself had. Dagny's pursuit of Quentin leads her to Galt's Gulch. Galt recognizes in him a younger version of himself, having emulated both Galt's achievements in physics and Galt's social reasoning. Sebastian d'Anconia was the 16th (or 17th) Century founder of the d'Anconia dynasty. Escaped from Spain because of expressing his opinions too freely and coming in conflict with the Inquisition, leaving behind a palace and his beloved. Started a small mine in South America, which became the beginning of a mining empire and a new fortune (and a new palace). Eventually sent for his beloved who had waited for him many years. He is the role model which Francisco d'Anconia looks to, as Dagny Taggart looks to Nathaniel Taggart. Francisco remarks that their respective ancestors would have liked each other.Balph Eubank is called "the literary leader of the age", despite the fact that no book he has written has sold more than 3,000 copies. He complains that it is disgraceful that artists are treated as peddlers, and that there should be a law limiting the sales of books to 10,000 copies. He is a misogynist who thinks it disgusting that Dagny Taggart is a railroad vice-president.The Fishwife is one of the strikers, who earns her living by providing the fish for Hammond's grocery market; she is described as having "dark, disheveled hair and large eyes", and is a writer. Galt says she "wouldn't be published outside. She believes that when one deals with words, one deals with the mind." According to Barbara Branden in her book The Passion of Ayn Rand, "The Fishwife is Ayn's Hitchcock-like appearance in Atlas Shrugged." So says too Leonard Peikoff.Lawrence Hammond runs Hammond Cars in Colorado, one of the few companies in existence that still produces top-quality vehicles. He eventually quits and joins the strike.Richard Halley is Dagny Taggart's favorite composer, who mysteriously disappeared after the evening of his greatest triumph. Halley spent years as a struggling and unappreciated composer. At age 24, his opera Phaethon was performed for the first time, to an audience who booed and heckled it. After 19 years, Phaethon was performed again, but this time it was received to the greatest ovation the opera house had ever heard. The following day, Halley retired, sold the rights to his music, and disappeared. It is later revealed that he has joined the strike and settled in Galt's Gulch.Mrs. William Hastings is the widow of the chief engineer at the Twentieth Century Motor Company. Her husband quit shortly after Galt did and joined the strike some years later. Her lead allows Dagny to find Hugh Akston.Dr. Thomas Hendricks is a famous brain surgeon who developed a new method of preventing strokes. He joined Galt's strike when the American medical system was put under government control.Tinky Holloway is one of the "looters" and is frequently referred to and quoted by other characters in the story, but he has only one major appearance: during the Washington meeting with Hank Rearden.Lee Hunsacker is in charge of a company called Amalgamated Service when takes over the Twentieth Century Motor Company. He files a lawsuit that eventually leads to Midas Mulligan and Judge Narragansett joining the strike. A failed businessman, he laments constantly that no-one ever gave him a chance.Gwen Ives is Hank Rearden's secretary, described as being in her late twenties and remaining calm and professional despite the chaos that threatens his business. When Rearden abandons his mills and joins Galt's strike, she and many other employees do the same.Gilbert Keith-Worthing is a British novelist of erstwhile fame, now neglected but still considered a "walking classic," and a proponent of the idea that freedom is an illusion. Kip Chalmers brings him along on the train to California, "for no reason that either of them could discover"; he dies in the Taggart Tunnel disaster.Owen Kellogg is Assistant to the Manager of the Taggart Terminal in New York. He catches Dagny Taggart's eye as one of the few competent men on staff. After seeing the sorry state of the Ohio Division, she decides to make him its new Superintendent. However, as soon as she returns to New York, Kellogg informs her that he is quitting his job. Owen Kellogg eventually reaches, and settles in, Galt's Gulch.Fred Kinnan is a labor leader and member of the looter cabal. Unlike the others, however, Kinnan is straightforward and honest about his purpose. Kinnan is the only one to openly state the true motivations of himself and his fellow conspirators. At the end of Galt's three-hour speech, he expresses admiration for the man, as he says what he means. Despite this, Kinnan admits that he is one of the people Galt is out to destroy.Paul Larkin is an unsuccessful, middle-aged businessman, a friend of the Rearden family. He meets with the other Looters to work out a plan to bring Rearden down. James Taggart knows he is friends with Hank Rearden and challenges his loyalty, and Larkin assures Taggart that he will go along with them.Eugene Lawson heads the Community Bank of Madison, then gets a job with the government when it his bank goes bankrupt. One of the looter's cabal, he is a collectivist who abhors production and money-making.Mort Liddy is a hack composer who writes trite scores for movies and modern symphonies to which no one listens. He believes melody is a primitive vulgarity. He is one of Lillian Rearden's friends and a member of the cultural elite.Clifton Locey is a friend of Jim Taggart who takes the position of vice-president of operation when Dagny Taggart quits.Pat Logan is the engineer on the first run of the John Galt Line. He later strikes.Kay Ludlow is a beautiful actress who quit Holywood because of the roles she was given and married secretly the pirate Ragnar Danneskjöld.Dick McNamara is a contractor who finished the San Sebastian Line. Dagny Taggart plans to hire him to lay the new Rearden Metal track for the Rio Norte Line, but before she does so, he mysteriously disappears. She later discovers that he has joined the strike and settled in Galt's Gulch.Cuffy Meigs is the Director of Unification for the railroad business. He carries a pistol and a lucky rabbit's foot, and he dresses in a military uniform, and has been described as "impervious to thought". Meigs seizes control of Project X and accidentally destroys it, demolishing the country's last railroad bridge across the Mississippi River and killing himself, his men, and Dr. Stadler.Dave Mitchum is a state-hired superintendent of the Colorado Division of Taggart Transcontinental. He is partially responsible for the Taggart Tunnel disaster.Chick Morrison holds the position of "Morale Conditioner" in the government. He quits when society begins to collapse and flees to a stronghold in Tennessee. His fellow looters consider it unlikely that he will survive.Horace Bussby Mowen is the president of the Amalgamated Switch and Signal Company, Inc. of Connecticut. He is a businessman who sees nothing wrong with the moral code that is destroying society and would never dream of saying he is in business for any reason other than the good of society. Dagny Taggart hires Mowen to produce switches made of Rearden Metal. He is reluctant to build anything with this unproven technology, and has to be cajoled into accepting the contract. When pressured by public opinion, he discontinues production of the switches, forcing Dagny to find an alternative source.Midas Mulligan is a wealthy banker who mysteriously disappeared in protest after he was given a court order to lend money to an incompetent applicant. When the order came down, he liquidated his entire business, paid off his depositors, and joined Galt's strike. He is the legal owner of the land where Galt's Gulch is located. Mulligan's birth name was Michael, but he had it legally changed after a news article called him "Midas" in a derogatory fashion, which Mulligan took as a compliment.Judge Narragansett is an American jurist who ruled in favor of Midas Mulligan during the case brought against him by the incompetent loan applicant. When Narragansett's ruling was reversed on appeal, he retired and joined the strike. At the end of the novel, he is seen editing the United States Constitution, crossing out the contradicting amendments of it and adding an amendment to prohibit Congress from passing laws that restrain freedom of trade.Ben Nealy is a railroad contractor whom Dagny Taggart hires to replace the track on the Rio Norte Line with Rearden Metal. Nealy is incompetent, but Dagny can find no one better in all the country. Nealy believes that anything can get done with enough muscle power. He sees no role for intelligence in human achievement. He relies on Dagny and Ellis Wyatt to run things, and resents them for doing it, because it appears to him like they are just bossing people around.Ted Nielsen is the head of Nielsen Motors. He eventually goes on strike, along with most of the other industrialist "producer" types, by closing his motor factory. Dagny later finds him when she visits Galt's Gulch for the first time.Betty Pope is a wealthy socialite who is having a meaningless sexual affair with James Taggart. She is deliberately crude in a way that casts ridicule on her high social position.Dr. Potter holds some undefined position with the State Science Institute. He is sent to try to obtain the rights to Rearden Metal.Dr. Simon Pritchett is the prestigious head of the Department of Philosophy at Patrick Henry University and is considered the leading philosopher of the age. He believes that man is nothing but a collection of chemicals, reason is a superstition, it is futile to seek meaning in life, and the duty of a philosopher is to show that nothing can be understood.Rearden's mother, whose name is not mentioned, lives with Rearden at his home in Philadelphia. She is involved in charity work, and berates Rearden whenever she can. She dotes on her weak son Philip Rearden.Philip Rearden is the younger brother of Hank Rearden. He lives in his brother's home in Philadelphia and is completely dependent on him. He is resentful of his brother's charity.Dwight Sanders owns Sanders Aircraft, a producer of high-quality airplanes, and joins the strike.Bertram Scudder is an editorial writer for the magazine The Future. He typically bashes business and businessmen, but he never says anything specific in his articles, relying on innuendo, sneers, and denunciation. He wrote a hatchet job on Hank Rearden called The Octopus. He is also vocal in support of the Equalization of Opportunity Bill. Scudder claims that the most important thing in life is "brother love" but seems to have nothing but hatred for those around him. He loses his job after Dagny Taggart reveals her affair with Hank Rearden over air on his radio show.Claude Slagenhop is president of political organization Friends of Global Progress and one of Lillian Rearden's friends. He believes that ideas are just air, that this is no time for talk, but for action. Global Progress is a sponsor of the Equalization of Opportunity Bill.Gerald and Ivy Starnes are the two surviving children of Jed Starnes, the founder of the Twentieth Century Motor Company. Together with their since-deceased brother Eric, they instituted a communistic payment-and-benefits program that drove the company into bankruptcy. Gerald, a dying alcoholic, and Ivy, a pseudo-Buddhist ascetic, continue to insist that the plan was perfect and that the failure of their father's company was entirely due to the workers. Eric was a weak, attention-seeking man with a pathological desire to be loved. He committed suicide after the woman he loved married another man. Gerald claims that he always acted for the good of the employees, but he was vain and incompetent and often threw lavish parties using company funds. Ivy, on the other hand, is described as a sadist who relishes seeing others in poverty, but who has no desire for wealth of her own.Andrew Stockton runs the Stockton Foundry in Stockton, Colorado. When he joins the strike, he opens a foundry in Galt's Gulch.Nathaniel "Nat" Taggart was the founder of Taggart Transcontinental. He built his railroad without any government handouts, and ran the business for no other reason than to turn a profit. He began as a penniless adventurer and ended up as one of the wealthiest men in the country. He never earned money by force or fraud (except for bribing government officials and throwing an opponent down a flight of stairs), and never apologized for becoming wealthy and successful. He was one of the most hated men of his time. Dagny is often inspired by looking at a statue of Nat Taggart at the railroad headquarters, and draws a dollar sign on its base as a signal to Francisco when she is ready to join Galt's strike.  It is suspected that he is modeled after James Jerome Hill, builder of the Great Northern Railroad. Mr. Thompson is the "Head of the State" for the United States. He is not particularly intelligent and has a very undistinguished look. He knows politics, however, and is a master of public relations and back-room deals. Rand's notes indicate that she modeled him on President Harry S. Truman, and that she deliberately decided not to call him "President of the United States" as this title has "honorable connotations" which the character does not deserve.Lester Tuck is the campaign manager for Kip Chalmers and one of his guests on the train trip to California. He dies in the Taggart Tunnel disaster.Clem Weatherby is a government representative on the board of directors of Taggart Transcontinental. Dagny considers him the least bad of the government representatives, since he does have some real knowledge on the running of trains. She notices, however, that he is the least appreciated by his own bosses.The Wet Nurse (Tony) is a young bureaucrat sent by the government to watch over Rearden's mills. Though he starts out as a cynical follower of the looters' code, his experience at the mills transforms him, and he comes to respect and admire the producers. He is shot attempting to inform Hank Rearden about a government plot, but does succeed in warning Rearden just before he dies.Ellis Wyatt is the head of Wyatt Oil. He has almost single-handedly revived the economy of Colorado by discovering a new process for extracting more oil from what were thought to be exhausted oil wells. When first introduced, he is aggressive towards Dagny, whom he does not yet know and whom he blames for what are, in fact, her brother's policies which directly threaten his business. When the government passes laws and decrees which make it impossible for him to continue, he sets all his oil wells on fire, leaving a single note: "I am leaving it as I found it. Take over. It's yours." One particular burning well that resists all efforts to extinguish it becomes known as "Wyatt's Torch". Later Dagny meets him in Galt's Gulch.FootnotesNotesCitationsGeneral referencesExternal linksWebsite with comprehensive list of individuals mentioned in Atlas Shrugged Fictional socialitesLists of literary charactersLiterary characters introduced in 1957
Anthropology is the scientific study of humanity, concerned with human behavior, human biology, cultures, societies, and linguistics, in both the present and past, including past human species. Social anthropology studies patterns of behaviour, while cultural anthropology studies cultural meaning, including norms and values. A portmanteau sociocultural anthropology is commonly used today. Linguistic anthropology studies how language influences social life. Biological or physical anthropology studies the biological development of humans.Archaeological anthropology, often termed as 'anthropology of the past', studies human activity through investigation of physical evidence. It is considered a branch of anthropology in North America and Asia, while in Europe archaeology is viewed as a discipline in its own right or grouped under other related disciplines, such as history.EtymologyThe abstract noun anthropology is first attested in reference to history. Its present use first appeared in Renaissance Germany in the works of Magnus Hundt and Otto Casmann. Their New Latin  derived from the combining forms of the Greek words ánthrōpos (, "human") and lógos (, "study"). (Its adjectival form appeared in the works of Aristotle.) It began to be used in English, possibly via French , by the early 18th century.HistoryThrough the 19th centuryIn 1647, the Bartholins, founders of the University of Copenhagen, defined  as follows:Sporadic use of the term for some of the subject matter occurred subsequently, such as the use by Étienne Serres in 1839 to describe the natural history, or paleontology, of man, based on comparative anatomy, and the creation of a chair in anthropology and ethnography in 1850 at the French National Museum of Natural History by Jean Louis Armand de Quatrefages de Bréau. Various short-lived organizations of anthropologists had already been formed. The Société Ethnologique de Paris, the first to use the term ethnology, was formed in 1839. Its members were primarily anti-slavery activists. When slavery was abolished in France in 1848, the Société was abandoned.Meanwhile, the Ethnological Society of New York, currently the American Ethnological Society, was founded on its model in 1842, as well as the Ethnological Society of London in 1843, a break-away group of the Aborigines' Protection Society. These anthropologists of the times were liberal, anti-slavery, and pro-human-rights activists. They maintained international connections.Anthropology and many other current fields are the intellectual results of the comparative methods developed in the earlier 19th century. Theorists in such diverse fields as anatomy, linguistics, and ethnology, making feature-by-feature comparisons of their subject matters, were beginning to suspect that similarities between animals, languages, and folkways were the result of processes or laws unknown to them then. For them, the publication of Charles Darwin's On the Origin of Species was the epiphany of everything they had begun to suspect. Darwin himself arrived at his conclusions through comparison of species he had seen in agronomy and in the wild.Darwin and Wallace unveiled evolution in the late 1850s. There was an immediate rush to bring it into the social sciences. Paul Broca in Paris was in the process of breaking away from the Société de biologie to form the first of the explicitly anthropological societies, the Société d'Anthropologie de Paris, meeting for the first time in Paris in 1859. When he read Darwin, he became an immediate convert to Transformisme, as the French called evolutionism. His definition now became "the study of the human group, considered as a whole, in its details, and in relation to the rest of nature".Broca, being what today would be called a neurosurgeon, had taken an interest in the pathology of speech. He wanted to localize the difference between man and the other animals, which appeared to reside in speech. He discovered the speech center of the human brain, today called Broca's area after him. His interest was mainly in Biological anthropology, but a German philosopher specializing in psychology, Theodor Waitz, took up the theme of general and social anthropology in his six-volume work, entitled Die Anthropologie der Naturvölker, 1859–1864. The title was soon translated as "The Anthropology of Primitive Peoples". The last two volumes were published posthumously.Waitz defined anthropology as "the science of the nature of man". Following Broca's lead, Waitz points out that anthropology is a new field, which would gather material from other fields, but would differ from them in the use of comparative anatomy, physiology, and psychology to differentiate man from "the animals nearest to him". He stresses that the data of comparison must be empirical, gathered by experimentation. The history of civilization, as well as ethnology, are to be brought into the comparison. It is to be presumed fundamentally that the species, man, is a unity, and that "the same laws of thought are applicable to all men".Waitz was influential among British ethnologists. In 1863, the explorer Richard Francis Burton and the speech therapist James Hunt broke away from the Ethnological Society of London to form the Anthropological Society of London, which henceforward would follow the path of the new anthropology rather than just ethnology. It was the 2nd society dedicated to general anthropology in existence. Representatives from the French Société were present, though not Broca. In his keynote address, printed in the first volume of its new publication, The Anthropological Review, Hunt stressed the work of Waitz, adopting his definitions as a standard. Among the first associates were the young Edward Burnett Tylor, inventor of cultural anthropology, and his brother Alfred Tylor, a geologist. Previously Edward had referred to himself as an ethnologist; subsequently, an anthropologist.Similar organizations in other countries followed: The Anthropological Society of Madrid (1865), the American Anthropological Association in 1902, the Anthropological Society of Vienna (1870), the Italian Society of Anthropology and Ethnology (1871), and many others subsequently. The majority of these were evolutionists. One notable exception was the Berlin Society for Anthropology, Ethnology, and Prehistory (1869) founded by Rudolph Virchow, known for his vituperative attacks on the evolutionists. Not religious himself, he insisted that Darwin's conclusions lacked empirical foundation.During the last three decades of the 19th century, a proliferation of anthropological societies and associations occurred, most independent, most publishing their own journals, and all international in membership and association. The major theorists belonged to these organizations. They supported the gradual osmosis of anthropology curricula into the major institutions of higher learning. By 1898, 48 educational institutions in 13 countries had some curriculum in anthropology. None of the 75 faculty members were under a department named anthropology.20th and 21st centuriesThis meager statistic expanded in the 20th century to comprise anthropology departments in the majority of the world's higher educational institutions, many thousands in number. Anthropology has diversified from a few major subdivisions to dozens more. Practical anthropology, the use of anthropological knowledge and technique to solve specific problems, has arrived; for example, the presence of buried victims might stimulate the use of a forensic archaeologist to recreate the final scene. The organization has reached a global level. For example, the World Council of Anthropological Associations (WCAA), "a network of national, regional and international associations that aims to promote worldwide communication and cooperation in anthropology", currently contains members from about three dozen nations.Since the work of Franz Boas and Bronisław Malinowski in the late 19th and early 20th centuries, social anthropology in Great Britain and cultural anthropology in the US have been distinguished from other social sciences by their emphasis on cross-cultural comparisons, long-term in-depth examination of context, and the importance they place on participant-observation or experiential immersion in the area of research. Cultural anthropology, in particular, has emphasized cultural relativism, holism, and the use of findings to frame cultural critiques. This has been particularly prominent in the United States, from Boas' arguments against 19th-century racial ideology, through Margaret Mead's advocacy for gender equality and sexual liberation, to current criticisms of post-colonial oppression and promotion of multiculturalism. Ethnography is one of its primary research designs as well as the text that is generated from anthropological fieldwork.In Great Britain and the Commonwealth countries, the British tradition of social anthropology tends to dominate. In the United States, anthropology has traditionally been divided into the four field approach developed by Franz Boas in the early 20th century: biological or physical anthropology; social, cultural, or sociocultural anthropology; and archaeological anthropology; plus linguistic anthropology. These fields frequently overlap but tend to use different methodologies and techniques.European countries with overseas colonies tended to practice more ethnology (a term coined and defined by Adam F. Kollár in 1783). It is sometimes referred to as sociocultural anthropology in the parts of the world that were influenced by the European tradition.FieldsAnthropology is a global discipline involving humanities, social sciences and natural sciences. Anthropology builds upon knowledge from natural sciences, including the discoveries about the origin and evolution of Homo sapiens, human physical traits, human behavior, the variations among different groups of humans, how the evolutionary past of Homo sapiens has influenced its social organization and culture, and from social sciences, including the organization of human social and cultural relations, institutions, social conflicts, etc. Early anthropology originated in Classical Greece and Persia and studied and tried to understand observable cultural diversity, such as by Al-Biruni of the Islamic Golden Age. As such, anthropology has been central in the development of several new (late 20th century) interdisciplinary fields such as cognitive science, global studies, and various ethnic studies.According to Clifford Geertz,Sociocultural anthropology has been heavily influenced by structuralist and postmodern theories, as well as a shift toward the analysis of modern societies. During the 1970s and 1990s, there was an epistemological shift away from the positivist traditions that had largely informed the discipline. During this shift, enduring questions about the nature and production of knowledge came to occupy a central place in cultural and social anthropology. In contrast, archaeology and biological anthropology remained largely positivist. Due to this difference in epistemology, the four sub-fields of anthropology have lacked cohesion over the last several decades.SocioculturalSociocultural anthropology draws together the principle axes of cultural anthropology and social anthropology. Cultural anthropology is the comparative study of the manifold ways in which people make sense of the world around them, while social anthropology is the study of the relationships among individuals and groups. Cultural anthropology is more related to philosophy, literature and the arts (how one's culture affects the experience for self and group, contributing to a more complete understanding of the people's knowledge, customs, and institutions), while social anthropology is more related to sociology and history. In that, it helps develop an understanding of social structures, typically of others and other populations (such as minorities, subgroups, dissidents, etc.). There is no hard-and-fast distinction between them, and these categories overlap to a considerable degree.Inquiry in sociocultural anthropology is guided in part by cultural relativism, the attempt to understand other societies in terms of their own cultural symbols and values. Accepting other cultures in their own terms moderates reductionism in cross-cultural comparison. This project is often accommodated in the field of ethnography. Ethnography can refer to both a methodology and the product of ethnographic research, i.e. an ethnographic monograph. As a methodology, ethnography is based upon long-term fieldwork within a community or other research site. Participant observation is one of the foundational methods of social and cultural anthropology. Ethnology involves the systematic comparison of different cultures. The process of participant-observation can be especially helpful to understanding a culture from an emic (conceptual, vs. etic, or technical) point of view.The study of kinship and social organization is a central focus of sociocultural anthropology, as kinship is a human universal. Sociocultural anthropology also covers economic and political organization, law and conflict resolution, patterns of consumption and exchange, material culture, technology, infrastructure, gender relations, ethnicity, childrearing and socialization, religion, myth, symbols, values, etiquette, worldview, sports, music, nutrition, recreation, games, food, festivals, and language (which is also the object of study in linguistic anthropology).Comparison across cultures is a key element of method in sociocultural anthropology, including the industrialized (and de-industrialized) West. The Standard Cross-Cultural Sample (SCCS) includes 186 such cultures.BiologicalBiological anthropology and physical anthropology are synonymous terms to describe anthropological research focused on the study of humans and non-human primates in their biological, evolutionary, and demographic dimensions. It examines the biological and social factors that have affected the evolution of humans and other primates, and that generate, maintain or change contemporary genetic and physiological variation.ArchaeologicalArchaeology is the study of the human past through its material remains. Artifacts, faunal remains, and human altered landscapes are evidence of the cultural and material lives of past societies. Archaeologists examine material remains in order to deduce patterns of past human behavior and cultural practices. Ethnoarchaeology is a type of archaeology that studies the practices and material remains of living human groups in order to gain a better understanding of the evidence left behind by past human groups, who are presumed to have lived in similar ways.LinguisticLinguistic anthropology (not to be confused with anthropological linguistics) seeks to understand the processes of human communications, verbal and non-verbal, variation in language across time and space, the social uses of language, and the relationship between language and culture. It is the branch of anthropology that brings linguistic methods to bear on anthropological problems, linking the analysis of linguistic forms and processes to the interpretation of sociocultural processes. Linguistic anthropologists often draw on related fields including sociolinguistics, pragmatics, cognitive linguistics, semiotics, discourse analysis, and narrative analysis.Ethnography Ethnography is a method of analysing social or cultural interaction. It often involves participant observation though an ethnographer may also draw from texts written by participants of in social interactions. Ethnography views first-hand experience and social context as important.Tim Ingold distinguishes ethnography from anthropology arguing that anthropology tries to construct general theories of human experience, applicable in general and novel settings, while ethnography concerns itself with fidelity. He argues that the anthropologist must make his writing consistent with their understanding of literature and other theory, but notes that ethnography may be of use to the anthropologists and the fields inform one another.Key topics by field: socioculturalArt, media, music, dance and filmArt One of the central problems in the anthropology of art concerns the universality of 'art' as a cultural phenomenon. Several anthropologists have noted that the Western categories of 'painting', 'sculpture', or 'literature', conceived as independent artistic activities, do not exist, or exist in a significantly different form, in most non-Western contexts. To surmount this difficulty, anthropologists of art have focused on formal features in objects which, without exclusively being 'artistic', have certain evident 'aesthetic' qualities. Boas' Primitive Art, Claude Lévi-Strauss' The Way of the Masks (1982) or Geertz's 'Art as Cultural System' (1983) are some examples in this trend to transform the anthropology of 'art' into an anthropology of culturally specific 'aesthetics'.Media Media anthropology (also known as the anthropology of media or mass media) emphasizes ethnographic studies as a means of understanding producers, audiences, and other cultural and social aspects of mass media. The types of ethnographic contexts explored range from contexts of media production (e.g., ethnographies of newsrooms in newspapers, journalists in the field, film production) to contexts of media reception, following audiences in their everyday responses to media. Other types include cyber anthropology, a relatively new area of internet research, as well as ethnographies of other areas of research which happen to involve media, such as development work, social movements, or health education. This is in addition to many classic ethnographic contexts, where media such as radio, the press, new media, and television have started to make their presences felt since the early 1990s.Music Ethnomusicology is an academic field encompassing various approaches to the study of music (broadly defined), that emphasize its cultural, social, material, cognitive, biological, and other dimensions or contexts instead of or in addition to its isolated sound component or any particular repertoire.Ethnomusicology can be used in a wide variety of fields, such as teaching, politics, cultural anthropology etc.  While the origins of ethnomusicology date back to the 18th and 19th centuries, it was formally introduced as “ethnomusicology” by Dutch scholar Jaap Kunst around 1950. Later, the influence of study in this area spawned the creation of the periodical Ethnomusicology and the Society of Ethnomusicology.Visual Visual anthropology is concerned, in part, with the study and production of ethnographic photography, film and, since the mid-1990s, new media. While the term is sometimes used interchangeably with ethnographic film, visual anthropology also encompasses the anthropological study of visual representation, including areas such as performance, museums, art, and the production and reception of mass media. Visual representations from all cultures, such as sandpaintings, tattoos, sculptures and reliefs, cave paintings, scrimshaw, jewelry, hieroglyphics, paintings, and photographs are included in the focus of visual anthropology.Economic, political economic, applied and developmentEconomic Economic anthropology attempts to explain human economic behavior in its widest historic, geographic and cultural scope. It has a complex relationship with the discipline of economics, of which it is highly critical. Its origins as a sub-field of anthropology begin with the Polish-British founder of anthropology, Bronisław Malinowski, and his French compatriot, Marcel Mauss, on the nature of gift-giving exchange (or reciprocity) as an alternative to market exchange. Economic Anthropology remains, for the most part, focused upon exchange. The school of thought derived from Marx and known as Political Economy focuses on production, in contrast. Economic anthropologists have abandoned the primitivist niche they were relegated to by economists, and have now turned to examine corporations, banks, and the global financial system from an anthropological perspective.Political economyPolitical economy in anthropology is the application of the theories and methods of historical materialism to the traditional concerns of anthropology, including, but not limited to, non-capitalist societies. Political economy introduced questions of history and colonialism to ahistorical anthropological theories of social structure and culture. Three main areas of interest rapidly developed. The first of these areas was concerned with the "pre-capitalist" societies that were subject to evolutionary "tribal" stereotypes. Sahlin's work on hunter-gatherers as the "original affluent society" did much to dissipate that image. The second area was concerned with the vast majority of the world's population at the time, the peasantry, many of whom were involved in complex revolutionary wars such as in Vietnam. The third area was on colonialism, imperialism, and the creation of the capitalist world-system. More recently, these political economists have more directly addressed issues of industrial (and post-industrial) capitalism around the world.Applied Applied anthropology refers to the application of the method and theory of anthropology to the analysis and solution of practical problems. It is a "complex of related, research-based, instrumental methods which produce change or stability in specific cultural systems through the provision of data, initiation of direct action, and/or the formulation of policy". More simply, applied anthropology is the practical side of anthropological research; it includes researcher involvement and activism within the participating community. It is closely related to development anthropology (distinct from the more critical anthropology of development).DevelopmentAnthropology of development tends to view development from a critical perspective. The kind of issues addressed and implications for the approach simply involve pondering why, if a key development goal is to alleviate poverty, is poverty increasing? Why is there such a gap between plans and outcomes? Why are those working in development so willing to disregard history and the lessons it might offer? Why is development so externally driven rather than having an internal basis? In short, why does so much planned development fail?Kinship, feminism, gender and sexualityKinship Kinship can refer both to the study of the patterns of social relationships in one or more human cultures, or it can refer to the patterns of social relationships themselves. Over its history, anthropology has developed a number of related concepts and terms, such as "descent", "descent groups", "lineages", "affines", "cognates", and even "fictive kinship". Broadly, kinship patterns may be considered to include people related both by descent (one's social relations during development), and also relatives by marriage. Within kinship you have two different families. People have their biological families and it is the people they share DNA with. This is called consanguineal relations or "blood ties". People can also have a chosen family Finding Connection Through "Chosen Family" in which they chose who they want to be a part of their family. In some cases people are closer with their chosen family more than with their biological families.Feminist Feminist anthropology is a four field approach to anthropology (archeological, biological, cultural, linguistic) that seeks to reduce male bias in research findings, anthropological hiring practices, and the scholarly production of knowledge. Anthropology engages often with feminists from non-Western traditions, whose perspectives and experiences can differ from those of white feminists of Europe, America, and elsewhere. From the perspective of the Western world, historically such 'peripheral' perspectives have been ignored, observed only from an outsider perspective, and regarded as less-valid or less-important than knowledge from the Western world. Exploring and addressing that double bias against women from marginalized racial or ethnic groups is of particular interest in intersectional feminist anthropology.Feminist anthropologists have stated that their publications have contributed to anthropology, along the way correcting against the systemic biases beginning with the "patriarchal origins of anthropology (and (academia)" and note that from 1891 to 1930 doctorates in anthropology went to males more than 85%, more than 81% were under 35, and only 7.2% to anyone over 40 years old, thus reflecting an age gap in the pursuit of anthropology by first-wave feminists until later in life. This correction of systemic bias may include mainstream feminist theory, history, linguistics, archaeology, and anthropology. Feminist anthropologists are often concerned with the construction of gender across societies. Gender constructs are of particular interest when studying sexism.According to St. Clair Drake, Vera Mae Green was, until "[w]ell into the 1960s", the only African-American female anthropologist who was also a Caribbeanist. She studied ethnic and family relations in the Caribbean as well as the United States, and thereby tried to improve the way black life, experiences, and culture were studied. However, Zora Neale Hurston, although often primarily considered to be a literary author, was trained in anthropology by Franz Boas, and published Tell my Horse about her "anthropological observations" of voodoo in the Caribbean (1938).Feminist anthropology is inclusive of the anthropology of birth as a specialization, which is the anthropological study of pregnancy and childbirth within cultures and societies.Medical, nutritional, psychological, cognitive and transpersonalMedical Medical anthropology is an interdisciplinary field which studies "human health and disease, health care systems, and biocultural adaptation". It is believed that William Caudell was the first to discover the field of medical anthropology. Currently, research in medical anthropology is one of the main growth areas in the field of anthropology as a whole. It focuses on the following six basic fields:Other subjects that have become central to medical anthropology worldwide are violence and social suffering (Farmer, 1999, 2003; Beneduce, 2010) as well as other issues that involve physical and psychological harm and suffering that are not a result of illness. On the other hand, there are fields that intersect with medical anthropology in terms of research methodology and theoretical production, such as cultural psychiatry and transcultural psychiatry or ethnopsychiatry.Nutritional Nutritional anthropology is a synthetic concept that deals with the interplay between economic systems, nutritional status and food security, and how changes in the former affect the latter. If economic and environmental changes in a community affect access to food, food security, and dietary health, then this interplay between culture and biology is in turn connected to broader historical and economic trends associated with globalization. Nutritional status affects overall health status, work performance potential, and the overall potential for economic development (either in terms of human development or traditional western models) for any given group of people.Psychological Psychological anthropology is an interdisciplinary subfield of anthropology that studies the interaction of cultural and mental processes. This subfield tends to focus on ways in which humans' development and enculturation within a particular cultural group –  with its own history, language, practices, and conceptual categories –  shape processes of human cognition, emotion, perception, motivation, and mental health. It also examines how the understanding of cognition, emotion, motivation, and similar psychological processes inform or constrain our models of cultural and social processes.Cognitive Cognitive anthropology seeks to explain patterns of shared knowledge, cultural innovation, and transmission over time and space using the methods and theories of the cognitive sciences (especially experimental psychology and evolutionary biology) often through close collaboration with historians, ethnographers, archaeologists, linguists, musicologists and other specialists engaged in the description and interpretation of cultural forms. Cognitive anthropology is concerned with what people from different groups know and how that implicit knowledge changes the way people perceive and relate to the world around them.Transpersonal Transpersonal anthropology studies the relationship between altered states of consciousness and culture. As with transpersonal psychology, the field is much concerned with altered states of consciousness (ASC) and transpersonal experience. However, the field differs from mainstream transpersonal psychology in taking more cognizance of cross-cultural issues –  for instance, the roles of myth, ritual, diet, and texts in evoking and interpreting extraordinary experiences.Political and legalPolitical Political anthropology concerns the structure of political systems, looked at from the basis of the structure of societies. Political anthropology developed as a discipline concerned primarily with politics in stateless societies, a new development started from the 1960s, and is still unfolding: anthropologists started increasingly to study more "complex" social settings in which the presence of states, bureaucracies and markets entered both ethnographic accounts and analysis of local phenomena. The turn towards complex societies meant that political themes were taken up at two main levels. Firstly, anthropologists continued to study political organization and political phenomena that lay outside the state-regulated sphere (as in patron-client relations or tribal political organization). Secondly, anthropologists slowly started to develop a disciplinary concern with states and their institutions (and on the relationship between formal and informal political institutions). An anthropology of the state developed, and it is a most thriving field today. Geertz' comparative work on "Negara", the Balinese state, is an early, famous example.LegalLegal anthropology or anthropology of law specializes in "the cross-cultural study of social ordering". Earlier legal anthropological research often focused more narrowly on conflict management, crime, sanctions, or formal regulation. More recent applications include issues such as human rights, legal pluralism, and political uprisings.PublicPublic anthropology was created by Robert Borofsky, a professor at Hawaii Pacific University, to "demonstrate the ability of anthropology and anthropologists to effectively address problems beyond the discipline – illuminating larger social issues of our times as well as encouraging broad, public conversations about them with the explicit goal of fostering social change".Nature, science, and technologyCyborgCyborg anthropology originated as a sub-focus group within the American Anthropological Association's annual meeting in 1993. The sub-group was very closely related to STS and the Society for the Social Studies of Science. Donna Haraway's 1985 Cyborg Manifesto could be considered the founding document of cyborg anthropology by first exploring the philosophical and sociological ramifications of the term. Cyborg anthropology studies humankind and its relations with the technological systems it has built, specifically modern technological systems that have reflexively shaped notions of what it means to be human beings.Digital Digital anthropology is the study of the relationship between humans and digital-era technology, and extends to various areas where anthropology and technology intersect. It is sometimes grouped with sociocultural anthropology, and sometimes considered part of material culture. The field is new, and thus has a variety of names with a variety of emphases. These include techno-anthropology, digital ethnography, cyberanthropology, and virtual anthropology.Ecological Ecological anthropology is defined as the "study of cultural adaptations to environments". The sub-field is also defined as, "the study of relationships between a population of humans and their biophysical environment". The focus of its research concerns "how cultural beliefs and practices helped human populations adapt to their environments, and how their environments change across space and time. The contemporary perspective of environmental anthropology, and arguably at least the backdrop, if not the focus of most of the ethnographies and cultural fieldworks of today, is political ecology. Many characterize this new perspective as more informed with culture, politics and power, globalization, localized issues, century anthropology and more. The focus and data interpretation is often used for arguments for/against or creation of policy, and to prevent corporate exploitation and damage of land. Often, the observer has become an active part of the struggle either directly (organizing, participation) or indirectly (articles, documentaries, books, ethnographies). Such is the case with environmental justice advocate Melissa Checker and her relationship with the people of Hyde Park.Environment Social sciences, like anthropology, can provide interdisciplinary approaches to the environment. Professor Kay Milton, Director of the Anthropology research network in the School of History and Anthropology, describes anthropology as distinctive, with its most distinguishing feature being its interest in non-industrial indigenous and traditional societies. Anthropological theory is distinct because of the consistent presence of the concept of culture; not an exclusive topic but a central position in the study and a deep concern with the human condition. Milton describes three trends that are causing a fundamental shift in what characterizes anthropology: dissatisfaction with the cultural relativist perspective, reaction against cartesian dualisms which obstructs progress in theory (nature culture divide), and finally an increased attention to globalization (transcending the barriers or time/space).Environmental discourse appears to be characterized by a high degree of globalization. (The troubling problem is borrowing non indigenous practices and creating standards, concepts, philosophies and practices in western countries.) Anthropology and environmental discourse now have become a distinct position in anthropology as a discipline. Knowledge about diversities in human culture can be important in addressing environmental problems - anthropology is now a study of human ecology. Human activity is the most important agent in creating environmental change, a study commonly found in human ecology which can claim a central place in how environmental problems are examined and addressed. Other ways anthropology contributes to environmental discourse is by being theorists and analysts,  or by refinement of definitions to become more neutral/universal, etc. In exploring environmentalism - the term typically refers to a concern that the environment should be protected, particularly from the harmful effects of human activities. Environmentalism itself can be expressed in many ways. Anthropologists can open the doors of environmentalism by looking beyond industrial society, understanding the opposition between industrial and non industrial relationships, knowing what ecosystem people and biosphere people are and are affected by, dependent and independent variables, “primitive” ecological wisdom, diverse environments, resource management, diverse cultural traditions, and knowing that environmentalism is a part of culture.Historical Ethnohistory is the study of ethnographic cultures and indigenous customs by examining historical records. It is also the study of the history of various ethnic groups that may or may not exist today. Ethnohistory uses both historical and ethnographic data as its foundation. Its historical methods and materials go beyond the standard use of documents and manuscripts. Practitioners recognize the utility of such source material as maps, music, paintings, photography, folklore, oral tradition, site exploration, archaeological materials, museum collections, enduring customs, language, and place names.Religion The anthropology of religion involves the study of religious institutions in relation to other social institutions, and the comparison of religious beliefs and practices across cultures. Modern anthropology assumes that there is complete continuity between magical thinking and religion, and that every religion is a cultural product, created by the human community that worships it.Urban Urban anthropology is concerned with issues of urbanization, poverty, and neoliberalism. Ulf Hannerz quotes a 1960s remark that traditional anthropologists were "a notoriously agoraphobic lot, anti-urban by definition". Various social processes in the Western World as well as in the "Third World" (the latter being the habitual focus of attention of anthropologists) brought the attention of "specialists in 'other cultures'" closer to their homes. There are two main approaches to urban anthropology: examining the types of cities or examining the social issues within the cities. These two methods are overlapping and dependent of each other. By defining different types of cities, one would use social factors as well as economic and political factors to categorize the cities. By directly looking at the different social issues, one would also be studying how they affect the dynamic of the city.Key topics by field: archaeological and biologicalAnthrozoology Anthrozoology (also known as "human–animal studies") is the study of interaction between living things. It is an interdisciplinary field that overlaps with a number of other disciplines, including anthropology, ethology, medicine, psychology, veterinary medicine and zoology. A major focus of anthrozoologic research is the quantifying of the positive effects of human-animal relationships on either party and the study of their interactions. It includes scholars from a diverse range of fields, including anthropology, sociology, biology, and philosophy.Biocultural Biocultural anthropology is the scientific exploration of the relationships between human biology and culture. Physical anthropologists throughout the first half of the 20th century viewed this relationship from a racial perspective; that is, from the assumption that typological human biological differences lead to cultural differences. After World War II the emphasis began to shift toward an effort to explore the role culture plays in shaping human biology.Evolutionary Evolutionary anthropology is the interdisciplinary study of the evolution of human physiology and human behaviour and the relation between hominins and non-hominin primates. Evolutionary anthropology is based in natural science and social science, combining the human development with socioeconomic factors. Evolutionary anthropology is concerned with both biological and cultural evolution of humans, past and present. It is based on a scientific approach, and brings together fields such as archaeology, behavioral ecology, psychology, primatology, and genetics. It is a dynamic and interdisciplinary field, drawing on many lines of evidence to understand the human experience, past and present.Forensic Forensic anthropology is the application of the science of physical anthropology and human osteology in a legal setting, most often in criminal cases where the victim's remains are in the advanced stages of decomposition. A forensic anthropologist can assist in the identification of deceased individuals whose remains are decomposed, burned, mutilated or otherwise unrecognizable. The adjective "forensic" refers to the application of this subfield of science to a court of law.Palaeoanthropology Paleoanthropology combines the disciplines of paleontology and physical anthropology. It is the study of ancient humans, as found in fossil hominid evidence such as petrifacted bones and footprints. Genetics and morphology of specimens are crucially important to this field. Markers on specimens, such as enamel fractures and dental decay on teeth, can also give insight into the behaviour and diet of past populations.Organizations Contemporary anthropology is an established science with academic departments at most universities and colleges. The single largest organization of anthropologists is the American Anthropological Association (AAA), which was founded in 1903. Its members are anthropologists from around the globe.In 1989, a group of European and American scholars in the field of anthropology established the European Association of Social Anthropologists (EASA) which serves as a major professional organization for anthropologists working in Europe. The EASA seeks to advance the status of anthropology in Europe and to increase visibility of marginalized anthropological traditions and thereby contribute to the project of a global anthropology or world anthropology.Hundreds of other organizations exist in the various sub-fields of anthropology, sometimes divided up by nation or region, and many anthropologists work with collaborators in other disciplines, such as geology, physics, zoology, paleontology, anatomy, music theory, art history, sociology and so on, belonging to professional societies in those disciplines as well.List of major organizations American Anthropological Association American Ethnological Society Asociación de Antropólogos Iberoamericanos en Red, AIBR Moving Anthropology Student Network Anthropological Society of London Center for World Indigenous Studies Ethnological Society of London Max Planck Institute for Evolutionary Anthropology Network of Concerned Anthropologists N.N. Miklukho-Maklai Institute of Ethnology and Anthropology Royal Anthropological Institute of Great Britain and Ireland Society for anthropological sciences Society for Applied Anthropology USC Center for Visual AnthropologyEthicsAs the field has matured it has debated and arrived at ethical principles aimed at protecting both the subjects of anthropological research as well as the researchers themselves, and professional societies have generated codes of ethics.Anthropologists, like other researchers (especially historians and scientists engaged in field research), have over time assisted state policies and projects, especially colonialism.Some commentators have contended: That the discipline grew out of colonialism, perhaps was in league with it, and derives some of its key notions from it, consciously or not. (See, for example, Gough, Pels and Salemink, but cf. Lewis 2004). That ethnographic work is often ahistorical, writing about people as if they were "out of time" in an "ethnographic present" (Johannes Fabian, Time and Its Other).In his article "The Misrepresentation of Anthropology and Its Consequence," Herbert S. Lewis critiqued older anthropological works that presented other cultures as if they were strange and unusual. While the findings of those researchers should not be discarded, the field should learn from its mistakes.Cultural relativism As part of their quest for scientific objectivity, present-day anthropologists typically urge cultural relativism, which has an influence on all the sub-fields of anthropology. This is the notion that cultures should not be judged by another's values or viewpoints, but be examined dispassionately on their own terms. There should be no notions, in good anthropology, of one culture being better or worse than another culture.Ethical commitments in anthropology include noticing and documenting genocide, infanticide, racism, sexism, mutilation (including circumcision and subincision), and torture. Topics like racism, slavery, and human sacrifice attract anthropological attention and theories ranging from nutritional deficiencies, to genes, to acculturation, to colonialism, have been proposed to explain their origins and continued recurrences.To illustrate the depth of an anthropological approach, one can take just one of these topics, such as "racism" and find thousands of anthropological references, stretching across all the major and minor sub-fields.Military involvementAnthropologists' involvement with the U.S. government, in particular, has caused bitter controversy within the discipline. Franz Boas publicly objected to US participation in World War I, and after the war he published a brief expose and condemnation of the participation of several American archaeologists in espionage in Mexico under their cover as scientists.But by the 1940s, many of Boas' anthropologist contemporaries were active in the allied war effort against the Axis Powers (Nazi Germany, Fascist Italy, and Imperial Japan). Many served in the armed forces, while others worked in intelligence (for example, Office of Strategic Services and the Office of War Information). At the same time, David H. Price's work on American anthropology during the Cold War provides detailed accounts of the pursuit and dismissal of several anthropologists from their jobs for communist sympathies.Attempts to accuse anthropologists of complicity with the CIA and government intelligence activities during the Vietnam War years have turned up surprisingly little. Many anthropologists (students and teachers) were active in the antiwar movement. Numerous resolutions condemning the war in all its aspects were passed overwhelmingly at the annual meetings of the American Anthropological Association (AAA).Professional anthropological bodies often object to the use of anthropology for the benefit of the state. Their codes of ethics or statements may proscribe anthropologists from giving secret briefings. The Association of Social Anthropologists of the UK and Commonwealth (ASA) has called certain scholarship ethically dangerous. The "Principles of Professional Responsibility" issued by the American Anthropological Association and amended through November 1986 stated that "in relation with their own government and with host governments ... no secret research, no secret reports or debriefings of any kind should be agreed to or given." The current "Principles of Professional Responsibility" does not make explicit mention of ethics surrounding state interactions.Anthropologists, along with other social scientists, are working with the US military as part of the US Army's strategy in Afghanistan. The Christian Science Monitor reports that "Counterinsurgency efforts focus on better grasping and meeting local needs" in Afghanistan, under the Human Terrain System (HTS) program; in addition, HTS teams are working with the US military in Iraq. In 2009, the American Anthropological Association's Commission on the Engagement of Anthropology with the US Security and Intelligence Communities released its final report concluding, in part, that, "When ethnographic investigation is determined by military missions, not subject to external review, where data collection occurs in the context of war, integrated into the goals of counterinsurgency, and in a potentially coercive environment – all characteristic factors of the HTS concept and its application – it can no longer be considered a legitimate professional exercise of anthropology. In summary, while we stress that constructive engagement between anthropology and the military is possible, CEAUSSIC suggests that the AAA emphasize the incompatibility of HTS with disciplinary ethics and practice for job seekers and that it further recognize the problem of allowing HTS to define the meaning of "anthropology" within DoD."Post–World War II developmentsBefore WWII British 'social anthropology' and American 'cultural anthropology' were still distinct traditions. After the war, enough British and American anthropologists borrowed ideas and methodological approaches from one another that some began to speak of them collectively as 'sociocultural' anthropology.Basic trendsThere are several characteristics that tend to unite anthropological work. One of the central characteristics is that anthropology tends to provide a comparatively more holistic account of phenomena and tends to be highly empirical. The quest for holism leads most anthropologists to study a particular place, problem or phenomenon in detail, using a variety of methods, over a more extensive period than normal in many parts of academia.In the 1990s and 2000s, calls for clarification of what constitutes a culture, of how an observer knows where his or her own culture ends and another begins, and other crucial topics in writing anthropology were heard. These dynamic relationships, between what can be observed on the ground, as opposed to what can be observed by compiling many local observations remain fundamental in any kind of anthropology, whether cultural, biological, linguistic or archaeological.Biological anthropologists are interested in both human variation and in the possibility of human universals (behaviors, ideas or concepts shared by virtually all human cultures). They use many different methods of study, but modern population genetics, participant observation and other techniques often take anthropologists "into the field," which means traveling to a community in its own setting, to do something called "fieldwork."  On the biological or physical side, human measurements, genetic samples, nutritional data may be gathered and published as articles or monographs.Along with dividing up their project by theoretical emphasis, anthropologists typically divide the world up into relevant time periods and geographic regions. Human time on Earth is divided up into relevant cultural traditions based on material, such as the Paleolithic and the Neolithic, of particular use in archaeology. Further cultural subdivisions according to tool types, such as Olduwan or Mousterian or Levalloisian help archaeologists and other anthropologists in understanding major trends in the human past. Anthropologists and geographers share approaches to culture regions as well, since mapping cultures is central to both sciences. By making comparisons across cultural traditions (time-based) and cultural regions (space-based), anthropologists have developed various kinds of comparative method, a central part of their science.Commonalities between fieldsBecause anthropology developed from so many different enterprises (see History of anthropology), including but not limited to fossil-hunting, exploring, documentary film-making, paleontology, primatology, antiquity dealings and curatorship, philology, etymology, genetics, regional analysis, ethnology, history, philosophy, and religious studies, it is difficult to characterize the entire field in a brief article, although attempts to write histories of the entire field have been made.Some authors argue that anthropology originated and developed as the study of "other cultures", both in terms of time (past societies) and space (non-European/non-Western societies). For example, the classic of urban anthropology, Ulf Hannerz in the introduction to his seminal Exploring the City: Inquiries Toward an Urban Anthropology mentions that the "Third World" had habitually received most of attention; anthropologists who traditionally specialized in "other cultures" looked for them far away and started to look "across the tracks" only in late 1960s.Now there exist many works focusing on peoples and topics very close to the author's "home". It is also argued that other fields of study, like History and Sociology, on the contrary focus disproportionately on the West.In France, the study of Western societies has been traditionally left to sociologists, but this is increasingly changing, starting in the 1970s from scholars like Isac Chiva and journals like Terrain ("fieldwork"), and developing with the center founded by Marc Augé (Le Centre d'anthropologie des mondes contemporains, the Anthropological Research Center of Contemporary Societies).Since the 1980s it has become common for social and cultural anthropologists to set ethnographic research in the North Atlantic region, frequently examining the connections between locations rather than limiting research to a single locale. There has also been a related shift toward broadening the focus beyond the daily life of ordinary people; increasingly, research is set in settings such as scientific laboratories, social movements, governmental and nongovernmental organizations and businesses.See also Anthropological science fiction Christian anthropology, a sub-field of theology Circumscription theory Culture Dual inheritance theory Engaged theory Ethnobiology Human behavioral ecology Human ethology Human Relations Area Files Intangible cultural heritage Origins of society Philosophical anthropology, a sub-field of philosophy Prehistoric medicine Qualitative researchLists Outline of anthropology List of indigenous peoples List of anthropologistsNotesReferencesFurther readingDictionaries and encyclopediasFieldnotes and memoirsHistories            .Textbooks and key theoretical worksExternal links               (AIO)
Agricultural science (or agriscience for short) is a broad multidisciplinary field of biology that encompasses the parts of exact, natural, economic and social sciences that are used in the practice and understanding of agriculture. Professionals of the agricultural science are called agricultural scientists or agriculturists.HistoryIn the 18th century, Johann Friedrich Mayer conducted experiments on the use of gypsum (hydrated calcium sulphate) as a fertilizer.In 1843, John Lawes and Joseph Henry Gilbert began a set of long-term field experiments at Rothamsted Research Station in England, some of which are still running as of 2018.In the United States, a scientific revolution in agriculture began with the Hatch Act of 1887, which used the term "agricultural science". The Hatch Act was driven by farmers' interest in knowing the constituents of early artificial fertilizer. The Smith-Hughes Act of 1917 shifted agricultural education back to its vocational roots, but the scientific foundation had been built. After 1906, public expenditures on agricultural research in the US exceeded private expenditures for the next 44 years.Prominent agricultural scientists Robert Bakewell Norman Borlaug Luther Burbank George Washington Carver Carl Henry Clerk George C. Clerk René Dumont Sir Albert Howard Kailas Nath KaulThomas Lecky Justus von Liebig Jay Lush Gregor Mendel Louis Pasteur M. S. Swaminathan Jethro Tull Artturi Ilmari Virtanen Sewall Wright Wilbur Olin AtwaterFields or related disciplines Agricultural biotechnology Agricultural chemistry Agricultural diversification Agricultural education Agricultural economics Agricultural engineering Agricultural geography Agricultural philosophy Agricultural marketing Agricultural soil science Agroecology Agrophysics Animal science Animal breeding Animal husbandry Animal nutrition Farm management Agronomy Botany Theoretical production ecology Horticulture Plant breeding Plant fertilization Aquaculture Biological engineering Genetic engineering Nematology Microbiology Plant pathologyRange management Environmental science Entomology Food science Human nutrition Irrigation and water management Soil science Agrology Waste management Weed scienceScopeAgriculture, agricultural science, and agronomy are often confused. However, they cover different concepts:Agriculture is the set of activities that transform the environment for the production of animals and plants for human use. Agriculture concerns techniques, including the application of agronomic research.Agronomy is research and development related to studying and improving plant-based crops.Soil forming factors and soil degradationAgricultural sciences include research and development on: Improving agricultural productivity in terms of quantity and quality (e.g., selection of drought-resistant crops and animals, development of new pesticides, yield-sensing technologies, simulation models of crop growth, in-vitro cell culture techniques) Minimizing the effects of pests (weeds, insects, pathogens, mollusks, nematodes) on crop or animal production systems. Transformation of primary products into end-consumer products (e.g., production, preservation, and packaging of dairy products) Prevention and correction of adverse environmental effects (e.g., soil degradation, waste management, bioremediation) Theoretical production ecology, relating to crop production modeling Traditional agricultural systems, sometimes termed subsistence agriculture, which feed most of the poorest people in the world.  These systems are of interest as they sometimes retain a level of integration with natural ecological systems greater than that of industrial agriculture, which may be more sustainable than some modern agricultural systems. Food production and demand on a global basis, with special attention paid to the major producers, such as China, India, Brazil, the US and the EU. Various sciences relating to agricultural resources and the environment (e.g. soil science, agroclimatology); biology of agricultural crops and animals (e.g. crop science, animal science and their included sciences, e.g. ruminant nutrition, farm animal welfare); such fields as agricultural economics and rural sociology; various disciplines encompassed in agricultural engineering.See also Agricultural Research Council Agricultural sciences basic topics Agriculture ministry Agroecology American Society of Agronomy Genomics of domestication History of agricultural science Institute of Food and Agricultural Sciences International Assessment of Agricultural Science and Technology for Development International Food Policy Research Institute, IFPRI List of agriculture topics National FFA Organization Research Institute of Crop Production (RICP) (in the Czech Republic) University of Agricultural SciencesReferencesFurther readingAgricultural Research, Livelihoods, and Poverty: Studies of Economic and Social Impacts in Six Countries Edited by Michelle Adato and Ruth Meinzen-Dick (2007), Johns Hopkins University Press Food Policy ReportClaude Bourguignon, Regenerating the Soil: From Agronomy to Agrology, Other India Press, 2005Pimentel David, Pimentel Marcia, Computer les kilocalories, Cérès, n. 59, sept-oct. 1977Russell E. Walter, Soil conditions and plant growth, Longman group, London, New York 1973 Saltini Antonio, Storia delle scienze agrarie, 4 vols, Bologna 1984–89, , , , Vavilov Nicolai I. (Starr Chester K. editor), The Origin, Variation, Immunity and Breeding of Cultivated Plants. Selected Writings, in Chronica botanica, 13: 1–6, Waltham, Mass., 1949–50Vavilov Nicolai I., World Resources of Cereals, Leguminous Seed Crops and Flax, Academy of Sciences of Urss, National Science Foundation, Washington, Israel Program for Scientific Translations, Jerusalem 1960Winogradsky Serge, Microbiologie du sol. Problèmes et methodes. Cinquante ans de recherches, Masson & c.ie, Paris 1949External linksConsultative Group on International Agricultural Research (CGIAR)Agricultural Research ServiceIndian Council of Agricultural ResearchInternational Institute of Tropical AgricultureInternational Livestock Research InstituteThe National Agricultural Library (NAL) - The most comprehensive agricultural library in the world.Crop Science Society of AmericaAmerican Society of AgronomySoil Science Society of AmericaAgricultural Science Researchers, Jobs and DiscussionsInformation System for Agriculture and Food ResearchSouth Dakota Agricultural LaboratoriesNMSU Department of Entomology Plant Pathology and Weed ScienceUP AgricultureBihar Agriculture
Alchemy (from Arabic: al-kīmiyā; from Ancient Greek: khumeía) is an ancient branch of natural philosophy, a philosophical and protoscientific tradition that was historically practiced in China, India, the Muslim world, and Europe. In its Western form, alchemy is first attested in a number of pseudepigraphical texts written in Greco-Roman Egypt during the first few centuries CE.Alchemists attempted to purify, mature, and perfect certain materials. Common aims were chrysopoeia, the transmutation of "base metals" (e.g., lead) into "noble metals" (particularly gold); the creation of an elixir of immortality; and the creation of panaceas able to cure any disease. The perfection of the human body and soul was thought to result from the alchemical magnum opus ("Great Work"). The concept of creating the philosophers' stone was variously connected with all of these projects.Islamic and European alchemists developed a basic set of laboratory techniques, theories, and terms, some of which are still in use today. They did not abandon the Ancient Greek philosophical idea that everything is composed of four elements, and they tended to guard their work in secrecy, often making use of cyphers and cryptic symbolism. In Europe, the 12th-century translations of medieval Islamic works on science and the rediscovery of Aristotelian philosophy gave birth to a flourishing tradition of Latin alchemy. This late medieval tradition of alchemy would go on to play a significant role in the development of early modern science (particularly chemistry and medicine).Modern discussions of alchemy are generally split into an examination of its exoteric practical applications and its esoteric spiritual aspects, despite criticisms by scholars such as Eric J. Holmyard and Marie-Louise von Franz that they should be understood as complementary. The former is pursued by historians of the physical sciences, who examine the subject in terms of early chemistry, medicine, and charlatanism, and the philosophical and religious contexts in which these events occurred. The latter interests historians of esotericism, psychologists, and some philosophers and spiritualists. The subject has also made an ongoing impact on literature and the arts.Etymology The word alchemy comes from Old French alquemie, alkimie, used in Medieval Latin as . This name was itself brought from the Arabic word al-kīmiyā ( or ) composed of two parts: the Late Greek term khēmeía (χημεία), also spelled khumeia (χυμεία) and khēmía (χημία) - see below, and the Arabic definite article al-  (), meaning 'The'. Together this association can be interpreted as 'the process of transmutation by which to fuse or reunite with the divine or original form'. Several etymologies have been proposed for the Greek term. The first was proposed by Zosimos of Panopolis (3rd–4th centuries), who derived it from the name of a book, the Khemeu. Hermanm Diels argued in 1914 that it rather derived from χύμα, used to describe metallic objects formed by casting.Others trace its roots to the Egyptian name kēme (hieroglyphic 𓆎𓅓𓏏𓊖 khmi ), meaning 'black earth', which refers to the fertile and auriferous soil of the Nile valley, as opposed to red desert sand. According to the Egyptologist Wallis Budge, the Arabic word al-kīmiyaʾ actually means "the Egyptian [science]", borrowing from the Coptic word for "Egypt", kēme (or its equivalent in the Mediaeval Bohairic dialect of Coptic, khēme). This Coptic word derives from Demotic kmỉ, itself from ancient Egyptian kmt. The ancient Egyptian word referred to both the country and the colour "black" (Egypt was the "Black Land", by contrast with the "Red Land", the surrounding desert); so this etymology could also explain the nickname "Egyptian black arts".History Alchemy encompasses several philosophical traditions spanning some four millennia and three continents. These traditions' general penchant for cryptic and symbolic language makes it hard to trace their mutual influences and "genetic" relationships. One can distinguish at least three major strands, which appear to be mostly independent, at least in their earlier stages: Chinese alchemy, centered in China and Indian alchemy, centered on the Indian subcontinent; and Western alchemy, which occurred around the Mediterranean and whose center has shifted over the millennia from Greco-Roman Egypt to the Islamic world, and finally medieval Europe. Chinese alchemy was closely connected to Taoism and Indian alchemy with the Dharmic faiths. In contrast, Western alchemy developed its philosophical system mostly independent of but influenced by various Western religions. It is still an open question whether these three strands share a common origin, or to what extent they influenced each other.Hellenistic Egypt The start of Western alchemy may generally be traced to ancient and Hellenistic Egypt, where the city of Alexandria  was a center of alchemical knowledge, and retained its pre-eminence through most of the Greek and Roman periods. Following the work of André-Jean Festugière, modern scholars see alchemical practice in the Roman Empire as originating from the Egyptian goldsmith's art, Greek philosophy and different religious traditions. Tracing the origins of the alchemical art in Egypt is complicated by the pseudepigraphic nature of texts from the Greek alchemical corpus. The treatises of Zosimos of Panopolis, the earliest historically attested author (fl. c. 300 CE), can help in situating the other authors. Zosimus based his work on that of older alchemical authors, such as Mary the Jewess, Pseudo-Democritus, and Agathodaimon, but very little is known about any of these authors. The most complete of their works, The Four Books of Pseudo-Democritus, were probably written in the first century AD.Recent scholarship tends to emphasize the testimony of Zosimus, who traced the alchemical arts back to Egyptian metallurgical and ceremonial practices. It has also been argued that early alchemical writers borrowed the vocabulary of Greek philosophical schools but did not implement any of its doctrines in a systematic way. Zosimos of Panopolis wrote in the Final Abstinence (also known as the "Final Count"). Zosimos explains that the ancient practice of "tinctures" (the technical Greek name for the alchemical arts) had been taken over by certain "demons" who taught the art only to those who offered them sacrifices. Since Zosimos also called the demons "guardians of places" (οἱ κατὰ τόπον ἔφοροι) and those who offered them sacrifices "priests" (ἱερέα), it is fairly clear that he was referring to the gods of Egypt and their priests. While critical of the kind of alchemy he associated with the Egyptian priests and their followers, Zosimos nonetheless saw the tradition's recent past as rooted in the rites of the Egyptian temples.Mythology – Zosimos of Panopolis asserted that alchemy dated back to Pharaonic Egypt where it was the domain of the priestly class, though there is little to no evidence for his assertion. Alchemical writers used Classical figures from Greek, Roman, and Egyptian mythology to illuminate their works and allegorize alchemical transmutation. These included the pantheon of gods related to the Classical planets, Isis, Osiris, Jason, and many others.The central figure in the mythology of alchemy is Hermes Trismegistus (or Thrice-Great Hermes). His name is derived from the god Thoth and his Greek counterpart Hermes. Hermes and his caduceus or serpent-staff, were among alchemy's principal symbols. According to Clement of Alexandria, he wrote what were called the "forty-two books of Hermes", covering all fields of knowledge. The Hermetica of Thrice-Great Hermes is generally understood to form the basis for Western alchemical philosophy and practice, called the hermetic philosophy by its early practitioners. These writings were collected in the first centuries of the common era.Technology – The dawn of Western alchemy is sometimes associated with that of metallurgy, extending back to 3500 BC. Many writings were lost when the Roman emperor Diocletian ordered the burning of alchemical books after suppressing a revolt in Alexandria (AD 292). Few original Egyptian documents on alchemy have survived, most notable among them the Stockholm papyrus and the Leyden papyrus X. Dating from AD 250–300, they contained recipes for dyeing and making artificial gemstones, cleaning and fabricating pearls, and manufacturing of imitation gold and silver. These writings lack the mystical, philosophical elements of alchemy, but do contain the works of Bolus of Mendes (or Pseudo-Democritus), which aligned these recipes with theoretical knowledge of astrology and the classical elements. Between the time of Bolus and Zosimos, the change took place that transformed this metallurgy into a Hermetic art.Philosophy – Alexandria acted as a melting pot for philosophies of Pythagoreanism, Platonism, Stoicism and Gnosticism which formed the origin of alchemy's character. An important example of alchemy's roots in Greek philosophy, originated by Empedocles and developed by Aristotle, was that all things in the universe were formed from only four elements: earth, air, water, and fire. According to Aristotle, each element had a sphere to which it belonged and to which it would return if left undisturbed. The four elements of the Greek were mostly qualitative aspects of matter, not quantitative, as our modern elements are; "...True alchemy never regarded earth, air, water, and fire as corporeal or chemical substances in the present-day sense of the word. The four elements are simply the primary, and most general, qualities by means of which the amorphous and purely quantitative substance of all bodies first reveals itself in differentiated form." Later alchemists extensively developed the mystical aspects of this concept.Alchemy coexisted alongside emerging Christianity. Lactantius believed Hermes Trismegistus had prophesied its birth. St Augustine later affirmed this in the 4th & 5th centuries, but also condemned Trismegistus for idolatry. Examples of Pagan, Christian, and Jewish alchemists can be found during this period.Most of the Greco-Roman alchemists preceding Zosimos are known only by pseudonyms, such as Moses, Isis, Cleopatra, Democritus, and Ostanes. Others authors such as Komarios, and Chymes, we only know through fragments of text. After AD 400, Greek alchemical writers occupied themselves solely in commenting on the works of these predecessors. By the middle of the 7th century alchemy was almost an entirely mystical discipline. It was at that time that Khalid Ibn Yazid sparked its migration from Alexandria to the Islamic world, facilitating the translation and preservation of Greek alchemical texts in the 8th and 9th centuries.Byzantium Greek alchemy is preserved in medieval Greek (Byzantine) manuscripts, and yet historians have only relatively recently begun to pay attention to the study and development of Greek alchemy in the Byzantine period.India The 2nd millennium BC text Vedas describe a connection between eternal life and gold. A considerable knowledge of metallurgy has been exhibited in a third-century CE text called Arthashastra which provides ingredients of explosives (Agniyoga) and salts extracted from fertile soils and plant remains (Yavakshara) such as saltpetre/nitre, perfume making (different qualities of perfumes are mentioned), granulated (refined) Sugar. Buddhist texts from the 2nd to 5th centuries mention the transmutation of base metals to gold. According to some scholars Greek alchemy may have influenced Indian alchemy but there are no hard evidences to back this claim.The 11th-century Persian chemist and physician Abū Rayhān Bīrūnī, who visited Gujarat as part of the court of Mahmud of Ghazni, reported that theyThe goals of alchemy in India included the creation of a divine body (Sanskrit divya-deham) and immortality while still embodied (Sanskrit jīvan-mukti).  Sanskrit alchemical texts include much material on the manipulation of mercury and sulphur, that are homologized with the semen of the god Śiva and the menstrual blood of the goddess Devī.Some early alchemical writings seem to have their origins in the Kaula tantric schools associated to the teachings of the personality of Matsyendranath.  Other early writings are found in the Jaina medical treatise Kalyāṇakārakam of Ugrāditya, written in South India in the early 9th century.Two famous early Indian alchemical authors were Nāgārjuna Siddha and Nityanātha Siddha. Nāgārjuna Siddha was a Buddhist monk. His book, Rasendramangalam, is an example of Indian alchemy and medicine. Nityanātha Siddha wrote Rasaratnākara, also a highly influential work. In Sanskrit, rasa translates to "mercury", and Nāgārjuna Siddha was said to have developed a method of converting mercury into gold.Scholarship on Indian alchemy is in the publication of The Alchemical Body by David Gordon White. A modern bibliography on Indian alchemical studies has been written by White.The contents of 39 Sanskrit alchemical treatises have been analysed in detail in G. Jan Meulenbeld's History of Indian Medical Literature. The discussion of these works in HIML gives a summary of the contents of each work, their special features, and where possible the evidence concerning their dating. Chapter 13 of HIML, Various works on rasaśāstra and ratnaśāstra (or Various works on alchemy and gems) gives brief details of a further 655 (six hundred and fifty-five) treatises.  In some cases Meulenbeld gives notes on the contents and authorship of these works; in other cases references are made only to the unpublished manuscripts of these titles.A great deal remains to be discovered about Indian alchemical literature.  The content of the Sanskrit alchemical corpus has not yet (2014) been adequately integrated into the wider general history of alchemy.Islamic world After the Fall of the Roman Empire, the focus of alchemical development moved to the Islamic World. Much more is known about Islamic alchemy because it was better documented: indeed, most of the earlier writings that have come down through the years were preserved as Arabic translations. The word alchemy itself was derived from the Arabic word al-kīmiyā (الكيمياء). The early Islamic world was a melting pot for alchemy. Platonic and Aristotelian thought, which had already been somewhat appropriated into hermetical science, continued to be assimilated during the late 7th and early 8th centuries through Syriac translations and scholarship.In the late ninth and early tenth centuries, the Arabic works attributed to Jābir ibn Hayyān (Latinized as "Geber" or "Geberus") introduced a new approach to alchemy. Paul Kraus, who wrote the standard reference work on Jabir, put it as follows:Islamic philosophers also made great contributions to alchemical hermeticism. The most influential author in this regard was arguably Jabir. Jabir's ultimate goal was Takwin, the artificial creation of life in the alchemical laboratory, up to, and including, human life. He analyzed each Aristotelian element in terms of four basic qualities of hotness, coldness, dryness, and moistness. According to Jabir, in each metal two of these qualities were interior and two were exterior. For example, lead was externally cold and dry, while gold was hot and moist. Thus, Jabir theorized, by rearranging the qualities of one metal, a different metal would result. By this reasoning, the search for the philosopher's stone was introduced to Western alchemy. Jabir developed an elaborate numerology whereby the root letters of a substance's name in Arabic, when treated with various transformations, held correspondences to the element's physical properties.The elemental system used in medieval alchemy also originated with Jabir. His original system consisted of seven elements, which included the five classical elements (aether, air, earth, fire, and water) in addition to two chemical elements representing the metals: sulphur, "the stone which burns", which characterized the principle of combustibility, and mercury, which contained the idealized principle of metallic properties. Shortly thereafter, this evolved into eight elements, with the Arabic concept of the three metallic principles: sulphur giving flammability or combustion, mercury giving volatility and stability, and salt giving solidity. The atomic theory of corpuscularianism, where all physical bodies possess an inner and outer layer of minute particles or corpuscles, also has its origins in the work of Jabir.From the 9th to 14th centuries, alchemical theories faced criticism from a variety of practical Muslim chemists, including Alkindus, Abū al-Rayhān al-Bīrūnī, Avicenna and Ibn Khaldun. In particular, they wrote refutations against the idea of the transmutation of metals.East Asia Whereas European alchemy eventually centered on the transmutation of base metals into noble metals, Chinese alchemy had a more obvious connection to medicine. The philosopher's stone of European alchemists can be compared to the Grand Elixir of Immortality sought by Chinese alchemists. In the hermetic view, these two goals were not unconnected, and the philosopher's stone was often equated with the universal panacea; therefore, the two traditions may have had more in common than initially appears.Black powder may have been an important invention of Chinese alchemists. As previously stated above, Chinese alchemy was more related to medicine. It is said that the Chinese invented gunpowder while trying to find a potion for eternal life. Described in 9th-century texts and used in fireworks in China by the 10th century, it was used in cannons by 1290. From China, the use of gunpowder spread to Japan, the Mongols, the Muslim world, and Europe. Gunpowder was used by the Mongols against the Hungarians in 1241, and in Europe by the 14th century.Chinese alchemy was closely connected to Taoist forms of traditional Chinese medicine, such as Acupuncture and Moxibustion. In the early Song dynasty, followers of this Taoist idea (chiefly the elite and upper class) would ingest mercuric sulfide, which, though tolerable in low levels, led many to suicide. Thinking that this consequential death would lead to freedom and access to the Taoist heavens, the ensuing deaths encouraged people to eschew this method of alchemy in favor of external sources (the aforementioned Tai Chi Chuan, mastering of the qi, etc.)  Chinese alchemy was introduced to the West by Obed Simon Johnson.Medieval Europe The introduction of alchemy to Latin Europe may be dated to 11 February 1144, with the completion of Robert of Chester's translation of the Arabic Book of the Composition of Alchemy. Although European craftsmen and technicians pre-existed, Robert notes in his preface that alchemy (though here still referring to the elixir rather than to the art itself) was unknown in Latin Europe at the time of his writing. The translation of Arabic texts concerning numerous disciplines including alchemy flourished in 12th-century Toledo, Spain, through contributors like Gerard of Cremona and Adelard of Bath. Translations of the time included the Turba Philosophorum, and the works of Avicenna and Muhammad ibn Zakariya al-Razi. These brought with them many new words to the European vocabulary for which there was no previous Latin equivalent. Alcohol, carboy, elixir, and athanor are examples.Meanwhile, theologian contemporaries of the translators made strides towards the reconciliation of faith and experimental rationalism, thereby priming Europe for the influx of alchemical thought. The 11th-century St Anselm put forth the opinion that faith and rationalism were compatible and encouraged rationalism in a Christian context. In the early 12th century, Peter Abelard followed Anselm's work, laying down the foundation for acceptance of Aristotelian thought before the first works of Aristotle had reached the West. In the early 13th century, Robert Grosseteste used Abelard's methods of analysis and added the use of observation, experimentation, and conclusions when conducting scientific investigations. Grosseteste also did much work to reconcile Platonic and Aristotelian thinking.Through much of the 12th and 13th centuries, alchemical knowledge in Europe remained centered on translations, and new Latin contributions were not made. The efforts of the translators were succeeded by that of the encyclopaedists. In the 13th century, Albertus Magnus and Roger Bacon were the most notable of these, their work summarizing and explaining the newly imported alchemical knowledge in Aristotelian terms. Albertus Magnus, a Dominican friar, is known to have written works such as the Book of Minerals where he observed and commented on the operations and theories of alchemical authorities like Hermes and Democritus and unnamed alchemists of his time. Albertus critically compared these to the writings of Aristotle and Avicenna, where they concerned the transmutation of metals. From the time shortly after his death through to the 15th century, more than 28 alchemical tracts were misattributed to him, a common practice giving rise to his reputation as an accomplished alchemist. Likewise, alchemical texts have been attributed to Albert's student Thomas Aquinas.Roger Bacon, a Franciscan friar who wrote on a wide variety of topics including optics, comparative linguistics, and medicine, composed his Great Work () for  as part of a project towards rebuilding the medieval university curriculum to include the new learning of his time. While alchemy was not more important to him than other sciences and he did not produce allegorical works on the topic, he did consider it and astrology to be important parts of both natural philosophy and theology and his contributions advanced alchemy's connections to soteriology and Christian theology. Bacon's writings integrated morality, salvation, alchemy, and the prolongation of life. His correspondence with Clement highlighted this, noting the importance of alchemy to the papacy. Like the Greeks before him, Bacon acknowledged the division of alchemy into practical and theoretical spheres. He noted that the theoretical lay outside the scope of Aristotle, the natural philosophers, and all Latin writers of his time. The practical confirmed the theoretical, and Bacon advocated its uses in natural science and medicine. In later European legend, he became an archmage. In particular, along with Albertus Magnus, he was credited with the forging of a brazen head capable of answering its owner's questions.Soon after Bacon, the influential work of Pseudo-Geber (sometimes identified as Paul of Taranto) appeared. His Summa Perfectionis remained a staple summary of alchemical practice and theory through the medieval and renaissance periods. It was notable for its inclusion of practical chemical operations alongside sulphur-mercury theory, and the unusual clarity with which they were described. By the end of the 13th century, alchemy had developed into a fairly structured system of belief. Adepts believed in the macrocosm-microcosm theories of Hermes, that is to say, they believed that processes that affect minerals and other substances could have an effect on the human body (for example, if one could learn the secret of purifying gold, one could use the technique to purify the human soul). They believed in the four elements and the four qualities as described above, and they had a strong tradition of cloaking their written ideas in a labyrinth of coded jargon set with traps to mislead the uninitiated. Finally, the alchemists practiced their art: they actively experimented with chemicals and made observations and theories about how the universe operated. Their entire philosophy revolved around their belief that man's soul was divided within himself after the fall of Adam. By purifying the two parts of man's soul, man could be reunited with God.In the 14th century, alchemy became more accessible to Europeans outside the confines of Latin speaking churchmen and scholars. Alchemical discourse shifted from scholarly philosophical debate to an exposed social commentary on the alchemists themselves. Dante, Piers Plowman, and Chaucer all painted unflattering pictures of alchemists as thieves and liars. Pope John XXII's 1317 edict, Spondent quas non-exhibent forbade the false promises of transmutation made by pseudo-alchemists. In 1403, Henry IV of England banned the practice of multiplying metals (although it was possible to buy a licence to attempt to make gold alchemically, and a number were granted by Henry VI and Edward IV). These critiques and regulations centered more around pseudo-alchemical charlatanism than the actual study of alchemy, which continued with an increasingly Christian tone. The 14th century saw the Christian imagery of death and resurrection employed in the alchemical texts of Petrus Bonus, John of Rupescissa, and in works written in the name of Raymond Lull and Arnold of Villanova.Nicolas Flamel is a well-known alchemist, but a good example of pseudepigraphy, the practice of giving your works the name of someone else, usually more famous. Although the historical Flamel existed, the writings and legends assigned to him only appeared in 1612. Flamel was not a religious scholar as were many of his predecessors, and his entire interest in the subject revolved around the pursuit of the philosopher's stone. His work spends a great deal of time describing the processes and reactions, but never actually gives the formula for carrying out the transmutations. Most of 'his' work was aimed at gathering alchemical knowledge that had existed before him, especially as regarded the philosopher's stone. Through the 14th and 15th centuries, alchemists were much like Flamel: they concentrated on looking for the philosophers' stone. Bernard Trevisan and George Ripley made similar contributions. Their cryptic allusions and symbolism led to wide variations in interpretation of the art.Renaissance and early modern Europe During the Renaissance, Hermetic and Platonic foundations were restored to European alchemy. The dawn of medical, pharmaceutical, occult, and entrepreneurial branches of alchemy followed.In the late 15th century, Marsilo Ficino translated the Corpus Hermeticum and the works of Plato into Latin. These were previously unavailable to Europeans who for the first time had a full picture of the alchemical theory that Bacon had declared absent. Renaissance Humanism and Renaissance Neoplatonism guided alchemists away from physics to refocus on mankind as the alchemical vessel.Esoteric systems developed that blended alchemy into a broader occult Hermeticism, fusing it with magic, astrology, and Christian cabala. A key figure in this development was German Heinrich Cornelius Agrippa (1486–1535), who received his Hermetic education in Italy in the schools of the humanists. In his De Occulta Philosophia, he attempted to merge Kabbalah, Hermeticism, and alchemy. He was instrumental in spreading this new blend of Hermeticism outside the borders of Italy.Philippus Aureolus Paracelsus, (Theophrastus Bombastus von Hohenheim, 1493–1541) cast alchemy into a new form, rejecting some of Agrippa's occultism and moving away from chrysopoeia. Paracelsus pioneered the use of chemicals and minerals in medicine and wrote, "Many have said of Alchemy, that it is for the making of gold and silver. For me such is not the aim, but to consider only what virtue and power may lie in medicines."His hermetical views were that sickness and health in the body relied on the harmony of man the microcosm and Nature the macrocosm. He took an approach different from those before him, using this analogy not in the manner of soul-purification but in the manner that humans must have certain balances of minerals in their bodies, and that certain illnesses of the body had chemical remedies that could cure them. Iatrochemistry refers to the pharmaceutical applications of alchemy championed by Paracelsus.John Dee (13 July 1527 – December, 1608) followed Agrippa's occult tradition. Although better known for angel summoning, divination, and his role as astrologer, cryptographer, and consultant to Queen Elizabeth I, Dee's alchemical Monas Hieroglyphica, written in 1564 was his most popular and influential work. His writing portrayed alchemy as a sort of terrestrial astronomy in line with the Hermetic axiom As above so below. During the 17th century, a short-lived "supernatural" interpretation of alchemy became popular, including support by fellows of the Royal Society: Robert Boyle and Elias Ashmole. Proponents of the supernatural interpretation of alchemy believed that the philosopher's stone might be used to summon and communicate with angels.Entrepreneurial opportunities were common for the alchemists of Renaissance Europe. Alchemists were contracted by the elite for practical purposes related to mining, medical services, and the production of chemicals, medicines, metals, and gemstones. Rudolf II, Holy Roman Emperor, in the late 16th century, famously received and sponsored various alchemists at his court in Prague, including Dee and his associate Edward Kelley. King James IV of Scotland, Julius, Duke of Brunswick-Lüneburg, Henry V, Duke of Brunswick-Lüneburg, Augustus, Elector of Saxony, Julius Echter von Mespelbrunn, and Maurice, Landgrave of Hesse-Kassel all contracted alchemists. John's son Arthur Dee worked as a court physician to Michael I of Russia and Charles I of England but also compiled the alchemical book Fasciculus Chemicus.Although most of these appointments were legitimate, the trend of pseudo-alchemical fraud continued through the Renaissance. Betrüger would use sleight of hand, or claims of secret knowledge to make money or secure patronage. Legitimate mystical and medical alchemists such as Michael Maier and Heinrich Khunrath wrote about fraudulent transmutations, distinguishing themselves from the con artists. False alchemists were sometimes prosecuted for fraud.The terms "chemia" and "alchemia" were used as synonyms in the early modern period, and the differences between alchemy, chemistry and small-scale assaying and metallurgy were not as neat as in the present day. There were important overlaps between practitioners, and trying to classify them into alchemists, chemists and craftsmen is anachronistic. For example, Tycho Brahe (1546–1601), an alchemist better known for his astronomical and astrological investigations, had a laboratory built at his Uraniborg observatory/research institute. Michael Sendivogius (Michał Sędziwój, 1566–1636), a Polish alchemist, philosopher, medical doctor and pioneer of chemistry wrote mystical works but is also credited with distilling oxygen in a lab sometime around 1600. Sendivogious taught his technique to Cornelius Drebbel who, in 1621, applied this in a submarine. Isaac Newton devoted considerably more of his writing to the study of alchemy (see Isaac Newton's occult studies) than he did to either optics or physics. Other early modern alchemists who were eminent in their other studies include Robert Boyle, and Jan Baptist van Helmont. Their Hermeticism complemented rather than precluded their practical achievements in medicine and science.Later modern period The decline of European alchemy was brought about by the rise of modern science with its emphasis on rigorous quantitative experimentation and its disdain for "ancient wisdom". Although the seeds of these events were planted as early as the 17th century, alchemy still flourished for some two hundred years, and in fact may have reached its peak in the 18th century. As late as 1781 James Price claimed to have produced a powder that could transmute mercury into silver or gold. Early modern European alchemy continued to exhibit a diversity of theories, practices, and purposes: "Scholastic and anti-Aristotelian, Paracelsian and anti-Paracelsian, Hermetic, Neoplatonic, mechanistic, vitalistic, and more—plus virtually every combination and compromise thereof."Robert Boyle (1627–1691) pioneered the scientific method in chemical investigations. He assumed nothing in his experiments and compiled every piece of relevant data. Boyle would note the place in which the experiment was carried out, the wind characteristics, the position of the Sun and Moon, and the barometer reading, all just in case they proved to be relevant. This approach eventually led to the founding of modern chemistry in the 18th and 19th centuries, based on revolutionary discoveries of Lavoisier and John Dalton.Beginning around 1720, a rigid distinction began to be drawn for the first time between "alchemy" and "chemistry". By the 1740s, "alchemy" was now restricted to the realm of gold making, leading to the popular belief that alchemists were charlatans, and the tradition itself nothing more than a fraud. In order to protect the developing science of modern chemistry from the negative censure to which alchemy was being subjected, academic writers during the 18th-century scientific Enlightenment attempted, for the sake of survival, to divorce and separate the "new" chemistry from the "old" practices of alchemy. This move was mostly successful, and the consequences of this continued into the 19th, 20th and 21st centuries.During the occult revival of the early 19th century, alchemy received new attention as an occult science. The esoteric or occultist school, which arose during the 19th century, held (and continues to hold) the view that the substances and operations mentioned in alchemical literature are to be interpreted in a spiritual sense, and it downplays the role of the alchemy as a practical tradition or protoscience. This interpretation further forwarded the view that alchemy is an art primarily concerned with spiritual enlightenment or illumination, as opposed to the physical manipulation of apparatus and chemicals, and claims that the obscure language of the alchemical texts were an allegorical guise for spiritual, moral or mystical processes.In the 19th-century revival of alchemy, the two most seminal figures were Mary Anne Atwood and Ethan Allen Hitchcock, who independently published similar works regarding spiritual alchemy. Both forwarded a completely esoteric view of alchemy, as Atwood claimed: "No modern art or chemistry, notwithstanding all its surreptitious claims, has any thing in common with Alchemy." Atwood's work influenced subsequent authors of the occult revival including Eliphas Levi, Arthur Edward Waite, and Rudolf Steiner. Hitchcock, in his Remarks Upon Alchymists (1855) attempted to make a case for his spiritual interpretation with his claim that the alchemists wrote about a spiritual discipline under a materialistic guise in order to avoid accusations of blasphemy from the church and state. In 1845, Baron Carl Reichenbach, published his studies on Odic force, a concept with some similarities to alchemy, but his research did not enter the mainstream of scientific discussion.In 1946, Louis Cattiaux published the Message Retrouvé, a work that was at once philosophical, mystical and highly influenced by alchemy. In his lineage, many researchers, including Emmanuel and Charles d'Hooghvorst, are updating alchemical studies in France and Belgium.Women Several women appear in the earliest history of alchemy. Michael Maier names Mary the Jewess, Cleopatra the Alchemist, Medera, and Taphnutia as the four women who knew how to make the philosopher's stone. Zosimos' sister Theosebia (later known as Euthica the Arab) and Isis the Prophetess also played a role in early alchemical texts.The first alchemist whose name we know was Mary the Jewess (c. 200 A.D.). Early sources claim that Mary (or Maria) devised a number of improvements to alchemical equipment and tools as well as novel techniques in chemistry. Her best known advances were in heating and distillation processes. The laboratory water-bath, known eponymously (especially in France) as the bain-marie, is said to have been invented or at least improved by her. Essentially a double-boiler, it was (and is) used in chemistry for processes that require gentle heating. The tribikos (a modified distillation apparatus) and the kerotakis (a more intricate apparatus used especially for sublimations) are two other advancements in the process of distillation that are credited to her. Although we have no writing from Mary herself, she is known from the early-fourth-century writings of Zosimos of Panopolis.Due to the proliferation of pseudepigrapha and anonymous works, it is difficult to know which of the alchemists were actually women. After the Greco-Roman period, women's names appear less frequently in the alchemical literature. Women vacate the history of alchemy during the medieval and renaissance periods, aside from the fictitious account of Perenelle Flamel. Mary Anne Atwood's A Suggestive Inquiry into the Hermetic Mystery (1850) marks their return during the nineteenth-century occult revival.Modern historical research The history of alchemy has become a significant and recognized subject of academic study. As the language of the alchemists is analyzed, historians are becoming more aware of the intellectual connections between that discipline and other facets of Western cultural history, such as the evolution of science and philosophy, the sociology and psychology of the intellectual communities, kabbalism, spiritualism, Rosicrucianism, and other mystic movements. Institutions involved in this research include The Chymistry of Isaac Newton project at Indiana University, the University of Exeter Centre for the Study of Esotericism (EXESESO), the European Society for the Study of Western Esotericism (ESSWE), and the University of Amsterdam's Sub-department for the History of Hermetic Philosophy and Related Currents. A large collection of books on alchemy is kept in the Bibliotheca Philosophica Hermetica in Amsterdam. A recipe found in a mid-19th-century kabbalah based book features step by step instructions on turning copper into gold. The author attributed this recipe to an ancient manuscript he located.Journals which publish regularly on the topic of Alchemy include 'Ambix', published by the Society for the History of Alchemy and Chemistry, and 'Isis', published by The History of Science Society.Core concepts Western alchemical theory corresponds to the worldview of late antiquity in which it was born. Concepts were imported from Neoplatonism and earlier Greek cosmology. As such, the classical elements appear in alchemical writings, as do the seven classical planets and the corresponding seven metals of antiquity. Similarly, the gods of the Roman pantheon who are associated with these luminaries are discussed in alchemical literature. The concepts of prima materia and anima mundi are central to the theory of the philosopher's stone.Magnum opus The Great Work of Alchemy is often described as a series of four stages represented by colors.nigredo, a blackening or melanosisalbedo, a whitening or leucosiscitrinitas, a yellowing or xanthosisrubedo, a reddening, purpling, or iosisModernity Due to the complexity and obscurity of alchemical literature, and the 18th-century disappearance of remaining alchemical practitioners into the area of chemistry, the general understanding of alchemy has been strongly influenced by several distinct and radically different interpretations. Those focusing on the exoteric, such as historians of science Lawrence M. Principe and William R. Newman, have interpreted the 'decknamen' (or code words) of alchemy as physical substances. These scholars have reconstructed physicochemical experiments that they say are described in medieval and early modern texts. At the opposite end of the spectrum, focusing on the esoteric, scholars, such as George Calian and Anna Marie Roos, who question the reading of Principe and Newman, interpret these same decknamen as spiritual, religious, or psychological concepts.New interpretations of alchemy are still perpetuated, sometimes merging in concepts from New Age or radical environmentalism movements. Groups like the Rosicrucians and Freemasons have a continued interest in alchemy and its symbolism. Since the Victorian revival of alchemy, "occultists reinterpreted alchemy as a spiritual practice, involving the self-transformation of the practitioner and only incidentally or not at all the transformation of laboratory substances", which has contributed to a merger of magic and alchemy in popular thought.Esoteric interpretations of historical textsIn the eyes of a variety of modern esoteric and Neo-Hermeticist practitioners, alchemy is fundamentally spiritual. In this interpretation, transmutation of lead into gold is presented as an analogy for personal transmutation, purification, and perfection.According to this view, early alchemists such as Zosimos of Panopolis (c. AD 300) highlighted the spiritual nature of the alchemical quest, symbolic of a religious regeneration of the human soul. This approach is held to have continued in the Middle Ages, as metaphysical aspects, substances, physical states, and material processes are supposed to have been used as metaphors for spiritual entities, spiritual states, and, ultimately, transformation. In this sense, the literal meanings of 'Alchemical Formulas' were like a veil, hiding their true spiritual philosophy. In the Neo-Hermeticist interpretation, both the transmutation of common metals into gold and the universal panacea are held to symbolize evolution from an imperfect, diseased, corruptible, and ephemeral state toward a perfect, healthy, incorruptible, and everlasting state, so the philosopher's stone then represented a mystic key that would make this evolution possible. Applied to the alchemist himself, the twin goal symbolized his evolution from ignorance to enlightenment, and the stone represented a hidden spiritual truth or power that would lead to that goal. In texts that are held to have been written according to this view, the cryptic alchemical symbols, diagrams, and textual imagery of late alchemical works are supposed to contain multiple layers of meanings, allegories, and references to other equally cryptic works; which must be laboriously decoded to discover their true meaning.In his 1766 Alchemical Catechism, Théodore Henri de Tschudi denotes that the usage of the metals was merely symbolic:Psychology Alchemical symbolism has been important in depth and analytical psychology and was revived and popularized from near extinction by the Swiss psychologist Carl Gustav Jung. Initially confounded and at odds with alchemy and its images, after being given a copy of the translation of The Secret of the Golden Flower, a Chinese alchemical text, by his friend Richard Wilhelm, Jung discovered a direct correlation or parallels between the symbolic images in the alchemical drawings and the inner, symbolic images coming up in dreams, visions or imaginations during the psychic processes of transformation occurring in his patients. A process, which he called "process of individuation". He regarded the alchemical images as symbols expressing aspects of this "process of individuation" of which the creation of the gold or lapis within were symbols for its origin and goal. Together with his alchemical mystica soror, Jungian Swiss analyst Marie-Louise von Franz, Jung began collecting all the old alchemical texts available, compiled a lexicon of key phrases with cross-references and pored over them. The volumes of work he wrote brought new light into understanding the art of transubstantiation and renewed alchemy's popularity as a symbolic process of coming into wholeness as a human being where opposites brought into contact and inner and outer, spirit and matter are reunited in the hieros gamos  or divine marriage. His writings are influential in psychology and for people who have an interest in understanding the importance of dreams, symbols and the unconscious archetypal forces (archetypes) that influence all of life.Both von Franz and Jung have contributed greatly to the subject and work of alchemy and its continued presence in psychology as well as contemporary culture. Jung wrote volumes on alchemy and his magnum opus is Volume 14 of his Collected Works, Mysterium Coniunctionis.Literature Alchemy has had a long-standing relationship with art, seen both in alchemical texts and in mainstream entertainment. Literary alchemy appears throughout the history of English literature from Shakespeare to J. K. Rowling, and also the popular Japanese manga Fullmetal Alchemist. Here, characters or plot structure follow an alchemical magnum opus. In the 14th century, Chaucer began a trend of alchemical satire that can still be seen in recent fantasy works like those of the late Sir Terry Pratchett.Visual artists had a similar relationship with alchemy. While some of them used alchemy as a source of satire, others worked with the alchemists themselves or integrated alchemical thought or symbols in their work. Music was also present in the works of alchemists and continues to influence popular performers. In the last hundred years, alchemists have been portrayed in a magical and spagyric role in fantasy fiction, film, television, novels, comics and video games.Science One goal of alchemy, the transmutation of base substances into gold, is now known to be impossible by chemical means but possible by physical means. Although not financially worthwhile, Gold was synthesized in particle accelerators as early as 1941.See also Alchemical symbolBiological transmutation in Corentin Louis KervranCupellationHistoricismHistory of chemistryList of alchemistsNuclear transmutationOutline of alchemyPorta AlchemicaRenaissance magicSpagyricSuperseded theories in scienceSynthesis of precious metalsWestern esotericismNotesReferencesCitationsBibliographyFurther readingGeneral  Lawrence Principe, The Secrets of Alchemy, Chicago, 2013.Jennifer M. Rampling. 2020. The Experimental Fire: Inventing English Alchemy, 1300-1700. University of Chicago Press.Greco-Egyptian alchemyTexts  Marcellin Berthelot and Charles-Émile Ruelle (eds.), Collection des anciens alchimistes grecs (CAAG), 3 vols., 1887–1888, Vol 1: https://gallica.bnf.fr/ark:/12148/bpt6k96492923, Vol 2: https://gallica.bnf.fr/ark:/12148/bpt6k9680734p, Vol. 3: https://gallica.bnf.fr/ark:/12148/bpt6k9634942s. André-Jean Festugière, La Révélation d'Hermès Trismégiste, Paris, Les Belles Lettres, 2014  (, OCLC 897235256). Robert Halleux and Henri-Dominique Saffrey (eds.), Les alchimistes grecs, t. 1 : Papyrus de Leyde – Papyrus de Stockholm – Recettes, Paris, Les Belles Lettres, 1981. Otto Lagercrantz (ed), Papyrus Graecus Holmiensis, Uppsala, A.B. Akademiska Bokhandeln, 1913, https://archive.org/details/papyrusgraecusho00lage/page/n8. Michèle Mertens and Henri-Dominique Saffrey (ed.), Les alchimistes grecs, t. 4.1 : Zosime de Panopolis. Mémoires authentiques, Paris, Les Belles Lettres, 1995. Andrée Collinet and Henri-Dominique Saffrey (ed.), Les alchimistes grecs, t. 10 : L'Anonyme de Zuretti ou l'Art sacré and divin de la chrysopée par un anonyme, Paris, Les Belles Lettres, 2000. Andrée Collinet (ed), Les alchimistes grecs, t. 11 : Recettes alchimiques (Par. Gr. 2419; Holkhamicus 109) – Cosmas le Hiéromoine – Chrysopée, Paris, Les Belles Lettres, 2000. Matteo Martelli (ed), The Four Books of Pseudo-Democritus, Maney Publishing, 2014.Studies  Dylan M. Burns, « μίξεώς τινι τέχνῃ κρείττονι : Alchemical Metaphor in the Paraphrase of Shem (NHC VII,1) », Aries 15 (2015), p. 79–106. Alberto Camplani, « Procedimenti magico-alchemici e discorso filosofico ermetico » in Giuliana Lanata (ed.), Il Tardoantico alle soglie del Duemila, ETS, 2000, p. 73–98. Alberto Camplani and Marco Zambon, « Il sacrificio come problema in alcune correnti filosofice di età imperiale », Annali di storia dell'esegesi 19 (2002), p. 59–99. Régine Charron and Louis Painchaud, « 'God is a Dyer,' The Background and Significance of a Puzzling Motif in the Coptic Gospel According to Philip (CG II, 3), Le Muséon 114 (2001), p. 41-50. Régine Charron, « The Apocryphon of John (NHC II,1) and the Greco-Egyptian Alchemical Literature », Vigiliae Christinae 59 (2005), p. 438-456. Philippe Derchain, "L'Atelier des Orfèvres à Dendara et les origines de l'alchimie," Chronique d'Égypte, vol. 65, no 130, 1990, p. 219–242. Korshi Dosoo, « A History of the Theban Magical Library », Bulletin of the American Society of Papyrologists 53 (2016), p. 251–274. Olivier Dufault, Early Greek Alchemy, Patronage and Innovation in Late Antiquity, California Classical Studies, 2019, https://escholarship.org/uc/item/2ks0g83x. Sergio Knipe, « Sacrifice and self-transformation in the alchemical writings of Zosimus of Panopolis », in Christopher Kelly, Richard Flower, Michael Stuart Williams (eds.), Unclassical Traditions. Volume II: Perspectives from East and West in Late Antiquity, Cambridge University Press, 2011, p. 59–69. André-Jean Festugière, La Révélation d'Hermès Trismégiste, Paris, Les Belles Lettres, 2014 , . Kyle A. Fraser, « Zosimos of Panopolis and the Book of Enoch: Alchemy as Forbidden Knowledge », Aries 4.2 (2004), p. 125–147. Kyle A. Fraser, « Baptized in Gnosis: The Spiritual Alchemy of Zosimos of Panopolis », Dionysius 25 (2007), p. 33–54. Kyle A. Fraser, « Distilling Nature’s Secrets: The Sacred Art of Alchemy », in John Scarborough and Paul Keyser (eds.), Oxford Handbook of Science and Medicine in the Classical World, Oxford University Press, 2018, p. 721–742. 2018. https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199734146.001.0001/oxfordhb-9780199734146-e-76. Shannon Grimes, Becoming Gold: Zosimos of Panopolis and the Alchemical Arts in Roman Egypt, Auckland, Rubedo Press, 2018,  Paul T. Keyser, « Greco-Roman Alchemy and Coins of Imitation Silver », American Journal of Numismatics 7–8 (1995–1996), p. 209–234. Paul Keyser, « The Longue Durée of Alchemy », in John Scarborough and Paul Keyser (eds.), Oxford Handbook of Science and Medicine in the Classical World, Oxford University Press, 2018, p. 409–430. Jean Letrouit, "Chronologie des alchimistes grecs," in Didier Kahn and Sylvain Matton, Alchimie: art, histoire et mythes, SEHA-Archè, 1995, p. 11–93. Lindsay, Jack. The Origins of Alchemy in Greco-Roman Egypt. Barnes & Noble, 1970. Paul Magdalino and Maria Mavroudi (eds.), The Occult Sciences in Byzantium, La Pomme d'or, 2006. Matteo Martelli, « The Alchemical Art of Dyeing: The Fourfold Division of Alchemy and the Enochian Tradition » in Sven Dupré (ed.), Laboratories of Art, Springer, 2014, . Matteo Martelli, « Alchemy, Medicine and Religion: Zosimus of Panopolis and the Egyptian Priests », Religion in the Roman Empire 3.2 (2017), p. 202–220. Gerasimos Merianos, « Alchemy », In A. Kaldellis & N. Siniossoglou (eds.), The Cambridge Intellectual History of Byzantium (pp. 234–251). Cambridge: Cambridge University Press, 2017, . Efthymios Nikolaïdis (ed.), Greek Alchemy from Late Antiquity to Early Modernity, Brepols, 2019, . Daniel Stolzenberg, « Unpropitious Tinctures: Alchemy, Astrology & Gnosis According to Zosimos of Panopolis », Archives internationales d'histoire des sciences 49 (1999), p. 3–31. Cristina Viano, « Byzantine Alchemy, or the Era of Systematization », in John Scarborough and Paul Keyser (eds.), Oxford Handbook of Science and Medicine in the Classical World, Oxford University Press, 2018, p. 943–964. C. Vlachou and al., « Experimental investigation of silvering in late Roman coinage », Material Research Society Symposium Proceedings 712 (2002), p. II9.2.1-II9.2.9, .Early modern  Principe, Lawrence and William Newman. Alchemy Tried in the Fire: Starkey, Boyle, and the Fate of Helmontian Chymistry. University of Chicago Press, 2002.External links  SHAC: Society for the History of Alchemy and Chemistry ESSWE: European Society for the Study of Western Esotericism Association for the Study of Esotericism The Alchemy Website. – Adam McLean's online collections and academic discussion.  Dictionary of the History of Ideas: Alchemy Book of Secrets: Alchemy and the European Imagination, 1500–2000 – A digital exhibition from the Beinecke Rare Book and Manuscript Library at Yale University Othmer MS 2 Alchemical Miscellany at OPenn Alchemy featured topic page on Science History Institute Digital Collections featuring selected manuscripts, rare books, paintings, and ephemera relating to alchemical topics and experimentation. EsotericismHermeticismHistory of philosophyHistory of science
Alien primarily refers to: Alien (law), a person in a country who is not a national of that country Enemy alien, the above in times of war Extraterrestrial life, life which does not originate from Earth Specifically, intelligent extraterrestrial beings; see List of alleged extraterrestrial beings Introduced species, a species not native to its environmentAlien(s), or The Alien(s) may also refer to:Science and technology  AliEn (ALICE Environment), a grid framework Alien (file converter), a Linux program Alien Technology, a manufacturer of RFID technologyArts and entertainment  Alien (franchise), a media franchise Alien (creature in Alien franchise)Films Alien (film), a 1979 film by Ridley Scott Aliens (film), second film in the franchise from 1986 by James Cameron Alien 3, third film in the franchise from 1992 by David Fincher Alien Resurrection, fourth film in the franchise from 1997 by Jean-Pierre Jeunet Alien vs. Predator (film), fifth film in the franchise from 2004 by Paul W. S. Anderson Aliens vs. Predator: Requiem, sixth film in the franchise from 2007 by the Brothers Strause Prometheus (2012 film), seventh film in the franchise from 2012 by Ridley Scott Alien: Covenant, eighth film in the franchise from 2017 by Ridley Scott Alien 2: On Earth, a 1980 unofficial sequel of the 1979 Alien filmAlien Visitor (also titled Epsilon) (1995 film) AustralianItalian science fiction film by Rolf de Heer The Alien (2016 film), a 2016 Mexican film The Alien (unproduced film), an incomplete 1960s IndianAmerican filmLiterature  Alien novels, an extension of the Alien franchise Aliens (Tappan Wright novel), a 1902 novel by Mary Tappan Wright The Alien (Animorphs), the eighth book in the Animorphs series The Aliens (play), a 2010 play by Annie BakerMusicPerformers  Alien (band), a 1980s Swedish rock group The Aliens (Australian band), a 1970s new wave group The Aliens (Scottish band), a 2005–2008 rock groupAlbums  Alien (soundtrack), 1979 Alien (Beam album), 2022 Alien (Northlane album), 2019 Alien (Strapping Young Lad album), 2005 Alien, a 1989 EP by Tankard Aliens (soundtrack), 1987Songs  "Alien" (Britney Spears song), 2013 "Alien" (Jonas Blue and Sabrina Carpenter song), 2018 "Alien", a song by Third Day from the album Conspiracy No. 5, 1997 "Alien", a song by Pennywise from the album Straight Ahead, 1999 "Alien", a song by Bush from the album Sixteen Stone, 1994 "Alien", a song by Erasure from the album Loveboat, 2000 "Alien", a song by Japan from the album Quiet Life, 1979 "Alien", a song by Lamb from the album Fear of Fours, 1999 "Alien", a song by Nerina Pallot from the album Dear Frustrated Superstar, 2001 "Alien", a song by P-Model from the album Landsale, 1980 "Alien", a song by Thriving Ivory from the album Thriving Ivory, 2003 "Alien", a song by Tokio Hotel from the album Humanoid, 2009. Fans of the band call themselves "Aliens". "Alien", a song by Atlanta Rhythm from the album Quinella, 1981 "Alien", a 2020 song by Lee Suhyun "Aliens" (song), a 2017 song by Coldplay "Aliens", a 1984 song by Warlord "The Alien", a song by Dream Theater from the album A View from the Top of the World, 2021Video games  Alien (1984 video game), based on the film Alien (Atari 2600), a 1982 maze game based on the 1979 film Alien: Isolation, a 2014 video game based on the Alien science fiction horror film series Aliens (1982 video game), a text-only clone of Space Invaders written for the CP/M operating system on the Kaypro computer Aliens (1990 video game), a game by Konami, based on the sequel of the filmOther media  Alien (Armenian TV series), a 2017 melodrama series Alien (sculpture), a 2012 work by David Breuer-Weil, in Mottisfont, Hampshire, England Aliens (Dark Horse Comics line) The Aliens (TV series), 2016 British sci-fi television series "Aliens" (Roseanne), a 1992 television episodeOther uses  Alien (shipping company), a Russian company Alien Sun (born 1974), Singaporean actress Alien, a perfume by Thierry MuglerSee also  Alians, an Islamic order Alien Project (disambiguation) Alien vs. Predator (disambiguation) Astrobiology, the study of hypothetical alien life ATLiens, a 1996 album by OutKast Predator (disambiguation) UFO (disambiguation) Unidentified flying object (disambiguation)
An astronomer is a scientist in the field of astronomy who focuses their studies on a specific question or field outside the scope of Earth. They observe astronomical objects such as stars, planets, moons, comets and galaxies – in either observational (by analyzing the data) or theoretical astronomy. Examples of topics or fields astronomers study include planetary science, solar astronomy, the origin or evolution of stars, or the formation of galaxies. A related but distinct subject is physical cosmology, which studies the Universe as a whole.TypesAstronomers usually fall under either of two main types: observational and theoretical. Observational astronomers make direct observations of celestial objects and analyze the data. In contrast, theoretical astronomers create and investigate models of things that cannot be observed. Because it takes millions to billions of years for a system of stars or a galaxy to complete a life cycle, astronomers must observe snapshots of different systems at unique points in their evolution to determine how they form, evolve, and die. They use these data to create models or simulations to theorize how different celestial objects work.Further subcategories under these two main branches of astronomy include planetary astronomy, galactic astronomy, or physical cosmology.Academic Historically, astronomy was more concerned with the classification and description of phenomena in the sky, while astrophysics attempted to explain these phenomena and the differences between them using physical laws. Today, that distinction has mostly disappeared and the terms "astronomer" and "astrophysicist" are interchangeable. Professional astronomers are highly educated individuals who typically have a PhD in physics or astronomy and are employed by research institutions or universities. They spend the majority of their time working on research, although they quite often have other duties such as teaching, building instruments, or aiding in the operation of an observatory.The American Astronomical Society, which is the major organization of professional astronomers in North America, has approximately 7,000 members. This number includes scientists from other fields such as physics, geology, and engineering, whose research interests are closely related to astronomy. The International Astronomical Union comprises almost 10,145 members from 70 different countries who are involved in astronomical research at the PhD level and beyond.Contrary to the classical image of an old astronomer peering through a telescope through the dark hours of the night, it is far more common to use a charge-coupled device (CCD) camera to record a long, deep exposure, allowing a more sensitive image to be created because the light is added over time. Before CCDs, photographic plates were a common method of observation. Modern astronomers spend relatively little time at telescopes usually just a few weeks per year. Analysis of observed phenomena, along with making predictions as to the causes of what they observe, takes the majority of observational astronomers' time.Astronomers who serve as faculty spend much of their time teaching undergraduate and graduate classes. Most universities also have outreach programs including public telescope time and sometimes planetariums as a public service to encourage interest in the field.Those who become astronomers usually have a broad background in maths, sciences and computing in high school. Taking courses that teach how to research, write, and present papers are also invaluable. In college/university most astronomers get a PhD in astronomy or physics.Amateur astronomers While there is a relatively low number of professional astronomers, the field is popular among amateurs. Most cities have amateur astronomy clubs that meet on a regular basis and often host star parties. The Astronomical Society of the Pacific is the largest general astronomical society in the world, comprising both professional and amateur astronomers as well as educators from 70 different nations. Like any hobby, most people who think of themselves as amateur astronomers may devote a few hours a month to stargazing and reading the latest developments in research. However, amateurs span the range from so-called "armchair astronomers" to the very ambitious, who own science-grade telescopes and instruments with which they are able to make their own discoveries and assist professional astronomers in research.See also  List of astronomers List of women astronomers List of Muslim astronomers List of French astronomers List of Hungarian astronomers List of Russian astronomers and astrophysicists List of Slovenian astronomersReferencesSourcesExternal links  American Astronomical Society European Astronomical Society International Astronomical Union Astronomical Society of the Pacific Space's astronomy newsAstronomy Science occupations
ASCII ( ), abbreviated from American Standard Code for Information Interchange, is a character encoding standard for electronic communication. ASCII codes represent text in computers, telecommunications equipment, and other devices. Most modern character-encoding schemes are based on ASCII, although they support many additional characters.The Internet Assigned Numbers Authority (IANA) prefers the name US-ASCII for this character encoding.ASCII is one of the IEEE milestones.OverviewASCII was developed from telegraph code. Its first commercial use was as a seven-bit teleprinter code promoted by Bell data services. Work on the ASCII standard began in May 1961, with the first meeting of the American Standards Association's (ASA) (now the American National Standards Institute or ANSI) X3.2 subcommittee. The first edition of the standard was published in 1963, underwent a major revision during 1967, and experienced its most recent update during 1986. Compared to earlier telegraph codes, the proposed Bell code and ASCII were both ordered for more convenient sorting (i.e., alphabetization) of lists and added features for devices other than teleprinters. The use of ASCII format for Network Interchange was described in 1969. That document was formally elevated to an Internet Standard in 2015.Originally based on the English alphabet, ASCII encodes 128 specified characters into seven-bit integers as shown by the ASCII chart above. Ninety-five of the encoded characters are printable: these include the digits 0 to 9, lowercase letters a to z, uppercase letters A to Z, and punctuation symbols. In addition, the original ASCII specification included 33 non-printing control codes which originated with Teletype machines; most of these are now obsolete, although a few are still commonly used, such as the carriage return, line feed, and tab codes.For example, lowercase i would be represented in the ASCII encoding by binary 1101001 = hexadecimal 69 (i is the ninth letter) = decimal 105.HistoryThe American Standard Code for Information Interchange (ASCII) was developed under the auspices of a committee of the American Standards Association (ASA), called the X3 committee, by its X3.2 (later X3L2) subcommittee, and later by that subcommittee's X3.2.4 working group (now INCITS). The ASA later became the United States of America Standards Institute (USASI), and ultimately became the American National Standards Institute (ANSI).With the other special characters and control codes filled in, ASCII was published as ASA X3.4-1963, leaving 28 code positions without any assigned meaning, reserved for future standardization, and one unassigned control code. There was some debate at the time whether there should be more control characters rather than the lowercase alphabet. The indecision did not last long: during May 1963 the CCITT Working Party on the New Telegraph Alphabet proposed to assign lowercase characters to sticks 6 and 7, and International Organization for Standardization TC 97 SC 2 voted during October to incorporate the change into its draft standard. The X3.2.4 task group voted its approval for the change to ASCII at its May 1963 meeting. Locating the lowercase letters in sticks 6 and 7 caused the characters to differ in bit pattern from the upper case by a single bit, which simplified case-insensitive character matching and the construction of keyboards and printers.The X3 committee made other changes, including other new characters (the brace and vertical bar characters), renaming some control characters (SOM became start of he
[truncated]


--- scripts/api_example/test_image.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

from openai import OpenAI
from transformers.utils.versions import require_version


require_version("openai>=1.5.0", "To fix: pip install openai>=1.5.0")


def main():
    client = OpenAI(
        api_key="{}".format(os.getenv("API_KEY", "0")),
        base_url="http://localhost:{}/v1".format(os.getenv("API_PORT", 8000)),
    )
    messages = []
    messages.append(
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "Output the color and number of each box."},
                {
                    "type": "image_url",
                    "image_url": {"url": "https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-VL/boxes.png"},
                },
            ],
        }
    )
    result = client.chat.completions.create(messages=messages, model="test")
    messages.append(result.choices[0].message)
    print("Round 1:", result.choices[0].message.content)
    # The image shows a pyramid of colored blocks with numbers on them. Here are the colors and numbers of ...
    messages.append(
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "What kind of flower is this?"},
                {
                    "type": "image_url",
                    "image_url": {"url": "https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen2-VL/flowers.jpg"},
                },
            ],
        }
    )
    result = client.chat.completions.create(messages=messages, model="test")
    messages.append(result.choices[0].message)
    print("Round 2:", result.choices[0].message.content)
    # The image shows a cluster of forget-me-not flowers. Forget-me-nots are small ...


if __name__ == "__main__":
    main()


--- scripts/api_example/test_toolcall.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
import os

from openai import OpenAI
from transformers.utils.versions import require_version


require_version("openai>=1.5.0", "To fix: pip install openai>=1.5.0")


def calculate_gpa(grades: list[str], hours: list[int]) -> float:
    grade_to_score = {"A": 4, "B": 3, "C": 2}
    total_score, total_hour = 0, 0
    for grade, hour in zip(grades, hours):
        total_score += grade_to_score[grade] * hour
        total_hour += hour
    return round(total_score / total_hour, 2)


def main():
    client = OpenAI(
        api_key="{}".format(os.getenv("API_KEY", "0")),
        base_url="http://localhost:{}/v1".format(os.getenv("API_PORT", 8000)),
    )
    tools = [
        {
            "type": "function",
            "function": {
                "name": "calculate_gpa",
                "description": "Calculate the Grade Point Average (GPA) based on grades and credit hours",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "grades": {"type": "array", "items": {"type": "string"}, "description": "The grades"},
                        "hours": {"type": "array", "items": {"type": "integer"}, "description": "The credit hours"},
                    },
                    "required": ["grades", "hours"],
                },
            },
        }
    ]
    tool_map = {"calculate_gpa": calculate_gpa}

    messages = []
    messages.append({"role": "user", "content": "My grades are A, A, B, and C. The credit hours are 3, 4, 3, and 2."})
    result = client.chat.completions.create(messages=messages, model="test", tools=tools)
    if result.choices[0].message.tool_calls is None:
        raise ValueError("Cannot retrieve function call from the response.")

    messages.append(result.choices[0].message)
    tool_call = result.choices[0].message.tool_calls[0].function
    print(tool_call)
    # Function(arguments='{"grades": ["A", "A", "B", "C"], "hours": [3, 4, 3, 2]}', name='calculate_gpa')
    name, arguments = tool_call.name, json.loads(tool_call.arguments)
    tool_result = tool_map[name](**arguments)
    messages.append({"role": "tool", "content": json.dumps({"gpa": tool_result}, ensure_ascii=False)})
    result = client.chat.completions.create(messages=messages, model="test", tools=tools)
    print(result.choices[0].message.content)
    # Based on the grades and credit hours you provided, your Grade Point Average (GPA) is 3.42.


if __name__ == "__main__":
    main()


## Links discovered
- [name](https://github.com/hiyouga/LlamaFactory/blob/main/scripts/api_example/**arguments.md)

--- src/api.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

import uvicorn

from llamafactory.api.app import create_app
from llamafactory.chat import ChatModel


def main():
    chat_model = ChatModel()
    app = create_app(chat_model)
    api_host = os.getenv("API_HOST", "0.0.0.0")
    api_port = int(os.getenv("API_PORT", "8000"))
    print(f"Visit http://localhost:{api_port}/docs for API document.")
    uvicorn.run(app, host=api_host, port=api_port)


if __name__ == "__main__":
    main()


--- src/llamafactory/api/app.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import asyncio
import os
from contextlib import asynccontextmanager
from functools import partial
from typing import Annotated

from ..chat import ChatModel
from ..extras.constants import EngineName
from ..extras.misc import torch_gc
from ..extras.packages import is_fastapi_available, is_starlette_available, is_uvicorn_available
from .chat import (
    create_chat_completion_response,
    create_score_evaluation_response,
    create_stream_chat_completion_response,
)
from .protocol import (
    ChatCompletionRequest,
    ChatCompletionResponse,
    ModelCard,
    ModelList,
    ScoreEvaluationRequest,
    ScoreEvaluationResponse,
)


if is_fastapi_available():
    from fastapi import Depends, FastAPI, HTTPException, status
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.security.http import HTTPAuthorizationCredentials, HTTPBearer


if is_starlette_available():
    from sse_starlette import EventSourceResponse


if is_uvicorn_available():
    import uvicorn


async def sweeper() -> None:
    while True:
        torch_gc()
        await asyncio.sleep(300)


@asynccontextmanager
async def lifespan(app: "FastAPI", chat_model: "ChatModel"):  # collects GPU memory
    if chat_model.engine.name == EngineName.HF:
        asyncio.create_task(sweeper())

    yield
    torch_gc()


def create_app(chat_model: "ChatModel") -> "FastAPI":
    root_path = os.getenv("FASTAPI_ROOT_PATH", "")
    app = FastAPI(lifespan=partial(lifespan, chat_model=chat_model), root_path=root_path)
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    api_key = os.getenv("API_KEY")
    security = HTTPBearer(auto_error=False)

    async def verify_api_key(auth: Annotated[HTTPAuthorizationCredentials | None, Depends(security)]):
        if api_key and (auth is None or auth.credentials != api_key):
            raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="Invalid API key.")

    @app.get(
        "/v1/models",
        response_model=ModelList,
        status_code=status.HTTP_200_OK,
        dependencies=[Depends(verify_api_key)],
    )
    async def list_models():
        model_card = ModelCard(id=os.getenv("API_MODEL_NAME", "gpt-3.5-turbo"))
        return ModelList(data=[model_card])

    @app.post(
        "/v1/chat/completions",
        response_model=ChatCompletionResponse,
        status_code=status.HTTP_200_OK,
        dependencies=[Depends(verify_api_key)],
    )
    async def create_chat_completion(request: ChatCompletionRequest):
        if not chat_model.engine.can_generate:
            raise HTTPException(status_code=status.HTTP_405_METHOD_NOT_ALLOWED, detail="Not allowed")

        if request.stream:
            generate = create_stream_chat_completion_response(request, chat_model)
            return EventSourceResponse(generate, media_type="text/event-stream", sep="\n")
        else:
            return await create_chat_completion_response(request, chat_model)

    @app.post(
        "/v1/score/evaluation",
        response_model=ScoreEvaluationResponse,
        status_code=status.HTTP_200_OK,
        dependencies=[Depends(verify_api_key)],
    )
    async def create_score_evaluation(request: ScoreEvaluationRequest):
        if chat_model.engine.can_generate:
            raise HTTPException(status_code=status.HTTP_405_METHOD_NOT_ALLOWED, detail="Not allowed")

        return await create_score_evaluation_response(request, chat_model)

    return app


def run_api() -> None:
    chat_model = ChatModel()
    app = create_app(chat_model)
    api_host = os.getenv("API_HOST", "0.0.0.0")
    api_port = int(os.getenv("API_PORT", "8000"))
    print(f"Visit http://localhost:{api_port}/docs for API document.")
    uvicorn.run(app, host=api_host, port=api_port)


--- src/llamafactory/api/chat.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import base64
import io
import json
import os
import re
import uuid
from collections.abc import AsyncGenerator
from typing import TYPE_CHECKING, Optional

from ..data import Role as DataRole
from ..extras import logging
from ..extras.constants import AUDIO_PLACEHOLDER, IMAGE_PLACEHOLDER, VIDEO_PLACEHOLDER
from ..extras.misc import is_env_enabled
from ..extras.packages import is_fastapi_available, is_pillow_available, is_requests_available
from .common import check_lfi_path, check_ssrf_url, dictify, jsonify
from .protocol import (
    ChatCompletionMessage,
    ChatCompletionResponse,
    ChatCompletionResponseChoice,
    ChatCompletionResponseUsage,
    ChatCompletionStreamResponse,
    ChatCompletionStreamResponseChoice,
    Finish,
    Function,
    FunctionCall,
    Role,
    ScoreEvaluationResponse,
)


if is_fastapi_available():
    from fastapi import HTTPException, status


if is_pillow_available():
    from PIL import Image


if is_requests_available():
    import requests


if TYPE_CHECKING:
    from ..chat import ChatModel
    from ..data.mm_plugin import AudioInput, ImageInput, VideoInput
    from .protocol import ChatCompletionRequest, ScoreEvaluationRequest


logger = logging.get_logger(__name__)
ROLE_MAPPING = {
    Role.USER: DataRole.USER.value,
    Role.ASSISTANT: DataRole.ASSISTANT.value,
    Role.SYSTEM: DataRole.SYSTEM.value,
    Role.FUNCTION: DataRole.FUNCTION.value,
    Role.TOOL: DataRole.OBSERVATION.value,
}


def _process_request(
    request: "ChatCompletionRequest",
) -> tuple[
    list[dict[str, str]],
    Optional[str],
    Optional[str],
    Optional[list["ImageInput"]],
    Optional[list["VideoInput"]],
    Optional[list["AudioInput"]],
]:
    if is_env_enabled("API_VERBOSE", "1"):
        logger.info_rank0(f"==== request ====\n{json.dumps(dictify(request), indent=2, ensure_ascii=False)}")

    if len(request.messages) == 0:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invalid length")

    if request.messages[0].role == Role.SYSTEM:
        content = request.messages.pop(0).content
        system = content[0].text if isinstance(content, list) else content
    else:
        system = None

    if len(request.messages) % 2 == 0:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Only supports u/a/u/a/u...")

    input_messages = []
    images, videos, audios = [], [], []
    for i, message in enumerate(request.messages):
        if i % 2 == 0 and message.role not in [Role.USER, Role.TOOL]:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invalid role")
        elif i % 2 == 1 and message.role not in [Role.ASSISTANT, Role.FUNCTION]:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invalid role")

        if message.role == Role.ASSISTANT and isinstance(message.tool_calls, list) and len(message.tool_calls):
            tool_calls = [
                {"name": tool_call.function.name, "arguments": tool_call.function.arguments}
                for tool_call in message.tool_calls
            ]
            content = json.dumps(tool_calls, ensure_ascii=False)
            input_messages.append({"role": ROLE_MAPPING[Role.FUNCTION], "content": content})
        elif isinstance(message.content, list):
            text_content = ""
            for input_item in message.content:
                if input_item.type == "text":
                    text_content += input_item.text
                elif input_item.type == "image_url":
                    text_content += IMAGE_PLACEHOLDER
                    image_url = input_item.image_url.url
                    if re.match(r"^data:image\/(png|jpg|jpeg|gif|bmp);base64,(.+)$", image_url):  # base64 image
                        image_stream = io.BytesIO(base64.b64decode(image_url.split(",", maxsplit=1)[1]))
                    elif os.path.isfile(image_url):  # local file
                        check_lfi_path(image_url)
                        image_stream = open(image_url, "rb")
                    else:  # web uri
                        check_ssrf_url(image_url)
                        image_stream = requests.get(image_url, stream=True).raw

                    images.append(Image.open(image_stream).convert("RGB"))
                elif input_item.type == "video_url":
                    text_content += VIDEO_PLACEHOLDER
                    video_url = input_item.video_url.url
                    if re.match(r"^data:video\/(mp4|mkv|avi|mov);base64,(.+)$", video_url):  # base64 video
                        video_stream = io.BytesIO(base64.b64decode(video_url.split(",", maxsplit=1)[1]))
                    elif os.path.isfile(video_url):  # local file
                        check_lfi_path(video_url)
                        video_stream = video_url
                    else:  # web uri
                        check_ssrf_url(video_url)
                        video_stream = requests.get(video_url, stream=True).raw

                    videos.append(video_stream)
                elif input_item.type == "audio_url":
                    text_content += AUDIO_PLACEHOLDER
                    audio_url = input_item.audio_url.url
                    if re.match(r"^data:audio\/(mpeg|mp3|wav|ogg);base64,(.+)$", audio_url):  # base64 audio
                        audio_stream = io.BytesIO(base64.b64decode(audio_url.split(",", maxsplit=1)[1]))
                    elif os.path.isfile(audio_url):  # local file
                        check_lfi_path(audio_url)
                        audio_stream = audio_url
                    else:  # web uri
                        check_ssrf_url(audio_url)
                        audio_stream = requests.get(audio_url, stream=True).raw

                    audios.append(audio_stream)
                else:
                    raise HTTPException(
                        status_code=status.HTTP_400_BAD_REQUEST, detail=f"Invalid input type {input_item.type}."
                    )

            input_messages.append({"role": ROLE_MAPPING[message.role], "content": text_content})
        else:
            input_messages.append({"role": ROLE_MAPPING[message.role], "content": message.content})

    tool_list = request.tools
    if isinstance(tool_list, list) and len(tool_list):
        try:
            tools = json.dumps([dictify(tool.function) for tool in tool_list], ensure_ascii=False)
        except json.JSONDecodeError:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invalid tools")
    else:
        tools = None

    return input_messages, system, tools, images or None, videos or None, audios or None


def _create_stream_chat_completion_chunk(
    completion_id: str,
    model: str,
    delta: "ChatCompletionMessage",
    index: Optional[int] = 0,
    finish_reason: Optional["Finish"] = None,
) -> str:
    choice_data = ChatCompletionStreamResponseChoice(index=index, delta=delta, finish_reason=finish_reason)
    chunk = ChatCompletionStreamResponse(id=completion_id, model=model, choices=[choice_data])
    return jsonify(chunk)


async def create_chat_completion_response(
    request: "ChatCompletionRequest", chat_model: "ChatModel"
) -> "ChatCompletionResponse":
    completion_id = f"chatcmpl-{uuid.uuid4().hex}"
    input_messages, system, tools, images, videos, audios = _process_request(request)
    responses = await chat_model.achat(
        input_messages,
        system,
        tools,
        images,
        videos,
        audios,
        do_sample=request.do_sample,
        temperature=request.temperature,
        top_p=request.top_p,
        max_new_tokens=request.max_tokens,
        num_return_sequences=request.n,
        repetition_penalty=request.presence_penalty,
        stop=request.stop,
    )

    prompt_length, response_length = 0, 0
    choices = []
    for i, response in enumerate(responses):
        if tools:
            result = chat_model.engine.template.extract_tool(response.response_text)
        else:
            result = response.response_text

        if isinstance(result, list):
            tool_calls = []
            for tool in result:
                function = Function(name=tool.name, arguments=tool.arguments)
                tool_calls.append(FunctionCall(id=f"call_{uuid.uuid4().hex}", function=function))

            response_message = ChatCompletionMessage(role=Role.ASSISTANT, tool_calls=tool_calls)
            finish_reason = Finish.TOOL
        else:
            response_message = ChatCompletionMessage(role=Role.ASSISTANT, content=result)
            finish_reason = Finish.STOP if response.finish_reason == "stop" else Finish.LENGTH

        choices.append(ChatCompletionResponseChoice(index=i, message=response_message, finish_reason=finish_reason))
        prompt_length = response.prompt_length
        response_length += response.response_length

    usage = ChatCompletionResponseUsage(
        prompt_tokens=prompt_length,
        completion_tokens=response_length,
        total_tokens=prompt_length + response_length,
    )

    return ChatCompletionResponse(id=completion_id, model=request.model, choices=choices, usage=usage)


async def create_stream_chat_completion_response(
    request: "ChatCompletionRequest", chat_model: "ChatModel"
) -> AsyncGenerator[str, None]:
    completion_id = f"chatcmpl-{uuid.uuid4().hex}"
    input_messages, system, tools, images, videos, audios = _process_request(request)
    if tools:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Cannot stream function calls.")

    if request.n > 1:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Cannot stream multiple responses.")

    yield _create_stream_chat_completion_chunk(
        completion_id=completion_id, model=request.model, delta=ChatCompletionMessage(role=Role.ASSISTANT, content="")
    )
    async for new_token in chat_model.astream_chat(
        input_messages,
        system,
        tools,
        images,
        videos,
        audios,
        do_sample=request.do_sample,
        temperature=request.temperature,
        top_p=request.top_p,
        max_new_tokens=request.max_tokens,
        repetition_penalty=request.presence_penalty,
        stop=request.stop,
    ):
        if len(new_token) != 0:
            yield _create_stream_chat_completion_chunk(
                completion_id=completion_id, model=request.model, delta=ChatCompletionMessage(content=new_token)
            )

    yield _create_stream_chat_completion_chunk(
        completion_id=completion_id, model=request.model, delta=ChatCompletionMessage(), finish_reason=Finish.STOP
    )
    yield "[DONE]"


async def create_score_evaluation_response(
    request: "ScoreEvaluationRequest", chat_model: "ChatModel"
) -> "ScoreEvaluationResponse":
    score_id = f"scoreval-{uuid.uuid4().hex}"
    if len(request.messages) == 0:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invalid request")

    scores = await chat_model.aget_scores(request.messages, max_length=request.max_length)
    return ScoreEvaluationResponse(id=score_id, model=request.model, scores=scores)


--- src/llamafactory/api/common.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import ipaddress
import json
import os
import socket
from typing import TYPE_CHECKING, Any
from urllib.parse import urlparse

from ..extras.misc import is_env_enabled
from ..extras.packages import is_fastapi_available


if is_fastapi_available():
    from fastapi import HTTPException, status


if TYPE_CHECKING:
    from pydantic import BaseModel


SAFE_MEDIA_PATH = os.environ.get("SAFE_MEDIA_PATH", os.path.join(os.path.dirname(__file__), "safe_media"))
ALLOW_LOCAL_FILES = is_env_enabled("ALLOW_LOCAL_FILES", "1")


def dictify(data: "BaseModel") -> dict[str, Any]:
    try:  # pydantic v2
        return data.model_dump(exclude_unset=True)
    except AttributeError:  # pydantic v1
        return data.dict(exclude_unset=True)


def jsonify(data: "BaseModel") -> str:
    try:  # pydantic v2
        return json.dumps(data.model_dump(exclude_unset=True), ensure_ascii=False)
    except AttributeError:  # pydantic v1
        return data.json(exclude_unset=True, ensure_ascii=False)


def check_lfi_path(path: str) -> None:
    """Checks if a given path is vulnerable to LFI. Raises HTTPException if unsafe."""
    if not ALLOW_LOCAL_FILES:
        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail="Local file access is disabled.")

    try:
        os.makedirs(SAFE_MEDIA_PATH, exist_ok=True)
        real_path = os.path.realpath(path)
        safe_path = os.path.realpath(SAFE_MEDIA_PATH)

        if not real_path.startswith(safe_path):
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN, detail="File access is restricted to the safe media directory."
            )
    except Exception:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invalid or inaccessible file path.")


def check_ssrf_url(url: str) -> None:
    """Checks if a given URL is vulnerable to SSRF. Raises HTTPException if unsafe."""
    try:
        parsed_url = urlparse(url)
        if parsed_url.scheme not in ["http", "https"]:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Only HTTP/HTTPS URLs are allowed.")

        hostname = parsed_url.hostname
        if not hostname:
            raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Invalid URL hostname.")

        ip_info = socket.getaddrinfo(hostname, parsed_url.port)
        ip_address_str = ip_info[0][4][0]
        ip = ipaddress.ip_address(ip_address_str)

        if not ip.is_global:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="Access to private or reserved IP addresses is not allowed.",
            )

    except socket.gaierror:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST, detail=f"Could not resolve hostname: {parsed_url.hostname}"
        )
    except Exception as e:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=f"Invalid URL: {e}")


--- src/llamafactory/api/__init__.py ---


--- src/llamafactory/api/protocol.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
from enum import Enum, unique
from typing import Any, Literal

from pydantic import BaseModel, Field


@unique
class Role(str, Enum):
    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"
    FUNCTION = "function"
    TOOL = "tool"


@unique
class Finish(str, Enum):
    STOP = "stop"
    LENGTH = "length"
    TOOL = "tool_calls"


class ModelCard(BaseModel):
    id: str
    object: Literal["model"] = "model"
    created: int = Field(default_factory=lambda: int(time.time()))
    owned_by: Literal["owner"] = "owner"


class ModelList(BaseModel):
    object: Literal["list"] = "list"
    data: list[ModelCard] = []


class Function(BaseModel):
    name: str
    arguments: str


class FunctionDefinition(BaseModel):
    name: str
    description: str
    parameters: dict[str, Any]


class FunctionAvailable(BaseModel):
    type: Literal["function", "code_interpreter"] = "function"
    function: FunctionDefinition | None = None


class FunctionCall(BaseModel):
    id: str
    type: Literal["function"] = "function"
    function: Function


class URL(BaseModel):
    url: str
    detail: Literal["auto", "low", "high"] = "auto"


class MultimodalInputItem(BaseModel):
    type: Literal["text", "image_url", "video_url", "audio_url"]
    text: str | None = None
    image_url: URL | None = None
    video_url: URL | None = None
    audio_url: URL | None = None


class ChatMessage(BaseModel):
    role: Role
    content: str | list[MultimodalInputItem] | None = None
    tool_calls: list[FunctionCall] | None = None


class ChatCompletionMessage(BaseModel):
    role: Role | None = None
    content: str | None = None
    tool_calls: list[FunctionCall] | None = None


class ChatCompletionRequest(BaseModel):
    model: str
    messages: list[ChatMessage]
    tools: list[FunctionAvailable] | None = None
    do_sample: bool | None = None
    temperature: float | None = None
    top_p: float | None = None
    n: int = 1
    presence_penalty: float | None = None
    max_tokens: int | None = None
    stop: str | list[str] | None = None
    stream: bool = False


class ChatCompletionResponseChoice(BaseModel):
    index: int
    message: ChatCompletionMessage
    finish_reason: Finish


class ChatCompletionStreamResponseChoice(BaseModel):
    index: int
    delta: ChatCompletionMessage
    finish_reason: Finish | None = None


class ChatCompletionResponseUsage(BaseModel):
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int


class ChatCompletionResponse(BaseModel):
    id: str
    object: Literal["chat.completion"] = "chat.completion"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    choices: list[ChatCompletionResponseChoice]
    usage: ChatCompletionResponseUsage


class ChatCompletionStreamResponse(BaseModel):
    id: str
    object: Literal["chat.completion.chunk"] = "chat.completion.chunk"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    choices: list[ChatCompletionStreamResponseChoice]


class ScoreEvaluationRequest(BaseModel):
    model: str
    messages: list[str]
    max_length: int | None = None


class ScoreEvaluationResponse(BaseModel):
    id: str
    object: Literal["score.evaluation"] = "score.evaluation"
    model: str
    scores: list[float]


--- tests/check_license.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import sys
from pathlib import Path


KEYWORDS = ("Copyright", "2025", "LlamaFactory")


def main():
    path_list: list[Path] = []
    for check_dir in sys.argv[1:]:
        path_list.extend(Path(check_dir).glob("**/*.py"))

    for path in path_list:
        with open(path.absolute(), encoding="utf-8") as f:
            file_content = f.read().strip().split("\n")
            if not file_content[0]:
                continue

            print(f"Check license: {path}")
            assert all(keyword in file_content[0] for keyword in KEYWORDS), f"File {path} does not contain license."


if __name__ == "__main__":
    main()


--- .github/CONTRIBUTING.md ---
# Contributing to LLaMA Factory

Everyone is welcome to contribute, and we value everybody's contribution. Code contributions are not the only way to help the community. Answering questions, helping others, and improving the documentation are also immensely valuable.

It also helps us if you spread the word! Reference the library in blog posts about the awesome projects it made possible, shout out on Twitter every time it has helped you, or simply ⭐️ the repository to say thank you.

However you choose to contribute, please be mindful and respect our [code of conduct](CODE_OF_CONDUCT.md).

**This guide was heavily inspired by [transformers guide to contributing](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md).**

## Ways to contribute

There are several ways you can contribute to LLaMA Factory:

* Fix outstanding issues with the existing code.
* Submit issues related to bugs or desired new features.
* Contribute to the examples or to the documentation.

### Style guide

LLaMA Factory follows the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html), check it for details.

### Create a Pull Request

1. Fork the [repository](https://github.com/hiyouga/LLaMA-Factory) by clicking on the [Fork](https://github.com/hiyouga/LLaMA-Factory/fork) button on the repository's page. This creates a copy of the code under your GitHub user account.

2. Clone your fork to your local disk, and add the base repository as a remote:

```bash
git clone git@github.com:[username]/LLaMA-Factory.git
cd LLaMA-Factory
git remote add upstream https://github.com/hiyouga/LLaMA-Factory.git
```

3. Create a new branch to hold your development changes:

```bash
git checkout -b dev_your_branch
```

4. Set up a development environment by running the following command in a virtual environment:

```bash
pip install -e ".[dev]"
```

If LLaMA Factory was already installed in the virtual environment, remove it with `pip uninstall llamafactory` before reinstalling it in editable mode with the -e flag.

5. Check code before commit:

```bash
make commit
make style && make quality
make test
```

6. Submit changes:

```bash
git add .
git commit -m "commit message"
git fetch upstream
git rebase upstream/main
git push -u origin dev_your_branch
```

7. Create a merge request from your branch `dev_your_branch` at [origin repo](https://github.com/hiyouga/LLaMA-Factory).


## Links discovered
- [code of conduct](https://github.com/hiyouga/LlamaFactory/blob/main/.github/CODE_OF_CONDUCT.md)
- [transformers guide to contributing](https://github.com/huggingface/transformers/blob/main/CONTRIBUTING.md)
- [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)
- [repository](https://github.com/hiyouga/LLaMA-Factory)
- [Fork](https://github.com/hiyouga/LLaMA-Factory/fork)
- [origin repo](https://github.com/hiyouga/LLaMA-Factory)

--- .github/SECURITY.md ---
# Reporting Security Issues

To report a security issue, please use the GitHub Security Advisory ["Report a Vulnerability"](https://github.com/hiyouga/LLaMA-Factory/security/advisories/new) tab.

We will send a response indicating the next steps in handling your report. After the initial reply to your report, the security team will keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance.

Report security bugs in third-party modules to the person or team maintaining the module.


## Links discovered
- ["Report a Vulnerability"](https://github.com/hiyouga/LLaMA-Factory/security/advisories/new)

--- README.md ---
![# LLaMA Factory](assets/logo.png)

[![GitHub Repo stars](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social)](https://github.com/hiyouga/LLaMA-Factory/stargazers)
[![GitHub last commit](https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory)](https://github.com/hiyouga/LLaMA-Factory/commits/main)
[![GitHub contributors](https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange)](https://github.com/hiyouga/LLaMA-Factory/graphs/contributors)
[![GitHub workflow](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg)](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml)
[![PyPI](https://img.shields.io/pypi/v/llamafactory)](https://pypi.org/project/llamafactory/)
[![Citation](https://img.shields.io/badge/citation-1000+-green)](https://scholar.google.com/scholar?cites=12620864006390196564)
[![Docker Pulls](https://img.shields.io/docker/pulls/hiyouga/llamafactory)](https://hub.docker.com/r/hiyouga/llamafactory/tags)

[![Twitter](https://img.shields.io/twitter/follow/llamafactory_ai)](https://twitter.com/llamafactory_ai)
[![Discord](assets/thirdparty/discord.svg)](https://discord.gg/rKfvV9r9FK)
[![WeChat](https://img.shields.io/badge/WeChat-User%20Group-blue?logo=wechat)](https://github.com/hiyouga/llamafactory-community)
[![Blog](https://img.shields.io/badge/Hugo-Official%20Blog-blue?logo=hugo)](https://blog.llamafactory.net/en/)

[![Open in Colab](assets/thirdparty/colab.svg)](https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing)
[![Open in DSW](assets/thirdparty/dsw.svg)](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory)
[![Open in Lab4ai](assets/thirdparty/lab4ai.svg)](https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory)
[![Open in Online](assets/thirdparty/online.svg)](https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory)
[![Open in Spaces](https://img.shields.io/badge/🤗-Open%20in%20Spaces-blue)](https://huggingface.co/spaces/hiyouga/LLaMA-Board)
[![Open in Studios](https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue)](https://modelscope.cn/studios/hiyouga/LLaMA-Board)
[![Open in Novita](https://img.shields.io/badge/Novita-Deploy%20Template-blue)](https://novita.ai/templates-library/105981?sharer=88115474-394e-4bda-968e-b88e123d0c47)

### Used by [Amazon](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/), [NVIDIA](https://developer.nvidia.com/rtx/ai-toolkit), [Aliyun](https://help.aliyun.com/zh/pai/use-cases/fine-tune-a-llama-3-model-with-llama-factory), etc.

<div align="center" markdown="1">

### Supporters ❤️

| <div style="text-align: center;"><a href="https://warp.dev/llama-factory"><img alt="Warp sponsorship" width="400" src="assets/sponsors/warp.jpg"></a><br><a href="https://warp.dev/llama-factory" style="font-size:larger;">Warp, the agentic terminal for developers</a><br><a href="https://warp.dev/llama-factory">Available for MacOS, Linux, & Windows</a> | <a href="https://serpapi.com"><img alt="SerpAPI sponsorship" width="250" src="assets/sponsors/serpapi.svg"> </a> |
| ---- | ---- |

----

### Easily fine-tune 100+ large language models with zero-code [CLI](#quickstart) and [Web UI](#fine-tuning-with-llama-board-gui-powered-by-gradio)

![GitHub Trend](https://trendshift.io/api/badge/repositories/4535)

</div>

👋 Join our [WeChat](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/main.jpg), [NPU](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/npu.jpg), [Lab4AI](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/lab4ai.jpg), [LLaMA Factory Online](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/online.jpg) user group.

\[ English | [中文](README_zh.md) \]

**Fine-tuning a large language model can be easy as...**

https://github.com/user-attachments/assets/3991a3a8-4276-4d30-9cab-4cb0c4b9b99e

Start local training:
- Please refer to [usage](#getting-started)

Start cloud training:
- **Colab (free)**: https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing
- **PAI-DSW (free trial)**: https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory
- **LLaMA Factory Online**: https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory
- **Alaya NeW (cloud GPU deal)**: https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory

Read technical notes:
- **Documentation (WIP)**: https://llamafactory.readthedocs.io/en/latest/
- **Documentation (AMD GPU)**: https://rocm.docs.amd.com/projects/ai-developer-hub/en/latest/notebooks/fine_tune/llama_factory_llama3.html
- **Official Blog**: https://blog.llamafactory.net/en/
- **Official Course**: https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory

> [!NOTE]
> Except for the above links, all other websites are unauthorized third-party websites. Please carefully use them.

## Table of Contents

- [Features](#features)
- [Blogs](#blogs)
- [Changelog](#changelog)
- [Supported Models](#supported-models)
- [Supported Training Approaches](#supported-training-approaches)
- [Provided Datasets](#provided-datasets)
- [Requirement](#requirement)
- [Getting Started](#getting-started)
  - [Installation](#installation)
  - [Data Preparation](#data-preparation)
  - [Quickstart](#quickstart)
  - [Fine-Tuning with LLaMA Board GUI](#fine-tuning-with-llama-board-gui-powered-by-gradio)
  - [LLaMA Factory Online](#llama-factory-online)
  - [Build Docker](#build-docker)
  - [Deploy with OpenAI-style API and vLLM](#deploy-with-openai-style-api-and-vllm)
  - [Download from ModelScope Hub](#download-from-modelscope-hub)
  - [Download from Modelers Hub](#download-from-modelers-hub)
  - [Use W&B Logger](#use-wb-logger)
  - [Use SwanLab Logger](#use-swanlab-logger)
- [Projects using LLaMA Factory](#projects-using-llama-factory)
- [License](#license)
- [Citation](#citation)
- [Acknowledgement](#acknowledgement)

## Features

- **Various models**: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Qwen2-VL, DeepSeek, Yi, Gemma, ChatGLM, Phi, etc.
- **Integrated methods**: (Continuous) pre-training, (multimodal) supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO, etc.
- **Scalable resources**: 16-bit full-tuning, freeze-tuning, LoRA and 2/3/4/5/6/8-bit QLoRA via AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.
- **Advanced algorithms**: [GaLore](https://github.com/jiaweizzhao/GaLore), [BAdam](https://github.com/Ledzy/BAdam), [APOLLO](https://github.com/zhuhanqing/APOLLO), [Adam-mini](https://github.com/zyushun/Adam-mini), [Muon](https://github.com/KellerJordan/Muon), [OFT](https://github.com/huggingface/peft/tree/main/src/peft/tuners/oft), DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ and PiSSA.
- **Practical tricks**: [FlashAttention-2](https://github.com/Dao-AILab/flash-attention), [Unsloth](https://github.com/unslothai/unsloth), [Liger Kernel](https://github.com/linkedin/Liger-Kernel), [KTransformers](https://github.com/kvcache-ai/ktransformers/), RoPE scaling, NEFTune and rsLoRA.
- **Wide tasks**: Multi-turn dialogue, tool using, image understanding, visual grounding, video recognition, audio understanding, etc.
- **Experiment monitors**: LlamaBoard, TensorBoard, Wandb, MLflow, [SwanLab](https://github.com/SwanHubX/SwanLab), etc.
- **Faster inference**: OpenAI-style API, Gradio UI and CLI with [vLLM worker](https://github.com/vllm-project/vllm) or [SGLang worker](https://github.com/sgl-project/sglang).

### Day-N Support for Fine-Tuning Cutting-Edge Models

| Support Date | Model Name                                                           |
| ------------ | -------------------------------------------------------------------- |
| Day 0        | Qwen3 / Qwen2.5-VL / Gemma 3 / GLM-4.1V / InternLM 3 / MiniCPM-o-2.6 |
| Day 1        | Llama 3 / GLM-4 / Mistral Small / PaliGemma2 / Llama 4               |

## Blogs

> [!TIP]
> Now we have a dedicated blog for LLaMA Factory!
>
> Website: https://blog.llamafactory.net/en/

- 💡 [KTransformers Fine-Tuning × LLaMA Factory: Fine-tuning 1000 Billion models with 2 4090-GPU + CPU](https://blog.llamafactory.net/en/posts/ktransformers/) (English)
- 💡 [Easy Dataset × LLaMA Factory: Enabling LLMs to Efficiently Learn Domain Knowledge](https://buaa-act.feishu.cn/wiki/GVzlwYcRFiR8OLkHbL6cQpYin7g) (English)
- [Fine-tune a mental health LLM using LLaMA-Factory](https://www.lab4ai.cn/project/detail?id=25cce32ec131497b9e06a93336a0817f&type=project&utm_source=LLaMA-Factory) (Chinese)
- [Fine-tune GPT-OSS for Role-Playing using LLaMA-Factory](https://docs.llamafactory.com.cn/docs/documents/best-practice/gptroleplay/?utm_source=LLaMA-Factory) (Chinese)
- [A One-Stop Code-Free Model Reinforcement Learning and Deployment Platform based on LLaMA-Factory and EasyR1](https://aws.amazon.com/cn/blogs/china/building-llm-model-hub-based-on-llamafactory-and-easyr1/) (Chinese)
- [How Apoidea Group enhances visual information extraction from banking documents with multimodal models using LLaMA-Factory on Amazon SageMaker HyperPod](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/) (English)

<details><summary>All Blogs</summary>

- [Fine-tune Llama3.1-70B for Medical Diagnosis using LLaMA-Factory](https://docs.alayanew.com/docs/documents/bestPractice/bigModel/llama70B/?utm_source=LLaMA-Factory) (Chinese)
- [Fine-tune Qwen2.5-VL for Autonomous Driving using LLaMA-Factory](https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory) (Chinese)
- [LLaMA Factory: Fine-tuning the DeepSeek-R1-Distill-Qwen-7B Model for News Classifier](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_deepseek_r1_distill_7b) (Chinese)
- [A One-Stop Code-Free Model Fine-Tuning \& Deployment Platform based on SageMaker and LLaMA-Factory](https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/) (Chinese)
- [LLaMA Factory Multi-Modal Fine-Tuning Practice: Fine-Tuning Qwen2-VL for Personal Tourist Guide](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_qwen2vl) (Chinese)
- [LLaMA Factory: Fine-tuning Llama3 for Role-Playing](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory) (Chinese)

</details>

## Changelog

[25/10/26] We support Megatron-core training backend with [**mcore_adapter**](https://github.com/alibaba/ROLL/tree/main/mcore_adapter). See [PR #9237](https://github.com/hiyouga/LLaMA-Factory/pull/9237) to get started.

[25/08/22] We supported **[OFT](https://arxiv.org/abs/2306.07280)** and **[OFTv2](https://arxiv.org/abs/2506.19847)**. See [examples](examples/README.md) for usage.

[25/08/20] We supported fine-tuning the **[Intern-S1-mini](https://huggingface.co/internlm/Intern-S1-mini)** models. See [PR #8976](https://github.com/hiyouga/LLaMA-Factory/pull/8976) to get started.

[25/08/06] We supported fine-tuning the **[GPT-OSS](https://github.com/openai/gpt-oss)** models. See [PR #8826](https://github.com/hiyouga/LLaMA-Factory/pull/8826) to get started.

<details><summary>Full Changelog</summary>

[25/07/02] We supported fine-tuning the **[GLM-4.1V-9B-Thinking](https://github.com/THUDM/GLM-4.1V-Thinking)** model.

[25/04/28] We supported fine-tuning the **[Qwen3](https://qwenlm.github.io/blog/qwen3/)** model family.

[25/04/21] We supported the **[Muon](https://github.com/KellerJordan/Muon)** optimizer. See [examples](examples/README.md) for usage. Thank [@tianshijing](https://github.com/tianshijing)'s PR.

[25/04/16] We supported fine-tuning the **[InternVL3](https://huggingface.co/OpenGVLab/InternVL3-8B)** model. See [PR #7258](https://github.com/hiyouga/LLaMA-Factory/pull/7258) to get started.

[25/04/14] We supported fine-tuning the **[GLM-Z1](https://huggingface.co/THUDM/GLM-Z1-9B-0414)** and **[Kimi-VL](https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct)** models.

[25/04/06] We supported fine-tuning the **[Llama 4](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)** model. See [PR #7611](https://github.com/hiyouga/LLaMA-Factory/pull/7611) to get started.

[25/03/31] We supported fine-tuning the **[Qwen2.5 Omni](https://qwenlm.github.io/blog/qwen2.5-omni/)** model. See [PR #7537](https://github.com/hiyouga/LLaMA-Factory/pull/7537) to get started.

[25/03/15] We supported **[SGLang](https://github.com/sgl-project/sglang)** as inference backend. Try `infer_backend: sglang` to accelerate inference.

[25/03/12] We supported fine-tuning the **[Gemma 3](https://huggingface.co/blog/gemma3)** model.

[25/02/24] Announcing **[EasyR1](https://github.com/hiyouga/EasyR1)**, an efficient, scalable and multi-modality RL training framework for efficient GRPO training.

[25/02/11] We supported saving the **[Ollama](https://github.com/ollama/ollama)** modelfile when exporting the model checkpoints. See [examples](examples/README.md) for usage.

[25/02/05] We supported fine-tuning the **[Qwen2-Audio](Qwen/Qwen2-Audio-7B-Instruct)** and **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** on audio understanding tasks.

[25/01/31] We supported fine-tuning the **[DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)** and **[Qwen2.5-VL](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct)** models.

[25/01/15] We supported **[APOLLO](https://arxiv.org/abs/2412.05270)** optimizer. See [examples](examples/README.md) for usage.

[25/01/14] We supported fine-tuning the **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** and **[MiniCPM-V-2.6](https://huggingface.co/openbmb/MiniCPM-V-2_6)** models. Thank [@BUAADreamer](https://github.com/BUAADreamer)'s PR.

[25/01/14] We supported fine-tuning the **[InternLM 3](https://huggingface.co/collections/internlm/)** models. Thank [@hhaAndroid](https://github.com/hhaAndroid)'s PR.

[25/01/10] We supported fine-tuning the **[Phi-4](https://huggingface.co/microsoft/phi-4)** model.

[24/12/21] We supported using **[SwanLab](https://github.com/SwanHubX/SwanLab)** for experiment tracking and visualization. See [this section](#use-swanlab-logger) for details.

[24/11/27] We supported fine-tuning the **[Skywork-o1](https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B)** model and the **[OpenO1](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)** dataset.

[24/10/09] We supported downloading pre-trained models and datasets from the **[Modelers Hub](https://modelers.cn/models)**. See [this tutorial](#download-from-modelers-hub) for usage.

[24/09/19] We supported fine-tuning the **[Qwen2.5](https://qwenlm.github.io/blog/qwen2.5/)** models.

[24/08/30] We supported fine-tuning the **[Qwen2-VL](https://qwenlm.github.io/blog/qwen2-vl/)** models. Thank [@simonJJJ](https://github.com/simonJJJ)'s PR.

[24/08/27] We supported **[Liger Kernel](https://github.com/linkedin/Liger-Kernel)**. Try `enable_liger_kernel: true` for efficient training.

[24/08/09] We supported **[Adam-mini](https://github.com/zyushun/Adam-mini)** optimizer. See [examples](examples/README.md) for usage. Thank [@relic-yuexi](https://github.com/relic-yuexi)'s PR.

[24/07/04] We supported [contamination-free packed training](https://github.com/MeetKai/functionary/tree/main/functionary/train/packing). Use `neat_packing: true` to activate it. Thank [@chuan298](https://github.com/chuan298)'s PR.

[24/06/16] We supported **[PiSSA](https://arxiv.org/abs/2404.02948)** algorithm. See [examples](examples/README.md) for usage.

[24/06/07] We supported fine-tuning the **[Qwen2](https://qwenlm.github.io/blog/qwen2/)** and **[GLM-4](https://github.com/THUDM/GLM-4)** models.

[24/05/26] We supported **[SimPO](https://arxiv.org/abs/2405.14734)** algorithm for preference learning. See [examples](examples/README.md) for usage.

[24/05/20] We supported fine-tuning the **PaliGemma** series models. Note that the PaliGemma models are pre-trained models, you need to fine-tune them with `paligemma` template for chat completion.

[24/05/18] We supported **[KTO](https://arxiv.org/abs/2402.01306)** algorithm for preference learning. See [examples](examples/README.md) for usage.

[24/05/14] We supported training and inference on the Ascend NPU devices. Check [installation](#installation) section for details.

[24/04/26] We supported fine-tuning the **LLaVA-1.5** multimodal LLMs. See [examples](examples/README.md) for usage.

[24/04/22] We provided a **[Colab notebook](https://colab.research.google.com/drive/1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9?usp=sharing)** for fine-tuning the Llama-3 model on a free T4 GPU. Two Llama-3-derived models fine-tuned using LLaMA Factory are available at Hugging Face, check [Llama3-8B-Chinese-Chat](https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat) and [Llama3-Chinese](https://huggingface.co/zhichen/Llama3-Chinese) for details.

[24/04/21] We supported **[Mixture-of-Depths](https://arxiv.org/abs/2404.02258)** according to [AstraMindAI's implementation](https://github.com/astramind-ai/Mixture-of-depths). See [examples](examples/README.md) for usage.

[24/04/16] We supported **[BAdam](https://arxiv.org/abs/2404.02827)** optimizer. See [examples](examples/README.md) for usage.

[24/04/16] We supported **[unsloth](https://github.com/unslothai/unsloth)**'s long-sequence training (Llama-2-7B-56k within 24GB). It achieves **117%** speed and **50%** memory compared with FlashAttention-2, more benchmarks can be found in [this page](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison).

[24/03/31] We supported **[ORPO](https://arxiv.org/abs/2403.07691)**. See [examples](examples/README.md) for usage.

[24/03/21] Our paper "[LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models](https://arxiv.org/abs/2403.13372)" is available at arXiv!

[24/03/20] We supported **FSDP+QLoRA** that fine-tunes a 70B model on 2x24GB GPUs. See [examples](examples/README.md) for usage.

[24/03/13] We supported **[LoRA+](https://arxiv.org/abs/2402.12354)**. See [examples](examples/README.md) for usage.

[24/03/07] We supported **[GaLore](https://arxiv.org/abs/2403.03507)** optimizer. See [examples](examples/README.md) for usage.

[24/03/07] We integrated **[vLLM](https://github.com/vllm-project/vllm)** for faster and concurrent inference. Try `infer_backend: vllm` to enjoy **270%** inference speed.

[24/02/28] We supported weight-decomposed LoRA (**[DoRA](https://arxiv.org/abs/2402.09353)**). Try `use_dora: true` to activate DoRA training.

[24/02/15] We supported **block expansion** proposed by [LLaMA Pro](https://github.com/TencentARC/LLaMA-Pro). See [examples](examples/README.md) for usage.

[24/02/05] Qwen1.5 (Qwen2 beta version) series models are supported in LLaMA-Factory. Check this [blog post](https://qwenlm.github.io/blog/qwen1.5/) for details.

[24/01/18] We supported **agent tuning** for most models, equipping model with tool using abilities by fine-tuning with `dataset: glaive_toolcall_en`.

[23/12/23] We supported **[unsloth](https://github.com/unslothai/unsloth)**'s implementation to boost LoRA tuning for the LLaMA, Mistral and Yi models. Try `use_unsloth: true` argument to activate unsloth patch. It achieves **170%** speed in our benchmark, check [this page](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison) for details.

[23/12/12] We supported fine-tuning the latest MoE model **[Mixtral 8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)** in our framework. See hardware requirement [here](#hardware-requirement).

[23/12/01] We supported downloading pre-trained models and datasets from the **[ModelScope Hub](https://modelscope.cn/models)**. See [this tutorial](#download-from-modelscope-hub) for usage.

[23/10/21] We supported **[NEFTune](https://arxiv.org/abs/2310.05914)** trick for fine-tuning. Try `neftune_noise_alpha: 5` argument to activate NEFTune.

[23/09/27] We supported **$S^2$-Attn** proposed by [LongLoRA](https://github.com/dvlab-research/LongLoRA) for the LLaMA models. Try `shift_attn: true` argument to enable shift short attention.

[23/09/23] We integrated MMLU, C-Eval and CMMLU benchmarks in this repo. See [examples](examples/README.md) for usage.

[23/09/10] We supported **[FlashAttention-2](https://github.com/Dao-AILab/flash-attention)**. Try `flash_attn: fa2` argument to enable FlashAttention-2 if you are using RTX4090, A100 or H100 GPUs.

[23/08/12] We supported **RoPE scaling** to extend the context length of the LLaMA models. Try `rope_scaling: linear` argument in training and `rope_scaling: dynamic` argument at inference to extrapolate the position embeddings.

[23/08/11] We supported **[DPO training](https://arxiv.org/abs/2305.18290)** for instruction-tuned models. See [examples](examples/README.md) for usage.

[23/07/31] We supported **dataset streaming**. Try `streaming: true` and `max_steps: 10000` arguments to load your dataset in streaming mode.

[23/07/29] We released two instruction-tuned 13B models at Hugging Face. See these Hugging Face Repos ([LLaMA-2](https://huggingface.co/hiyouga/Llama-2-Chinese-13b-chat) / [Baichuan](https://huggingface.co/hiyouga/Baichuan-13B-sft)) for details.

[23/07/18] We developed an **all-in-one Web UI** for training, evaluation and inference. Try `train_web.py` to fine-tune models in your Web browser. Thank [@KanadeSiina](https://github.com/KanadeSiina) and [@codemayq](https://github.com/codemayq) for their efforts in the development.

[23/07/09] We released **[FastEdit](https://github.com/hiyouga/FastEdit)** ⚡🩹, an easy-to-use package for editing the factual knowledge of large language models efficiently. Please follow [FastEdit](https://github.com/hiyouga/FastEdit) if you are interested.

[23/06/29] We provided a **reproducible example** of training a chat model using instruction-following datasets, see [Baichuan-7B-sft](https://huggingface.co/hiyouga/Baichuan-7B-sft) for details.

[23/06/22] We aligned the [demo API](src/api_demo.py) with the [OpenAI's](https://platform.openai.com/docs/api-reference/chat) format where you can insert the fine-tuned model in **arbitrary ChatGPT-based applications**.

[23/06/03] We supported quantized training and inference (aka **[QLoRA](https://github.com/artidoro/qlora)**). See [examples](examples/README.md) for usage.

</details>

> [!TIP]
> If you cannot use the latest feature, please pull the latest code and install LLaMA-Factory again.

## Supported Models

| Model                                                             | Model size                       | Template             |
| ----------------------------------------------------------------- | -------------------------------- | -------------------- |
| [BLOOM/BLOOMZ](https://huggingface.co/bigscience)                 | 560M/1.1B/1.7B/3B/7.1B/176B      | -                    |
| [Command R](https://huggingface.co/CohereForAI)                   | 35B/104B                         | cohere               |
| [DeepSeek (LLM/Code/MoE)](https://huggingface.co/deepseek-ai)     | 7B/16B/67B/236B                  | deepseek             |
| [DeepSeek 3-3.2](https://huggingface.co/deepseek-ai)              | 236B/671B                        | deepseek3            |
| [DeepSeek R1 (Distill)](https://huggingface.co/deepseek-ai)       | 1.5B/7B/8B/14B/32B/70B/671B      | deepseekr1           |
| [ERNIE-4.5](https://huggingface.co/baidu)                         | 0.3B/21B/300B                    | ernie/ernie_nothink  |
| [Falcon/Falcon H1](https://huggingface.co/tiiuae)                 | 0.5B/1.5B/3B/7B/11B/34B/40B/180B | falcon/falcon_h1     |
| [Gemma/Gemma 2/CodeGemma](https://huggingface.co/google)          | 2B/7B/9B/27B                     | gemma/gemma2         |
| [Gemma 3/Gemma 3n](https://huggingface.co/google)                 | 270M/1B/4B/6B/8B/12B/27B         | gemma3/gemma3n       |
| [GLM-4/GLM-4-0414/GLM-Z1](https://huggingface.co/zai-org)         | 9B/32B                           | glm4/glmz1           |
| [GLM-4.5/GLM-4.5(6)V](https://huggingface.co/zai-org)             | 9B/106B/355B                     | glm4_moe/glm4_5v     |
| [GPT-2](https://huggingface.co/openai-community)                  | 0.1B/0.4B/0.8B/1.5B              | -                    |
| [GPT-OSS](https://huggingface.co/openai)                          | 20B/120B                         | gpt_oss              |
| [Granite 3-4](https://huggingface.co/ibm-granite)                 | 1B/2B/3B/7B/8B                   | granite3/granite4    |
| [Hunyuan (MT)](https://huggingface.co/tencent/)                   | 7B                               | hunyuan              |
| [InternLM 2-3](https://huggingface.co/internlm)                   | 7B/8B/20B                        | intern2              |
| [InternVL 2.5-3.5](https://huggingface.co/OpenGVLab)              | 1B/2B/4B/8B/14B/30B/38B/78B/241B | intern_vl            |
| [InternLM/Intern-S1-mini](https://huggingface.co/internlm/)       | 8B                               | intern_s1            |
| [Kimi-VL](https://huggingface.co/moonshotai)                      | 16B                              | kimi_vl              |
| [Ling 2.0 (mini/flash)](https://huggingface.co/inclusionAI)       | 16B/100B                         | bailing_v2           |
| [Llama](https://github.com/facebookresearch/llama)                | 7B/13B/33B/65B                   | -                    |
| [Llama 2](https://huggingface.co/meta-llama)                      | 7B/13B/70B                       | llama2               |
| [Llama 3-3.3](https://huggingface.co/meta-llama)                  | 1B/3B/8B/70B                     | llama3               |
| [Llama 4](https://huggingface.co/meta-llama)                      | 109B/402B                        | llama4               |
| [Llama 3.2 Vision](https://huggingface.co/meta-llama)             | 11B/90B                          | mllama               |
| [LLaVA-1.5](https://huggingface.co/llava-hf)                      | 7B/13B                           | llava                |
| [LLaVA-NeXT](https://huggingface.co/llava-hf)                     | 7B/8B/13B/34B/72B/110B           | llava_next           |
| [LLaVA-NeXT-Video](https://huggingface.co/llava-hf)               | 7B/34B                           | llava_next_video     |
| [MiMo](https://huggingface.co/XiaomiMiMo)                         | 7B/309B                          | mimo/mimo_v2         |
| [MiniCPM 1-4.1](https://huggingface.co/openbmb)                   | 0.5B/1B/2B/4B/8B                 | cpm/cpm3/cpm4        |
| [MiniCPM-o-2.6/MiniCPM-V-2.6](https://huggingface.co/openbmb)     | 8B                               | minicpm_o/minicpm_v  |
| [MiniMax-M1/MiniMax-M2](https://huggingface.co/MiniMaxAI/models)  | 229B/456B                        | minimax1/minimax2    |
| [Ministral 3](https://huggingface.co/mistralai)                   | 3B/8B/14B                        | ministral3           |
| [Mistral/Mixtral](https://huggingface.co/mistralai)               | 7B/8x7B/8x22B                    | mistral              |
| [OLMo](https://huggingface.co/allenai)                            | 1B/7B                            | -                    |
| [PaliGemma/PaliGemma2](https://huggingface.co/google)             | 3B/10B/28B                       | paligemma            |
| [Phi-3/Phi-3.5](https://huggingface.co/microsoft)                 | 4B/14B                           | phi                  |
| [Phi-3-small](https://huggingface.co/microsoft)                   | 7B                               | phi_small            |
| [Phi-4](https://huggingface.co/microsoft)                         | 14B                              | phi4                 |
| [Pixtral](https://huggingface.co/mistralai)                       | 12B                              | pixtral              |
| [Qwen (1-2.5) (Code/Math/MoE/QwQ)](https://huggingface.co/Qwen)   | 0.5B/1.5B/3B/7B/14B/32B/72B/110B | qwen                 |
| [Qwen3 (MoE/Instruct/Thinking/Next)](https://huggingface.co/Qwen) | 0.6B/1.7B/4B/8B/14B/32B/80B/235B | qwen3/qwen3_nothink  |
| [Qwen2-Audio](https://huggingface.co/Qwen)                        | 7B                               | qwen2_audio          |
| [Qwen2.5-Omni](https://huggingface.co/Qwen)                       | 3B/7B                            | qwen2_omni           |
| [Qwen3-Omni](https://huggingface.co/Qwen)                         | 30B                              | qwen3_omni           |
| [Qwen2-VL/Qwen2.5-VL/QVQ](https://huggingface.co/Qwen)            | 2B/3B/7B/32B/72B                 | qwen2_vl             |
| [Qwen3-VL](https://huggingface.co/Qwen)                           | 2B/4B/8B/30B/32B/235B            | qwen3_vl             |
| [Seed (OSS/Coder)](https://huggingface.co/ByteDance-Seed)         | 8B/36B                           | seed_oss/seed_coder  |
| [StarCoder 2](https://huggingface.co/bigcode)                     | 3B/7B/15B                        | -                    |
| [VibeThinker-1.5B](https://huggingface.co/WeiboAI)                | 1.5B                             | qwen3                |
| [Yi/Yi-1.5 (Code)](https://huggingface.co/01-ai)                  | 1.5B/6B/9B/34B                   | yi                   |
| [Youtu-LLM](https://huggingface.co/tencent/)                      | 2B                               | youtu                |
| [Yuan 2](https://huggingface.co/IEITYuan)                         | 2B/51B/102B                      | yuan                 |

> [!NOTE]
> For the "base" models, the `template` argument can be chosen from `default`, `alpaca`, `vicuna` etc. But make sure to use the **corresponding template** for the "instruct/chat" models.
>
> If the model has both reasoning and non-reasoning versions, please use the `_nothink` suffix to distinguish between them. For example, `qwen3` and `qwen3_nothink`.
>
> Remember to use the **SAME** template in training and inference.
>
> \*: You should install the `transformers` from main branch and use `DISABLE_VERSION_CHECK=1` to skip version check.
>
> \*\*: You need to install a specific version of `transformers` to use the corresponding model.

Please refer to [constants.py](src/llamafactory/extras/constants.py) for a full list of models we supported.

You also can add a custom chat template to [template.py](src/llamafactory/data/template.py).

## Supported Training Approaches

| Approach               |     Full-tuning    |    Freeze-tuning   |       LoRA         |       QLoRA        |        OFT         |        QOFT        |
| ---------------------- | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ | ------------------ |
| Pre-Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| Supervised Fine-Tuning | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| Reward Modeling        | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| PPO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| DPO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| KTO Training           | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| ORPO Training          | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| SimPO Training         | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |

> [!TIP]
> The implementation details of PPO can be found in [this blog](https://newfacade.github.io/notes-on-reinforcement-learning/17-ppo-trl.html).

## Provided Datasets

<details><summary>Pre-training datasets</summary>

- [Wiki Demo (en)](data/wiki_demo.txt)
- [RefinedWeb (en)](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)
- [RedPajama V2 (en)](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2)
- [Wikipedia (en)](https://huggingface.co/datasets/olm/olm-wikipedia-20221220)
- [Wikipedia (zh)](https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered)
- [Pile (en)](https://huggingface.co/datasets/EleutherAI/pile)
- [SkyPile (zh)](https://huggingface.co/datasets/Skywork/SkyPile-150B)
- [FineWeb (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb)
- [FineWeb-Edu (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu)
- [CCI3-HQ (zh)](https://huggingface.co/datasets/BAAI/CCI3-HQ)
- [CCI3-Data (zh)](https://huggingface.co/datasets/BAAI/CCI3-Data)
- [CCI4.0-M2-Base-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Base-v1)
- [CCI4.0-M2-CoT-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-CoT-v1)
- [CCI4.0-M2-Extra-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Extra-v1)
- [The Stack (en)](https://huggingface.co/datasets/bigcode/the-stack)
- [StarCoder (en)](https://huggingface.co/datasets/bigcode/starcoderdata)

</details>

<details><summary>Supervised fine-tuning datasets</summary>

- [Identity (en&zh)](data/identity.json)
- [Stanford Alpaca (en)](https://github.com/tatsu-lab/stanford_alpaca)
- [Stanford Alpaca (zh)](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3)
- [Alpaca GPT4 (en&zh)](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM)
- [Glaive Function Calling V2 (en&zh)](https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2)
- [LIMA (en)](https://huggingface.co/datasets/GAIR/lima)
- [Guanaco Dataset (multilingual)](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset)
- [BELLE 2M (zh)](https://huggingface.co/datasets/BelleGroup/train_2M_CN)
- [BELLE 1M (zh)](https://huggingface.co/datasets/BelleGroup/train_1M_CN)
- [BELLE 0.5M (zh)](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)
- [BELLE Dialogue 0.4M (zh)](https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M)
- [BELLE School Math 0.25M (zh)](https://huggingface.co/datasets/BelleGroup/school_math_0.25M)
- [BELLE Multiturn Chat 0.8M (zh)](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M)
- [UltraChat (en)](https://github.com/thunlp/UltraChat)
- [OpenPlatypus (en)](https://huggingface.co/datasets/garage-bAInd/Open-Platypus)
- [CodeAlpaca 20k (en)](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)
- [Alpaca CoT (multilingual)](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT)
- [OpenOrca (en)](https://huggingface.co/datasets/Open-Orca/OpenOrca)
- [SlimOrca (en)](https://huggingface.co/datasets/Open-Orca/SlimOrca)
- [MathInstruct (en)](https://huggingface.co/datasets/TIGER-Lab/MathInstruct)
- [Firefly 1.1M (zh)](https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M)
- [Wiki QA (en)](https://huggingface.co/datasets/wiki_qa)
- [Web QA (zh)](https://huggingface.co/datasets/suolyer/webqa)
- [WebNovel (zh)](https://huggingface.co/datasets/zxbsmk/webnovel_cn)
- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)
- [deepctrl (en&zh)](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data)
- [Advertise Generating (zh)](https://huggingface.co/datasets/HasturOfficial/adgen)
- [ShareGPT Hyperfiltered (en)](https://huggingface.co/datasets/totally-not-an-llm/sharegpt-hyperfiltered-3k)
- [ShareGPT4 (en&zh)](https://huggingface.co/datasets/shibing624/sharegpt_gpt4)
- [UltraChat 200k (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k)
- [Infinity Instruct (zh)](https://huggingface.co/datasets/BAAI/Infinity-Instruct)
- [AgentInstruct (en)](https://huggingface.co/datasets/THUDM/AgentInstruct)
- [LMSYS Chat 1M (en)](https://huggingface.co/datasets/lmsys/lmsys-chat-1m)
- [Evol Instruct V2 (en)](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k)
- [Cosmopedia (en)](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia)
- [STEM (zh)](https://huggingface.co/datasets/hfl/stem_zh_instruction)
- [Ruozhiba (zh)](https://huggingface.co/datasets/hfl/ruozhiba_gpt4_turbo)
- [Neo-sft (zh)](https://huggingface.co/datasets/m-a-p/neo_sft_phase2)
- [Magpie-Pro-300K-Filtered (en)](https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-300K-Filtered)
- [Magpie-ultra-v0.1 (en)](https://huggingface.co/datasets/argilla/magpie-ultra-v0.1)
- [WebInstructSub (en)](https://huggingface.co/datasets/TIGER-Lab/WebInstructSub)
- [OpenO1-SFT (en&zh)](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)
- [Open-Thoughts (en)](https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k)
- [Open-R1-Math (en)](https://huggingface.co/datasets/open-r1/OpenR1-Math-220k)
- [Chinese-DeepSeek-R1-Distill (zh)](https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT)
- [LLaVA mixed (en&zh)](https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k)
- [Pokemon-gpt4o-captions (en&zh)](https://huggingface.co/datasets/jugg1024/pokemon-gpt4o-captions)
- [DLR-Web (en)](https://huggingface.co/datasets/Attention1115/DLR-Web)
- [Open Assistant (de)](https://huggingface.co/datasets/mayflowergmbh/oasst_de)
- [Dolly 15k (de)](https://huggingface.co/datasets/mayflowergmbh/dolly-15k_de)
- [Alpaca GPT4 (de)](https://huggingface.co/datasets/mayflowergmbh/alpaca-gpt4_de)
- [OpenSchnabeltier (de)](https://huggingface.co/datasets/mayflowergmbh/openschnabeltier_de)
- [Evol Instruct (de)](https://huggingface.co/datasets/mayflowergmbh/evol-instruct_de)
- [Dolphin (de)](https://huggingface.co/datasets/mayflowergmbh/dolphin_de)
- [Booksum (de)](https://huggingface.co/datasets/mayflowergmbh/booksum_de)
- [Airoboros (de)](https://huggingface.co/datasets/mayflowergmbh/airoboros-3.0_de)
- [Ultrachat (de)](https://huggingface.co/datasets/mayflowergmbh/ultra-chat_de)

</details>

<details><summary>Preference datasets</summary>

- [DPO mixed (en&zh)](https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k)
- [UltraFeedback (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized)
- [COIG-P (zh)](https://huggingface.co/datasets/m-a-p/COIG-P)
- [RLHF-V (en)](https://huggingface.co/datasets/openbmb/RLHF-V-Dataset)
- [VLFeedback (en)](https://huggingface.co/datasets/Zhihui/VLFeedback)
- [RLAIF-V (en)](https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset)
- [Orca DPO Pairs (en)](https://huggingface.co/datasets/Intel/orca_dpo_pairs)
- [HH-RLHF (en)](https://huggingface.co/datasets/Anthropic/hh-rlhf)
- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)
- [Orca DPO (de)](https://huggingface.co/datasets/mayflowergmbh/intel_orca_dpo_pairs_de)
- [KTO mixed (en)](https://huggingface.co/datasets/argilla/kto-mix-15k)

</details>

Some datasets require confirmation before using them, so we recommend logging in with your Hugging Face account using these commands.

```bash
pip install "huggingface_hub<1.0.0"
huggingface-cli login
```

## Requirement

| Mandatory    | Minimum | Recommend |
| ------------ | ------- | --------- |
| python       | 3.9     | 3.10      |
| torch        | 2.0.0   | 2.6.0     |
| torchvision  | 0.15.0  | 0.21.0    |
| transformers | 4.49.0  | 4.50.0    |
| datasets     | 2.16.0  | 3.2.0     |
| accelerate   | 0.34.0  | 1.2.1     |
| peft         | 0.14.0  | 0.15.1    |
| trl          | 0.8.6   | 0.9.6     |

| Optional     | Minimum | Recommend |
| ------------ | ------- | --------- |
| CUDA         | 11.6    | 12.2      |
| deepspeed    | 0.10.0  | 0.16.4    |
| bitsandbytes | 0.39.0  | 0.43.1    |
| vllm         | 0.4.3   | 0.8.2     |
| flash-attn   | 2.5.6   | 2.7.2     |

### Hardware Requirement

\* *estimated*

| Method                              | Bits |   7B  |  14B  |  30B  |   70B  |   `x`B  |
| ----------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |
| Full (`bf16` or `fp16`)             |  32  | 120GB | 240GB | 600GB | 1200GB | `18x`GB |
| Full (`pure_bf16`)                  |  16  |  60GB | 120GB | 300GB |  600GB |  `8x`GB |
| Freeze/LoRA/GaLore/APOLLO/BAdam/OFT |  16  |  16GB |  32GB |  64GB |  160GB |  `2x`GB |
| QLoRA / QOFT                        |   8  |  10GB |  20GB |  40GB |   80GB |   `x`GB |
| QLoRA / QOFT                        |   4  |   6GB |  12GB |  24GB |   48GB | `x/2`GB |
| QLoRA / QOFT                        |   2  |   4GB |   8GB |  16GB |   24GB | `x/4`GB |

## Getting Started

### Installation

> [!IMPORTANT]
> Installation is mandatory.

#### Install from Source

```bash
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e .
pip install -r requirements/metrics.txt
```

Optional dependencies available: `metrics`, `deepspeed`. Install with: `pip install -e . && pip install -r requirements/metrics.txt -r requirements/deepspeed.txt`

Additional dependencies for specific features are available in `examples/requirements/`.

#### Install from Docker Image

```bash
docker run -it --rm --gpus=all --ipc=host hiyouga/llamafactory:latest
```

This image is built on Ubuntu 22.04 (x86\_64), CUDA 12.4, Python 3.11, PyTorch 2.6.0, and Flash-attn 2.7.4.

Find the pre-built images: https://hub.docker.com/r/hiyouga/llamafactory/tags

Please refer to [build docker](#build-docker) to build the image yourself.

<details><summary>Setting up a virtual environment with <b>uv</b></summary>

Create an isolated Python environment with [uv](https://github.com/astral-sh/uv):

```bash
uv run llamafactory-cli webui
```

</details>

<details><summary>For Windows users</summary>

#### Install PyTorch

You need to manually install the GPU version of PyTorch on the Windows platform. Please refer to the [official website](https://pytorch.org/get-started/locally/) and the following command to install PyTorch with CUDA support:

```bash
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
python -c "import torch; print(torch.cuda.is_available())"
```

If you see `True` then you have successfully installed PyTorch with CUDA support.

Try `dataloader_num_workers: 0` if you encounter `Can't pickle local object` error.

#### Install BitsAndBytes

If you want to enable the quantized LoRA (QLoRA) on the Windows platform, you need to install a pre-built version of `bitsandbytes` library, which supports CUDA 11.1 to 12.2, please select the appropriate [release version](https://github.com/jllllll/bitsandbytes-windows-webui/releases/tag/wheels) based on your CUDA version.

```bash
pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl
```

#### Install Flash Attention-2

To enable FlashAttention-2 on the Windows platform, please use the script from [flash-attention-windows-wheel](https://huggingface.co/lldacing/flash-attention-windows-wheel) to compile and install it by yourself.

</details>

<details><summary>For Ascend NPU users</summary>

To install LLaMA Factory on Ascend NPU devices, please upgrade Python to version 3.10 or higher: `pip install -r requirements/npu.txt`. Additionally, you need to install the **Ascend CANN Toolkit and Kernels**. Please follow the [installation tutorial](https://llamafactory.readthedocs.io/en/latest/advanced/npu_installation.html).


You can also download the pre-built Docker images:

```bash
# Docker Hub
docker pull hiyouga/llamafactory:latest-npu-a2
docker pull hiyouga/llamafactory:latest-npu-a3

# quay.io
docker pull quay.io/ascend/llamafactory:latest-npu-a2
docker pull quay.io/ascend/llamafactory:latest-npu-a3
```

#### Install BitsAndBytes

To use QLoRA based on bitsandbytes on Ascend NPU, please follow these 3 steps:

1. Manually compile bitsandbytes: Refer to [the installation documentation](https://huggingface.co/docs/bitsandbytes/installation?backend=Ascend+NPU&platform=Ascend+NPU) for the NPU version of bitsandbytes to complete the compilation and installation. The compilation requires a cmake version of at least 3.22.1 and a g++ version of at least 12.x.

```bash
# Install bitsandbytes from source
# Clone bitsandbytes repo, Ascend NPU backend is currently enabled on multi-backend-refactor branch
git clone -b multi-backend-refactor https://github.com/bitsandbytes-foundation/bitsandbytes.git
cd bitsandbytes/

# Install dependencies
pip install -r requirements-dev.txt

# Install the dependencies for the compilation tools. Note that the commands for this step may vary depending on the operating system. The following are provided for reference
apt-get install -y build-essential cmake

# Compile & install  
cmake -DCOMPUTE_BACKEND=npu -S .
make
pip install .
```

2. Install transformers from the main branch.

```bash
git clone -b main https://github.com/huggingface/transformers.git
cd transformers
pip install .
```

3. Set `double_quantization: false` in the configuration. You can refer to the [example](examples/train_qlora/qwen3_lora_sft_bnb_npu.yaml).

</details>

### Data Preparation

Please refer to [data/README.md](data/README.md) for checking the details about the format of dataset files. You can use datasets on HuggingFace / ModelScope / Modelers hub, load the dataset in local disk, or specify a path to s3/gcs cloud storage.

> [!NOTE]
> Please update `data/dataset_info.json` to use your custom dataset.

You can also use **[Easy Dataset](https://github.com/ConardLi/easy-dataset)**, **[DataFlow](https://github.com/OpenDCAI/DataFlow)** and **[GraphGen](https://github.com/open-sciencelab/GraphGen)** to create synthetic data for fine-tuning.

### Quickstart

Use the following 3 commands to run LoRA **fine-tuning**, **inference** and **merging** of the Qwen3-4B-Instruct model, respectively.

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml
llamafactory-cli chat examples/inference/qwen3_lora_sft.yaml
llamafactory-cli export examples/merge_lora/qwen3_lora_sft.yaml
```

See [examples/README.md](examples/README.md) for advanced usage (including distributed training).

> [!TIP]
> Use `llamafactory-cli help` to show help information.
>
> Read [FAQs](https://github.com/hiyouga/LLaMA-Factory/issues/4614) first if you encounter any problems.

### Fine-Tuning with LLaMA Board GUI (powered by [Gradio](https://github.com/gradio-app/gradio))

```bash
llamafactory-cli webui
```

### LLaMA Factory Online

Read our [documentation](https://docs.llamafactory.com.cn/docs/documents/quickstart/getstarted/?utm_source=LLaMA-Factory).

### Build Docker

For CUDA users:

```bash
cd docker/docker-cuda/
docker compose up -d
docker compose exec llamafactory bash
```

For Ascend NPU users:

```bash
cd docker/docker-npu/
docker compose up -d
docker compose exec llamafactory bash
```

For AMD ROCm users:

```bash
cd docker/docker-rocm/
docker compose up -d
docker compose exec llamafactory bash
```

<details><summary>Build without Docker Compose</summary>

For CUDA users:

```bash
docker build -f ./docker/docker-cuda/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    -t llamafactory:latest .

docker run -dit --ipc=host --gpus=all \
    -p 7860:7860 \
    -p 8000:8000 \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
```

For Ascend NPU users:

```bash
docker build -f ./docker/docker-npu/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    -t llamafactory:latest .

docker run -dit --ipc=host \
    -v /usr/local/dcmi:/usr/local/dcmi \
    -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \
    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \
    -v /etc/ascend_install.info:/etc/ascend_install.info \
    -p 7860:7860 \
    -p 8000:8000 \
    --device /dev/davinci0 \
    --device /dev/davinci_manager \
    --device /dev/devmm_svm \
    --device /dev/hisi_hdc \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
```

For AMD ROCm users:

```bash
docker build -f ./docker/docker-rocm/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    -t llamafactory:latest .

docker run -dit --ipc=host \
    -p 7860:7860 \
    -p 8000:8000 \
    --device /dev/kfd \
    --device /dev/dri \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
```

</details>

<details><summary>Use Docker volumes</summary>

You can uncomment `VOLUME [ "/root/.cache/huggingface", "/app/shared_data", "/app/output" ]` in the Dockerfile to use data volumes.

When building the Docker image, use `-v ./hf_cache:/root/.cache/huggingface` argument to mount the local directory to the container. The following data volumes are available.

- `hf_cache`: Utilize Hugging Face cache on the host machine.
- `shared_data`: The directionary to store datasets on the host machine.
- `output`: Set export dir to this location so that the merged result can be accessed directly on the host machine.

</details>

### Deploy with OpenAI-style API and vLLM

```bash
API_PORT=8000 llamafactory-cli api examples/inference/qwen3.yaml infer_backend=vllm vllm_enforce_eager=true
```

> [!TIP]
> Visit [this page](https://platform.openai.com/docs/api-reference/chat/create) for API document.
>
> Examples: [Image understanding](scripts/api_example/test_image.py) | [Function calling](scripts/api_example/test_toolcall.py)

### Download from ModelScope Hub

If you have trouble with downloading models and datasets from Hugging Face, you can use ModelScope.

```bash
export USE_MODELSCOPE_HUB=1 # `set USE_MODELSCOPE_HUB=1` for Windows
```

Train the model by specifying a model ID of the ModelScope Hub as the `model_name_or_path`. You can find a full list of model IDs at [ModelScope Hub](https://modelscope.cn/models), e.g., `LLM-Research/Meta-Llama-3-8B-Instruct`.

### Download from Modelers Hub

You can also use Modelers Hub to download models and datasets.

```bash
export USE_OPENMIND_HUB=1 # `set USE_OPENMIND_HUB=1` for Windows
```

Train the model by specifying a model ID of the Modelers Hub as the `model_name_or_path`. You can find a full list of model IDs at [Modelers Hub](https://modelers.cn/models), e.g., `TeleAI/TeleChat-7B-pt`.

### Use W&B Logger

To use [Weights & Biases](https://wandb.ai) for logging experimental results, you need to add the following arguments to yaml files.

```yaml
report_to: wandb
run_name: test_run # optional
```

Set `WANDB_API_KEY` to [your key](https://wandb.ai/authorize) when launching training tasks to log in with your W&B account.

### Use SwanLab Logger

To use [SwanLab](https://github.com/SwanHubX/SwanLab) for logging experimental results, you need to add the following arguments to yaml files.

```yaml
use_swanlab: true
swanlab_run_name: test_run # optional
```

When launching training tasks, you can log in to SwanLab in three ways:

1. Add `swanlab_api_key=<your_api_key>` to the yaml file, and set it to your [API key](https://swanlab.cn/settings).
2. Set the environment variable `SWANLAB_API_KEY` to your [API key](https://swanlab.cn/settings).
3. Use the `swanlab login` command to complete the login.

## Projects using LLaMA Factory

If you have a project that should be incorporated, please contact via email or create a pull request.

<details><summary>Click to show</summary>

1. Wang et al. ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. 2023. [[arxiv]](https://arxiv.org/abs/2308.02223)
1. Yu et al. Open, Closed, or Small Language Models for Text Classification? 2023. [[arxiv]](https://arxiv.org/abs/2308.10092)
1. Wang et al. UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with Action Understanding and Feedback in Natural Language. 2023. [[arxiv]](https://arxiv.org/abs/2308.10526)
1. Luceri et al. Leveraging Large Language Models to Detect Influence Campaigns in Social Media. 2023. [[arxiv]](https://arxiv.org/abs/2311.07816)
1. Zhang et al. Alleviating Hallucinations of Large Language Models through Induced Hallucinations. 2023. [[arxiv]](https://arxiv.org/abs/2312.15710)
1. Wang et al. Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. KDD 2024. [[arxiv]](https://arxiv.org/abs/2401.04319)
1. Wang et al. CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2401.07286)
1. Choi et al. FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2402.05904)
1. Zhang et al. AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts. 2024. [[arxiv]](https://arxiv.org/abs/2402.07625)
1. Lyu et al. KnowTuning: Knowledge-aware Fine-tuning for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11176)
1. Yang et al. LaCo: Large Language Model Pruning via Layer Collaps. 2024. [[arxiv]](https://arxiv.org/abs/2402.11187)
1. Bhardwaj et al. Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic. 2024. [[arxiv]](https://arxiv.org/abs/2402.11746)
1. Yang et al. Enhancing Empathetic Response Generation by Augmenting LLMs with Small-scale Empathetic Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11801)
1. Yi et al. Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2402.11809)
1. Cao et al. Head-wise Shareable Attention for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11819)
1. Zhang et al. Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages. 2024. [[arxiv]](https://arxiv.org/abs/2402.12204)
1. Kim et al. Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.14714)
1. Yu et al. KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models. ACL 2024. [[arxiv]](https://arxiv.org/abs/2402.15043)
1. Huang et al. Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning. 2024. [[arxiv]](https://arxiv.org/abs/2403.02333)
1. Duan et al. Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization. 2024. [[arxiv]](https://arxiv.org/abs/2403.03419)
1. Xie and Schwertfeger. Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2403.08228)
1. Wu et al. Large Language Models are Parallel Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2403.09073)
1. Zhang et al. EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling. 2024. [[arxiv]](https://arxiv.org/abs/2403.14541)
1. Weller et al. FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2403.15246)
1. Hongbin Na. CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering. COLING 2024. [[arxiv]](https://arxiv.org/abs/2403.16008)
1. Zan et al. CodeS: Natural Language to Code Repository via Multi-Layer Sketch. 2024. [[arxiv]](https://arxiv.org/abs/2403.16443)
1. Liu et al. Extensive Self-Contrast Enables Feedback-Free Language Model Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2404.00604)
1. Luo et al. BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.02827)
1. Du et al. Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2404.04167)
1. Ma et al. Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation. ICML 2024. [[arxiv]](https://arxiv.org/abs/2404.04316)
1. Liu et al. Dynamic Generation of Personalities with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.07084)
1. Shang et al. How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.09836)
1. Huang et al. LLMTune: Accelerate Database Knob Tuning with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.11581)
1. Deng et al. Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction. 2024. [[arxiv]](https://arxiv.org/abs/2404.14215)
1. Acikgoz et al. Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2404.16621)
1. Zhang et al. Small Language Models Need Strong Verifiers to Self-Correct Reasoning. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2404.17140)
1. Zhou et al. FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering. NAACL 2024. [[arxiv]](https://arxiv.org/abs/2404.18585)
1. Xu et al. Large Language Models for Cyber Security: A Systematic Literature Review. 2024. [[arxiv]](https://arxiv.org/abs/2405.04760)
1. Dammu et al. "They are uncultured": Unveiling Covert Harms and Social Threats in LLM Generated Conversations. 2024. [[arxiv]](https://arxiv.org/abs/2405.05378)
1. Yi et al. A safety realignment framework via subspace-oriented model fusion for large language models. 2024. [[arxiv]](https://arxiv.org/abs/2405.09055)
1. Lou et al. SPO: Multi-Dimensional Preference Sequential Alignment With Implicit Reward Modeling. 2024. [[arxiv]](https://arxiv.org/abs/2405.12739)
1. Zhang et al. Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2405.13816)
1. Zhang et al. TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2405.20215)
1. Zihong Chen. Sentence Segmentation and Sentence Punctuation Based on XunziALLM. 2024. [[paper]](https://aclanthology.org/2024.lt4hala-1.30)
1. Gao et al. The Best of Both Worlds: Toward an Honest and Helpful Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2406.00380)
1. Wang and Song. MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset. 2024. [[arxiv]](https://arxiv.org/abs/2406.02106)
1. Hu et al. Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models. 2024. [[arxiv]](https://arxiv.org/abs/2406.03136)
1. Ge et al. Time Sensitive Knowledge Editing through Efficient Finetuning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2406.04496)
1. Tan et al. Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions. 2024. [[arxiv]](https://arxiv.org/abs/2406.05688)
1. Song et al. Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters. 2024. [[arxiv]](https://arxiv.org/abs/2406.05955)
1. Gu et al. RWKV-CLIP: A Robust Vision-Language Representation Learner. 2024. [[arxiv]](https://arxiv.org/abs/2406.06973)
1. Chen et al. Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees. 2024. [[arxiv]](https://arxiv.org/abs/2406.07115)
1. Zhu et al. Are Large Language Models Good Statisticians?. 2024. [[arxiv]](https://arxiv.org/abs/2406.07815)
1. Li et al. Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2406.10099)
1. Ding et al. IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce. 2024. [[arxiv]](https://arxiv.org/abs/2406.10173)
1. He et al. COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities. 2024. [[arxiv]](https://arxiv.org/abs/2406.12074)
1. Lin et al. FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving. 2024. [[arxiv]](https://arxiv.org/abs/2406.14408)
1. Treutlein et al. Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. 2024. [[arxiv]](https://arxiv.org/abs/2406.14546)
1. Feng et al. SS-Bench: A Benchmark for Social Story Generation and Evaluation. 2024. [[arxiv]](https://arxiv.org/abs/2406.15695)
1. Feng et al. Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement. 2024. [[arxiv]](https://arxiv.org/abs/2406.17233)
1. Liu et al. Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals. 2024. [[arxiv]](https://arxiv.org/abs/2406.18069)
1. Iyer et al. Exploring Very Low-Resource Translation with LLMs: The University of Edinburgh's Submission to AmericasNLP 2024 Translation Task. AmericasNLP 2024. [[paper]](https://aclanthology.org/2024.americasnlp-1.25)
1. Li et al. Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring. 2024. [[arxiv]](https://arxiv.org/abs/2406.19949)
1. Yang et al. Financial Knowledge Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2407.00365)
1. Lin et al. DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging. 2024. [[arxiv]](https://arxiv.org/abs/2407.01470)
1. Bako et al. Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization. 2024. [[arxiv]](https://arxiv.org/abs/2407.06129)
1. Huang et al. RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization. 2024. [[arxiv]](https://arxiv.org/abs/2407.08044)
1. Jiang et al. LLM-Collaboration on Automatic Science Journalism for the General Audience. 2024. [[arxiv]](https://arxiv.org/abs/2407.09756)
1. Inouye et al. Applied Auto-tuning on LoRA Hyperparameters. 2024. [[paper]](https://scholarcommons.scu.edu/cseng_senior/272/)
1. Qi et al. Research on Tibetan Tourism Viewpoints information generation system based on LLM. 2024. [[arxiv]](https://arxiv.org/abs/2407.13561)
1. Xu et al. Course-Correction: Safety Alignment Using Synthetic Preferences. 2024. [[arxiv]](https://arxiv.org/abs/2407.16637)
1. Sun et al. LAMBDA: A Large Model Based Data Agent. 2024. [[arxiv]](https://arxiv.org/abs/2407.17535)
1. Zhu et al. CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2407.19705)
1. Yu et al. Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2408.00137)
1. Xie et al. The Power of Personalized Datasets: Advancing Chinese Composition Writing for Elementary School through Targeted Model Fine-Tuning. IALP 2024. [[paper]](https://www.asianlp.sg/conferences/ialp2024/proceedings/papers/IALP2024_P055.pdf)
1. Liu et al. Instruct-Code-Llama: Improving Capabilities of Language Model in Competition Level Code Generation by Online Judge Feedback. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_11)
1. Wang et al. Cybernetic Sentinels: Unveiling the Impact of Safety Data Selection on Model Security in Supervised Fine-Tuning. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_23)
1. Xia et al. Understanding the Performance and Estimating the Cost of LLM Fine-Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2408.04693)
1. Zeng et al. Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2408.04168)
1. Xia et al. Using Pre-trained Language Model for Accurate ESG Prediction. FinNLP 2024. [[paper]](https://aclanthology.org/2024.finnlp-2.1/)
1. Liang et al. I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm. 2024. [[arxiv]](https://arxiv.org/abs/2408.08072)
1. Bai et al. Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation. CIKM 2024. [[paper]](https://dl.acm.org/doi/10.1145/3627673.3679611)
1. Zhang et al. CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling. ACL 2024. [[paper]](https://aclanthology.org/2024.findings-acl.830.pdf)
1. **[StarWhisper](https://github.com/Yu-Yang-Li/StarWhisper)**: A large language model for Astronomy, based on ChatGLM2-6B and Qwen-14B.
1. **[DISC-LawLLM](https://github.com/FudanDISC/DISC-LawLLM)**: A large language model specialized in Chinese legal domain, based on Baichuan-13B, is capable of retrieving and reasoning on legal knowledge.
1. **[Sunsimiao](https://github.com/X-D-Lab/Sunsimiao)**: A large language model specialized in Chinese medical domain, based on Baichuan-7B and ChatGLM-6B.
1. **[CareGPT](https://github.com/WangRongsheng/CareGPT)**: A series of large language models for Chinese medical domain, based on LLaMA2-7B and Baichuan-13B.
1. **[MachineMindset](https://github.com/PKU-YuanGroup/Machine-Mindset/)**: A series of MBTI Personality large language models, capable of giving any LLM 16 different personality types based on different datasets and training methods.
1. **[Luminia-13B-v3](https://huggingface.co/Nekochu/Luminia-13B-v3)**: A large language model specialized in generate metadata for stable diffusion. [[demo]](https://huggingface.co/spaces/Nekochu/Luminia-13B_SD_Prompt)
1. **[Chinese-LLaVA-Med](https://github.com/BUAADreamer/Chinese-LLaVA-Med)**: A multimodal large language model specialized in Chinese medical domain, based on LLaVA-1.5-7B.
1. **[AutoRE](https://github.com/THUDM/AutoRE)**: A document-level relation extraction system based on large language models.
1. **[NVIDIA RTX AI Toolkit](https://github.com/NVIDIA/RTX-AI-Toolkit)**: SDKs for fine-tuning LLMs on Windows PC for NVIDIA RTX.
1. **[LazyLLM](https://github.com/LazyAGI/LazyLLM)**: An easy and lazy way for building multi-agent LLMs applications and supports model fine-tuning via LLaMA Factory.
1. **[RAG-Retrieval](https://github.com/NLPJCL/RAG-Retrieval)**: A full pipeline for RAG retrieval model fine-tuning, inference, and distillation. [[blog]](https://zhuanlan.zhihu.com/p/987727357)
1. **[360-LLaMA-Factory](https://github.com/Qihoo360/360-LLaMA-Factory)**: A modified library that supports long sequence SFT & DPO using ring attention.
1. **[Sky-T1](https://novasky-ai.github.io/posts/sky-t1/)**: An o1-like model fine-tuned by NovaSky AI with very small cost.
1. **[WeClone](https://github.com/xming521/WeClone)**: One-stop solution for creating your digital avatar from chat logs.
1. **[EmoLLM](https://github.com/SmartFlowAI/EmoLLM)**: A project about large language models (LLMs) and mental health.
</details>

## License

This repository is licensed under the [Apache-2.0 License](LICENSE).

Please follow the model licenses to use the corresponding model weights: [Baichuan 2](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/blob/main/Community%20License%20for%20Baichuan%202%20Model.pdf) / [BLOOM](https://huggingface.co/spaces/bigscience/license) / [ChatGLM3](https://github.com/THUDM/ChatGLM3/blob/main/MODEL_LICENSE) / [Command R](https://cohere.com/c4ai-cc-by-nc-license) / [DeepSeek](https://github.com/deepseek-ai/DeepSeek-LLM/blob/main/LICENSE-MODEL) / [Falcon](https://huggingface.co/tiiuae/falcon-180B/blob/main/LICENSE.txt) / [Gemma](https://ai.google.dev/gemma/terms) / [GLM-4](https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE) / [GPT-2](https://github.com/openai/gpt-2/blob/master/LICENSE) / [Granite](LICENSE) / [Index](https://huggingface.co/IndexTeam/Index-1.9B/blob/main/LICENSE) / [InternLM](https://github.com/InternLM/InternLM#license) / [Llama](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md) / [Llama 2](https://ai.meta.com/llama/license/) / [Llama 3](https://llama.meta.com/llama3/license/) / [Llama 4](https://github.com/meta-llama/llama-models/blob/main/models/llama4/LICENSE) / [MiniCPM](https://github.com/OpenBMB/MiniCPM/blob/main/MiniCPM%20Model%20License.md) / [Mistral/Mixtral/Pixtral](LICENSE) / [OLMo](LICENSE) / [Phi-1.5/Phi-2](https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx) / [Phi-3/Phi-4](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE) / [Qwen](https://github.com/QwenLM/Qwen/blob/main/Tongyi%20Qianwen%20LICENSE%20AGREEMENT) / [Skywork](https://huggingface.co/Skywork/Skywork-13B-base/blob/main/Skywork%20Community%20License.pdf) / [StarCoder 2](https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement) / [TeleChat2](https://huggingface.co/Tele-AI/telechat-7B/blob/main/TeleChat%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf) / [XVERSE](https://github.com/xverse-ai/XVERSE-13B/blob/main/MODEL_LICENSE.pdf) / [Yi](https://huggingface.co/01-ai/Yi-6B/blob/main/LICENSE) / [Yi-1.5](LICENSE) / [Yuan 2](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/LICENSE-Yuan)

## Citation

If this work is helpful, please kindly cite as:

```bibtex
@inproceedings{zheng2024llamafactory,
  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  address={Bangkok, Thailand},
  publisher={Association for Computational Linguistics},
  year={2024},
  url={http://arxiv.org/abs/2403.13372}
}
```

## Acknowledgement

This repo benefits from [PEFT](https://github.com/huggingface/peft), [TRL](https://github.com/huggingface/trl), [QLoRA](https://github.com/artidoro/qlora) and [FastChat](https://github.com/lm-sys/FastChat). Thanks for their wonderful works.

## Star History

![Star History Chart](https://api.star-history.com/svg?repos=hiyouga/LLaMA-Factory&type=Date)


## Links discovered
- [# LLaMA Factory](https://github.com/hiyouga/LlamaFactory/blob/main/assets/logo.png)
- [![GitHub Repo stars](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social)
- [![GitHub last commit](https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory)
- [![GitHub contributors](https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange)
- [![GitHub workflow](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg)
- [![PyPI](https://img.shields.io/pypi/v/llamafactory)
- [![Citation](https://img.shields.io/badge/citation-1000+-green)
- [![Docker Pulls](https://img.shields.io/docker/pulls/hiyouga/llamafactory)
- [![Twitter](https://img.shields.io/twitter/follow/llamafactory_ai)
- [![Discord](https://github.com/hiyouga/LlamaFactory/blob/main/assets/thirdparty/discord.svg)
- [![WeChat](https://img.shields.io/badge/WeChat-User%20Group-blue?logo=wechat)
- [![Blog](https://img.shields.io/badge/Hugo-Official%20Blog-blue?logo=hugo)
- [![Open in Colab](https://github.com/hiyouga/LlamaFactory/blob/main/assets/thirdparty/colab.svg)
- [![Open in DSW](https://github.com/hiyouga/LlamaFactory/blob/main/assets/thirdparty/dsw.svg)
- [![Open in Lab4ai](https://github.com/hiyouga/LlamaFactory/blob/main/assets/thirdparty/lab4ai.svg)
- [![Open in Online](https://github.com/hiyouga/LlamaFactory/blob/main/assets/thirdparty/online.svg)
- [![Open in Spaces](https://img.shields.io/badge/🤗-Open%20in%20Spaces-blue)
- [![Open in Studios](https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue)
- [![Open in Novita](https://img.shields.io/badge/Novita-Deploy%20Template-blue)
- [Amazon](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/)
- [NVIDIA](https://developer.nvidia.com/rtx/ai-toolkit)
- [Aliyun](https://help.aliyun.com/zh/pai/use-cases/fine-tune-a-llama-3-model-with-llama-factory)
- [GitHub Trend](https://trendshift.io/api/badge/repositories/4535)
- [WeChat](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/main.jpg)
- [NPU](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/npu.jpg)
- [Lab4AI](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/lab4ai.jpg)
- [LLaMA Factory Online](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/online.jpg)
- [English | [中文](https://github.com/hiyouga/LlamaFactory/blob/main/README_zh.md)
- [GaLore](https://github.com/jiaweizzhao/GaLore)
- [BAdam](https://github.com/Ledzy/BAdam)
- [APOLLO](https://github.com/zhuhanqing/APOLLO)
- [Adam-mini](https://github.com/zyushun/Adam-mini)
- [Muon](https://github.com/KellerJordan/Muon)
- [OFT](https://github.com/huggingface/peft/tree/main/src/peft/tuners/oft)
- [FlashAttention-2](https://github.com/Dao-AILab/flash-attention)
- [Unsloth](https://github.com/unslothai/unsloth)
- [Liger Kernel](https://github.com/linkedin/Liger-Kernel)
- [KTransformers](https://github.com/kvcache-ai/ktransformers/)
- [SwanLab](https://github.com/SwanHubX/SwanLab)
- [vLLM worker](https://github.com/vllm-project/vllm)
- [SGLang worker](https://github.com/sgl-project/sglang)
- [KTransformers Fine-Tuning × LLaMA Factory: Fine-tuning 1000 Billion models with 2 4090-GPU + CPU](https://blog.llamafactory.net/en/posts/ktransformers/)
- [Easy Dataset × LLaMA Factory: Enabling LLMs to Efficiently Learn Domain Knowledge](https://buaa-act.feishu.cn/wiki/GVzlwYcRFiR8OLkHbL6cQpYin7g)
- [Fine-tune a mental health LLM using LLaMA-Factory](https://www.lab4ai.cn/project/detail?id=25cce32ec131497b9e06a93336a0817f&type=project&utm_source=LLaMA-Factory)
- [Fine-tune GPT-OSS for Role-Playing using LLaMA-Factory](https://docs.llamafactory.com.cn/docs/documents/best-practice/gptroleplay/?utm_source=LLaMA-Factory)
- [A One-Stop Code-Free Model Reinforcement Learning and Deployment Platform based on LLaMA-Factory and EasyR1](https://aws.amazon.com/cn/blogs/china/building-llm-model-hub-based-on-llamafactory-and-easyr1/)
- [How Apoidea Group enhances visual information extraction from banking documents with multimodal models using LLaMA-Factory on Amazon SageMaker HyperPod](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/)
- [Fine-tune Llama3.1-70B for Medical Diagnosis using LLaMA-Factory](https://docs.alayanew.com/docs/documents/bestPractice/bigModel/llama70B/?utm_source=LLaMA-Factory)
- [Fine-tune Qwen2.5-VL for Autonomous Driving using LLaMA-Factory](https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory)
- [LLaMA Factory: Fine-tuning the DeepSeek-R1-Distill-Qwen-7B Model for News Classifier](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_deepseek_r1_distill_7b)
- [A One-Stop Code-Free Model Fine-Tuning \& Deployment Platform based on SageMaker and LLaMA-Factory](https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/)
- [LLaMA Factory Multi-Modal Fine-Tuning Practice: Fine-Tuning Qwen2-VL for Personal Tourist Guide](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_qwen2vl)
- [LLaMA Factory: Fine-tuning Llama3 for Role-Playing](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory)
- [**mcore_adapter**](https://github.com/alibaba/ROLL/tree/main/mcore_adapter)
- [PR #9237](https://github.com/hiyouga/LLaMA-Factory/pull/9237)
- [OFT](https://arxiv.org/abs/2306.07280)
- [OFTv2](https://arxiv.org/abs/2506.19847)
- [examples](https://github.com/hiyouga/LlamaFactory/blob/main/examples/README.md)
- [Intern-S1-mini](https://huggingface.co/internlm/Intern-S1-mini)
- [PR #8976](https://github.com/hiyouga/LLaMA-Factory/pull/8976)
- [GPT-OSS](https://github.com/openai/gpt-oss)
- [PR #8826](https://github.com/hiyouga/LLaMA-Factory/pull/8826)
- [GLM-4.1V-9B-Thinking](https://github.com/THUDM/GLM-4.1V-Thinking)
- [Qwen3](https://qwenlm.github.io/blog/qwen3/)
- [@tianshijing](https://github.com/tianshijing)
- [InternVL3](https://huggingface.co/OpenGVLab/InternVL3-8B)
- [PR #7258](https://github.com/hiyouga/LLaMA-Factory/pull/7258)
- [GLM-Z1](https://huggingface.co/THUDM/GLM-Z1-9B-0414)
- [Kimi-VL](https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct)
- [Llama 4](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)
- [PR #7611](https://github.com/hiyouga/LLaMA-Factory/pull/7611)
- [Qwen2.5 Omni](https://qwenlm.github.io/blog/qwen2.5-omni/)
- [PR #7537](https://github.com/hiyouga/LLaMA-Factory/pull/7537)
- [SGLang](https://github.com/sgl-project/sglang)
- [Gemma 3](https://huggingface.co/blog/gemma3)
- [EasyR1](https://github.com/hiyouga/EasyR1)
- [Ollama](https://github.com/ollama/ollama)
- [Qwen2-Audio](https://github.com/hiyouga/LlamaFactory/blob/main/Qwen/Qwen2-Audio-7B-Instruct.md)
- [MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)
- [DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)
- [Qwen2.5-VL](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct)
- [APOLLO](https://arxiv.org/abs/2412.05270)
- [MiniCPM-V-2.6](https://huggingface.co/openbmb/MiniCPM-V-2_6)
- [@BUAADreamer](https://github.com/BUAADreamer)
- [InternLM 3](https://huggingface.co/collections/internlm/)
- [@hhaAndroid](https://github.com/hhaAndroid)
- [Phi-4](https://huggingface.co/microsoft/phi-4)
- [Skywork-o1](https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B)
- [OpenO1](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)
- [Modelers Hub](https://modelers.cn/models)
- [Qwen2.5](https://qwenlm.github.io/blog/qwen2.5/)
- [Qwen2-VL](https://qwenlm.github.io/blog/qwen2-vl/)
- [@simonJJJ](https://github.com/simonJJJ)
- [@relic-yuexi](https://github.com/relic-yuexi)
- [contamination-free packed training](https://github.com/MeetKai/functionary/tree/main/functionary/train/packing)
- [@chuan298](https://github.com/chuan298)
- [PiSSA](https://arxiv.org/abs/2404.02948)
- [Qwen2](https://qwenlm.github.io/blog/qwen2/)
- [GLM-4](https://github.com/THUDM/GLM-4)
- [SimPO](https://arxiv.org/abs/2405.14734)

--- README_zh.md ---
![# LLaMA Factory](assets/logo.png)

[![GitHub Repo stars](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social)](https://github.com/hiyouga/LLaMA-Factory/stargazers)
[![GitHub last commit](https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory)](https://github.com/hiyouga/LLaMA-Factory/commits/main)
[![GitHub contributors](https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange)](https://github.com/hiyouga/LLaMA-Factory/graphs/contributors)
[![GitHub workflow](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg)](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml)
[![PyPI](https://img.shields.io/pypi/v/llamafactory)](https://pypi.org/project/llamafactory/)
[![Citation](https://img.shields.io/badge/citation-1000+-green)](https://scholar.google.com/scholar?cites=12620864006390196564)
[![Docker Pulls](https://img.shields.io/docker/pulls/hiyouga/llamafactory)](https://hub.docker.com/r/hiyouga/llamafactory/tags)

[![Twitter](https://img.shields.io/twitter/follow/llamafactory_ai)](https://twitter.com/llamafactory_ai)
[![Discord](assets/thirdparty/discord.svg)](https://discord.gg/rKfvV9r9FK)
[![WeChat](https://img.shields.io/badge/WeChat-User%20Group-blue?logo=wechat)](https://github.com/hiyouga/llamafactory-community)
[![Blog](https://img.shields.io/badge/Hugo-Official%20Blog-blue?logo=hugo)](https://blog.llamafactory.net/)

[![Open in Colab](assets/thirdparty/colab.svg)](https://colab.research.google.com/drive/1d5KQtbemerlSDSxZIfAaWXhKr30QypiK?usp=sharing)
[![Open in DSW](assets/thirdparty/dsw.svg)](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory)
[![Open in Lab4ai](assets/thirdparty/lab4ai.svg)](https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory)
[![Open in Online](assets/thirdparty/online.svg)](https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory)
[![Open in Spaces](https://img.shields.io/badge/🤗-Open%20in%20Spaces-blue)](https://huggingface.co/spaces/hiyouga/LLaMA-Board)
[![Open in Studios](https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue)](https://modelscope.cn/studios/hiyouga/LLaMA-Board)
[![Open in Novita](https://img.shields.io/badge/Novita-Deploy%20Template-blue)](https://novita.ai/templates-library/105981?sharer=88115474-394e-4bda-968e-b88e123d0c47)

### 获得[亚马逊](https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/)、[英伟达](https://developer.nvidia.cn/rtx/ai-toolkit)、[阿里云](https://help.aliyun.com/zh/pai/use-cases/fine-tune-a-llama-3-model-with-llama-factory)等的应用。

<div align="center" markdown="1">

### 赞助商 ❤️

| <div style="text-align: center;"><a href="https://warp.dev/llama-factory"><img alt="Warp sponsorship" width="400" src="assets/sponsors/warp.jpg"></a><br><a href="https://warp.dev/llama-factory" style="font-size:larger;">Warp，面向开发者的智能终端</a><br><a href="https://warp.dev/llama-factory">适用于 MacOS、Linux 和 Windows</a> | <a href="https://serpapi.com"><img alt="SerpAPI sponsorship" width="250" src="assets/sponsors/serpapi.svg"> </a> |
| ---- | ---- |

----

### 使用零代码[命令行](#快速开始)与 [Web UI](#llama-board-可视化微调由-gradio-驱动) 轻松微调百余种大模型

![GitHub Trend](https://trendshift.io/api/badge/repositories/4535)

</div>

👋 加入我们的[微信群](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/main.jpg)、[NPU 用户群](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/npu.jpg)、[大模型实验室群](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/lab4ai.jpg) 或 [LLaMA Factory Online 用户群](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/online.png)。

\[ [English](README.md) | 中文 \]

**微调大模型可以像这样轻松…**

https://github.com/user-attachments/assets/43b700c6-a178-41db-b1f8-8190a5d3fcfc

开始本地训练：
- 请见[如何使用](#如何使用)

开始云端训练：
- **Colab（免费）**：https://colab.research.google.com/drive/1d5KQtbemerlSDSxZIfAaWXhKr30QypiK?usp=sharing
- **PAI-DSW（免费试用）**：https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory
- **LLaMA Factory Online（在线微调）**：https://www.llamafactory.com.cn/?utm_source=LLaMA-Factory
- **九章智算云（算力优惠活动）**：https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory

阅读技术文档：
- **入门教程**：https://zhuanlan.zhihu.com/p/695287607
- **微调视频教程**：https://www.bilibili.com/video/BV1djgRzxEts/
- **框架文档**：https://llamafactory.readthedocs.io/zh-cn/latest/
- **框架文档（昇腾 NPU）**：https://ascend.github.io/docs/sources/llamafactory/
- **官方博客**：https://blog.llamafactory.net/
- **官方课程**：https://www.lab4ai.cn/course/detail?id=7c13e60f6137474eb40f6fd3983c0f46&utm_source=LLaMA-Factory

> [!NOTE]
> 除上述链接以外的其他网站均为未经许可的第三方网站，请小心甄别。

## 目录

- [项目特色](#项目特色)
- [官方博客](#官方博客)
- [更新日志](#更新日志)
- [模型](#模型)
- [训练方法](#训练方法)
- [数据集](#数据集)
- [软硬件依赖](#软硬件依赖)
- [如何使用](#如何使用)
  - [安装 LLaMA Factory](#安装-llama-factory)
  - [数据准备](#数据准备)
  - [快速开始](#快速开始)
  - [LLaMA Board 可视化微调](#llama-board-可视化微调由-gradio-驱动)
  - [LLaMA Factory Online 在线微调](#llama-factory-online-在线微调)
  - [构建 Docker](#构建-docker)
  - [利用 vLLM 部署 OpenAI API](#利用-vllm-部署-openai-api)
  - [从魔搭社区下载](#从魔搭社区下载)
  - [从魔乐社区下载](#从魔乐社区下载)
  - [使用 W&B 面板](#使用-wb-面板)
  - [使用 SwanLab 面板](#使用-swanlab-面板)
- [使用了 LLaMA Factory 的项目](#使用了-llama-factory-的项目)
- [协议](#协议)
- [引用](#引用)
- [致谢](#致谢)

## 项目特色

- **多种模型**：LLaMA、LLaVA、Mistral、Mixtral-MoE、Qwen、Qwen2-VL、DeepSeek、Yi、Gemma、ChatGLM、Phi 等等。
- **集成方法**：（增量）预训练、（多模态）指令监督微调、奖励模型训练、PPO 训练、DPO 训练、KTO 训练、ORPO 训练等等。
- **多种精度**：16 比特全参数微调、冻结微调、LoRA 微调和基于 AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ 的 2/3/4/5/6/8 比特 QLoRA 微调。
- **先进算法**：[GaLore](https://github.com/jiaweizzhao/GaLore)、[BAdam](https://github.com/Ledzy/BAdam)、[APOLLO](https://github.com/zhuhanqing/APOLLO)、[Adam-mini](https://github.com/zyushun/Adam-mini)、[Muon](https://github.com/KellerJordan/Muon)、[OFT](https://github.com/huggingface/peft/tree/main/src/peft/tuners/oft)、DoRA、LongLoRA、LLaMA Pro、Mixture-of-Depths、LoRA+、LoftQ 和 PiSSA。
- **实用技巧**：[FlashAttention-2](https://github.com/Dao-AILab/flash-attention)、[Unsloth](https://github.com/unslothai/unsloth)、[Liger Kernel](https://github.com/linkedin/Liger-Kernel)、[KTransformers](https://github.com/kvcache-ai/ktransformers/)、RoPE scaling、NEFTune 和 rsLoRA。
- **广泛任务**：多轮对话、工具调用、图像理解、视觉定位、视频识别和语音理解等等。
- **实验监控**：LlamaBoard、TensorBoard、Wandb、MLflow、[SwanLab](https://github.com/SwanHubX/SwanLab) 等等。
- **极速推理**：基于 [vLLM](https://github.com/vllm-project/vllm) 或 [SGLang](https://github.com/sgl-project/sglang) 的 OpenAI 风格 API、浏览器界面和命令行接口。

### 最新模型的 Day-N 微调适配

| 适配时间      | 模型名称                                                              |
| ------------ | -------------------------------------------------------------------- |
| Day 0        | Qwen3 / Qwen2.5-VL / Gemma 3 / GLM-4.1V / InternLM 3 / MiniCPM-o-2.6 |
| Day 1        | Llama 3 / GLM-4 / Mistral Small / PaliGemma2 / Llama 4               |

## 官方博客

> [!TIP]
> 我们现在拥有了 LLaMA Factory 的专属博客！
>
> 网站地址：https://blog.llamafactory.net/

- 💡 [KTransformers Fine-Tuning × LLaMA Factory: 用2张4090级的GPU+CPU 微调 1000B规模的超大模型](https://swcil84qspu.feishu.cn/wiki/Z1sSwb2poijybxkyPEkcDG6enVc) (中文)
- 💡 [Easy Dataset × LLaMA Factory: 让大模型高效学习领域知识](https://buaa-act.feishu.cn/wiki/KY9xwTGs1iqHrRkjXBwcZP9WnL9)（中文）
- [使用 LLaMA-Factory 微调心理健康大模型](https://www.lab4ai.cn/project/detail?id=25cce32ec131497b9e06a93336a0817f&type=project&utm_source=LLaMA-Factory)（中文）
- [使用 LLaMA-Factory 构建 GPT-OSS 角色扮演模型](https://docs.llamafactory.com.cn/docs/documents/best-practice/gptroleplay/?utm_source=LLaMA-Factory)（中文）
- [基于 LLaMA-Factory 和 EasyR1 打造一站式无代码大模型强化学习和部署平台 LLM Model Hub](https://aws.amazon.com/cn/blogs/china/building-llm-model-hub-based-on-llamafactory-and-easyr1/)（中文）
- [通过亚马逊 SageMaker HyperPod 上的 LLaMA-Factory 增强多模态模型银行文档的视觉信息提取](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/)（英文）

<details><summary>全部博客</summary>

- [使用 LLaMA-Factory 微调 Llama3.1-70B 医学诊断模型](https://docs.alayanew.com/docs/documents/bestPractice/bigModel/llama70B/?utm_source=LLaMA-Factory)（中文）
- [使用 LLaMA-Factory 微调 Qwen2.5-VL 实现自动驾驶场景微调](https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory)（中文）
- [LLaMA Factory：微调 DeepSeek-R1-Distill-Qwen-7B 模型实现新闻标题分类器](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_deepseek_r1_distill_7b)（中文）
- [基于 Amazon SageMaker 和 LLaMA-Factory 打造一站式无代码模型微调部署平台 Model Hub](https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/)（中文）
- [LLaMA Factory 多模态微调实践：微调 Qwen2-VL 构建文旅大模型](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_qwen2vl)（中文）
- [LLaMA Factory：微调 Llama3 模型实现角色扮演](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory)（中文）

</details>

## 更新日志

[25/10/26] 我们支持了Megatron-core作为训练后端和适配了[**mcore_adapter**](https://github.com/alibaba/ROLL/tree/main/mcore_adapter)。查看[PR #9237](https://github.com/hiyouga/LLaMA-Factory/pull/9237)以使用。

[25/08/22] 我们支持了 **[OFT](https://arxiv.org/abs/2306.07280)** 和 **[OFTv2](https://arxiv.org/abs/2506.19847)** 模型的微调。查看 [examples](examples/README.md) 以使用。

[25/08/20] 我们支持了 **[Intern-S1-mini](https://huggingface.co/internlm/Intern-S1-mini)** 模型的微调。查看 [PR #8976](https://github.com/hiyouga/LLaMA-Factory/pull/8976) 以使用。

[25/08/06] 我们支持了 **[GPT-OSS](https://github.com/openai/gpt-oss)** 模型的微调。查看 [PR #8826](https://github.com/hiyouga/LLaMA-Factory/pull/8826) 以使用。

<details><summary>展开日志</summary>

[25/07/02] 我们支持了 **[GLM-4.1V-9B-Thinking](https://github.com/THUDM/GLM-4.1V-Thinking)** 模型的微调。

[25/04/28] 我们支持了 **[Qwen3](https://qwenlm.github.io/blog/qwen3/)** 系列模型的微调。

[25/04/21] 我们支持了 **[Muon](https://github.com/KellerJordan/Muon)** 优化器。详细用法请参照 [examples](examples/README_zh.md)。感谢 [@tianshijing](https://github.com/tianshijing) 的 PR。

[25/04/16] 我们支持了 **[InternVL3](https://huggingface.co/OpenGVLab/InternVL3-8B)** 模型的微调。查看 [PR #7258](https://github.com/hiyouga/LLaMA-Factory/pull/7258) 以使用。

[25/04/14] 我们支持了 **[GLM-Z1](https://huggingface.co/THUDM/GLM-Z1-9B-0414)** 和 **[Kimi-VL](https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct)** 模型的微调。

[25/04/06] 我们支持了 **[Llama 4](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)** 模型的微调。查看 [PR #7611](https://github.com/hiyouga/LLaMA-Factory/pull/7611) 以使用。

[25/03/31] 我们支持了 **[Qwen2.5 Omni](https://qwenlm.github.io/blog/qwen2.5-omni/)** 模型的微调。查看 [PR #7537](https://github.com/hiyouga/LLaMA-Factory/pull/7537) 以使用。

[25/03/15] 我们支持了 **[SGLang](https://github.com/sgl-project/sglang)** 推理后端，请使用 `infer_backend: sglang` 启用。

[25/03/12] 我们支持了 **[Gemma 3](https://huggingface.co/blog/gemma3)** 模型的微调。

[25/02/24] 我们宣布开源 **[EasyR1](https://github.com/hiyouga/EasyR1)**，一个高效可扩展的多模态强化学习框架，支持高效的 GRPO 训练。

[25/02/11] 我们支持了在导出模型时保存 **[Ollama](https://github.com/ollama/ollama)** 配置文件。详细用法请参照 [examples](examples/README_zh.md)。

[25/02/05] 我们支持了在语音理解任务上微调 **[Qwen2-Audio](Qwen/Qwen2-Audio-7B-Instruct)** 和 **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** 模型。

[25/01/31] 我们支持了 **[DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)** 和 **[Qwen2.5-VL](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct)** 模型的微调。

[25/01/15] 我们支持了 **[APOLLO](https://arxiv.org/abs/2412.05270)** 优化器。详细用法请参照 [examples](examples/README_zh.md)。

[25/01/14] 我们支持了 **[MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)** 和 **[MiniCPM-V-2.6](https://huggingface.co/openbmb/MiniCPM-V-2_6)** 模型的微调。 感谢 [@BUAADreamer](https://github.com/BUAADreamer) 的 PR.

[25/01/14] 我们支持了 **[InternLM 3](https://huggingface.co/collections/internlm/)** 模型的微调。感谢 [@hhaAndroid](https://github.com/hhaAndroid) 的 PR。

[25/01/10] 我们支持了 **[Phi-4](https://huggingface.co/microsoft/phi-4)** 模型的微调。

[24/12/21] 我们支持了使用 **[SwanLab](https://github.com/SwanHubX/SwanLab)** 跟踪与可视化实验。详细用法请参考 [此部分](#使用-swanlab-面板)。

[24/11/27] 我们支持了 **[Skywork-o1](https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B)** 模型的微调和 **[OpenO1](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)** 数据集。

[24/10/09] 我们支持了从 **[魔乐社区](https://modelers.cn/models)** 下载预训练模型和数据集。详细用法请参照 [此教程](#从魔乐社区下载)。

[24/09/19] 我们支持了 **[Qwen2.5](https://qwenlm.github.io/blog/qwen2.5/)** 模型的微调。

[24/08/30] 我们支持了 **[Qwen2-VL](https://qwenlm.github.io/blog/qwen2-vl/)** 模型的微调。感谢 [@simonJJJ](https://github.com/simonJJJ) 的 PR。

[24/08/27] 我们支持了 **[Liger Kernel](https://github.com/linkedin/Liger-Kernel)**。请使用 `enable_liger_kernel: true` 来加速训练。

[24/08/09] 我们支持了 **[Adam-mini](https://github.com/zyushun/Adam-mini)** 优化器。详细用法请参照 [examples](examples/README_zh.md)。感谢 [@relic-yuexi](https://github.com/relic-yuexi) 的 PR。

[24/07/04] 我们支持了[无污染打包训练](https://github.com/MeetKai/functionary/tree/main/functionary/train/packing)。请使用 `neat_packing: true` 参数。感谢 [@chuan298](https://github.com/chuan298) 的 PR。

[24/06/16] 我们支持了 **[PiSSA](https://arxiv.org/abs/2404.02948)** 算法。详细用法请参照 [examples](examples/README_zh.md)。

[24/06/07] 我们支持了 **[Qwen2](https://qwenlm.github.io/blog/qwen2/)** 和 **[GLM-4](https://github.com/THUDM/GLM-4)** 模型的微调。

[24/05/26] 我们支持了 **[SimPO](https://arxiv.org/abs/2405.14734)** 偏好对齐算法。详细用法请参照 [examples](examples/README_zh.md)。

[24/05/20] 我们支持了 **PaliGemma** 系列模型的微调。注意 PaliGemma 是预训练模型，你需要使用 `paligemma` 模板进行微调使其获得对话能力。

[24/05/18] 我们支持了 **[KTO](https://arxiv.org/abs/2402.01306)** 偏好对齐算法。详细用法请参照 [examples](examples/README_zh.md)。

[24/05/14] 我们支持了昇腾 NPU 设备的训练和推理。详情请查阅[安装](#安装-llama-factory)部分。

[24/04/26] 我们支持了多模态模型 **LLaVA-1.5** 的微调。详细用法请参照 [examples](examples/README_zh.md)。

[24/04/22] 我们提供了在免费 T4 GPU 上微调 Llama-3 模型的 **[Colab 笔记本](https://colab.research.google.com/drive/1d5KQtbemerlSDSxZIfAaWXhKr30QypiK?usp=sharing)**。Hugging Face 社区公开了两个利用 LLaMA Factory 微调的 Llama-3 模型，详情请见 [Llama3-8B-Chinese-Chat](https://huggingface.co/shenzhi-wang/Llama3-8B-Chinese-Chat) 和 [Llama3-Chinese](https://huggingface.co/zhichen/Llama3-Chinese)。

[24/04/21] 我们基于 [AstraMindAI 的仓库](https://github.com/astramind-ai/Mixture-of-depths)支持了 **[混合深度训练](https://arxiv.org/abs/2404.02258)**。详细用法请参照 [examples](examples/README_zh.md)。

[24/04/16] 我们支持了 **[BAdam](https://arxiv.org/abs/2404.02827)** 优化器。详细用法请参照 [examples](examples/README_zh.md)。

[24/04/16] 我们支持了 **[unsloth](https://github.com/unslothai/unsloth)** 的长序列训练（24GB 可训练 Llama-2-7B-56k）。该方法相比 FlashAttention-2 提供了 **117%** 的训练速度和 **50%** 的显存节约。更多数据请见[此页面](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison)。

[24/03/31] 我们支持了 **[ORPO](https://arxiv.org/abs/2403.07691)**。详细用法请参照 [examples](examples/README_zh.md)。

[24/03/21] 我们的论文 "[LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models](https://arxiv.org/abs/2403.13372)" 可在 arXiv 上查看！

[24/03/20] 我们支持了能在 2x24GB GPU 上微调 70B 模型的 **FSDP+QLoRA**。详细用法请参照 [examples](examples/README_zh.md)。

[24/03/13] 我们支持了 **[LoRA+](https://arxiv.org/abs/2402.12354)**。详细用法请参照 [examples](examples/README_zh.md)。

[24/03/07] 我们支持了 **[GaLore](https://arxiv.org/abs/2403.03507)** 优化器。详细用法请参照 [examples](examples/README_zh.md)。

[24/03/07] 我们集成了 **[vLLM](https://github.com/vllm-project/vllm)** 以实现极速并发推理。请使用 `infer_backend: vllm` 来获得 **270%** 的推理速度。

[24/02/28] 我们支持了 **[DoRA](https://arxiv.org/abs/2402.09353)** 微调。请使用 `use_dora: true` 参数进行 DoRA 微调。

[24/02/15] 我们支持了 [LLaMA Pro](https://github.com/TencentARC/LLaMA-Pro) 提出的**块扩展**方法。详细用法请参照 [examples](examples/README_zh.md)。

[24/02/05] Qwen1.5（Qwen2 测试版）系列模型已在 LLaMA-Factory 中实现微调支持。详情请查阅该[博客页面](https://qwenlm.github.io/zh/blog/qwen1.5/)。

[24/01/18] 我们针对绝大多数模型实现了 **Agent 微调**，微调时指定 `dataset: glaive_toolcall_zh` 即可使模型获得工具调用能力。

[23/12/23] 我们针对 LLaMA, Mistral 和 Yi 模型支持了 **[unsloth](https://github.com/unslothai/unsloth)** 的 LoRA 训练加速。请使用 `use_unsloth: true` 参数启用 unsloth 优化。该方法可提供 **170%** 的训练速度，详情请查阅[此页面](https://github.com/hiyouga/LLaMA-Factory/wiki/Performance-comparison)。

[23/12/12] 我们支持了微调最新的混合专家模型 **[Mixtral 8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)**。硬件需求请查阅[此处](#硬件依赖)。

[23/12/01] 我们支持了从 **[魔搭社区](https://modelscope.cn/models)** 下载预训练模型和数据集。详细用法请参照 [此教程](#从魔搭社区下载)。

[23/10/21] 我们支持了 **[NEFTune](https://arxiv.org/abs/2310.05914)** 训练技巧。请使用 `neftune_noise_alpha: 5` 参数启用 NEFTune。

[23/09/27] 我们针对 LLaMA 模型支持了 [LongLoRA](https://github.com/dvlab-research/LongLoRA) 提出的 **$S^2$-Attn**。请使用 `shift_attn: true` 参数以启用该功能。

[23/09/23] 我们在项目中集成了 MMLU、C-Eval 和 CMMLU 评估集。详细用法请参照 [examples](examples/README_zh.md)。

[23/09/10] 我们支持了 **[FlashAttention-2](https://github.com/Dao-AILab/flash-attention)**。如果您使用的是 RTX4090、A100 或 H100 GPU，请使用 `flash_attn: fa2` 参数以启用 FlashAttention-2。

[23/08/12] 我们支持了 **RoPE 插值**来扩展 LLaMA 模型的上下文长度。请使用 `rope_scaling: linear` 参数训练模型或使用 `rope_scaling: dynamic` 参数评估模型。

[23/08/11] 我们支持了指令模型的 **[DPO 训练](https://arxiv.org/abs/2305.18290)**。详细用法请参照 [examples](examples/README_zh.md)。

[23/07/31] 我们支持了**数据流式加载**。请使用 `streaming: true` 和 `max_steps: 10000` 参数来流式加载数据集。

[23/07/29] 我们在 Hugging Face 发布了两个 13B 指令微调模型。详细内容请查阅我们的 Hugging Face 项目（[LLaMA-2](https://huggingface.co/hiyouga/Llama-2-Chinese-13b-chat) / [Baichuan](https://huggingface.co/hiyouga/Baichuan-13B-sft)）。

[23/07/18] 我们开发了支持训练和测试的**浏览器一体化界面**。请使用 `train_web.py` 在您的浏览器中微调模型。感谢 [@KanadeSiina](https://github.com/KanadeSiina) 和 [@codemayq](https://github.com/codemayq) 在该功能开发中付出的努力。

[23/07/09] 我们开源了 **[FastEdit](https://github.com/hiyouga/FastEdit)** ⚡🩹，一个简单易用的、能迅速编辑大模型事实记忆的工具包。如果您感兴趣请关注我们的 [FastEdit](https://github.com/hiyouga/FastEdit) 项目。

[23/06/29] 我们提供了一个**可复现的**指令模型微调示例，详细内容请查阅 [Baichuan-7B-sft](https://huggingface.co/hiyouga/Baichuan-7B-sft)。

[23/06/22] 我们对齐了[示例 API](src/api_demo.py) 与 [OpenAI API](https://platform.openai.com/docs/api-reference/chat) 的格式，您可以将微调模型接入**任意基于 ChatGPT 的应用**中。

[23/06/03] 我们实现了 4 比特的 LoRA 训练（也称 **[QLoRA](https://github.com/artidoro/qlora)**）。详细用法请参照 [examples](examples/README_zh.md)。

</details>

> [!TIP]
> 如果您无法使用最新的功能，请尝试重新拉取代码并再次安装 LLaMA-Factory。

## 模型

| 模型名                                                             | 参数量                            | Template             |
| ----------------------------------------------------------------- | -------------------------------- | -------------------- |
| [BLOOM/BLOOMZ](https://huggingface.co/bigscience)                 | 560M/1.1B/1.7B/3B/7.1B/176B      | -                    |
| [Command R](https://huggingface.co/CohereForAI)                   | 35B/104B                         | cohere               |
| [DeepSeek (LLM/Code/MoE)](https://huggingface.co/deepseek-ai)     | 7B/16B/67B/236B                  | deepseek             |
| [DeepSeek 3-3.2](https://huggingface.co/deepseek-ai)              | 236B/671B                        | deepseek3            |
| [DeepSeek R1 (Distill)](https://huggingface.co/deepseek-ai)       | 1.5B/7B/8B/14B/32B/70B/671B      | deepseekr1           |
| [ERNIE-4.5](https://huggingface.co/baidu)                         | 0.3B/21B/300B                    | ernie/ernie_nothink  |
| [Falcon/Falcon H1](https://huggingface.co/tiiuae)                 | 0.5B/1.5B/3B/7B/11B/34B/40B/180B | falcon/falcon_h1     |
| [Gemma/Gemma 2/CodeGemma](https://huggingface.co/google)          | 2B/7B/9B/27B                     | gemma/gemma2         |
| [Gemma 3/Gemma 3n](https://huggingface.co/google)                 | 270M/1B/4B/6B/8B/12B/27B         | gemma3/gemma3n       |
| [GLM-4/GLM-4-0414/GLM-Z1](https://huggingface.co/zai-org)         | 9B/32B                           | glm4/glmz1           |
| [GLM-4.5/GLM-4.5(6)V](https://huggingface.co/zai-org)             | 9B/106B/355B                     | glm4_moe/glm4_5v     |
| [GPT-2](https://huggingface.co/openai-community)                  | 0.1B/0.4B/0.8B/1.5B              | -                    |
| [GPT-OSS](https://huggingface.co/openai)                          | 20B/120B                         | gpt_oss              |
| [Granite 3-4](https://huggingface.co/ibm-granite)                 | 1B/2B/3B/7B/8B                   | granite3/granite4    |
| [Hunyuan (MT)](https://huggingface.co/tencent/)                   | 7B                               | hunyuan              |
| [InternLM 2-3](https://huggingface.co/internlm)                   | 7B/8B/20B                        | intern2              |
| [InternVL 2.5-3.5](https://huggingface.co/OpenGVLab)              | 1B/2B/4B/8B/14B/30B/38B/78B/241B | intern_vl            |
| [InternLM/Intern-S1-mini](https://huggingface.co/internlm/)       | 8B                               | intern_s1            |
| [Kimi-VL](https://huggingface.co/moonshotai)                      | 16B                              | kimi_vl              |
| [Ling 2.0 (mini/flash)](https://huggingface.co/inclusionAI)       | 16B/100B                         | bailing_v2           |
| [Llama](https://github.com/facebookresearch/llama)                | 7B/13B/33B/65B                   | -                    |
| [Llama 2](https://huggingface.co/meta-llama)                      | 7B/13B/70B                       | llama2               |
| [Llama 3-3.3](https://huggingface.co/meta-llama)                  | 1B/3B/8B/70B                     | llama3               |
| [Llama 4](https://huggingface.co/meta-llama)                      | 109B/402B                        | llama4               |
| [Llama 3.2 Vision](https://huggingface.co/meta-llama)             | 11B/90B                          | mllama               |
| [LLaVA-1.5](https://huggingface.co/llava-hf)                      | 7B/13B                           | llava                |
| [LLaVA-NeXT](https://huggingface.co/llava-hf)                     | 7B/8B/13B/34B/72B/110B           | llava_next           |
| [LLaVA-NeXT-Video](https://huggingface.co/llava-hf)               | 7B/34B                           | llava_next_video     |
| [MiMo](https://huggingface.co/XiaomiMiMo)                         | 7B/309B                          | mimo/mimo_v2         |
| [MiniCPM 1-4.1](https://huggingface.co/openbmb)                   | 0.5B/1B/2B/4B/8B                 | cpm/cpm3/cpm4        |
| [MiniCPM-o-2.6/MiniCPM-V-2.6](https://huggingface.co/openbmb)     | 8B                               | minicpm_o/minicpm_v  |
| [MiniMax-M1/MiniMax-M2](https://huggingface.co/MiniMaxAI/models)  | 229B/456B                        | minimax1/minimax2    |
| [Ministral 3](https://huggingface.co/mistralai)                   | 3B/8B/14B                        | ministral3           |
| [Mistral/Mixtral](https://huggingface.co/mistralai)               | 7B/8x7B/8x22B                    | mistral              |
| [OLMo](https://huggingface.co/allenai)                            | 1B/7B                            | -                    |
| [PaliGemma/PaliGemma2](https://huggingface.co/google)             | 3B/10B/28B                       | paligemma            |
| [Phi-3/Phi-3.5](https://huggingface.co/microsoft)                 | 4B/14B                           | phi                  |
| [Phi-3-small](https://huggingface.co/microsoft)                   | 7B                               | phi_small            |
| [Phi-4](https://huggingface.co/microsoft)                         | 14B                              | phi4                 |
| [Pixtral](https://huggingface.co/mistralai)                       | 12B                              | pixtral              |
| [Qwen (1-2.5) (Code/Math/MoE/QwQ)](https://huggingface.co/Qwen)   | 0.5B/1.5B/3B/7B/14B/32B/72B/110B | qwen                 |
| [Qwen3 (MoE/Instruct/Thinking/Next)](https://huggingface.co/Qwen) | 0.6B/1.7B/4B/8B/14B/32B/80B/235B | qwen3/qwen3_nothink  |
| [Qwen2-Audio](https://huggingface.co/Qwen)                        | 7B                               | qwen2_audio          |
| [Qwen2.5-Omni](https://huggingface.co/Qwen)                       | 3B/7B                            | qwen2_omni           |
| [Qwen3-Omni](https://huggingface.co/Qwen)                         | 30B                              | qwen3_omni           |
| [Qwen2-VL/Qwen2.5-VL/QVQ](https://huggingface.co/Qwen)            | 2B/3B/7B/32B/72B                 | qwen2_vl             |
| [Qwen3-VL](https://huggingface.co/Qwen)                           | 2B/4B/8B/30B/32B/235B            | qwen3_vl             |
| [Seed (OSS/Coder)](https://huggingface.co/ByteDance-Seed)         | 8B/36B                           | seed_oss/seed_coder  |
| [StarCoder 2](https://huggingface.co/bigcode)                     | 3B/7B/15B                        | -                    |
| [VibeThinker-1.5B](https://huggingface.co/WeiboAI)                | 1.5B                             | qwen3                |
| [Yi/Yi-1.5 (Code)](https://huggingface.co/01-ai)                  | 1.5B/6B/9B/34B                   | yi                   |
| [Youtu-LLM](https://huggingface.co/tencent/)                      | 2B                               | youtu                |
| [Yuan 2](https://huggingface.co/IEITYuan)                         | 2B/51B/102B                      | yuan                 |

> [!NOTE]
> 对于所有“基座”（Base）模型，`template` 参数可以是 `default`, `alpaca`, `vicuna` 等任意值。但“对话”（Instruct/Chat）模型请务必使用**对应的模板**。
>
> 如果模型有推理 / 非推理两个版本，请使用 `_nothink` 后缀来区分不同的模板。例如 `qwen3` 和 `qwen3_nothink`。
>
> 请务必在训练和推理时采用**完全一致**的模板。
>
> \*：您需要从 main 分支安装 `transformers` 并使用 `DISABLE_VERSION_CHECK=1` 来跳过版本检查。
>
> \*\*：您需要安装特定版本的 `transformers` 以使用该模型。

项目所支持模型的完整列表请参阅 [constants.py](src/llamafactory/extras/constants.py)。

您也可以在 [template.py](src/llamafactory/data/template.py) 中添加自己的对话模板。

## 训练方法

| 方法                   |     全参数训练      |    部分参数训练     |       LoRA         |       QLoRA        |
| --------------------- | ------------------ | ------------------ | ------------------ | ------------------ |
| 预训练                 | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| 指令监督微调            | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| 奖励模型训练            | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| PPO 训练               | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| DPO 训练               | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| KTO 训练               | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| ORPO 训练              | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |
| SimPO 训练             | :white_check_mark: | :white_check_mark: | :white_check_mark: | :white_check_mark: |

> [!TIP]
> 有关 PPO 的实现细节，请参考[此博客](https://newfacade.github.io/notes-on-reinforcement-learning/17-ppo-trl.html)。

## 数据集

<details><summary>预训练数据集</summary>

- [Wiki Demo (en)](data/wiki_demo.txt)
- [RefinedWeb (en)](https://huggingface.co/datasets/tiiuae/falcon-refinedweb)
- [RedPajama V2 (en)](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2)
- [Wikipedia (en)](https://huggingface.co/datasets/olm/olm-wikipedia-20221220)
- [Wikipedia (zh)](https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered)
- [Pile (en)](https://huggingface.co/datasets/EleutherAI/pile)
- [SkyPile (zh)](https://huggingface.co/datasets/Skywork/SkyPile-150B)
- [FineWeb (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb)
- [FineWeb-Edu (en)](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu)
- [CCI3-HQ (zh)](https://huggingface.co/datasets/BAAI/CCI3-HQ)
- [CCI3-Data (zh)](https://huggingface.co/datasets/BAAI/CCI3-Data)
- [CCI4.0-M2-Base-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Base-v1)
- [CCI4.0-M2-CoT-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-CoT-v1)
- [CCI4.0-M2-Extra-v1 (en&zh)](https://huggingface.co/datasets/BAAI/CCI4.0-M2-Extra-v1)
- [The Stack (en)](https://huggingface.co/datasets/bigcode/the-stack)
- [StarCoder (en)](https://huggingface.co/datasets/bigcode/starcoderdata)

</details>

<details><summary>指令微调数据集</summary>

- [Identity (en&zh)](data/identity.json)
- [Stanford Alpaca (en)](https://github.com/tatsu-lab/stanford_alpaca)
- [Stanford Alpaca (zh)](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3)
- [Alpaca GPT4 (en&zh)](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM)
- [Glaive Function Calling V2 (en&zh)](https://huggingface.co/datasets/glaiveai/glaive-function-calling-v2)
- [LIMA (en)](https://huggingface.co/datasets/GAIR/lima)
- [Guanaco Dataset (multilingual)](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset)
- [BELLE 2M (zh)](https://huggingface.co/datasets/BelleGroup/train_2M_CN)
- [BELLE 1M (zh)](https://huggingface.co/datasets/BelleGroup/train_1M_CN)
- [BELLE 0.5M (zh)](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)
- [BELLE Dialogue 0.4M (zh)](https://huggingface.co/datasets/BelleGroup/generated_chat_0.4M)
- [BELLE School Math 0.25M (zh)](https://huggingface.co/datasets/BelleGroup/school_math_0.25M)
- [BELLE Multiturn Chat 0.8M (zh)](https://huggingface.co/datasets/BelleGroup/multiturn_chat_0.8M)
- [UltraChat (en)](https://github.com/thunlp/UltraChat)
- [OpenPlatypus (en)](https://huggingface.co/datasets/garage-bAInd/Open-Platypus)
- [CodeAlpaca 20k (en)](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)
- [Alpaca CoT (multilingual)](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT)
- [OpenOrca (en)](https://huggingface.co/datasets/Open-Orca/OpenOrca)
- [SlimOrca (en)](https://huggingface.co/datasets/Open-Orca/SlimOrca)
- [MathInstruct (en)](https://huggingface.co/datasets/TIGER-Lab/MathInstruct)
- [Firefly 1.1M (zh)](https://huggingface.co/datasets/YeungNLP/firefly-train-1.1M)
- [Wiki QA (en)](https://huggingface.co/datasets/wiki_qa)
- [Web QA (zh)](https://huggingface.co/datasets/suolyer/webqa)
- [WebNovel (zh)](https://huggingface.co/datasets/zxbsmk/webnovel_cn)
- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)
- [deepctrl (en&zh)](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data)
- [Advertise Generating (zh)](https://huggingface.co/datasets/HasturOfficial/adgen)
- [ShareGPT Hyperfiltered (en)](https://huggingface.co/datasets/totally-not-an-llm/sharegpt-hyperfiltered-3k)
- [ShareGPT4 (en&zh)](https://huggingface.co/datasets/shibing624/sharegpt_gpt4)
- [UltraChat 200k (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k)
- [Infinity Instruct (zh)](https://huggingface.co/datasets/BAAI/Infinity-Instruct)
- [AgentInstruct (en)](https://huggingface.co/datasets/THUDM/AgentInstruct)
- [LMSYS Chat 1M (en)](https://huggingface.co/datasets/lmsys/lmsys-chat-1m)
- [Evol Instruct V2 (en)](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k)
- [Cosmopedia (en)](https://huggingface.co/datasets/HuggingFaceTB/cosmopedia)
- [STEM (zh)](https://huggingface.co/datasets/hfl/stem_zh_instruction)
- [Ruozhiba (zh)](https://huggingface.co/datasets/hfl/ruozhiba_gpt4_turbo)
- [Neo-sft (zh)](https://huggingface.co/datasets/m-a-p/neo_sft_phase2)
- [Magpie-Pro-300K-Filtered (en)](https://huggingface.co/datasets/Magpie-Align/Magpie-Pro-300K-Filtered)
- [Magpie-ultra-v0.1 (en)](https://huggingface.co/datasets/argilla/magpie-ultra-v0.1)
- [WebInstructSub (en)](https://huggingface.co/datasets/TIGER-Lab/WebInstructSub)
- [OpenO1-SFT (en&zh)](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)
- [Open-Thoughts (en)](https://huggingface.co/datasets/open-thoughts/OpenThoughts-114k)
- [Open-R1-Math (en)](https://huggingface.co/datasets/open-r1/OpenR1-Math-220k)
- [Chinese-DeepSeek-R1-Distill (zh)](https://huggingface.co/datasets/Congliu/Chinese-DeepSeek-R1-Distill-data-110k-SFT)
- [LLaVA mixed (en&zh)](https://huggingface.co/datasets/BUAADreamer/llava-en-zh-300k)
- [Pokemon-gpt4o-captions (en&zh)](https://huggingface.co/datasets/jugg1024/pokemon-gpt4o-captions)
- [DLR-Web (en)](https://huggingface.co/datasets/Attention1115/DLR-Web)
- [Open Assistant (de)](https://huggingface.co/datasets/mayflowergmbh/oasst_de)
- [Dolly 15k (de)](https://huggingface.co/datasets/mayflowergmbh/dolly-15k_de)
- [Alpaca GPT4 (de)](https://huggingface.co/datasets/mayflowergmbh/alpaca-gpt4_de)
- [OpenSchnabeltier (de)](https://huggingface.co/datasets/mayflowergmbh/openschnabeltier_de)
- [Evol Instruct (de)](https://huggingface.co/datasets/mayflowergmbh/evol-instruct_de)
- [Dolphin (de)](https://huggingface.co/datasets/mayflowergmbh/dolphin_de)
- [Booksum (de)](https://huggingface.co/datasets/mayflowergmbh/booksum_de)
- [Airoboros (de)](https://huggingface.co/datasets/mayflowergmbh/airoboros-3.0_de)
- [Ultrachat (de)](https://huggingface.co/datasets/mayflowergmbh/ultra-chat_de)

</details>

<details><summary>偏好数据集</summary>

- [DPO mixed (en&zh)](https://huggingface.co/datasets/hiyouga/DPO-En-Zh-20k)
- [UltraFeedback (en)](https://huggingface.co/datasets/HuggingFaceH4/ultrafeedback_binarized)
- [COIG-P (zh)](https://huggingface.co/datasets/m-a-p/COIG-P)
- [RLHF-V (en)](https://huggingface.co/datasets/openbmb/RLHF-V-Dataset)
- [VLFeedback (en)](https://huggingface.co/datasets/Zhihui/VLFeedback)
- [RLAIF-V (en)](https://huggingface.co/datasets/openbmb/RLAIF-V-Dataset)
- [Orca DPO Pairs (en)](https://huggingface.co/datasets/Intel/orca_dpo_pairs)
- [HH-RLHF (en)](https://huggingface.co/datasets/Anthropic/hh-rlhf)
- [Nectar (en)](https://huggingface.co/datasets/berkeley-nest/Nectar)
- [Orca DPO (de)](https://huggingface.co/datasets/mayflowergmbh/intel_orca_dpo_pairs_de)
- [KTO mixed (en)](https://huggingface.co/datasets/argilla/kto-mix-15k)

</details>

部分数据集的使用需要确认，我们推荐使用下述命令登录您的 Hugging Face 账户。

```bash
pip install --upgrade huggingface_hub
huggingface-cli login
```

## 软硬件依赖

| 必需项        | 至少     | 推荐      |
| ------------ | ------- | --------- |
| python       | 3.9     | 3.10      |
| torch        | 2.0.0   | 2.6.0     |
| torchvision  | 0.15.0  | 0.21.0    |
| transformers | 4.49.0  | 4.50.0    |
| datasets     | 2.16.0  | 3.2.0     |
| accelerate   | 0.34.0  | 1.2.1     |
| peft         | 0.14.0  | 0.15.1    |
| trl          | 0.8.6   | 0.9.6     |

| 可选项        | 至少     | 推荐      |
| ------------ | ------- | --------- |
| CUDA         | 11.6    | 12.2      |
| deepspeed    | 0.10.0  | 0.16.4    |
| bitsandbytes | 0.39.0  | 0.43.1    |
| vllm         | 0.4.3   | 0.8.2     |
| flash-attn   | 2.5.6   | 2.7.2     |

### 硬件依赖

\* *估算值*

| 方法                             | 精度 |   7B  |  14B  |  30B  |   70B  |   `x`B  |
| ------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |
| Full (`bf16` or `fp16`)         |  32  | 120GB | 240GB | 600GB | 1200GB | `18x`GB |
| Full (`pure_bf16`)              |  16  |  60GB | 120GB | 300GB |  600GB |  `8x`GB |
| Freeze/LoRA/GaLore/APOLLO/BAdam |  16  |  16GB |  32GB |  64GB |  160GB |  `2x`GB |
| QLoRA                           |   8  |  10GB |  20GB |  40GB |   80GB |   `x`GB |
| QLoRA                           |   4  |   6GB |  12GB |  24GB |   48GB | `x/2`GB |
| QLoRA                           |   2  |   4GB |   8GB |  16GB |   24GB | `x/4`GB |

## 如何使用

### 安装 LLaMA Factory

> [!IMPORTANT]
> 此步骤为必需。

#### 从源码安装

```bash
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e .
pip install -r requirements/metrics.txt
```

可选的额外依赖项：`metrics`、`deepspeed`。使用 `pip install -e . && pip install -r requirements/metrics.txt -r requirements/deepspeed.txt` 安装。

其他可选依赖项请参考 `examples/requirements/` 目录下的文件。

#### 从镜像安装

```bash
docker run -it --rm --gpus=all --ipc=host hiyouga/llamafactory:latest
```

该镜像基于 Ubuntu 22.04（x86\_64）、CUDA 12.4、Python 3.11、PyTorch 2.6.0 和 Flash-attn 2.7.4 构建。

查看全部镜像：https://hub.docker.com/r/hiyouga/llamafactory/tags

请参阅[构建 Docker](#构建-docker) 来重新构建镜像。

<details><summary>使用 <b>uv</b> 构建虚拟环境</summary>

使用 [uv](https://github.com/astral-sh/uv) 创建隔离的 Python 环境：

```bash
uv run llamafactory-cli webui
```

</details>

<details><summary>Windows 用户指南</summary>

#### 安装 PyTorch

Windows 平台需要额外手动安装 GPU 版本的 PyTorch 依赖包，您可以参考[官方网站](https://pytorch.org/get-started/locally/)和以下命令安装并测试 PyTorch 是否正确安装。

```bash
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126
python -c "import torch; print(torch.cuda.is_available())"
```

如果看到 `True` 则说明安装成功。

若遇到类似 `Can't pickle local object` 的报错，请设置 `dataloader_num_workers: 0`。

#### 安装 BitsAndBytes

如果要在 Windows 平台上开启量化 LoRA（QLoRA），需要安装预编译的 `bitsandbytes` 库, 支持 CUDA 11.1 到 12.2, 请根据您的 CUDA 版本情况选择适合的[发布版本](https://github.com/jllllll/bitsandbytes-windows-webui/releases/tag/wheels)。

```bash
pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl
```

#### 安装 Flash Attention-2

如果要在 Windows 平台上开启 FlashAttention-2，请使用 [flash-attention-windows-wheel](https://huggingface.co/lldacing/flash-attention-windows-wheel) 中的脚本自行编译与安装。

</details>

<details><summary>昇腾 NPU 用户指南</summary>

在昇腾 NPU 设备上安装 LLaMA Factory 时，请升级 Python 到 3.10 及以上，并需要指定额外依赖项，使用 `pip install -r requirements/npu.txt` 命令安装。此外，还需要安装 **Ascend CANN Toolkit 与 Kernels**，安装方法请参考[安装教程](https://llamafactory.readthedocs.io/zh-cn/latest/advanced/npu_installation.html)。

您可以直接下载预安装的最新docker镜像：

```bash
# Docker Hub
docker pull hiyouga/llamafactory:latest-npu-a2
docker pull hiyouga/llamafactory:latest-npu-a3

# quay.io
docker pull quay.io/ascend/llamafactory:latest-npu-a2
docker pull quay.io/ascend/llamafactory:latest-npu-a3
```

#### 安装 BitsAndBytes

如果要在 Ascend NPU 上进行基于 bitsandbytes 的 QLoRA 量化微调，请执行如下步骤：

1. 手动编译 bitsandbytes：请参考[安装文档](https://huggingface.co/docs/bitsandbytes/installation?backend=Ascend+NPU&platform=Ascend+NPU)完成 NPU 版的 bitsandbytes 安装，编译要求环境 cmake 版本不低于 3.22.1，g++ 版本不低于 12.x。

```bash
# 从源码安装 bitsandbytes
# 克隆 bitsandbytes 仓库, Ascend NPU 目前在 multi-backend-refactor 中支持
git clone -b multi-backend-refactor https://github.com/bitsandbytes-foundation/bitsandbytes.git
cd bitsandbytes/

# 安装依赖
pip install -r requirements-dev.txt

# 安装编译工具依赖，该步骤在不同系统上命令有所不同，供参考
apt-get install -y build-essential cmake

# 编译 & 安装
cmake -DCOMPUTE_BACKEND=npu -S .
make
pip install .
```

2. 安装 transformers 的 main 分支版本。

```bash
git clone -b main https://github.com/huggingface/transformers.git
cd transformers
pip install .
```

3. 在训练参数中设置 `double_quantization: false`，可参考[示例](examples/train_qlora/qwen3_lora_sft_bnb_npu.yaml)。

</details>

### 数据准备

关于数据集文件的格式，请参考 [data/README_zh.md](data/README_zh.md) 的内容。你可以使用 HuggingFace / ModelScope / Modelers 上的数据集或加载本地数据集。

> [!NOTE]
> 使用自定义数据集时，请更新 `data/dataset_info.json` 文件。

您也可以使用 **[Easy Dataset](https://github.com/ConardLi/easy-dataset)**、**[DataFlow](https://github.com/OpenDCAI/DataFlow)** 和 **[GraphGen](https://github.com/open-sciencelab/GraphGen)** 构建用于微调的合成数据。

### 快速开始

下面三行命令分别对 Qwen3-4B-Instruct 模型进行 LoRA **微调**、**推理**和**合并**。

```bash
llamafactory-cli train examples/train_lora/qwen3_lora_sft.yaml
llamafactory-cli chat examples/inference/qwen3_lora_sft.yaml
llamafactory-cli export examples/merge_lora/qwen3_lora_sft.yaml
```

高级用法请参考 [examples/README_zh.md](examples/README_zh.md)（包括多 GPU 微调）。

> [!TIP]
> 使用 `llamafactory-cli help` 显示帮助信息。
>
> 遇到报错请先看[常见问题](https://github.com/hiyouga/LLaMA-Factory/issues/4614)。

### LLaMA Board 可视化微调（由 [Gradio](https://github.com/gradio-app/gradio) 驱动）

```bash
llamafactory-cli webui
```

### LLaMA Factory Online 在线微调

详情阅读该[文档](https://docs.llamafactory.com.cn/docs/documents/quickstart/getstarted/?utm_source=LLaMA-Factory)。

### 构建 Docker

CUDA 用户：

```bash
cd docker/docker-cuda/
docker compose up -d
docker compose exec llamafactory bash
```

昇腾 NPU 用户：

```bash
cd docker/docker-npu/
docker compose up -d
docker compose exec llamafactory bash
```

AMD ROCm 用户：

```bash
cd docker/docker-rocm/
docker compose up -d
docker compose exec llamafactory bash
```

<details><summary>不使用 Docker Compose 构建</summary>

CUDA 用户：

```bash
docker build -f ./docker/docker-cuda/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    --build-arg EXTRAS=metrics \
    -t llamafactory:latest .

docker run -dit --ipc=host --gpus=all \
    -p 7860:7860 \
    -p 8000:8000 \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
```

昇腾 NPU 用户：

```bash
docker build -f ./docker/docker-npu/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    --build-arg EXTRAS=torch-npu,metrics \
    -t llamafactory:latest .

docker run -dit --ipc=host \
    -v /usr/local/dcmi:/usr/local/dcmi \
    -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \
    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \
    -v /etc/ascend_install.info:/etc/ascend_install.info \
    -p 7860:7860 \
    -p 8000:8000 \
    --device /dev/davinci0 \
    --device /dev/davinci_manager \
    --device /dev/devmm_svm \
    --device /dev/hisi_hdc \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
```

AMD ROCm 用户：

```bash
docker build -f ./docker/docker-rocm/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    --build-arg EXTRAS=metrics \
    -t llamafactory:latest .

docker run -dit --ipc=host \
    -p 7860:7860 \
    -p 8000:8000 \
    --device /dev/kfd \
    --device /dev/dri \
    --name llamafactory \
    llamafactory:latest

docker exec -it llamafactory bash
```

</details>

<details><summary>使用数据卷</summary>

您可以通过移除 Dockerfile 中 `VOLUME [ "/root/.cache/huggingface", "/app/shared_data", "/app/output" ]` 的注释来使用数据卷。

在构建 Docker 时使用参数 `-v ./hf_cache:/root/.cache/huggingface` 来挂载数据卷。各个数据卷的含义表示如下。

- `hf_cache`：使用宿主机的 Hugging Face 缓存文件夹。
- `shared_data`：宿主机中存放数据集的文件夹路径。
- `output`：将导出目录设置为该路径后，即可在宿主机中访问导出后的模型。

</details>

### 利用 vLLM 部署 OpenAI API

```bash
API_PORT=8000 llamafactory-cli api examples/inference/qwen3.yaml infer_backend=vllm vllm_enforce_eager=true
```

> [!TIP]
> API 文档请查阅[这里](https://platform.openai.com/docs/api-reference/chat/create)。
>
> 示例：[图像理解](scripts/api_example/test_image.py) | [工具调用](scripts/api_example/test_toolcall.py)

### 从魔搭社区下载

如果您在 Hugging Face 模型和数据集的下载中遇到了问题，可以通过下述方法使用魔搭社区。

```bash
export USE_MODELSCOPE_HUB=1 # Windows 使用 `set USE_MODELSCOPE_HUB=1`
```

将 `model_name_or_path` 设置为模型 ID 来加载对应的模型。在[魔搭社区](https://modelscope.cn/models)查看所有可用的模型，例如 `LLM-Research/Meta-Llama-3-8B-Instruct`。

### 从魔乐社区下载

您也可以通过下述方法，使用魔乐社区下载数据集和模型。

```bash
export USE_OPENMIND_HUB=1 # Windows 使用 `set USE_OPENMIND_HUB=1`
```

将 `model_name_or_path` 设置为模型 ID 来加载对应的模型。在[魔乐社区](https://modelers.cn/models)查看所有可用的模型，例如 `TeleAI/TeleChat-7B-pt`。

### 使用 W&B 面板

若要使用 [Weights & Biases](https://wandb.ai) 记录实验数据，请在 yaml 文件中添加下面的参数。

```yaml
report_to: wandb
run_name: test_run # 可选
```

在启动训练任务时，将 `WANDB_API_KEY` 设置为[密钥](https://wandb.ai/authorize)来登录 W&B 账户。

### 使用 SwanLab 面板

若要使用 [SwanLab](https://github.com/SwanHubX/SwanLab) 记录实验数据，请在 yaml 文件中添加下面的参数。

```yaml
use_swanlab: true
swanlab_run_name: test_run # 可选
```

在启动训练任务时，登录SwanLab账户有以下三种方式：

方式一：在 yaml 文件中添加 `swanlab_api_key=<your_api_key>` ，并设置为你的 [API 密钥](https://swanlab.cn/settings)。
方式二：将环境变量 `SWANLAB_API_KEY` 设置为你的 [API 密钥](https://swanlab.cn/settings)。
方式三：启动前使用 `swanlab login` 命令完成登录。

## 使用了 LLaMA Factory 的项目

如果您有项目希望添加至下述列表，请通过邮件联系或者创建一个 PR。

<details><summary>点击显示</summary>

1. Wang et al. ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. 2023. [[arxiv]](https://arxiv.org/abs/2308.02223)
1. Yu et al. Open, Closed, or Small Language Models for Text Classification? 2023. [[arxiv]](https://arxiv.org/abs/2308.10092)
1. Wang et al. UbiPhysio: Support Daily Functioning, Fitness, and Rehabilitation with Action Understanding and Feedback in Natural Language. 2023. [[arxiv]](https://arxiv.org/abs/2308.10526)
1. Luceri et al. Leveraging Large Language Models to Detect Influence Campaigns in Social Media. 2023. [[arxiv]](https://arxiv.org/abs/2311.07816)
1. Zhang et al. Alleviating Hallucinations of Large Language Models through Induced Hallucinations. 2023. [[arxiv]](https://arxiv.org/abs/2312.15710)
1. Wang et al. Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. KDD 2024. [[arxiv]](https://arxiv.org/abs/2401.04319)
1. Wang et al. CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2401.07286)
1. Choi et al. FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2402.05904)
1. Zhang et al. AutoMathText: Autonomous Data Selection with Language Models for Mathematical Texts. 2024. [[arxiv]](https://arxiv.org/abs/2402.07625)
1. Lyu et al. KnowTuning: Knowledge-aware Fine-tuning for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11176)
1. Yang et al. LaCo: Large Language Model Pruning via Layer Collaps. 2024. [[arxiv]](https://arxiv.org/abs/2402.11187)
1. Bhardwaj et al. Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic. 2024. [[arxiv]](https://arxiv.org/abs/2402.11746)
1. Yang et al. Enhancing Empathetic Response Generation by Augmenting LLMs with Small-scale Empathetic Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11801)
1. Yi et al. Generation Meets Verification: Accelerating Large Language Model Inference with Smart Parallel Auto-Correct Decoding. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2402.11809)
1. Cao et al. Head-wise Shareable Attention for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.11819)
1. Zhang et al. Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages. 2024. [[arxiv]](https://arxiv.org/abs/2402.12204)
1. Kim et al. Efficient and Effective Vocabulary Expansion Towards Multilingual Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2402.14714)
1. Yu et al. KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large Language Models. ACL 2024. [[arxiv]](https://arxiv.org/abs/2402.15043)
1. Huang et al. Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning. 2024. [[arxiv]](https://arxiv.org/abs/2403.02333)
1. Duan et al. Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization. 2024. [[arxiv]](https://arxiv.org/abs/2403.03419)
1. Xie and Schwertfeger. Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs. 2024. [[arxiv]](https://arxiv.org/abs/2403.08228)
1. Wu et al. Large Language Models are Parallel Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2403.09073)
1. Zhang et al. EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling. 2024. [[arxiv]](https://arxiv.org/abs/2403.14541)
1. Weller et al. FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2403.15246)
1. Hongbin Na. CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering. COLING 2024. [[arxiv]](https://arxiv.org/abs/2403.16008)
1. Zan et al. CodeS: Natural Language to Code Repository via Multi-Layer Sketch. 2024. [[arxiv]](https://arxiv.org/abs/2403.16443)
1. Liu et al. Extensive Self-Contrast Enables Feedback-Free Language Model Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2404.00604)
1. Luo et al. BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.02827)
1. Du et al. Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2404.04167)
1. Ma et al. Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation. ICML 2024. [[arxiv]](https://arxiv.org/abs/2404.04316)
1. Liu et al. Dynamic Generation of Personalities with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.07084)
1. Shang et al. How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.09836)
1. Huang et al. LLMTune: Accelerate Database Knob Tuning with Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2404.11581)
1. Deng et al. Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction. 2024. [[arxiv]](https://arxiv.org/abs/2404.14215)
1. Acikgoz et al. Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2404.16621)
1. Zhang et al. Small Language Models Need Strong Verifiers to Self-Correct Reasoning. ACL 2024 Findings. [[arxiv]](https://arxiv.org/abs/2404.17140)
1. Zhou et al. FREB-TQA: A Fine-Grained Robustness Evaluation Benchmark for Table Question Answering. NAACL 2024. [[arxiv]](https://arxiv.org/abs/2404.18585)
1. Xu et al. Large Language Models for Cyber Security: A Systematic Literature Review. 2024. [[arxiv]](https://arxiv.org/abs/2405.04760)
1. Dammu et al. "They are uncultured": Unveiling Covert Harms and Social Threats in LLM Generated Conversations. 2024. [[arxiv]](https://arxiv.org/abs/2405.05378)
1. Yi et al. A safety realignment framework via subspace-oriented model fusion for large language models. 2024. [[arxiv]](https://arxiv.org/abs/2405.09055)
1. Lou et al. SPO: Multi-Dimensional Preference Sequential Alignment With Implicit Reward Modeling. 2024. [[arxiv]](https://arxiv.org/abs/2405.12739)
1. Zhang et al. Getting More from Less: Large Language Models are Good Spontaneous Multilingual Learners. 2024. [[arxiv]](https://arxiv.org/abs/2405.13816)
1. Zhang et al. TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models. 2024. [[arxiv]](https://arxiv.org/abs/2405.20215)
1. Zihong Chen. Sentence Segmentation and Sentence Punctuation Based on XunziALLM. 2024. [[paper]](https://aclanthology.org/2024.lt4hala-1.30)
1. Gao et al. The Best of Both Worlds: Toward an Honest and Helpful Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2406.00380)
1. Wang and Song. MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset. 2024. [[arxiv]](https://arxiv.org/abs/2406.02106)
1. Hu et al. Computational Limits of Low-Rank Adaptation (LoRA) for Transformer-Based Models. 2024. [[arxiv]](https://arxiv.org/abs/2406.03136)
1. Ge et al. Time Sensitive Knowledge Editing through Efficient Finetuning. ACL 2024. [[arxiv]](https://arxiv.org/abs/2406.04496)
1. Tan et al. Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions. 2024. [[arxiv]](https://arxiv.org/abs/2406.05688)
1. Song et al. Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters. 2024. [[arxiv]](https://arxiv.org/abs/2406.05955)
1. Gu et al. RWKV-CLIP: A Robust Vision-Language Representation Learner. 2024. [[arxiv]](https://arxiv.org/abs/2406.06973)
1. Chen et al. Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees. 2024. [[arxiv]](https://arxiv.org/abs/2406.07115)
1. Zhu et al. Are Large Language Models Good Statisticians?. 2024. [[arxiv]](https://arxiv.org/abs/2406.07815)
1. Li et al. Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2406.10099)
1. Ding et al. IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce. 2024. [[arxiv]](https://arxiv.org/abs/2406.10173)
1. He et al. COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for Aligning Large Language Models to Online Communities. 2024. [[arxiv]](https://arxiv.org/abs/2406.12074)
1. Lin et al. FVEL: Interactive Formal Verification Environment with Large Language Models via Theorem Proving. 2024. [[arxiv]](https://arxiv.org/abs/2406.14408)
1. Treutlein et al. Connecting the Dots: LLMs can Infer and Verbalize Latent Structure from Disparate Training Data. 2024. [[arxiv]](https://arxiv.org/abs/2406.14546)
1. Feng et al. SS-Bench: A Benchmark for Social Story Generation and Evaluation. 2024. [[arxiv]](https://arxiv.org/abs/2406.15695)
1. Feng et al. Self-Constructed Context Decompilation with Fined-grained Alignment Enhancement. 2024. [[arxiv]](https://arxiv.org/abs/2406.17233)
1. Liu et al. Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals. 2024. [[arxiv]](https://arxiv.org/abs/2406.18069)
1. Iyer et al. Exploring Very Low-Resource Translation with LLMs: The University of Edinburgh's Submission to AmericasNLP 2024 Translation Task. AmericasNLP 2024. [[paper]](https://aclanthology.org/2024.americasnlp-1.25)
1. Li et al. Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring. 2024. [[arxiv]](https://arxiv.org/abs/2406.19949)
1. Yang et al. Financial Knowledge Large Language Model. 2024. [[arxiv]](https://arxiv.org/abs/2407.00365)
1. Lin et al. DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging. 2024. [[arxiv]](https://arxiv.org/abs/2407.01470)
1. Bako et al. Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization. 2024. [[arxiv]](https://arxiv.org/abs/2407.06129)
1. Huang et al. RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization. 2024. [[arxiv]](https://arxiv.org/abs/2407.08044)
1. Jiang et al. LLM-Collaboration on Automatic Science Journalism for the General Audience. 2024. [[arxiv]](https://arxiv.org/abs/2407.09756)
1. Inouye et al. Applied Auto-tuning on LoRA Hyperparameters. 2024. [[paper]](https://scholarcommons.scu.edu/cseng_senior/272/)
1. Qi et al. Research on Tibetan Tourism Viewpoints information generation system based on LLM. 2024. [[arxiv]](https://arxiv.org/abs/2407.13561)
1. Xu et al. Course-Correction: Safety Alignment Using Synthetic Preferences. 2024. [[arxiv]](https://arxiv.org/abs/2407.16637)
1. Sun et al. LAMBDA: A Large Model Based Data Agent. 2024. [[arxiv]](https://arxiv.org/abs/2407.17535)
1. Zhu et al. CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare. 2024. [[arxiv]](https://arxiv.org/abs/2407.19705)
1. Yu et al. Correcting Negative Bias in Large Language Models through Negative Attention Score Alignment. 2024. [[arxiv]](https://arxiv.org/abs/2408.00137)
1. Xie et al. The Power of Personalized Datasets: Advancing Chinese Composition Writing for Elementary School through Targeted Model Fine-Tuning. IALP 2024. [[paper]](https://www.asianlp.sg/conferences/ialp2024/proceedings/papers/IALP2024_P055.pdf)
1. Liu et al. Instruct-Code-Llama: Improving Capabilities of Language Model in Competition Level Code Generation by Online Judge Feedback. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_11)
1. Wang et al. Cybernetic Sentinels: Unveiling the Impact of Safety Data Selection on Model Security in Supervised Fine-Tuning. ICIC 2024. [[paper]](https://link.springer.com/chapter/10.1007/978-981-97-5669-8_23)
1. Xia et al. Understanding the Performance and Estimating the Cost of LLM Fine-Tuning. 2024. [[arxiv]](https://arxiv.org/abs/2408.04693)
1. Zeng et al. Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions. 2024. [[arxiv]](https://arxiv.org/abs/2408.04168)
1. Xia et al. Using Pre-trained Language Model for Accurate ESG Prediction. FinNLP 2024. [[paper]](https://aclanthology.org/2024.finnlp-2.1/)
1. Liang et al. I-SHEEP: Self-Alignment of LLM from Scratch through an Iterative Self-Enhancement Paradigm. 2024. [[arxiv]](https://arxiv.org/abs/2408.08072)
1. Bai et al. Aligning Large Language Model with Direct Multi-Preference Optimization for Recommendation. CIKM 2024. [[paper]](https://dl.acm.org/doi/10.1145/3627673.3679611)
1. **[StarWhisper](https://github.com/Yu-Yang-Li/StarWhisper)**: 天文大模型 StarWhisper，基于 ChatGLM2-6B 和 Qwen-14B 在天文数据上微调而得。
1. **[DISC-LawLLM](https://github.com/FudanDISC/DISC-LawLLM)**: 中文法律领域大模型 DISC-LawLLM，基于 Baichuan-13B 微调而得，具有法律推理和知识检索能力。
1. **[Sunsimiao](https://github.com/X-D-Lab/Sunsimiao)**: 孙思邈中文医疗大模型 Sumsimiao，基于 Baichuan-7B 和 ChatGLM-6B 在中文医疗数据上微调而得。
1. **[CareGPT](https://github.com/WangRongsheng/CareGPT)**: 医疗大模型项目 CareGPT，基于 LLaMA2-7B 和 Baichuan-13B 在中文医疗数据上微调而得。
1. **[MachineMindset](https://github.com/PKU-YuanGroup/Machine-Mindset/)**：MBTI性格大模型项目，根据数据集与训练方式让任意 LLM 拥有 16 个不同的性格类型。
1. **[Luminia-13B-v3](https://huggingface.co/Nekochu/Luminia-13B-v3)**：一个用于生成 Stable Diffusion 提示词的大型语言模型。[[demo]](https://huggingface.co/spaces/Nekochu/Luminia-13B_SD_Prompt)
1. **[Chinese-LLaVA-Med](https://github.com/BUAADreamer/Chinese-LLaVA-Med)**：中文多模态医学大模型，基于 LLaVA-1.5-7B 在中文多模态医疗数据上微调而得。
1. **[AutoRE](https://github.com/THUDM/AutoRE)**：基于大语言模型的文档级关系抽取系统。
1. **[NVIDIA RTX AI Toolkit](https://github.com/NVIDIA/RTX-AI-Toolkit)**：在 Windows 主机上利用英伟达 RTX 设备进行大型语言模型微调的开发包。
1. **[LazyLLM](https://github.com/LazyAGI/LazyLLM)**：一个低代码构建多 Agent 大模型应用的开发工具，支持基于 LLaMA Factory 的模型微调.
1. **[RAG-Retrieval](https://github.com/NLPJCL/RAG-Retrieval)**：一个全链路 RAG 检索模型微调、推理和蒸馏代码库。[[blog]](https://zhuanlan.zhihu.com/p/987727357)
1. **[360-LLaMA-Factory](https://github.com/Qihoo360/360-LLaMA-Factory)**：一个魔改后的代码库，通过 Ring Attention 支持长序列的 SFT 和 DPO 训练。
1. **[Sky-T1](https://novasky-ai.github.io/posts/sky-t1/)**：由 NovaSky AI 微调的低成本类 o1 长推理模型。
1. **[WeClone](https://github.com/xming521/WeClone)**：从聊天记录创造数字分身的一站式解决方案。

</details>

## 协议

本仓库的代码依照 [Apache-2.0](LICENSE) 协议开源。

使用模型权重时，请遵循对应的模型协议：[Baichuan 2](https://huggingface.co/baichuan-inc/Baichuan2-7B-Base/blob/main/Community%20License%20for%20Baichuan%202%20Model.pdf) / [BLOOM](https://huggingface.co/spaces/bigscience/license) / [ChatGLM3](https://github.com/THUDM/ChatGLM3/blob/main/MODEL_LICENSE) / [Command R](https://cohere.com/c4ai-cc-by-nc-license) / [DeepSeek](https://github.com/deepseek-ai/DeepSeek-LLM/blob/main/LICENSE-MODEL) / [Falcon](https://huggingface.co/tiiuae/falcon-180B/blob/main/LICENSE.txt) / [Gemma](https://ai.google.dev/gemma/terms) / [GLM-4](https://huggingface.co/THUDM/glm-4-9b/blob/main/LICENSE) / [GPT-2](https://github.com/openai/gpt-2/blob/master/LICENSE) / [Granite](LICENSE) / [Index](https://huggingface.co/IndexTeam/Index-1.9B/blob/main/LICENSE) / [InternLM](https://github.com/InternLM/InternLM#license) / [Llama](https://github.com/facebookresearch/llama/blob/main/MODEL_CARD.md) / [Llama 2](https://ai.meta.com/llama/license/) / [Llama 3](https://llama.meta.com/llama3/license/) / [Llama 4](https://github.com/meta-llama/llama-models/blob/main/models/llama4/LICENSE) / [MiniCPM](https://github.com/OpenBMB/MiniCPM/blob/main/MiniCPM%20Model%20License.md) / [Mistral/Mixtral/Pixtral](LICENSE) / [OLMo](LICENSE) / [Phi-1.5/Phi-2](https://huggingface.co/microsoft/phi-1_5/resolve/main/Research%20License.docx) / [Phi-3/Phi-4](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct/blob/main/LICENSE) / [Qwen](https://github.com/QwenLM/Qwen/blob/main/Tongyi%20Qianwen%20LICENSE%20AGREEMENT) / [Skywork](https://huggingface.co/Skywork/Skywork-13B-base/blob/main/Skywork%20Community%20License.pdf) / [StarCoder 2](https://huggingface.co/spaces/bigcode/bigcode-model-license-agreement) / [TeleChat2](https://huggingface.co/Tele-AI/telechat-7B/blob/main/TeleChat%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf) / [XVERSE](https://github.com/xverse-ai/XVERSE-13B/blob/main/MODEL_LICENSE.pdf) / [Yi](https://huggingface.co/01-ai/Yi-6B/blob/main/LICENSE) / [Yi-1.5](LICENSE) / [Yuan 2](https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/LICENSE-Yuan)

## 引用

如果您觉得此项目有帮助，请考虑以下列格式引用

```bibtex
@inproceedings{zheng2024llamafactory,
  title={LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models},
  author={Yaowei Zheng and Richong Zhang and Junhao Zhang and Yanhan Ye and Zheyan Luo and Zhangchi Feng and Yongqiang Ma},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)},
  address={Bangkok, Thailand},
  publisher={Association for Computational Linguistics},
  year={2024},
  url={http://arxiv.org/abs/2403.13372}
}
```

## 致谢

本项目受益于 [PEFT](https://github.com/huggingface/peft)、[TRL](https://github.com/huggingface/trl)、[QLoRA](https://github.com/artidoro/qlora) 和 [FastChat](https://github.com/lm-sys/FastChat)，感谢以上诸位作者的付出。

## Star History

![Star History Chart](https://api.star-history.com/svg?repos=hiyouga/LLaMA-Factory&type=Date)


## Links discovered
- [# LLaMA Factory](https://github.com/hiyouga/LlamaFactory/blob/main/assets/logo.png)
- [![GitHub Repo stars](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory?style=social)
- [![GitHub last commit](https://img.shields.io/github/last-commit/hiyouga/LLaMA-Factory)
- [![GitHub contributors](https://img.shields.io/github/contributors/hiyouga/LLaMA-Factory?color=orange)
- [![GitHub workflow](https://github.com/hiyouga/LLaMA-Factory/actions/workflows/tests.yml/badge.svg)
- [![PyPI](https://img.shields.io/pypi/v/llamafactory)
- [![Citation](https://img.shields.io/badge/citation-1000+-green)
- [![Docker Pulls](https://img.shields.io/docker/pulls/hiyouga/llamafactory)
- [![Twitter](https://img.shields.io/twitter/follow/llamafactory_ai)
- [![Discord](https://github.com/hiyouga/LlamaFactory/blob/main/assets/thirdparty/discord.svg)
- [![WeChat](https://img.shields.io/badge/WeChat-User%20Group-blue?logo=wechat)
- [![Blog](https://img.shields.io/badge/Hugo-Official%20Blog-blue?logo=hugo)
- [![Open in Colab](https://github.com/hiyouga/LlamaFactory/blob/main/assets/thirdparty/colab.svg)
- [![Open in DSW](https://github.com/hiyouga/LlamaFactory/blob/main/assets/thirdparty/dsw.svg)
- [![Open in Lab4ai](https://github.com/hiyouga/LlamaFactory/blob/main/assets/thirdparty/lab4ai.svg)
- [![Open in Online](https://github.com/hiyouga/LlamaFactory/blob/main/assets/thirdparty/online.svg)
- [![Open in Spaces](https://img.shields.io/badge/🤗-Open%20in%20Spaces-blue)
- [![Open in Studios](https://img.shields.io/badge/ModelScope-Open%20in%20Studios-blue)
- [![Open in Novita](https://img.shields.io/badge/Novita-Deploy%20Template-blue)
- [亚马逊](https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/)
- [英伟达](https://developer.nvidia.cn/rtx/ai-toolkit)
- [阿里云](https://help.aliyun.com/zh/pai/use-cases/fine-tune-a-llama-3-model-with-llama-factory)
- [GitHub Trend](https://trendshift.io/api/badge/repositories/4535)
- [微信群](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/main.jpg)
- [NPU 用户群](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/npu.jpg)
- [大模型实验室群](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/lab4ai.jpg)
- [LLaMA Factory Online 用户群](https://github.com/hiyouga/llamafactory-community/blob/main/wechat/online.png)
- [[English](https://github.com/hiyouga/LlamaFactory/blob/main/README.md)
- [GaLore](https://github.com/jiaweizzhao/GaLore)
- [BAdam](https://github.com/Ledzy/BAdam)
- [APOLLO](https://github.com/zhuhanqing/APOLLO)
- [Adam-mini](https://github.com/zyushun/Adam-mini)
- [Muon](https://github.com/KellerJordan/Muon)
- [OFT](https://github.com/huggingface/peft/tree/main/src/peft/tuners/oft)
- [FlashAttention-2](https://github.com/Dao-AILab/flash-attention)
- [Unsloth](https://github.com/unslothai/unsloth)
- [Liger Kernel](https://github.com/linkedin/Liger-Kernel)
- [KTransformers](https://github.com/kvcache-ai/ktransformers/)
- [SwanLab](https://github.com/SwanHubX/SwanLab)
- [vLLM](https://github.com/vllm-project/vllm)
- [SGLang](https://github.com/sgl-project/sglang)
- [KTransformers Fine-Tuning × LLaMA Factory: 用2张4090级的GPU+CPU 微调 1000B规模的超大模型](https://swcil84qspu.feishu.cn/wiki/Z1sSwb2poijybxkyPEkcDG6enVc)
- [Easy Dataset × LLaMA Factory: 让大模型高效学习领域知识](https://buaa-act.feishu.cn/wiki/KY9xwTGs1iqHrRkjXBwcZP9WnL9)
- [使用 LLaMA-Factory 微调心理健康大模型](https://www.lab4ai.cn/project/detail?id=25cce32ec131497b9e06a93336a0817f&type=project&utm_source=LLaMA-Factory)
- [使用 LLaMA-Factory 构建 GPT-OSS 角色扮演模型](https://docs.llamafactory.com.cn/docs/documents/best-practice/gptroleplay/?utm_source=LLaMA-Factory)
- [基于 LLaMA-Factory 和 EasyR1 打造一站式无代码大模型强化学习和部署平台 LLM Model Hub](https://aws.amazon.com/cn/blogs/china/building-llm-model-hub-based-on-llamafactory-and-easyr1/)
- [通过亚马逊 SageMaker HyperPod 上的 LLaMA-Factory 增强多模态模型银行文档的视觉信息提取](https://aws.amazon.com/cn/blogs/machine-learning/how-apoidea-group-enhances-visual-information-extraction-from-banking-documents-with-multimodal-models-using-llama-factory-on-amazon-sagemaker-hyperpod/)
- [使用 LLaMA-Factory 微调 Llama3.1-70B 医学诊断模型](https://docs.alayanew.com/docs/documents/bestPractice/bigModel/llama70B/?utm_source=LLaMA-Factory)
- [使用 LLaMA-Factory 微调 Qwen2.5-VL 实现自动驾驶场景微调](https://docs.alayanew.com/docs/documents/useGuide/LLaMAFactory/mutiple/?utm_source=LLaMA-Factory)
- [LLaMA Factory：微调 DeepSeek-R1-Distill-Qwen-7B 模型实现新闻标题分类器](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_deepseek_r1_distill_7b)
- [基于 Amazon SageMaker 和 LLaMA-Factory 打造一站式无代码模型微调部署平台 Model Hub](https://aws.amazon.com/cn/blogs/china/a-one-stop-code-free-model-fine-tuning-deployment-platform-based-on-sagemaker-and-llama-factory/)
- [LLaMA Factory 多模态微调实践：微调 Qwen2-VL 构建文旅大模型](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory_qwen2vl)
- [LLaMA Factory：微调 Llama3 模型实现角色扮演](https://gallery.pai-ml.com/#/preview/deepLearning/nlp/llama_factory)
- [**mcore_adapter**](https://github.com/alibaba/ROLL/tree/main/mcore_adapter)
- [PR #9237](https://github.com/hiyouga/LLaMA-Factory/pull/9237)
- [OFT](https://arxiv.org/abs/2306.07280)
- [OFTv2](https://arxiv.org/abs/2506.19847)
- [examples](https://github.com/hiyouga/LlamaFactory/blob/main/examples/README.md)
- [Intern-S1-mini](https://huggingface.co/internlm/Intern-S1-mini)
- [PR #8976](https://github.com/hiyouga/LLaMA-Factory/pull/8976)
- [GPT-OSS](https://github.com/openai/gpt-oss)
- [PR #8826](https://github.com/hiyouga/LLaMA-Factory/pull/8826)
- [GLM-4.1V-9B-Thinking](https://github.com/THUDM/GLM-4.1V-Thinking)
- [Qwen3](https://qwenlm.github.io/blog/qwen3/)
- [examples](https://github.com/hiyouga/LlamaFactory/blob/main/examples/README_zh.md)
- [@tianshijing](https://github.com/tianshijing)
- [InternVL3](https://huggingface.co/OpenGVLab/InternVL3-8B)
- [PR #7258](https://github.com/hiyouga/LLaMA-Factory/pull/7258)
- [GLM-Z1](https://huggingface.co/THUDM/GLM-Z1-9B-0414)
- [Kimi-VL](https://huggingface.co/moonshotai/Kimi-VL-A3B-Instruct)
- [Llama 4](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)
- [PR #7611](https://github.com/hiyouga/LLaMA-Factory/pull/7611)
- [Qwen2.5 Omni](https://qwenlm.github.io/blog/qwen2.5-omni/)
- [PR #7537](https://github.com/hiyouga/LLaMA-Factory/pull/7537)
- [Gemma 3](https://huggingface.co/blog/gemma3)
- [EasyR1](https://github.com/hiyouga/EasyR1)
- [Ollama](https://github.com/ollama/ollama)
- [Qwen2-Audio](https://github.com/hiyouga/LlamaFactory/blob/main/Qwen/Qwen2-Audio-7B-Instruct.md)
- [MiniCPM-o-2.6](https://huggingface.co/openbmb/MiniCPM-o-2_6)
- [DeepSeek-R1](https://huggingface.co/deepseek-ai/DeepSeek-R1)
- [Qwen2.5-VL](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct)
- [APOLLO](https://arxiv.org/abs/2412.05270)
- [MiniCPM-V-2.6](https://huggingface.co/openbmb/MiniCPM-V-2_6)
- [@BUAADreamer](https://github.com/BUAADreamer)
- [InternLM 3](https://huggingface.co/collections/internlm/)
- [@hhaAndroid](https://github.com/hhaAndroid)
- [Phi-4](https://huggingface.co/microsoft/phi-4)
- [Skywork-o1](https://huggingface.co/Skywork/Skywork-o1-Open-Llama-3.1-8B)
- [OpenO1](https://huggingface.co/datasets/O1-OPEN/OpenO1-SFT)
- [魔乐社区](https://modelers.cn/models)
- [Qwen2.5](https://qwenlm.github.io/blog/qwen2.5/)
- [Qwen2-VL](https://qwenlm.github.io/blog/qwen2-vl/)
- [@simonJJJ](https://github.com/simonJJJ)
- [@relic-yuexi](https://github.com/relic-yuexi)
- [无污染打包训练](https://github.com/MeetKai/functionary/tree/main/functionary/train/packing)
- [@chuan298](https://github.com/chuan298)
- [PiSSA](https://arxiv.org/abs/2404.02948)
- [Qwen2](https://qwenlm.github.io/blog/qwen2/)
- [GLM-4](https://github.com/THUDM/GLM-4)
- [SimPO](https://arxiv.org/abs/2405.14734)

--- docker/docker-cuda/README.md ---
# Docker Setup for NVIDIA GPUs

This directory contains Docker configuration files for running LLaMA Factory with NVIDIA GPU support.

## Prerequisites

### Linux-specific Requirements

Before running the Docker container with GPU support, you need to install the following packages:

1. **Docker**: The container runtime
   ```bash
   # Ubuntu/Debian
   sudo apt-get update
   sudo apt-get install docker.io

   # Or install Docker Engine from the official repository:
   # https://docs.docker.com/engine/install/
   ```

2. **Docker Compose** (if using the docker-compose method):
   ```bash
   # Ubuntu/Debian
   sudo apt-get install docker-compose

   # Or install the latest version:
   # https://docs.docker.com/compose/install/
   ```

3. **NVIDIA Container Toolkit** (required for GPU support):
   ```bash
   # Add the NVIDIA GPG key and repository
   distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
   curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
   curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

   # Install nvidia-container-toolkit
   sudo apt-get update
   sudo apt-get install -y nvidia-container-toolkit

   # Restart Docker to apply changes
   sudo systemctl restart docker
   ```

   **Note**: Without `nvidia-container-toolkit`, the Docker container will not be able to access your NVIDIA GPU.

### Verify GPU Access

After installation, verify that Docker can access your GPU:

```bash
sudo docker run --rm --gpus all nvidia/cuda:12.4.0-base-ubuntu22.04 nvidia-smi
```

If successful, you should see your GPU information displayed.

## Usage

### Using Docker Compose (Recommended)

```bash
cd docker/docker-cuda/
docker compose up -d
docker compose exec llamafactory bash
```

### Using Docker Run

```bash
# Build the image
docker build -f ./docker/docker-cuda/Dockerfile \
    --build-arg PIP_INDEX=https://pypi.org/simple \
    --build-arg EXTRAS=metrics \
    -t llamafactory:latest .

# Run the container
docker run -dit --ipc=host --gpus=all \
    -p 7860:7860 \
    -p 8000:8000 \
    --name llamafactory \
    llamafactory:latest

# Enter the container
docker exec -it llamafactory bash
```

## Troubleshooting

### GPU Not Detected

If your GPU is not detected inside the container:

1. Ensure `nvidia-container-toolkit` is installed
2. Check that the Docker daemon has been restarted after installation
3. Verify your NVIDIA drivers are properly installed: `nvidia-smi`
4. Check Docker GPU support: `docker run --rm --gpus all ubuntu nvidia-smi`

### Permission Denied

If you get permission errors, ensure your user is in the docker group:

```bash
sudo usermod -aG docker $USER
# Log out and back in for changes to take effect
```

## Additional Notes

- The default image is built on Ubuntu 22.04 (x86_64), CUDA 12.4, Python 3.11, PyTorch 2.6.0, and Flash-attn 2.7.4
- For different CUDA versions, you may need to adjust the base image in the Dockerfile
- Make sure your NVIDIA driver version is compatible with the CUDA version used in the Docker image


--- .github/CODE_OF_CONDUCT.md ---
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
`hoshihiyouga AT gmail DOT com`.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.


## Links discovered
- [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity)

--- .github/copilot-instructions.md ---
# GitHub Copilot Instructions for LLaMA Factory

## Project Overview

LLaMA Factory is an efficient fine-tuning framework for 100+ large language models (LLMs). It provides:
- Support for various models: LLaMA, LLaVA, Mistral, Qwen, DeepSeek, Yi, Gemma, ChatGLM, Phi, etc.
- Multiple training methods: pre-training, supervised fine-tuning, reward modeling, PPO, DPO, KTO, ORPO
- Scalable resources: 16-bit full-tuning, freeze-tuning, LoRA and QLoRA variants
- Advanced algorithms: GaLore, BAdam, APOLLO, Adam-mini, Muon, OFT, DoRA, etc.
- Web UI (LLaMA Board) and CLI interfaces

### Architecture Versions

LLaMA Factory has two parallel architectures that can be switched via the `USE_V1` environment variable:

**v0 (default)** - File hierarchy:
- `api`, `webui` → `chat`, `eval`, `train` → `data`, `model` → `hparams` → `extras`

**v1** - File hierarchy:
- `trainers` → `core` → `accelerator`, `plugins`, `config` → `utils`

Set `USE_V1=1` to enable v1 architecture.

## Code Structure

### v0 Architecture (Default)

- `src/llamafactory/` - Main package directory
  - `api/` - OpenAI-style API implementation
  - `chat/` - Chat interface implementation
  - `cli.py` - Command-line interface
  - `data/` - Data processing and dataset handling
  - `eval/` - Model evaluation utilities
  - `extras/` - Additional utilities and helpers
  - `hparams/` - Hyperparameter definitions
  - `model/` - Model loading, patching, and utilities
  - `train/` - Training pipeline implementation
  - `webui/` - Gradio-based web interface
- `src/train.py` - Training entry script (delegates to `llamafactory.train.tuner`)
- `src/webui.py` - Web UI entry script (delegates to `llamafactory.webui.interface`)
- `src/api.py` - API server entry script (delegates to `llamafactory.api.app`)
- `tests/` - Test suite
- `examples/` - Example configurations for various training scenarios
- `data/` - Dataset definitions and examples

### v1 Architecture (USE_V1=1)

- `src/llamafactory/v1/` - Version 1 package directory
  - `trainers/` - Training implementations
  - `core/` - Core training utilities
  - `accelerator/` - Acceleration and distributed training
  - `plugins/` - Pluggable components (model, data, sampler, trainer)
  - `config/` - Configuration management
  - `utils/` - Utility functions

## Development Practices

### Code Style

- Follow the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)
- Use ruff for linting and formatting
- Line length: 119 characters
- Indentation: 4 spaces
- Quote style: double quotes
- Use Google-style docstrings for documentation

### Import Organization

- Known first-party: `llamafactory`
- Known third-party: `accelerate`, `datasets`, `gradio`, `numpy`, `peft`, `torch`, `transformers`, `trl`
- Use 2 blank lines after imports

### Quality Checks

Before committing code, run:
```bash
make style      # Auto-fix style issues
make quality    # Check code quality
make test       # Run test suite
```

Or use the combined command:
```bash
make commit     # Run pre-commit hooks
```

### Testing

- Use pytest for testing
- Tests are located in `tests/` and `tests_v1/` directories
- Run tests with: `make test` (which runs `WANDB_DISABLED=true pytest -vv --import-mode=importlib tests/ tests_v1/`)
- Disable wandb during testing to avoid external dependencies
- **Note**: Training configurations require GPU machines, so training is typically not tested end-to-end. Use `make test` to validate file-level functionality.

### Building

Build the package with:
```bash
pip3 install build && python3 -m build
```

### License

- All source files must include the Apache 2.0 license header
- Check license headers with: `make license`

## Common Patterns

### Configuration Files

- Training configurations are typically YAML or JSON files in `examples/` directory
- Hyperparameters are defined using dataclasses in `src/llamafactory/hparams/`

### Model Support

- New model support is added through model patches in `src/llamafactory/model/`
- Visual models use the visual utilities in `src/llamafactory/model/model_utils/visual.py`
- Quantization support is in `src/llamafactory/model/model_utils/quantization.py`

### Data Processing

- Dataset definitions are in `data/dataset_info.json`
- Data templates and processors are in `src/llamafactory/data/`

### Training

- Training pipelines are in `src/llamafactory/train/`
- Support for different training methods: SFT, DPO, PPO, RM, PT, KTO, ORPO

## Key Dependencies

- Python >= 3.9.0
- PyTorch and transformers for model handling
- datasets for data processing
- peft for parameter-efficient fine-tuning
- accelerate for distributed training
- gradio for web UI
- trl for reinforcement learning
- Optional: vllm/sglang for inference, flash-attention-2, unsloth, liger-kernel

## Entry Points

- **CLI Training**: `llamafactory-cli train --config examples/train_lora/llama3_lora_sft.yaml`
- **Web UI**: `llamafactory-cli webui` or `python src/webui.py`
- **API Server**: `llamafactory-cli api` or `python src/api.py`
- **Chat Interface**: `llamafactory-cli chat --model_name_or_path MODEL_PATH`

## Environment Setup

For development:
```bash
pip install -e ".[dev]"
```

## Important Notes

- The project supports multiple backends: default PyTorch, vLLM, SGLang
- Megatron-core training is supported via mcore_adapter
- SwanLab and W&B are supported for experiment tracking
- Docker support is available with pre-built images
- Day-0/Day-1 support for latest cutting-edge models
- Multi-modal support for vision and audio understanding tasks

## Contribution Guidelines

1. Fork the repository
2. Create a development branch
3. Set up development environment with `pip install -e ".[dev]"`
4. Make changes following the style guide
5. Run quality checks: `make style && make quality`
6. Run tests: `make test`
7. Submit a pull request

## Common Commands

- `make style` - Format code
- `make quality` - Run linters
- `make test` - Run tests
- `make commit` - Install and run pre-commit hooks
- `make license` - Check license headers


## Links discovered
- [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html)

--- .github/PULL_REQUEST_TEMPLATE.md ---
# What does this PR do?

Fixes # (issue)

## Before submitting

- [ ] Did you read the [contributor guideline](https://github.com/hiyouga/LLaMA-Factory/blob/main/.github/CONTRIBUTING.md)?
- [ ] Did you write any new necessary tests?


## Links discovered
- [contributor guideline](https://github.com/hiyouga/LLaMA-Factory/blob/main/.github/CONTRIBUTING.md)

--- data/README.md ---
The [dataset_info.json](dataset_info.json) contains all available datasets. If you are using a custom dataset, please **make sure** to add a *dataset description* in `dataset_info.json` and specify `dataset: dataset_name` before training to use it.

The `dataset_info.json` file should be put in the `dataset_dir` directory. You can change `dataset_dir` to use another directory. The default value is `./data`.

Currently we support datasets in **alpaca** and **sharegpt** format. Allowed file types include json, jsonl, csv, parquet, arrow.

```json
"dataset_name": {
  "hf_hub_url": "the name of the dataset repository on the Hugging Face hub. (if specified, ignore script_url, file_name and cloud_file_name)",
  "ms_hub_url": "the name of the dataset repository on the Model Scope hub. (if specified, ignore script_url, file_name and cloud_file_name)",
  "script_url": "the name of the directory containing a dataset loading script. (if specified, ignore file_name and cloud_file_name)",
  "cloud_file_name": "the name of the dataset file in s3/gcs cloud storage. (if specified, ignore file_name)",
  "file_name": "the name of the dataset folder or dataset file in this directory. (required if above are not specified)",
  "formatting": "the format of the dataset. (optional, default: alpaca, can be chosen from {alpaca, sharegpt})",
  "ranking": "whether the dataset is a preference dataset or not. (default: False)",
  "subset": "the name of the subset. (optional, default: None)",
  "split": "the name of dataset split to be used. (optional, default: train)",
  "folder": "the name of the folder of the dataset repository on the Hugging Face hub. (optional, default: None)",
  "num_samples": "the number of samples in the dataset to be used. (optional, default: None)",
  "columns (optional)": {
    "prompt": "the column name in the dataset containing the prompts. (default: instruction)",
    "query": "the column name in the dataset containing the queries. (default: input)",
    "response": "the column name in the dataset containing the responses. (default: output)",
    "history": "the column name in the dataset containing the histories. (default: None)",
    "messages": "the column name in the dataset containing the messages. (default: conversations)",
    "system": "the column name in the dataset containing the system prompts. (default: None)",
    "tools": "the column name in the dataset containing the tool description. (default: None)",
    "images": "the column name in the dataset containing the image inputs. (default: None)",
    "videos": "the column name in the dataset containing the videos inputs. (default: None)",
    "audios": "the column name in the dataset containing the audios inputs. (default: None)",
    "chosen": "the column name in the dataset containing the chosen answers. (default: None)",
    "rejected": "the column name in the dataset containing the rejected answers. (default: None)",
    "kto_tag": "the column name in the dataset containing the kto tags. (default: None)"
  },
  "tags (optional, used for the sharegpt format)": {
    "role_tag": "the key in the message represents the identity. (default: from)",
    "content_tag": "the key in the message represents the content. (default: value)",
    "user_tag": "the value of the role_tag represents the user. (default: human)",
    "assistant_tag": "the value of the role_tag represents the assistant. (default: gpt)",
    "observation_tag": "the value of the role_tag represents the tool results. (default: observation)",
    "function_tag": "the value of the role_tag represents the function call. (default: function_call)",
    "system_tag": "the value of the role_tag represents the system prompt. (default: system, can override system column)"
  }
}
```

## Alpaca Format

### Supervised Fine-Tuning Dataset

* [Example dataset](alpaca_en_demo.json)

In supervised fine-tuning, the `instruction` column will be concatenated with the `input` column and used as the user prompt, then the user prompt would be `instruction\ninput`. The `output` column represents the model response.

For reasoning models, if the dataset contains chain-of-thought (CoT), the CoT needs to be placed in the model responses, such as `<think>cot</think>output`.

The `system` column will be used as the system prompt if specified.

The `history` column is a list consisting of string tuples representing prompt-response pairs in the history messages. Note that the responses in the history **will also be learned by the model** in supervised fine-tuning.

```json
[
  {
    "instruction": "user instruction (required)",
    "input": "user input (optional)",
    "output": "model response (required)",
    "system": "system prompt (optional)",
    "history": [
      ["user instruction in the first round (optional)", "model response in the first round (optional)"],
      ["user instruction in the second round (optional)", "model response in the second round (optional)"]
    ]
  }
]
```

Regarding the above dataset, the *dataset description* in `dataset_info.json` should be:

```json
"dataset_name": {
  "file_name": "data.json",
  "columns": {
    "prompt": "instruction",
    "query": "input",
    "response": "output",
    "system": "system",
    "history": "history"
  }
}
```

> [!TIP]  
> If the model has reasoning capabilities (e.g. Qwen3) but the dataset does not contain chain-of-thought (CoT), LLaMA-Factory will automatically add empty CoT to the data. When `enable_thinking` is `True` (slow thinking, by default), the empty CoT will be added to the model responses and loss computation will be considered; otherwise (fast thinking), it will be added to the user prompts and loss computation will be ignored. Please keep the `enable_thinking` parameter consistent during training and inference.
>
> If you want to train data containing CoT with slow thinking and data without CoT with fast thinking, you can set `enable_thinking` to `None`. However, this feature is relatively complicated and should be used with caution.

### Pre-training Dataset

- [Example dataset](c4_demo.jsonl)

In pre-training, only the `text` column will be used for model learning.

```json
[
  {"text": "document"},
  {"text": "document"}
]
```

Regarding the above dataset, the *dataset description* in `dataset_info.json` should be:

```json
"dataset_name": {
  "file_name": "data.json",
  "columns": {
    "prompt": "text"
  }
}
```

### Preference Dataset

Preference datasets are used for reward modeling, DPO training, ORPO and SimPO training.

It requires a better response in `chosen` column and a worse response in `rejected` column.

```json
[
  {
    "instruction": "user instruction (required)",
    "input": "user input (optional)",
    "chosen": "chosen answer (required)",
    "rejected": "rejected answer (required)"
  }
]
```

Regarding the above dataset, the *dataset description* in `dataset_info.json` should be:

```json
"dataset_name": {
  "file_name": "data.json",
  "ranking": true,
  "columns": {
    "prompt": "instruction",
    "query": "input",
    "chosen": "chosen",
    "rejected": "rejected"
  }
}
```

### KTO Dataset

An additional column `kto_tag` is required. Please refer to the [sharegpt](#sharegpt-format) format for details.

### Multimodal Image Dataset

An additional column `images` is required. Please refer to the [sharegpt](#sharegpt-format) format for details.

### Multimodal Video Dataset

An additional column `videos` is required. Please refer to the [sharegpt](#sharegpt-format) format for details.

### Multimodal Audio Dataset

An additional column `audios` is required. Please refer to the [sharegpt](#sharegpt-format) format for details.

## Sharegpt Format

### Supervised Fine-Tuning Dataset

- [Example dataset](glaive_toolcall_en_demo.json)

Compared to the alpaca format, the sharegpt format allows the datasets have **more roles**, such as human, gpt, observation and function. They are presented in a list of objects in the `conversations` column.

Note that the human and observation should appear in odd positions, while gpt and function should appear in even positions. The gpt and function will be learned by the model.

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "user instruction"
      },
      {
        "from": "function_call",
        "value": "tool arguments"
      },
      {
        "from": "observation",
        "value": "tool result"
      },
      {
        "from": "gpt",
        "value": "model response"
      }
    ],
    "system": "system prompt (optional)",
    "tools": "tool description (optional)"
  }
]
```

Regarding the above dataset, the *dataset description* in `dataset_info.json` should be:

```json
"dataset_name": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "system": "system",
    "tools": "tools"
  }
}
```

### Pre-training Dataset

Not yet supported, please use the [alpaca](#alpaca-format) format.

### Preference Dataset

- [Example dataset](dpo_en_demo.json)

Preference datasets in sharegpt format also require a better message in `chosen` column and a worse message in `rejected` column.

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "user instruction"
      },
      {
        "from": "gpt",
        "value": "model response"
      },
      {
        "from": "human",
        "value": "user instruction"
      }
    ],
    "chosen": {
      "from": "gpt",
      "value": "chosen answer (required)"
    },
    "rejected": {
      "from": "gpt",
      "value": "rejected answer (required)"
    }
  }
]
```

Regarding the above dataset, the *dataset description* in `dataset_info.json` should be:

```json
"dataset_name": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "ranking": true,
  "columns": {
    "messages": "conversations",
    "chosen": "chosen",
    "rejected": "rejected"
  }
}
```

### KTO Dataset

- [Example dataset](kto_en_demo.json)

KTO datasets require a extra `kto_tag` column containing the boolean human feedback.

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "user instruction"
      },
      {
        "from": "gpt",
        "value": "model response"
      }
    ],
    "kto_tag": "human feedback [true/false] (required)"
  }
]
```

Regarding the above dataset, the *dataset description* in `dataset_info.json` should be:

```json
"dataset_name": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "kto_tag": "kto_tag"
  }
}
```

### Multimodal Image Dataset

- [Example dataset](mllm_demo.json)

Multimodal image datasets require an `images` column containing the paths to the input images.

The number of images should be identical to the `<image>` tokens in the conversations.

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "<image>user instruction"
      },
      {
        "from": "gpt",
        "value": "model response"
      }
    ],
    "images": [
      "image path (required)"
    ]
  }
]
```

Regarding the above dataset, the *dataset description* in `dataset_info.json` should be:

```json
"dataset_name": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "images": "images"
  }
}
```

### Multimodal Video Dataset

- [Example dataset](mllm_video_demo.json)

Multimodal video datasets require a `videos` column containing the paths to the input videos.

The number of videos should be identical to the `<video>` tokens in the conversations.

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "<video>user instruction"
      },
      {
        "from": "gpt",
        "value": "model response"
      }
    ],
    "videos": [
      "video path (required)"
    ]
  }
]
```

Regarding the above dataset, the *dataset description* in `dataset_info.json` should be:

```json
"dataset_name": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "videos": "videos"
  }
}
```

### Multimodal Audio Dataset

- [Example dataset](mllm_audio_demo.json)

Multimodal audio datasets require an `audios` column containing the paths to the input audios.

The number of audios should be identical to the `<audio>` tokens in the conversations.

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "<audio>user instruction"
      },
      {
        "from": "gpt",
        "value": "model response"
      }
    ],
    "audios": [
      "audio path (required)"
    ]
  }
]
```

Regarding the above dataset, the *dataset description* in `dataset_info.json` should be:

```json
"dataset_name": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "audios": "audios"
  }
}
```

### OpenAI Format

The openai format is simply a special case of the sharegpt format, where the first message may be a system prompt.

```json
[
  {
    "messages": [
      {
        "role": "system",
        "content": "system prompt (optional)"
      },
      {
        "role": "user",
        "content": "user instruction"
      },
      {
        "role": "assistant",
        "content": "model response"
      }
    ]
  }
]
```

Regarding the above dataset, the *dataset description* in `dataset_info.json` should be:

```json
"dataset_name": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "messages"
  },
  "tags": {
    "role_tag": "role",
    "content_tag": "content",
    "user_tag": "user",
    "assistant_tag": "assistant",
    "system_tag": "system"
  }
}
```


## Links discovered
- [dataset_info.json](https://github.com/hiyouga/LlamaFactory/blob/main/data/dataset_info.json)
- [Example dataset](https://github.com/hiyouga/LlamaFactory/blob/main/data/alpaca_en_demo.json)
- [Example dataset](https://github.com/hiyouga/LlamaFactory/blob/main/data/c4_demo.jsonl)
- [Example dataset](https://github.com/hiyouga/LlamaFactory/blob/main/data/glaive_toolcall_en_demo.json)
- [Example dataset](https://github.com/hiyouga/LlamaFactory/blob/main/data/dpo_en_demo.json)
- [Example dataset](https://github.com/hiyouga/LlamaFactory/blob/main/data/kto_en_demo.json)
- [Example dataset](https://github.com/hiyouga/LlamaFactory/blob/main/data/mllm_demo.json)
- [Example dataset](https://github.com/hiyouga/LlamaFactory/blob/main/data/mllm_video_demo.json)
- [Example dataset](https://github.com/hiyouga/LlamaFactory/blob/main/data/mllm_audio_demo.json)

--- data/README_zh.md ---
[dataset_info.json](dataset_info.json) 包含了所有可用的数据集。如果您希望使用自定义数据集，请**务必**在 `dataset_info.json` 文件中添加*数据集描述*，并通过修改 `dataset: 数据集名称` 配置来使用数据集。

其中 `dataset_info.json` 文件应放置在 `dataset_dir` 目录下。您可以通过修改 `dataset_dir` 参数来使用其他目录。默认值为 `./data`。

目前我们支持 **alpaca** 格式和 **sharegpt** 格式的数据集。允许的文件类型包括 json、jsonl、csv、parquet 和 arrow。

```json
"数据集名称": {
  "hf_hub_url": "Hugging Face 的数据集仓库地址（若指定，则忽略 script_url 和 file_name）",
  "ms_hub_url": "ModelScope 的数据集仓库地址（若指定，则忽略 script_url 和 file_name）",
  "script_url": "包含数据加载脚本的本地文件夹名称（若指定，则忽略 file_name）",
  "file_name": "该目录下数据集文件夹或文件的名称（若上述参数未指定，则此项必需）",
  "formatting": "数据集格式（可选，默认：alpaca，可以为 alpaca 或 sharegpt）",
  "ranking": "是否为偏好数据集（可选，默认：False）",
  "subset": "数据集子集的名称（可选，默认：None）",
  "split": "所使用的数据集切分（可选，默认：train）",
  "folder": "Hugging Face 仓库的文件夹名称（可选，默认：None）",
  "num_samples": "该数据集所使用的样本数量。（可选，默认：None）",
  "columns（可选）": {
    "prompt": "数据集代表提示词的表头名称（默认：instruction）",
    "query": "数据集代表请求的表头名称（默认：input）",
    "response": "数据集代表回答的表头名称（默认：output）",
    "history": "数据集代表历史对话的表头名称（默认：None）",
    "messages": "数据集代表消息列表的表头名称（默认：conversations）",
    "system": "数据集代表系统提示的表头名称（默认：None）",
    "tools": "数据集代表工具描述的表头名称（默认：None）",
    "images": "数据集代表图像输入的表头名称（默认：None）",
    "videos": "数据集代表视频输入的表头名称（默认：None）",
    "audios": "数据集代表音频输入的表头名称（默认：None）",
    "chosen": "数据集代表更优回答的表头名称（默认：None）",
    "rejected": "数据集代表更差回答的表头名称（默认：None）",
    "kto_tag": "数据集代表 KTO 标签的表头名称（默认：None）"
  },
  "tags（可选，用于 sharegpt 格式）": {
    "role_tag": "消息中代表发送者身份的键名（默认：from）",
    "content_tag": "消息中代表文本内容的键名（默认：value）",
    "user_tag": "消息中代表用户的 role_tag（默认：human）",
    "assistant_tag": "消息中代表助手的 role_tag（默认：gpt）",
    "observation_tag": "消息中代表工具返回结果的 role_tag（默认：observation）",
    "function_tag": "消息中代表工具调用的 role_tag（默认：function_call）",
    "system_tag": "消息中代表系统提示的 role_tag（默认：system，会覆盖 system column）"
  }
}
```

## Alpaca 格式

### 指令监督微调数据集

- [样例数据集](alpaca_zh_demo.json)

在指令监督微调时，`instruction` 列对应的内容会与 `input` 列对应的内容拼接后作为提示词，即提示词为 `instruction\ninput`。而 `output` 列对应的内容为模型回答。

对于推理类模型的微调，如果数据集包含思维链，则需要把思维链放在模型回答中，例如 `<think>cot</think>output`。

如果指定，`system` 列对应的内容将被作为系统提示词。

`history` 列是由多个字符串二元组构成的列表，分别代表历史消息中每轮对话的指令和回答。注意在指令监督微调时，历史消息中的回答内容**也会被用于模型学习**。

```json
[
  {
    "instruction": "用户指令（必填）",
    "input": "用户输入（选填）",
    "output": "模型回答（必填）",
    "system": "系统提示词（选填）",
    "history": [
      ["第一轮指令（选填）", "第一轮回答（选填）"],
      ["第二轮指令（选填）", "第二轮回答（选填）"]
    ]
  }
]
```

对于上述格式的数据，`dataset_info.json` 中的*数据集描述*应为：

```json
"数据集名称": {
  "file_name": "data.json",
  "columns": {
    "prompt": "instruction",
    "query": "input",
    "response": "output",
    "system": "system",
    "history": "history"
  }
}
```

> [!TIP]
> 如果模型本身具备推理能力（如 Qwen3）而数据集不包含思维链，LLaMA-Factory 会自动为数据添加空思维链。当 `enable_thinking` 为 `True` 时（慢思考，默认），空思维链会添加到模型回答中并且计算损失，否则会添加到用户指令中并且不计算损失（快思考）。请在训练和推理时保持 `enable_thinking` 参数一致。
>
> 如果您希望训练包含思维链的数据时使用慢思考，训练不包含思维链的数据时使用快思考，可以设置 `enable_thinking` 为 `None`。但该功能较为复杂，请谨慎使用。

### 预训练数据集

- [样例数据集](c4_demo.jsonl)

在预训练时，只有 `text` 列中的内容会用于模型学习。

```json
[
  {"text": "document"},
  {"text": "document"}
]
```

对于上述格式的数据，`dataset_info.json` 中的*数据集描述*应为：

```json
"数据集名称": {
  "file_name": "data.json",
  "columns": {
    "prompt": "text"
  }
}
```

### 偏好数据集

偏好数据集用于奖励模型训练、DPO 训练、ORPO 训练和 SimPO 训练。

它需要在 `chosen` 列中提供更优的回答，并在 `rejected` 列中提供更差的回答。

```json
[
  {
    "instruction": "用户指令（必填）",
    "input": "用户输入（选填）",
    "chosen": "优质回答（必填）",
    "rejected": "劣质回答（必填）"
  }
]
```

对于上述格式的数据，`dataset_info.json` 中的*数据集描述*应为：

```json
"数据集名称": {
  "file_name": "data.json",
  "ranking": true,
  "columns": {
    "prompt": "instruction",
    "query": "input",
    "chosen": "chosen",
    "rejected": "rejected"
  }
}
```

### KTO 数据集

KTO 数据集需要提供额外的 `kto_tag` 列。详情请参阅 [sharegpt](#sharegpt-格式)。

### 多模态图像数据集

多模态图像数据集需要提供额外的 `images` 列。详情请参阅 [sharegpt](#sharegpt-格式)。

### 多模态视频数据集

多模态视频数据集需要提供额外的 `videos` 列。详情请参阅 [sharegpt](#sharegpt-格式)。

### 多模态音频数据集

多模态音频数据集需要提供额外的 `audios` 列。详情请参阅 [sharegpt](#sharegpt-格式)。

## Sharegpt 格式

### 指令监督微调数据集

- [样例数据集](glaive_toolcall_zh_demo.json)

相比 alpaca 格式的数据集，sharegpt 格式支持**更多的角色种类**，例如 human、gpt、observation、function 等等。它们构成一个对象列表呈现在 `conversations` 列中。

注意其中 human 和 observation 必须出现在奇数位置，gpt 和 function 必须出现在偶数位置。默认所有的 gpt 和 function 会被用于学习。

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "用户指令"
      },
      {
        "from": "function_call",
        "value": "工具参数"
      },
      {
        "from": "observation",
        "value": "工具结果"
      },
      {
        "from": "gpt",
        "value": "模型回答"
      }
    ],
    "system": "系统提示词（选填）",
    "tools": "工具描述（选填）"
  }
]
```

对于上述格式的数据，`dataset_info.json` 中的*数据集描述*应为：

```json
"数据集名称": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "system": "system",
    "tools": "tools"
  }
}
```

### 预训练数据集

尚不支持，请使用 [alpaca](#alpaca-格式) 格式。

### 偏好数据集

- [样例数据集](dpo_zh_demo.json)

Sharegpt 格式的偏好数据集同样需要在 `chosen` 列中提供更优的消息，并在 `rejected` 列中提供更差的消息。

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "用户指令"
      },
      {
        "from": "gpt",
        "value": "模型回答"
      },
      {
        "from": "human",
        "value": "用户指令"
      }
    ],
    "chosen": {
      "from": "gpt",
      "value": "优质回答"
    },
    "rejected": {
      "from": "gpt",
      "value": "劣质回答"
    }
  }
]
```

对于上述格式的数据，`dataset_info.json` 中的*数据集描述*应为：

```json
"数据集名称": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "ranking": true,
  "columns": {
    "messages": "conversations",
    "chosen": "chosen",
    "rejected": "rejected"
  }
}
```

### KTO 数据集

- [样例数据集](kto_en_demo.json)

KTO 数据集需要额外添加一个 `kto_tag` 列，包含 bool 类型的人类反馈。

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "用户指令"
      },
      {
        "from": "gpt",
        "value": "模型回答"
      }
    ],
    "kto_tag": "人类反馈 [true/false]（必填）"
  }
]
```

对于上述格式的数据，`dataset_info.json` 中的*数据集描述*应为：

```json
"数据集名称": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "kto_tag": "kto_tag"
  }
}
```

### 多模态图像数据集

- [样例数据集](mllm_demo.json)

多模态图像数据集需要额外添加一个 `images` 列，包含输入图像的路径。

注意图片的数量必须与文本中所有 `<image>` 标记的数量严格一致。

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "<image><image>用户指令"
      },
      {
        "from": "gpt",
        "value": "模型回答"
      }
    ],
    "images": [
      "图像路径（必填）",
      "图像路径（必填）"
    ]
  }
]
```

对于上述格式的数据，`dataset_info.json` 中的*数据集描述*应为：

```json
"数据集名称": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "images": "images"
  }
}
```

### 多模态视频数据集

- [样例数据集](mllm_video_demo.json)

多模态视频数据集需要额外添加一个 `videos` 列，包含输入视频的路径。

注意视频的数量必须与文本中所有 `<video>` 标记的数量严格一致。

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "<video><video>用户指令"
      },
      {
        "from": "gpt",
        "value": "模型回答"
      }
    ],
    "videos": [
      "视频路径（必填）",
      "视频路径（必填）"
    ]
  }
]
```

对于上述格式的数据，`dataset_info.json` 中的*数据集描述*应为：

```json
"数据集名称": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "videos": "videos"
  }
}
```

### 多模态音频数据集

- [样例数据集](mllm_audio_demo.json)

多模态音频数据集需要额外添加一个 `audios` 列，包含输入音频的路径。

注意音频的数量必须与文本中所有 `<audio>` 标记的数量严格一致。

```json
[
  {
    "conversations": [
      {
        "from": "human",
        "value": "<audio><audio>用户指令"
      },
      {
        "from": "gpt",
        "value": "模型回答"
      }
    ],
    "audios": [
      "音频路径（必填）",
      "音频路径（必填）"
    ]
  }
]
```

对于上述格式的数据，`dataset_info.json` 中的*数据集描述*应为：

```json
"数据集名称": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "conversations",
    "audios": "audios"
  }
}
```


### OpenAI 格式

OpenAI 格式仅仅是 sharegpt 格式的一种特殊情况，其中第一条消息可能是系统提示词。

```json
[
  {
    "messages": [
      {
        "role": "system",
        "content": "系统提示词（选填）"
      },
      {
        "role": "user",
        "content": "用户指令"
      },
      {
        "role": "assistant",
        "content": "模型回答"
      }
    ]
  }
]
```

对于上述格式的数据，`dataset_info.json` 中的*数据集描述*应为：

```json
"数据集名称": {
  "file_name": "data.json",
  "formatting": "sharegpt",
  "columns": {
    "messages": "messages"
  },
  "tags": {
    "role_tag": "role",
    "content_tag": "content",
    "user_tag": "user",
    "assistant_tag": "assistant",
    "system_tag": "system"
  }
}
```


## Links discovered
- [dataset_info.json](https://github.com/hiyouga/LlamaFactory/blob/main/data/dataset_info.json)
- [样例数据集](https://github.com/hiyouga/LlamaFactory/blob/main/data/alpaca_zh_demo.json)
- [样例数据集](https://github.com/hiyouga/LlamaFactory/blob/main/data/c4_demo.jsonl)
- [样例数据集](https://github.com/hiyouga/LlamaFactory/blob/main/data/glaive_toolcall_zh_demo.json)
- [样例数据集](https://github.com/hiyouga/LlamaFactory/blob/main/data/dpo_zh_demo.json)
- [样例数据集](https://github.com/hiyouga/LlamaFactory/blob/main/data/kto_en_demo.json)
- [样例数据集](https://github.com/hiyouga/LlamaFactory/blob/main/data/mllm_demo.json)
- [样例数据集](https://github.com/hiyouga/LlamaFactory/blob/main/data/mllm_video_demo.json)
- [样例数据集](https://github.com/hiyouga/LlamaFactory/blob/main/data/mllm_audio_demo.json)

--- requirements/adam-mini.txt ---
adam-mini


--- requirements/apollo.txt ---
apollo-torch


--- requirements/aqlm.txt ---
aqlm[gpu]>=1.1.0


--- requirements/badam.txt ---
badam>=1.2.1


--- requirements/bitsandbytes.txt ---
bitsandbytes>=0.39.0


--- requirements/deepspeed.txt ---
deepspeed>=0.10.0,<=0.16.9


--- requirements/dev.txt ---
pre-commit
ruff
pytest
build


--- requirements/eetq.txt ---
eetq


--- requirements/fp8.txt ---
torchao>=0.8.0
accelerate>=1.10.0


--- requirements/fp8-te.txt ---
transformer_engine[pytorch]>=2.0.0
accelerate>=1.10.0


--- scripts/bench_qwen.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
from dataclasses import dataclass
from typing import Any

import fire
import torch
from peft import PeftModel
from torch.utils.data import Dataset
from transformers import DataCollatorForSeq2Seq, Qwen2_5_VLProcessor

from llamafactory.extras.constants import IGNORE_INDEX
from llamafactory.hparams import get_train_args
from llamafactory.model import load_model, load_tokenizer
from llamafactory.train.callbacks import LogCallback
from llamafactory.train.sft.trainer import CustomSeq2SeqTrainer


class DummyDataset(Dataset):
    def __init__(self, size: int = 1000, seq_length: int = 1024, processor: Qwen2_5_VLProcessor = None):
        self.size = size
        self.seq_length = seq_length
        self.vocab_size = 32768
        self.processor = processor

        image_token_num = 18 * 18 // (2 * 2)
        image_t = 2

        self.text_seqlen = seq_length // 4  # 25% text
        video_seq_length = self.seq_length - self.text_seqlen - image_t * image_token_num
        video_t = video_seq_length // image_token_num

        self.image_size = [18 * 18 * image_t, 1176]
        self.image_grid_thw = torch.tensor([[1, 18, 18]] * image_t, dtype=torch.long)
        self.image_seqlen = image_t * image_token_num

        self.video_size = [18 * 18 * video_t, 1176]
        self.video_grid_thw = torch.tensor([[video_t, 18, 18]], dtype=torch.long)
        self.video_seqlen = video_t * image_token_num

    def __len__(self):
        return self.size

    def __getitem__(self, index: int):
        input_ids = torch.randint(low=0, high=self.vocab_size, size=(self.seq_length,))
        input_ids[: self.image_seqlen] = self.processor.image_token_id
        input_ids[self.image_seqlen : self.image_seqlen + self.video_seqlen] = self.processor.video_token_id

        attention_mask = torch.ones((self.seq_length,), dtype=torch.long)
        labels = input_ids.clone()
        labels[: self.image_seqlen + self.video_seqlen] = IGNORE_INDEX
        pixel_values = torch.rand(self.image_size, dtype=torch.float32)
        pixel_values_videos = torch.rand(self.video_size, dtype=torch.float32)
        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "labels": labels,
            "pixel_values": pixel_values,
            "pixel_values_videos": pixel_values_videos,
            "image_grid_thw": self.image_grid_thw,
            "video_grid_thw": self.video_grid_thw,
        }


@dataclass
class MultiModalDataCollatorForSeq2Seq(DataCollatorForSeq2Seq):
    def __post_init__(self):
        if isinstance(self.model, PeftModel):
            self.model = self.model.base_model.model

        if self.model is not None and hasattr(self.model, "get_rope_index"):  # for qwen2vl mrope
            self.get_rope_func = self.model.get_rope_index  # transformers < 4.52.0 or qwen2.5 omni
        elif self.model is not None and hasattr(self.model, "model") and hasattr(self.model.model, "get_rope_index"):
            self.get_rope_func = self.model.model.get_rope_index  # transformers >= 4.52.0
        else:
            self.get_rope_func = None

    def __call__(self, features: list[dict[str, Any]]) -> dict[str, "torch.Tensor"]:
        batch_pixel_values = [feature.pop("pixel_values") for feature in features]
        batch_pixel_values_videos = [feature.pop("pixel_values_videos") for feature in features]
        batch_image_grid_thw = [feature.pop("image_grid_thw") for feature in features]
        batch_video_grid_thw = [feature.pop("video_grid_thw") for feature in features]

        batch: dict[str, torch.Tensor] = super().__call__(features)

        batch["pixel_values"] = torch.cat(batch_pixel_values, dim=0)
        batch["pixel_values_videos"] = torch.cat(batch_pixel_values_videos, dim=0)
        batch["image_grid_thw"] = torch.cat(batch_image_grid_thw, dim=0)
        batch["video_grid_thw"] = torch.cat(batch_video_grid_thw, dim=0)

        if self.get_rope_func is not None:
            rope_index_kwargs = {
                "input_ids": batch["input_ids"],
                "image_grid_thw": batch["image_grid_thw"],
                "video_grid_thw": batch["video_grid_thw"],
                "attention_mask": (batch["attention_mask"] >= 1).float(),
            }
            batch["position_ids"], batch["rope_deltas"] = self.get_rope_func(**rope_index_kwargs)

        if "position_ids" not in batch or batch["position_ids"].dim() != 3:
            raise ValueError("Qwen2VL requires 3D position ids for mrope.")

        return batch


def bench_qwen(
    model_name_or_path: str = "Qwen/Qwen2-VL-7B-Instruct",
    batch_size: int = 1,
    seq_length: int = 2048,
    liger_kernel: bool = False,
    deepspeed_stage: int = 3,
):
    os.environ["LLAMABOARD_ENABLED"] = "true"
    os.environ["LLAMABOARD_WORKDIR"] = "output/dummy_dir"
    args = {
        "model_name_or_path": model_name_or_path,
        "enable_liger_kernel": liger_kernel,
        "stage": "sft",
        "do_train": True,
        "finetuning_type": "full",
        "dataset": "alpaca_en_demo",
        "template": "qwen2_vl",
        "cutoff_len": seq_length,
        "output_dir": "output/dummy_dir",
        "logging_steps": 10,
        "save_strategy": "no",
        "save_only_model": True,
        "overwrite_output_dir": True,
        "per_device_train_batch_size": batch_size,
        "max_steps": 1000,
        "bf16": True,
        "include_num_input_tokens_seen": True,
        "report_to": "none",
    }
    if deepspeed_stage in [2, 3]:
        args["deepspeed"] = f"examples/deepspeed/ds_z{deepspeed_stage}_config.json"

    model_args, _, training_args, finetuning_args, _ = get_train_args(args)
    tokenizer_module = load_tokenizer(model_args)
    tokenizer = tokenizer_module["tokenizer"]
    trainset = DummyDataset(size=100000, seq_length=seq_length, processor=tokenizer_module["processor"])
    model = load_model(tokenizer, model_args, finetuning_args, training_args.do_train)
    data_collator = MultiModalDataCollatorForSeq2Seq(
        tokenizer=tokenizer, model=model, pad_to_multiple_of=8, label_pad_token_id=IGNORE_INDEX
    )

    trainer = CustomSeq2SeqTrainer(
        model=model,
        args=training_args,
        finetuning_args=finetuning_args,
        data_collator=data_collator,
        callbacks=[LogCallback()],
        train_dataset=trainset,
        **tokenizer_module,
    )
    trainer.train(resume_from_checkpoint=training_args.resume_from_checkpoint)


if __name__ == "__main__":
    fire.Fire(bench_qwen)


--- scripts/eval_bleu_rouge.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
import logging
import time

import fire
from datasets import load_dataset


try:
    import jieba  # type: ignore
    from nltk.translate.bleu_score import SmoothingFunction, sentence_bleu  # type: ignore
    from rouge_chinese import Rouge  # type: ignore

    jieba.setLogLevel(logging.CRITICAL)
    jieba.initialize()
except ImportError:
    print("Please install llamafactory with `pip install -r requirements/metrics.txt`.")
    raise


def compute_metrics(sample):
    hypothesis = list(jieba.cut(sample["predict"]))
    reference = list(jieba.cut(sample["label"]))

    bleu_score = sentence_bleu(
        [list(sample["label"])],
        list(sample["predict"]),
        smoothing_function=SmoothingFunction().method3,
    )

    if len(" ".join(hypothesis).split()) == 0 or len(" ".join(reference).split()) == 0:
        result = {"rouge-1": {"f": 0.0}, "rouge-2": {"f": 0.0}, "rouge-l": {"f": 0.0}}
    else:
        rouge = Rouge()
        scores = rouge.get_scores(" ".join(hypothesis), " ".join(reference))
        result = scores[0]

    metric_result = {}
    for k, v in result.items():
        metric_result[k] = round(v["f"] * 100, 4)

    metric_result["bleu-4"] = round(bleu_score * 100, 4)

    return metric_result


def main(filename: str):
    start_time = time.time()
    dataset = load_dataset("json", data_files=filename, split="train")
    dataset = dataset.map(compute_metrics, num_proc=8, remove_columns=dataset.column_names)
    score_dict = dataset.to_dict()

    average_score = {}
    for task, scores in sorted(score_dict.items(), key=lambda x: x[0]):
        print(f"{task}: {sum(scores) / len(scores):.4f}")
        average_score[task] = sum(scores) / len(scores)

    with open("predictions_score.json", "w", encoding="utf-8") as f:
        json.dump(average_score, f, indent=4)

    print(f"\nDone in {time.time() - start_time:.3f}s.\nScore file saved to predictions_score.json")


if __name__ == "__main__":
    fire.Fire(main)


--- scripts/llama_pro.py ---
# Copyright 2025 Tencent Inc. and the LlamaFactory team.
#
# This code is inspired by the Tencent's LLaMA-Pro library.
# https://github.com/TencentARC/LLaMA-Pro/blob/main/scripts/block_expansion.py
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
import os
from collections import OrderedDict
from typing import TYPE_CHECKING

import fire
import torch
from huggingface_hub import split_torch_state_dict_into_shards
from safetensors.torch import save_file
from tqdm import tqdm
from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, PreTrainedModel
from transformers.modeling_utils import SAFE_WEIGHTS_INDEX_NAME, SAFE_WEIGHTS_NAME, WEIGHTS_INDEX_NAME, WEIGHTS_NAME


if TYPE_CHECKING:
    from transformers import PretrainedConfig


def change_name(name: str, old_index: int, new_index: int) -> str:
    return name.replace(f".{old_index:d}.", f".{new_index:d}.")


def block_expansion(
    model_name_or_path: str,
    output_dir: str,
    num_expand: int,
    shard_size: str = "5GB",
    save_safetensors: bool = True,
):
    r"""Perform block expansion for LLaMA, Mistral, Qwen2 or Yi models.

    Usage: python llama_pro.py --model_name_or_path meta-llama/Llama-2-7b-hf --output_dir llama2_pro --num_expand 8
    """
    config: PretrainedConfig = AutoConfig.from_pretrained(model_name_or_path, trust_remote_code=True)
    num_layers = getattr(config, "num_hidden_layers")
    if num_layers % num_expand != 0:
        raise ValueError(f"`num_layers` {num_layers} should be divisible by `num_expand` {num_expand}.")

    setattr(config, "num_hidden_layers", num_layers + num_expand)
    config.save_pretrained(output_dir)

    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)
    tokenizer.save_pretrained(output_dir)

    print(f"Expanding model of {num_layers} layers to {num_layers + num_expand} layers.")
    model = AutoModelForCausalLM.from_pretrained(
        model_name_or_path, torch_dtype="auto", device_map="cpu", trust_remote_code=True, low_cpu_mem_usage=True
    )
    assert isinstance(model, PreTrainedModel)  # type hint
    if save_safetensors and getattr(model.config, "tie_word_embeddings", False):
        del model.lm_head  # safetensors does not allow shared weights

    split = num_layers // num_expand
    layer_cnt = 0
    state_dict = model.state_dict()
    output_state_dict: dict[str, torch.Tensor] = OrderedDict()
    for i in range(num_layers):
        for key, value in state_dict.items():
            if f".{i:d}." in key:
                output_state_dict[change_name(key, i, layer_cnt)] = value

        print(f"Add layer {layer_cnt} copied from layer {i}.")
        layer_cnt += 1
        if (i + 1) % split == 0:
            for key, value in state_dict.items():
                if f".{i:d}." in key:
                    if "down_proj" in key or "o_proj" in key:
                        output_state_dict[change_name(key, i, layer_cnt)] = torch.zeros_like(value)
                    else:
                        output_state_dict[change_name(key, i, layer_cnt)] = torch.clone(value)

            print(f"Add layer {layer_cnt} expanded from layer {i}.")
            layer_cnt += 1

    for key, value in state_dict.items():
        if key not in output_state_dict:
            output_state_dict[key] = value

    weights_name = SAFE_WEIGHTS_NAME if save_safetensors else WEIGHTS_NAME
    filename_pattern = weights_name.replace(".bin", "{suffix}.bin").replace(".safetensors", "{suffix}.safetensors")
    state_dict_split = split_torch_state_dict_into_shards(
        output_state_dict, filename_pattern=filename_pattern, max_shard_size=shard_size
    )
    for shard_file, tensors in tqdm(state_dict_split.filename_to_tensors.items(), desc="Save weights"):
        shard = {tensor: output_state_dict[tensor].contiguous() for tensor in tensors}
        if save_safetensors:
            save_file(shard, os.path.join(output_dir, shard_file), metadata={"format": "pt"})
        else:
            torch.save(shard, os.path.join(output_dir, shard_file))

    if not state_dict_split.is_sharded:
        print(f"Model weights saved in {os.path.join(output_dir, weights_name)}.")
    else:
        index = {
            "metadata": state_dict_split.metadata,
            "weight_map": state_dict_split.tensor_to_filename,
        }
        index_name = SAFE_WEIGHTS_INDEX_NAME if save_safetensors else WEIGHTS_INDEX_NAME
        with open(os.path.join(output_dir, index_name), "w", encoding="utf-8") as f:
            json.dump(index, f, indent=2, sort_keys=True)

        print(f"Model weights saved in {output_dir}.")

    print("- Fine-tune this model with:")
    print(f"model_name_or_path: {output_dir}")
    print("finetuning_type: freeze")
    print(f"freeze_trainable_layers: {num_expand}")
    print("use_llama_pro: true")


if __name__ == "__main__":
    fire.Fire(block_expansion)


--- scripts/loftq_init.py ---
# Copyright 2025 HuggingFace Inc. and the LlamaFactory team.
#
# This code is based on the HuggingFace's PEFT library.
# https://github.com/huggingface/peft/blob/v0.10.0/examples/loftq_finetuning/quantize_save_load.py
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
from typing import TYPE_CHECKING

import fire
from peft import LoftQConfig, LoraConfig, TaskType, get_peft_model
from transformers import AutoModelForCausalLM, AutoTokenizer


if TYPE_CHECKING:
    from transformers import PreTrainedModel


def quantize_loftq(
    model_name_or_path: str,
    output_dir: str,
    loftq_bits: int = 4,
    loftq_iter: int = 4,
    lora_alpha: int = None,
    lora_rank: int = 16,
    lora_dropout: float = 0,
    lora_target: tuple = ("q_proj", "v_proj"),
    save_safetensors: bool = True,
):
    r"""Initialize LoRA weights with LoRA-fine-tuning-aware Quantization (LoftQ).

    Usage: python loftq_init.py --model_name_or_path path_to_model --output_dir output_dir
    """
    if isinstance(lora_target, str):
        lora_target = [name.strip() for name in lora_target.split(",")]

    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True, torch_dtype="auto")

    loftq_config = LoftQConfig(loftq_bits=loftq_bits, loftq_iter=loftq_iter)
    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        inference_mode=True,
        r=lora_rank,
        lora_alpha=lora_alpha if lora_alpha is not None else lora_rank * 2,
        lora_dropout=lora_dropout,
        target_modules=lora_target,
        init_lora_weights="loftq",
        loftq_config=loftq_config,
    )

    # Init LoftQ model
    print("Initializing LoftQ weights, it may be take several minutes, wait patiently.")
    peft_model = get_peft_model(model, lora_config)
    loftq_dir = os.path.join(output_dir, "loftq_init")

    # Save LoftQ model
    setattr(peft_model.peft_config["default"], "base_model_name_or_path", os.path.abspath(output_dir))
    setattr(peft_model.peft_config["default"], "init_lora_weights", True)  # don't apply loftq again
    peft_model.save_pretrained(loftq_dir, safe_serialization=save_safetensors)
    print(f"Adapter weights saved in {loftq_dir}")

    # Save base model
    base_model: PreTrainedModel = peft_model.unload()
    base_model.save_pretrained(output_dir, safe_serialization=save_safetensors)
    tokenizer.save_pretrained(output_dir)
    print(f"Model weights saved in {output_dir}")

    print("- Fine-tune this model with:")
    print(f"model_name_or_path: {output_dir}")
    print(f"adapter_name_or_path: {loftq_dir}")
    print("finetuning_type: lora")
    print(f"quantization_bit: {loftq_bits}")


if __name__ == "__main__":
    fire.Fire(quantize_loftq)


--- scripts/megatron_merge.py ---
# Copyright 2025 the ROLL team and the LlamaFactory team.
#
# This code is modified from the ROLL library.
# https://github.com/alibaba/ROLL/blob/main/mcore_adapter/tools/convert.py
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

import fire
import torch
from mcore_adapter.models.converter.post_converter import convert_checkpoint_to_hf, convert_checkpoint_to_mca
from mcore_adapter.training_args import DistributingParallelArguments
from mcore_adapter.utils import get_logger
from transformers import AutoConfig


logger = get_logger(__name__)


def convert_mca_to_hf(
    checkpoint_path: str,
    output_path: str = "./output",
    bf16: bool = False,
    fp16: bool = False,
    convert_model_max_length: int | None = None,
):
    """Convert megatron checkpoint to HuggingFace format.

    Args:
        checkpoint_path: Path to the checkpoint to convert
        output_path: Path to save the converted checkpoint
        bf16: Use bfloat16 precision
        fp16: Use float16 precision
        convert_model_max_length: Change the model_max_length in hf config.json
    """
    if bf16 and fp16:
        raise ValueError("bf16 and fp16 cannot be both True.")

    torch_dtype = None
    if bf16:
        torch_dtype = torch.bfloat16
    elif fp16:
        torch_dtype = torch.float16

    convert_checkpoint_to_hf(checkpoint_path, output_path, torch_dtype=torch_dtype)

    if convert_model_max_length is not None:
        config = AutoConfig.from_pretrained(output_path, trust_remote_code=True)
        config.model_max_length = convert_model_max_length
        config.save_pretrained(output_path)


def convert(
    checkpoint_path: str,
    output_path: str = "./output",
    bf16: bool = False,
    fp16: bool = False,
    convert_model_max_length: int | None = None,
    tensor_model_parallel_size: int = 1,
    pipeline_model_parallel_size: int = 1,
    expert_model_parallel_size: int = 1,
    virtual_pipeline_model_parallel_size: int | None = None,
):
    """Convert checkpoint between MCA and HuggingFace formats.

    Args:
        checkpoint_path: Path to the checkpoint to convert
        output_path: Path to save the converted checkpoint
        bf16: Use bfloat16 precision
        fp16: Use float16 precision
        convert_model_max_length: Change the model_max_length in hf config.json
        tensor_model_parallel_size: Tensor model parallel size
        pipeline_model_parallel_size: Pipeline model parallel size
        expert_model_parallel_size: Expert model parallel size
        virtual_pipeline_model_parallel_size: Virtual pipeline model parallel size
    """
    if bf16 and fp16:
        raise ValueError("bf16 and fp16 cannot be both True.")

    mca_config_path = os.path.join(checkpoint_path, "mca_config.json")
    from_mca = os.path.exists(mca_config_path)

    if not from_mca:
        dist_args = DistributingParallelArguments(
            tensor_model_parallel_size=tensor_model_parallel_size,
            pipeline_model_parallel_size=pipeline_model_parallel_size,
            expert_model_parallel_size=expert_model_parallel_size,
            virtual_pipeline_model_parallel_size=virtual_pipeline_model_parallel_size,
        )

        convert_checkpoint_to_mca(
            checkpoint_path,
            output_path,
            dist_args,
            bf16=bf16,
            fp16=fp16,
        )
    else:
        convert_mca_to_hf(
            checkpoint_path=checkpoint_path,
            output_path=output_path,
            bf16=bf16,
            fp16=fp16,
            convert_model_max_length=convert_model_max_length,
        )


def main():
    fire.Fire(convert)


if __name__ == "__main__":
    main()


--- scripts/pissa_init.py ---
# Copyright 2025 HuggingFace Inc. and the LlamaFactory team.
#
# This code is based on the HuggingFace's PEFT library.
# https://github.com/huggingface/peft/blob/v0.11.0/examples/pissa_finetuning/preprocess.py
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
from typing import TYPE_CHECKING

import fire
from peft import LoraConfig, TaskType, get_peft_model
from transformers import AutoModelForCausalLM, AutoTokenizer


if TYPE_CHECKING:
    from transformers import PreTrainedModel


def quantize_pissa(
    model_name_or_path: str,
    output_dir: str,
    pissa_iter: int = 16,
    lora_alpha: int = None,
    lora_rank: int = 16,
    lora_dropout: float = 0,
    lora_target: tuple = ("q_proj", "v_proj"),
    save_safetensors: bool = True,
):
    r"""Initialize LoRA weights with Principal Singular values and Singular vectors Adaptation (PiSSA).

    Usage: python pissa_init.py --model_name_or_path path_to_model --output_dir output_dir
    """
    if isinstance(lora_target, str):
        lora_target = [name.strip() for name in lora_target.split(",")]

    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True, torch_dtype="auto")

    lora_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM,
        r=lora_rank,
        lora_alpha=lora_alpha if lora_alpha is not None else lora_rank * 2,
        lora_dropout=lora_dropout,
        target_modules=lora_target,
        init_lora_weights="pissa" if pissa_iter == -1 else f"pissa_niter_{pissa_iter}",
    )

    # Init PiSSA model
    peft_model = get_peft_model(model, lora_config)
    pissa_dir = os.path.join(output_dir, "pissa_init")

    # Save PiSSA model
    setattr(peft_model.peft_config["default"], "base_model_name_or_path", os.path.abspath(output_dir))
    setattr(peft_model.peft_config["default"], "init_lora_weights", True)  # don't apply pissa again
    peft_model.save_pretrained(pissa_dir, safe_serialization=save_safetensors)
    print(f"Adapter weights saved in {pissa_dir}")

    # Save base model
    base_model: PreTrainedModel = peft_model.unload()
    base_model.save_pretrained(output_dir, safe_serialization=save_safetensors)
    tokenizer.save_pretrained(output_dir)
    print(f"Model weights saved in {output_dir}")

    print("- Fine-tune this model with:")
    print(f"model_name_or_path: {output_dir}")
    print(f"adapter_name_or_path: {pissa_dir}")
    print("finetuning_type: lora")
    print("pissa_init: false")
    print("pissa_convert: true")
    print("- and optionally with:")
    print("quantization_bit: 4")


if __name__ == "__main__":
    fire.Fire(quantize_pissa)


--- scripts/qwen_omni_merge.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Why we need this script for qwen_omni?

Because the qwen_omni model is constructed by two parts:
1. [Thinker]:[audio_encoder, vision_encoder, LLM backbone], which our repository does support to post-training.
2. [Talker]: [audio_decoder, wave_model], which is not supported to post-training without specific tokenizer.
When we post-training the model, we exactly train the [Thinker] part, and the [Talker] part is dropped.
So, to get the complete model, we need to merge the [Talker] part back to the [Thinker] part.
LoRA mode: [Thinker + LoRA weights] + [Original Talker] -> [Omni model]
Full mode: [Thinker] + [Original Talker] -> [Omni model]
For Processor, we do saved the processor from trained model instead of the original model.
"""

import os
import shutil

import fire
from peft import PeftModel
from transformers import AutoConfig, AutoModelForTextToWaveform, AutoProcessor
from transformers.utils import cached_file


def merge_lora(
    model_path: str,
    lora_path: str,
    save_path: str = "./merged_model_checkpoint",
    extra_file: str = "spk_dict.pt",
    submodule_name: str = "thinker",
):
    """Load the original model, merge the LoRA weights.

    For a specified submodule, and save the final merged model along with its configurations.

    Args:
        model_path (str): Path to the original model directory.
        lora_path (str): Path to the directory containing LoRA weights.
        save_path (str): Directory where the merged model and configurations will be saved.
        extra_file (str): Name of the extra file to be copied (default: "spk_dict.pt").
        submodule_name (str): Name of the submodule to merge (default: "thinker").
    """
    # 1. Load the original model
    model = AutoModelForTextToWaveform.from_pretrained(model_path, torch_dtype="auto", device_map="cpu")
    print("Successfully loaded the original model.")

    # 2. Extract the submodule to be merged (e.g., model.thinker)
    if not hasattr(model, submodule_name):
        raise AttributeError(f"The model does not have a submodule named '{submodule_name}'.")

    base_submodule = getattr(model, submodule_name)
    print(f"Successfully extracted submodule: {submodule_name}.")

    # 3. Load the LoRA weights onto the extracted submodule
    lora_model = PeftModel.from_pretrained(base_submodule, lora_path)
    processor = AutoProcessor.from_pretrained(lora_path)
    print("Successfully loaded LoRA weights and processor.")

    # 4. Merge the LoRA weights into the submodule and unload the LoRA modules
    merged_submodule = lora_model.merge_and_unload()
    print("Successfully merged LoRA weights.")

    # 5. Replace the original submodule with the merged submodule in the model
    setattr(model, submodule_name, merged_submodule)

    # 6. Save the final merged model along with the tokenizer and processor configuration
    model.save_pretrained(save_path)
    processor.save_pretrained(save_path)
    print(f"Merged model and processor saved to {save_path}.")

    try:
        source_file = cached_file(path_or_repo_id=model_path, filename=extra_file)
        shutil.copy(source_file, os.path.join(save_path, extra_file))
        print(f"File '{extra_file}' copied from {model_path} to {save_path}.")
    except Exception:
        print(f"File '{extra_file}' not found in {model_path}, skipping copy.")


def save_full_model(
    model_path: str,
    thinker_path: str,
    save_path: str = "./merged_model_checkpoint",
    extra_file: str = "spk_dict.pt",
):
    """Load the saved thinker module and the original model, replace the thinker in the original model.

    Then save the complete model along with its tokenizer and processor configuration.

    Args:
        model_path (str): Directory path of the original model.
        thinker_path (str): Path to the saved thinker weights.
        save_path (str): Directory where the merged model and configurations will be saved.
        extra_file (str): Name of the extra file to be copied (default: "spk_dict.pt").
    """
    # 1. Load the saved thinker module and the original model
    config = AutoConfig.from_pretrained(model_path)
    if getattr(config, "model_type") == "qwen2_5_omni":
        from transformers.models.qwen2_5_omni import Qwen2_5OmniThinkerForConditionalGeneration  # type: ignore

        ThinkerClass = Qwen2_5OmniThinkerForConditionalGeneration
    elif getattr(config, "model_type") == "qwen3_omni_moe":
        from transformers.models.qwen3_omni_moe import Qwen3OmniMoeThinkerForConditionalGeneration  # type: ignore

        ThinkerClass = Qwen3OmniMoeThinkerForConditionalGeneration
    else:
        raise ValueError(f"Unsupported model type: {getattr(config, 'model_type')}.")

    thinker = ThinkerClass.from_pretrained(thinker_path, torch_dtype="auto", device_map="cpu")
    base_model = AutoModelForTextToWaveform.from_pretrained(model_path, torch_dtype="auto", device_map="cpu")
    base_model.thinker = thinker
    processor = AutoProcessor.from_pretrained(thinker_path)
    print("Successfully loaded model weights and processor.")

    # 2. Save the complete model along with its tokenizer and processor configuration
    base_model.save_pretrained(save_path)
    processor.save_pretrained(save_path)
    print(f"Merged model and processor saved to {save_path}.")

    # 3. Copy the extra file from the base model directory to the save_path
    try:
        source_file = cached_file(path_or_repo_id=model_path, filename=extra_file)
        shutil.copy(source_file, os.path.join(save_path, extra_file))
        print(f"File '{extra_file}' copied from {model_path} to {save_path}.")
    except Exception:
        print(f"File '{extra_file}' not found in {model_path}, skipping copy.")


if __name__ == "__main__":
    fire.Fire({"save_full": save_full_model, "merge_lora": merge_lora})


--- scripts/vllm_infer.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import gc
import json
import time

import av
import fire
from datasets import load_dataset
from eval_bleu_rouge import compute_metrics
from tqdm import tqdm
from transformers import Seq2SeqTrainingArguments

from llamafactory.data import get_dataset, get_template_and_fix_tokenizer
from llamafactory.extras.constants import IGNORE_INDEX
from llamafactory.extras.misc import get_device_count
from llamafactory.extras.packages import is_vllm_available
from llamafactory.hparams import get_infer_args
from llamafactory.model import load_tokenizer


if is_vllm_available():
    from vllm import LLM, SamplingParams
    from vllm.lora.request import LoRARequest


def _need_video_kwargs(template):
    NEEDED_TEMPLATE = ["qwen3_vl", "glm4v"]
    if any(t in template for t in NEEDED_TEMPLATE):
        return True

    return False


def vllm_infer(
    model_name_or_path: str,
    adapter_name_or_path: str = None,
    dataset: str = "alpaca_en_demo",
    dataset_dir: str = "data",
    template: str = "default",
    cutoff_len: int = 2048,
    max_samples: int | None = None,
    vllm_config: str = "{}",
    save_name: str = "generated_predictions.jsonl",
    matrix_save_name: str = None,
    temperature: float = 0.95,
    top_p: float = 0.7,
    top_k: int = 50,
    max_new_tokens: int = 1024,
    repetition_penalty: float = 1.0,
    skip_special_tokens: bool = True,
    default_system: str | None = None,
    enable_thinking: bool = True,
    seed: int | None = None,
    pipeline_parallel_size: int = 1,
    image_max_pixels: int = 768 * 768,
    image_min_pixels: int = 32 * 32,
    video_fps: float = 2.0,
    video_maxlen: int = 128,
    batch_size: int = 1024,
):
    r"""Perform batch generation using vLLM engine, which supports tensor parallelism.

    Usage: python vllm_infer.py --model_name_or_path meta-llama/Llama-2-7b-hf --template llama --dataset alpaca_en_demo
    """
    if pipeline_parallel_size > get_device_count():
        raise ValueError("Pipeline parallel size should be smaller than the number of gpus.")

    model_args, data_args, _, generating_args = get_infer_args(
        dict(
            model_name_or_path=model_name_or_path,
            adapter_name_or_path=adapter_name_or_path,
            dataset=dataset,
            dataset_dir=dataset_dir,
            template=template,
            cutoff_len=cutoff_len,
            max_samples=max_samples,
            preprocessing_num_workers=16,
            default_system=default_system,
            enable_thinking=enable_thinking,
            vllm_config=vllm_config,
            temperature=temperature,
            top_p=top_p,
            top_k=top_k,
            max_new_tokens=max_new_tokens,
            repetition_penalty=repetition_penalty,
        )
    )

    training_args = Seq2SeqTrainingArguments(output_dir="dummy_dir")
    tokenizer_module = load_tokenizer(model_args)
    tokenizer = tokenizer_module["tokenizer"]
    template_obj = get_template_and_fix_tokenizer(tokenizer, data_args)
    template_obj.mm_plugin.expand_mm_tokens = False  # for vllm generate

    engine_args = {
        "model": model_args.model_name_or_path,
        "trust_remote_code": True,
        "dtype": model_args.infer_dtype,
        "max_model_len": cutoff_len + max_new_tokens,
        "tensor_parallel_size": (get_device_count() // pipeline_parallel_size) or 1,
        "pipeline_parallel_size": pipeline_parallel_size,
        "disable_log_stats": True,
        "enable_lora": model_args.adapter_name_or_path is not None,
    }
    if template_obj.mm_plugin.__class__.__name__ != "BasePlugin":
        engine_args["limit_mm_per_prompt"] = {"image": 4, "video": 2, "audio": 2}

    if isinstance(model_args.vllm_config, dict):
        engine_args.update(model_args.vllm_config)

    model_preparation_start_time = time.time()
    llm = LLM(**engine_args)

    # load datasets
    dataset_module = get_dataset(template_obj, model_args, data_args, training_args, "ppo", **tokenizer_module)
    train_dataset = dataset_module["train_dataset"]

    sampling_params = SamplingParams(
        repetition_penalty=generating_args.repetition_penalty or 1.0,  # repetition_penalty must > 0
        temperature=generating_args.temperature,
        top_p=generating_args.top_p or 1.0,  # top_p must > 0
        top_k=generating_args.top_k or -1,  # top_k must > 0
        stop_token_ids=template_obj.get_stop_token_ids(tokenizer),
        max_tokens=generating_args.max_new_tokens,
        skip_special_tokens=skip_special_tokens,
        seed=seed,
    )
    if model_args.adapter_name_or_path is not None:
        lora_request = LoRARequest("default", 1, model_args.adapter_name_or_path[0])
    else:
        lora_request = None

    # Store all results in these lists
    all_prompts, all_preds, all_labels = [], [], []
    need_video_kwargs = _need_video_kwargs(template)

    model_predict_start_time = time.time()
    # Add batch process to avoid the issue of too many files opened
    for i in tqdm(range(0, len(train_dataset), batch_size), desc="Processing batched inference"):
        vllm_inputs, prompts, labels = [], [], []
        batch = train_dataset[i : min(i + batch_size, len(train_dataset))]

        for j in range(len(batch["input_ids"])):
            if batch["images"][j] is not None:
                image = batch["images"][j]
                multi_modal_data = {
                    "image": template_obj.mm_plugin._regularize_images(
                        image, image_max_pixels=image_max_pixels, image_min_pixels=image_min_pixels
                    )["images"]
                }
            elif batch["videos"][j] is not None:
                video_metadata, video_metadata_kwargs = None, None
                video = batch["videos"][j]
                multi_modal_data = {
                    "video": template_obj.mm_plugin._regularize_videos(
                        video,
                        image_max_pixels=image_max_pixels,
                        image_min_pixels=image_min_pixels,
                        video_fps=video_fps,
                        video_maxlen=video_maxlen,
                    )["videos"]
                }
                if need_video_kwargs:
                    container = av.open(video[0], "r")
                    video_stream = next(stream for stream in container.streams if stream.type == "video")
                    sampling_indices = template_obj.mm_plugin._get_video_sample_indices(
                        video_stream, video_fps, video_maxlen
                    )
                    total_frames = video_stream.frames
                    video_metadata_kwargs = {
                        "fps": getattr(tokenizer_module["processor"], "video_fps", 24.0),
                        "do_sample_frames": False,
                        "total_num_frames": total_frames,
                    }
                    video_metadata = dict(
                        fps=video_fps,
                        frames_indices=sampling_indices,
                        total_num_frames=total_frames,
                        video_backend="opencv",
                    )
                    multi_modal_data["video"] = (multi_modal_data["video"], video_metadata)
            elif batch["audios"][j] is not None:
                audio = batch["audios"][j]
                audio_data = template_obj.mm_plugin._regularize_audios(
                    audio,
                    sampling_rate=16000,
                )
                multi_modal_data = {"audio": zip(audio_data["audios"], audio_data["sampling_rates"])}
            else:
                multi_modal_data = None

            vllm_input_data = {"prompt_token_ids": batch["input_ids"][j], "multi_modal_data": multi_modal_data}
            if "video_metadata_kwargs" in locals() and video_metadata_kwargs is not None:
                vllm_input_data["mm_processor_kwargs"] = video_metadata_kwargs

            vllm_inputs.append(vllm_input_data)
            prompts.append(tokenizer.decode(batch["input_ids"][j], skip_special_tokens=skip_special_tokens))
            labels.append(
                tokenizer.decode(
                    list(filter(lambda x: x != IGNORE_INDEX, batch["labels"][j])),
                    skip_special_tokens=skip_special_tokens,
                )
            )

        results = llm.generate(vllm_inputs, sampling_params, lora_request=lora_request)
        preds = [result.outputs[0].text for result in results]

        # Accumulate results
        all_prompts.extend(prompts)
        all_preds.extend(preds)
        all_labels.extend(labels)
        gc.collect()

    model_predict_end_time = time.time()
    # Write all results at once outside the loop
    with open(save_name, "w", encoding="utf-8") as f:
        for text, pred, label in zip(all_prompts, all_preds, all_labels):
            f.write(json.dumps({"prompt": text, "predict": pred, "label": label}, ensure_ascii=False) + "\n")

    print("*" * 70)
    print(f"{len(all_prompts)} total generated results have been saved at {save_name}.")
    print("*" * 70)

    # Write all matrix results when matrix_save_name is not None,
    # The result matrix is referencing src.llamafactory.train.sft.workflow.run_sft # 127~132
    # trainer.save_metrics("predict", predict_results.metrics)
    #
    #   {
    #        "predict_bleu-4": 4.349975,
    #        "predict_model_preparation_time": 0.0128,
    #        "predict_rouge-1": 21.873359375,
    #        "predict_rouge-2": 4.144340625,
    #        "predict_rouge-l": 10.83949375,
    #        "predict_runtime": 131.664,
    #        "predict_samples_per_second": 0.076,
    #        "predict_steps_per_second": 0.008
    #    }
    #
    if matrix_save_name is not None:
        predict_time = model_predict_end_time - model_predict_start_time
        preparation_time = model_predict_start_time - model_preparation_start_time

        start_time = time.time()
        dataset = load_dataset("json", data_files=save_name, split="train")
        dataset = dataset.map(compute_metrics, num_proc=8, remove_columns=dataset.column_names)
        score_dict = dataset.to_dict()

        average_score = {}
        for task, scores in sorted(score_dict.items(), key=lambda x: x[0]):
            score = sum(scores) / len(scores) if scores else 0.0
            print(f"predict_{task}: {score:.4f}")
            average_score["predict_" + task] = score

        average_score["predict_model_preparation_time"] = preparation_time
        average_score["predict_runtime"] = predict_time
        num_steps = len(range(0, len(train_dataset), batch_size))
        average_score["predict_samples_per_second"] = len(dataset) / predict_time if predict_time > 0 else 0.0
        average_score["predict_steps_per_second"] = num_steps / predict_time if predict_time > 0 else 0.0

        with open(matrix_save_name, "w", encoding="utf-8") as f:
            json.dump(average_score, f, indent=4)

        print("*" * 70)
        print(f"\nDone in {time.time() - start_time:.3f}s.\nScore file saved to {matrix_save_name}.")
        print("*" * 70)


if __name__ == "__main__":
    fire.Fire(vllm_infer)


--- scripts/stat_utils/cal_flops.py ---
# Copyright 2025 Microsoft Corporation and the LlamaFactory team.
#
# This code is inspired by the Microsoft's DeepSpeed library.
# https://www.deepspeed.ai/tutorials/flops-profiler/
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import fire
import torch
from deepspeed.accelerator import get_accelerator  # type: ignore
from deepspeed.profiling.flops_profiler import get_model_profile  # type: ignore

from llamafactory.chat import ChatModel


def calculate_flops(
    model_name_or_path: str,
    batch_size: int = 1,
    seq_length: int = 512,
    flash_attn: str = "auto",
):
    r"""Calculate the flops of pre-trained models.

    Usage: python cal_flops.py --model_name_or_path path_to_model --batch_size 1 --seq_length 512
    """
    with get_accelerator().device(0):
        chat_model = ChatModel(dict(model_name_or_path=model_name_or_path, template="empty", flash_attn=flash_attn))
        fake_input = torch.ones((batch_size, seq_length), dtype=torch.long, device=chat_model.engine.model.device)
        input_dict = {"input_ids": fake_input, "labels": fake_input.clone()}
        flops, macs, params = get_model_profile(
            chat_model.engine.model, kwargs=input_dict, print_profile=True, detailed=True
        )
        print("FLOPs:", flops)
        print("MACs:", macs)
        print("Params:", params)


if __name__ == "__main__":
    fire.Fire(calculate_flops)


--- scripts/stat_utils/cal_lr.py ---
# Copyright 2025 imoneoi and the LlamaFactory team.
#
# This code is inspired by the imoneoi's OpenChat library.
# https://github.com/imoneoi/openchat/blob/3.6.0/ochat/training_deepspeed/train.py
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import math
from typing import Literal

import fire
import torch
from torch.utils.data import DataLoader
from tqdm import tqdm
from transformers import DataCollatorForLanguageModeling

from llamafactory.data import MultiModalDataCollatorForSeq2Seq, get_dataset, get_template_and_fix_tokenizer
from llamafactory.extras.constants import IGNORE_INDEX
from llamafactory.hparams import get_train_args
from llamafactory.model import load_tokenizer


BASE_LR = 3e-4  # 1.5e-4 for 30B-70B models
BASE_BS = 4_000_000  # from llama paper


def calculate_lr(
    model_name_or_path: str,
    batch_size: int,  # total batch size, namely (batch size * gradient accumulation * world size)
    stage: Literal["pt", "sft"] = "sft",
    dataset: str = "alpaca_en_demo",
    dataset_dir: str = "data",
    template: str = "default",
    cutoff_len: int = 2048,  # i.e. maximum input length during training
    is_mistral_or_gemma: bool = False,  # mistral and gemma models opt for a smaller learning rate,
    packing: bool = False,
):
    r"""Calculate the optimal learning rate for 7B/13B models using LLaMA's hyper-parameters.

    Usage:
    python cal_lr.py --model_name_or_path path_to_model --dataset alpaca_en_demo --cutoff_len 1024 --batch_size 16
    """
    model_args, data_args, training_args, _, _ = get_train_args(
        dict(
            stage=stage,
            model_name_or_path=model_name_or_path,
            dataset=dataset,
            dataset_dir=dataset_dir,
            template=template,
            cutoff_len=cutoff_len,
            packing=packing,
            preprocessing_num_workers=16,
            output_dir="dummy_dir",
            overwrite_cache=True,
            do_train=True,
        )
    )
    tokenizer_module = load_tokenizer(model_args)
    tokenizer = tokenizer_module["tokenizer"]
    template = get_template_and_fix_tokenizer(tokenizer, data_args)
    trainset = get_dataset(template, model_args, data_args, training_args, stage, **tokenizer_module)["train_dataset"]
    if stage == "pt":
        data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)
    elif stage == "sft":
        data_collator = MultiModalDataCollatorForSeq2Seq(
            template=template, tokenizer=tokenizer, label_pad_token_id=IGNORE_INDEX
        )
    else:
        raise NotImplementedError(f"Stage does not supported: {stage}.")

    dataloader = DataLoader(trainset, batch_size, shuffle=False, collate_fn=data_collator, pin_memory=True)
    valid_tokens, total_tokens = 0, 0
    for batch in tqdm(dataloader, desc="Collecting valid tokens"):
        valid_tokens += torch.sum(batch["labels"] != IGNORE_INDEX).item()
        total_tokens += torch.numel(batch["labels"])

    valid_ratio = valid_tokens / total_tokens
    token_batch_size = cutoff_len * batch_size * valid_ratio
    lr = BASE_LR * math.sqrt(token_batch_size / BASE_BS)  # lr ~ sqrt(batch_size)
    lr = lr / 6.0 if is_mistral_or_gemma else lr
    print(
        f"Optimal learning rate is {lr:.2e} for valid ratio% {valid_ratio * 100:.2f} "
        f"and effective token batch size {token_batch_size:.2f}"
    )


if __name__ == "__main__":
    fire.Fire(calculate_lr)


--- src/train.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from llamafactory.train.tuner import run_exp


def main():
    run_exp()


def _mp_fn(index):
    # For xla_spawn (TPUs)
    run_exp()


if __name__ == "__main__":
    main()


--- src/webui.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

from llamafactory.extras.misc import fix_proxy, is_env_enabled
from llamafactory.webui.interface import create_ui


def main():
    gradio_ipv6 = is_env_enabled("GRADIO_IPV6")
    gradio_share = is_env_enabled("GRADIO_SHARE")
    server_name = os.getenv("GRADIO_SERVER_NAME", "[::]" if gradio_ipv6 else "0.0.0.0")
    print("Visit http://ip:port for Web UI, e.g., http://127.0.0.1:7860")
    fix_proxy(ipv6_enabled=gradio_ipv6)
    create_ui().queue().launch(share=gradio_share, server_name=server_name, inbrowser=True)


if __name__ == "__main__":
    main()


--- src/llamafactory/cli.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


def main():
    from .extras.misc import is_env_enabled

    if is_env_enabled("USE_V1"):
        from .v1 import launcher
    else:
        from . import launcher

    launcher.launch()


if __name__ == "__main__":
    from multiprocessing import freeze_support

    freeze_support()
    main()


--- src/llamafactory/__init__.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

r"""Efficient fine-tuning of large language models.

Level:
  api, webui > chat, eval, train > data, model > hparams > extras

Disable version checking: DISABLE_VERSION_CHECK=1
Enable VRAM recording: RECORD_VRAM=1
Force using torchrun: FORCE_TORCHRUN=1
Set logging verbosity: LLAMAFACTORY_VERBOSITY=WARN
Use modelscope: USE_MODELSCOPE_HUB=1
Use openmind: USE_OPENMIND_HUB=1
"""

from .extras.env import VERSION


__version__ = VERSION


--- src/llamafactory/launcher.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import subprocess
import sys
from copy import deepcopy


USAGE = (
    "-" * 70
    + "\n"
    + "| Usage:                                                             |\n"
    + "|   llamafactory-cli api -h: launch an OpenAI-style API server       |\n"
    + "|   llamafactory-cli chat -h: launch a chat interface in CLI         |\n"
    + "|   llamafactory-cli export -h: merge LoRA adapters and export model |\n"
    + "|   llamafactory-cli train -h: train models                          |\n"
    + "|   llamafactory-cli webchat -h: launch a chat interface in Web UI   |\n"
    + "|   llamafactory-cli webui: launch LlamaBoard                        |\n"
    + "|   llamafactory-cli env: show environment info                      |\n"
    + "|   llamafactory-cli version: show version info                      |\n"
    + "| Hint: You can use `lmf` as a shortcut for `llamafactory-cli`.      |\n"
    + "-" * 70
)


def launch():
    from .extras import logging
    from .extras.env import VERSION, print_env
    from .extras.misc import find_available_port, get_device_count, is_env_enabled, use_kt, use_ray

    logger = logging.get_logger(__name__)
    WELCOME = (
        "-" * 58
        + "\n"
        + f"| Welcome to LLaMA Factory, version {VERSION}"
        + " " * (21 - len(VERSION))
        + "|\n|"
        + " " * 56
        + "|\n"
        + "| Project page: https://github.com/hiyouga/LLaMA-Factory |\n"
        + "-" * 58
    )

    command = sys.argv.pop(1) if len(sys.argv) > 1 else "help"
    if is_env_enabled("USE_MCA"):  # force use torchrun
        os.environ["FORCE_TORCHRUN"] = "1"

    if command == "train" and (
        is_env_enabled("FORCE_TORCHRUN") or (get_device_count() > 1 and not use_ray() and not use_kt())
    ):
        # launch distributed training
        nnodes = os.getenv("NNODES", "1")
        node_rank = os.getenv("NODE_RANK", "0")
        nproc_per_node = os.getenv("NPROC_PER_NODE", str(get_device_count()))
        master_addr = os.getenv("MASTER_ADDR", "127.0.0.1")
        master_port = os.getenv("MASTER_PORT", str(find_available_port()))
        logger.info_rank0(f"Initializing {nproc_per_node} distributed tasks at: {master_addr}:{master_port}")
        if int(nnodes) > 1:
            logger.info_rank0(f"Multi-node training enabled: num nodes: {nnodes}, node rank: {node_rank}")

        # elastic launch support
        max_restarts = os.getenv("MAX_RESTARTS", "0")
        rdzv_id = os.getenv("RDZV_ID")
        min_nnodes = os.getenv("MIN_NNODES")
        max_nnodes = os.getenv("MAX_NNODES")

        env = deepcopy(os.environ)
        if is_env_enabled("OPTIM_TORCH", "1"):
            # optimize DDP, see https://zhuanlan.zhihu.com/p/671834539
            env["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
            env["TORCH_NCCL_AVOID_RECORD_STREAMS"] = "1"

        if rdzv_id is not None:
            # launch elastic job with fault tolerant support when possible
            # see also https://docs.pytorch.org/docs/stable/elastic/train_script.html
            rdzv_nnodes = nnodes
            # elastic number of nodes if MIN_NNODES and MAX_NNODES are set
            if min_nnodes is not None and max_nnodes is not None:
                rdzv_nnodes = f"{min_nnodes}:{max_nnodes}"

            process = subprocess.run(
                (
                    "torchrun --nnodes {rdzv_nnodes} --nproc-per-node {nproc_per_node} "
                    "--rdzv-id {rdzv_id} --rdzv-backend c10d --rdzv-endpoint {master_addr}:{master_port} "
                    "--max-restarts {max_restarts} {file_name} {args}"
                )
                .format(
                    rdzv_nnodes=rdzv_nnodes,
                    nproc_per_node=nproc_per_node,
                    rdzv_id=rdzv_id,
                    master_addr=master_addr,
                    master_port=master_port,
                    max_restarts=max_restarts,
                    file_name=__file__,
                    args=" ".join(sys.argv[1:]),
                )
                .split(),
                env=env,
                check=True,
            )
        else:
            # NOTE: DO NOT USE shell=True to avoid security risk
            process = subprocess.run(
                (
                    "torchrun --nnodes {nnodes} --node_rank {node_rank} --nproc_per_node {nproc_per_node} "
                    "--master_addr {master_addr} --master_port {master_port} {file_name} {args}"
                )
                .format(
                    nnodes=nnodes,
                    node_rank=node_rank,
                    nproc_per_node=nproc_per_node,
                    master_addr=master_addr,
                    master_port=master_port,
                    file_name=__file__,
                    args=" ".join(sys.argv[1:]),
                )
                .split(),
                env=env,
                check=True,
            )

        sys.exit(process.returncode)

    elif command == "api":
        from .api.app import run_api

        run_api()

    elif command == "chat":
        from .chat.chat_model import run_chat

        run_chat()

    elif command == "eval":
        raise NotImplementedError("Evaluation will be deprecated in the future.")

    elif command == "export":
        from .train.tuner import export_model

        export_model()

    elif command == "train":
        from .train.tuner import run_exp

        run_exp()

    elif command == "webchat":
        from .webui.interface import run_web_demo

        run_web_demo()

    elif command == "webui":
        from .webui.interface import run_web_ui

        run_web_ui()

    elif command == "env":
        print_env()

    elif command == "version":
        print(WELCOME)

    elif command == "help":
        print(USAGE)

    else:
        print(f"Unknown command: {command}.\n{USAGE}")


if __name__ == "__main__":
    from llamafactory.train.tuner import run_exp  # use absolute import

    run_exp()


--- src/llamafactory/model/adapter.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re
from typing import TYPE_CHECKING

import torch
from peft import LoraConfig, LoraModel, OFTConfig, PeftModel, TaskType, get_peft_model
from transformers.integrations import is_deepspeed_zero3_enabled

from ..extras import logging
from ..extras.constants import EngineName
from .model_utils.ktransformers import get_kt_peft_model, load_kt_peft_model
from .model_utils.misc import find_all_linear_modules, find_expanded_modules
from .model_utils.quantization import QuantizationMethod
from .model_utils.unsloth import get_unsloth_peft_model, load_unsloth_peft_model
from .model_utils.visual import COMPOSITE_MODELS, get_forbidden_modules, patch_target_modules


if TYPE_CHECKING:
    from transformers import PretrainedConfig, PreTrainedModel

    from ..hparams import FinetuningArguments, ModelArguments


logger = logging.get_logger(__name__)


def _setup_full_tuning(
    model: "PreTrainedModel",
    finetuning_args: "FinetuningArguments",
    is_trainable: bool,
    cast_trainable_params_to_fp32: bool,
) -> None:
    if not is_trainable:
        return

    logger.info_rank0("Fine-tuning method: Full")
    forbidden_modules = get_forbidden_modules(model.config, finetuning_args)
    for name, param in model.named_parameters():
        if not any(forbidden_module in name for forbidden_module in forbidden_modules):
            if cast_trainable_params_to_fp32:
                param.data = param.data.to(torch.float32)
        else:
            param.requires_grad_(False)


def _setup_freeze_tuning(
    model: "PreTrainedModel",
    finetuning_args: "FinetuningArguments",
    is_trainable: bool,
    cast_trainable_params_to_fp32: bool,
) -> None:
    if not is_trainable:
        return

    logger.info_rank0("Fine-tuning method: Freeze")
    if hasattr(model.config, "text_config"):  # composite models
        config = getattr(model.config, "text_config")
    else:
        config = model.config

    num_layers = (
        getattr(config, "num_hidden_layers", None)
        or getattr(config, "num_layers", None)
        or getattr(config, "n_layer", None)
    )
    if not num_layers:
        raise ValueError("Current model does not support freeze tuning.")

    if finetuning_args.use_llama_pro:
        if num_layers % finetuning_args.freeze_trainable_layers != 0:
            raise ValueError(
                f"`num_layers` {num_layers} should be "
                f"divisible by `num_layer_trainable` {finetuning_args.freeze_trainable_layers}."
            )

        stride = num_layers // finetuning_args.freeze_trainable_layers
        trainable_layer_ids = range(stride - 1, num_layers + stride - 1, stride)
    elif finetuning_args.freeze_trainable_layers > 0:  # fine-tuning the last n layers if num_layer_trainable > 0
        trainable_layer_ids = range(max(0, num_layers - finetuning_args.freeze_trainable_layers), num_layers)
    else:  # fine-tuning the first n layers if num_layer_trainable < 0
        trainable_layer_ids = range(min(-finetuning_args.freeze_trainable_layers, num_layers))

    hidden_modules = set()
    non_hidden_modules = set()
    for name, _ in model.named_parameters():
        if ".0." in name:
            hidden_modules.add(name.split(".0.")[-1].split(".")[0])
        elif ".1." in name:  # MoD starts from layer 1
            hidden_modules.add(name.split(".1.")[-1].split(".")[0])

        if re.search(r"\.\d+\.", name) is None:
            non_hidden_modules.add(name.split(".")[-2])  # remove weight/bias

    trainable_layers = []
    for module_name in finetuning_args.freeze_trainable_modules:
        if module_name != "all" and module_name not in hidden_modules:
            raise ValueError(
                "Module {} is not found, please choose from {}".format(module_name, ", ".join(hidden_modules))
            )

        for idx in trainable_layer_ids:
            trainable_layers.append(".{:d}.{}".format(idx, module_name if module_name != "all" else ""))

    if finetuning_args.freeze_extra_modules:
        for module_name in finetuning_args.freeze_extra_modules:
            if module_name not in non_hidden_modules:
                raise ValueError(
                    "Module {} is not found, please choose from {}".format(module_name, ", ".join(non_hidden_modules))
                )

            trainable_layers.append(module_name)

    model_type = getattr(model.config, "model_type", None)
    if not finetuning_args.freeze_multi_modal_projector and model_type in COMPOSITE_MODELS:
        trainable_layers.append(COMPOSITE_MODELS[model_type].projector_key)

    forbidden_modules = get_forbidden_modules(model.config, finetuning_args)
    for name, param in model.named_parameters():
        if any(trainable_layer in name for trainable_layer in trainable_layers) and not any(
            forbidden_module in name for forbidden_module in forbidden_modules
        ):
            if cast_trainable_params_to_fp32:
                param.data = param.data.to(torch.float32)
        else:
            param.requires_grad_(False)

    logger.info_rank0("Set trainable layers: {}".format(",".join(trainable_layers)))


def _setup_lora_tuning(
    config: "PretrainedConfig",
    model: "PreTrainedModel",
    model_args: "ModelArguments",
    finetuning_args: "FinetuningArguments",
    is_trainable: bool,
    cast_trainable_params_to_fp32: bool,
) -> "PeftModel":
    if is_trainable:
        if finetuning_args.finetuning_type == "oft":
            logger.info_rank0("Fine-tuning method: OFT")
        else:
            logger.info_rank0("Fine-tuning method: {}".format("DoRA" if finetuning_args.use_dora else "LoRA"))

    adapter_to_resume = None

    if model_args.adapter_name_or_path is not None:
        is_mergeable = True
        if getattr(model, "quantization_method", None):  # merge lora in quantized model is unstable
            assert len(model_args.adapter_name_or_path) == 1, "Quantized model only accepts a single adapter."
            is_mergeable = False

        if is_deepspeed_zero3_enabled():
            assert len(model_args.adapter_name_or_path) == 1, "Cannot use multiple adapters in DeepSpeed ZeRO-3."
            is_mergeable = False

        if model_args.use_kt:
            assert len(model_args.adapter_name_or_path) == 1, "KTransformers model only accepts a single adapter"
            is_mergeable = False

        if model_args.use_unsloth:
            assert len(model_args.adapter_name_or_path) == 1, "Unsloth model only accepts a single adapter."
            is_mergeable = False

        if (is_trainable and not finetuning_args.create_new_adapter) or (not is_mergeable):
            adapter_to_merge = model_args.adapter_name_or_path[:-1]
            adapter_to_resume = model_args.adapter_name_or_path[-1]
        else:
            adapter_to_merge = model_args.adapter_name_or_path

        init_kwargs = {
            "subfolder": model_args.adapter_folder,
            "offload_folder": model_args.offload_folder,
            "cache_dir": model_args.cache_dir,
            "revision": model_args.model_revision,
            "token": model_args.hf_hub_token,
        }

        if model_args.use_kt:
            if model_args.infer_backend != EngineName.KT:
                raise ValueError(
                    "We should use ktransformers as backend to infer the adapter fine-tuned by ktransformers."
                )

        for adapter in adapter_to_merge:
            model: LoraModel = PeftModel.from_pretrained(model, adapter, **init_kwargs)
            model = model.merge_and_unload()

        if len(adapter_to_merge) > 0:
            logger.info_rank0(f"Merged {len(adapter_to_merge)} adapter(s).")

        if adapter_to_resume is not None:  # resume lora training
            if model_args.use_kt:
                model = load_kt_peft_model(model_args, model)
            elif model_args.use_unsloth:
                model = load_unsloth_peft_model(config, model_args, finetuning_args, is_trainable=is_trainable)
            else:
                model = PeftModel.from_pretrained(model, adapter_to_resume, is_trainable=is_trainable, **init_kwargs)

        logger.info_rank0("Loaded adapter(s): {}".format(",".join(model_args.adapter_name_or_path)))

    if is_trainable and adapter_to_resume is None:  # create new lora weights while training
        if len(finetuning_args.lora_target) == 1 and finetuning_args.lora_target[0] == "all":
            target_modules = find_all_linear_modules(model, finetuning_args.freeze_vision_tower)
        else:
            target_modules = finetuning_args.lora_target

        if model_args.use_kt:
            new_list = []
            for m in target_modules:
                if m in ("down_proj", "up_proj", "gate_proj"):
                    new_list.extend([f"mlp.{m}", f"shared_experts.{m}"])
                elif m not in ("generate_linear", "orig_module", "prefill_linear"):
                    new_list.append(m)

            target_modules[:] = new_list

        if finetuning_args.use_llama_pro:
            target_modules = find_expanded_modules(model, target_modules, finetuning_args.freeze_trainable_layers)

        target_modules = patch_target_modules(model, finetuning_args, target_modules)

        if (
            finetuning_args.use_dora
            and getattr(model, "quantization_method", None) is not None
            and getattr(model, "quantization_method", None) != QuantizationMethod.BNB
        ):
            raise ValueError("DoRA is not compatible with PTQ-quantized models.")

        if model_args.resize_vocab and finetuning_args.additional_target is None:
            input_embeddings = model.get_input_embeddings()
            output_embeddings = model.get_output_embeddings()
            module_names = set()
            for name, module in model.named_modules():
                if module in [input_embeddings, output_embeddings]:
                    module_names.add(name.split(".")[-1])

            finetuning_args.additional_target = module_names
            logger.warning_rank0("Vocab has been resized, add {} to trainable params.".format(",".join(module_names)))

        if finetuning_args.finetuning_type == "lora":
            peft_kwargs = {
                "r": finetuning_args.lora_rank,
                "target_modules": target_modules,
                "lora_alpha": finetuning_args.lora_alpha,
                "lora_dropout": finetuning_args.lora_dropout,
                "use_rslora": finetuning_args.use_rslora,
                "use_dora": finetuning_args.use_dora,
                "modules_to_save": finetuning_args.additional_target,
            }
        elif finetuning_args.finetuning_type == "oft":
            peft_kwargs = {
                "r": finetuning_args.oft_rank,
                "oft_block_size": finetuning_args.oft_block_size,
                "target_modules": target_modules,
                "module_dropout": finetuning_args.module_dropout,
                "modules_to_save": finetuning_args.additional_target,
            }

        if model_args.use_kt:
            if finetuning_args.finetuning_type == "oft":
                raise ValueError("KTransformers is currently not supported for OFT.")
            if finetuning_args.finetuning_type == "lora":
                peft_config = LoraConfig(
                    task_type=TaskType.CAUSAL_LM,
                    inference_mode=False,
                    **peft_kwargs,
                )
            else:
                raise ValueError("KTransformers is currently only supported for LoRA.")

            model = get_kt_peft_model(model, peft_config)
            print(f"KT_model:{model}")
        elif model_args.use_unsloth:
            if finetuning_args.finetuning_type == "oft":
                raise ValueError("Unsloth is currently not supported for OFT.")

            model = get_unsloth_peft_model(model, model_args, peft_kwargs)
        else:
            if finetuning_args.pissa_init:
                if finetuning_args.pissa_iter == -1:
                    logger.info_rank0("Using PiSSA initialization.")
                    peft_kwargs["init_lora_weights"] = "pissa"
                else:
                    logger.info_rank0(f"Using PiSSA initialization with FSVD steps {finetuning_args.pissa_iter}.")
                    peft_kwargs["init_lora_weights"] = f"pissa_niter_{finetuning_args.pissa_iter}"

            if finetuning_args.finetuning_type == "lora":
                peft_config = LoraConfig(
                    task_type=TaskType.CAUSAL_LM,
                    inference_mode=False,
                    **peft_kwargs,
                )
            elif finetuning_args.finetuning_type == "oft":
                peft_config = OFTConfig(
                    task_type=TaskType.CAUSAL_LM,
                    inference_mode=False,
                    **peft_kwargs,
                )
            model = get_peft_model(model, peft_config)

    if is_trainable and cast_trainable_params_to_fp32:
        for param in filter(lambda p: p.requires_grad, model.parameters()):
            param.data = param.data.to(torch.float32)

    return model


def init_adapter(
    config: "PretrainedConfig",
    model: "PreTrainedModel",
    model_args: "ModelArguments",
    finetuning_args: "FinetuningArguments",
    is_trainable: bool,
) -> "PreTrainedModel":
    r"""Initialize the adapters.

    Support full-parameter, freeze and LoRA training.

    Note that the trainable parameters must be cast to float32.
    """
    if is_trainable and getattr(model, "quantization_method", None) is not None:
        if finetuning_args.finetuning_type not in ["lora", "oft"]:
            raise ValueError("Quantized models can only be used for the LoRA or OFT tuning.")

        if finetuning_args.pissa_init:
            raise ValueError("Cannot initialize PiSSA adapter on quantized models.")

    # cast trainable parameters to float32 if:
    # 1. is_trainable and not pure_bf16 and not badam and quantization_bit is not None (qlora)
    # 2. is_trainable and not pure_bf16 and not badam and not zero3 (zero3 already in fp32)
    cast_trainable_params_to_fp32 = False
    if not is_trainable:
        pass
    elif finetuning_args.pure_bf16 or finetuning_args.use_badam:
        logger.info_rank0("Pure bf16 / BAdam detected, remaining trainable params in half precision.")
    elif model_args.quantization_bit is None and is_deepspeed_zero3_enabled():
        logger.info_rank0("DeepSpeed ZeRO3 detected, remaining trainable params in float32.")
    else:
        logger.info_rank0("Upcasting trainable params to float32.")
        cast_trainable_params_to_fp32 = True

    if finetuning_args.finetuning_type == "full":
        _setup_full_tuning(model, finetuning_args, is_trainable, cast_trainable_params_to_fp32)
    elif finetuning_args.finetuning_type == "freeze":
        _setup_freeze_tuning(model, finetuning_args, is_trainable, cast_trainable_params_to_fp32)
    elif finetuning_args.finetuning_type in ["lora", "oft"]:
        model = _setup_lora_tuning(
            config, model, model_args, finetuning_args, is_trainable, cast_trainable_params_to_fp32
        )
    else:
        raise NotImplementedError(f"Unknown finetuning type: {finetuning_args.finetuning_type}.")

    return model


--- src/llamafactory/chat/base_engine.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from abc import ABC, abstractmethod
from collections.abc import AsyncGenerator
from dataclasses import dataclass
from typing import TYPE_CHECKING, Any, Literal, Optional, Union


if TYPE_CHECKING:
    from transformers import PreTrainedModel, PreTrainedTokenizer
    from vllm import AsyncLLMEngine

    from ..data import Template
    from ..data.mm_plugin import AudioInput, ImageInput, VideoInput
    from ..extras.constants import EngineName
    from ..hparams import DataArguments, FinetuningArguments, GeneratingArguments, ModelArguments


@dataclass
class Response:
    response_text: str
    response_length: int
    prompt_length: int
    finish_reason: Literal["stop", "length"]


class BaseEngine(ABC):
    r"""Base class for inference engine of chat models.

    Must implements async methods: chat(), stream_chat() and get_scores().
    """

    name: "EngineName"
    model: Union["PreTrainedModel", "AsyncLLMEngine"]
    tokenizer: "PreTrainedTokenizer"
    can_generate: bool
    template: "Template"
    generating_args: dict[str, Any]

    @abstractmethod
    def __init__(
        self,
        model_args: "ModelArguments",
        data_args: "DataArguments",
        finetuning_args: "FinetuningArguments",
        generating_args: "GeneratingArguments",
    ) -> None:
        r"""Initialize an inference engine."""
        ...

    @abstractmethod
    async def chat(
        self,
        messages: list[dict[str, str]],
        system: Optional[str] = None,
        tools: Optional[str] = None,
        images: Optional[list["ImageInput"]] = None,
        videos: Optional[list["VideoInput"]] = None,
        audios: Optional[list["AudioInput"]] = None,
        **input_kwargs,
    ) -> list["Response"]:
        r"""Get a list of responses of the chat model."""
        ...

    @abstractmethod
    async def stream_chat(
        self,
        messages: list[dict[str, str]],
        system: Optional[str] = None,
        tools: Optional[str] = None,
        images: Optional[list["ImageInput"]] = None,
        videos: Optional[list["VideoInput"]] = None,
        audios: Optional[list["AudioInput"]] = None,
        **input_kwargs,
    ) -> AsyncGenerator[str, None]:
        r"""Get the response token-by-token of the chat model."""
        ...

    @abstractmethod
    async def get_scores(
        self,
        batch_input: list[str],
        **input_kwargs,
    ) -> list[float]:
        r"""Get a list of scores of the reward model."""
        ...


--- src/llamafactory/train/callbacks.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
import os
import signal
import sys
import time
from concurrent.futures import ThreadPoolExecutor
from datetime import timedelta
from typing import TYPE_CHECKING, Any, Optional

import torch
import transformers
from peft import PeftModel
from transformers import PreTrainedModel, ProcessorMixin, TrainerCallback
from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR, has_length
from transformers.utils import SAFE_WEIGHTS_NAME, WEIGHTS_NAME
from typing_extensions import override

from ..extras import logging
from ..extras.constants import TRAINER_LOG, V_HEAD_SAFE_WEIGHTS_NAME, V_HEAD_WEIGHTS_NAME
from ..extras.misc import get_peak_memory, is_env_enabled, use_ray
from ..extras.packages import is_safetensors_available


if is_safetensors_available():
    from safetensors import safe_open
    from safetensors.torch import save_file


if TYPE_CHECKING:
    from transformers import TrainerControl, TrainerState, TrainingArguments
    from trl import AutoModelForCausalLMWithValueHead

    from ..hparams import DataArguments, FinetuningArguments, GeneratingArguments, ModelArguments


logger = logging.get_logger(__name__)


def fix_valuehead_checkpoint(
    model: "AutoModelForCausalLMWithValueHead", output_dir: str, safe_serialization: bool
) -> None:
    r"""Fix the valuehead checkpoint files.

    The model is already unwrapped.

    There are three cases:
    1. full tuning without ds_zero3: state_dict = {"model.layers.*": ..., "v_head.summary.*": ...}
    2. lora tuning without ds_zero3: state_dict = {"v_head.summary.*": ...}
    3. under deepspeed zero3: state_dict = {"pretrained_model.model.layers.*": ..., "v_head.summary.*": ...}

    We assume `stage3_gather_16bit_weights_on_model_save=true`.
    """
    if not isinstance(model.pretrained_model, (PreTrainedModel, PeftModel)):
        return

    if safe_serialization:
        path_to_checkpoint = os.path.join(output_dir, SAFE_WEIGHTS_NAME)
        with safe_open(path_to_checkpoint, framework="pt", device="cpu") as f:
            state_dict: dict[str, torch.Tensor] = {key: f.get_tensor(key).clone() for key in f.keys()}
    else:
        path_to_checkpoint = os.path.join(output_dir, WEIGHTS_NAME)
        state_dict: dict[str, torch.Tensor] = torch.load(path_to_checkpoint, map_location="cpu", weights_only=True)

    os.remove(path_to_checkpoint)
    decoder_state_dict, v_head_state_dict = {}, {}
    for name, param in state_dict.items():
        if name.startswith("v_head."):
            v_head_state_dict[name] = param
        else:
            decoder_state_dict[name.replace("pretrained_model.", "", 1)] = param

    model.pretrained_model.save_pretrained(
        output_dir, state_dict=decoder_state_dict or None, safe_serialization=safe_serialization
    )

    if safe_serialization:
        save_file(v_head_state_dict, os.path.join(output_dir, V_HEAD_SAFE_WEIGHTS_NAME), metadata={"format": "pt"})
    else:
        torch.save(v_head_state_dict, os.path.join(output_dir, V_HEAD_WEIGHTS_NAME))

    logger.info_rank0(f"Value head model saved at: {output_dir}")


class FixValueHeadModelCallback(TrainerCallback):
    r"""A callback for fixing the checkpoint for valuehead models."""

    @override
    def on_save(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if args.should_save:
            output_dir = os.path.join(args.output_dir, f"{PREFIX_CHECKPOINT_DIR}-{state.global_step}")
            fix_valuehead_checkpoint(
                model=kwargs.pop("model"), output_dir=output_dir, safe_serialization=args.save_safetensors
            )


class SaveProcessorCallback(TrainerCallback):
    r"""A callback for saving the processor."""

    def __init__(self, processor: "ProcessorMixin") -> None:
        self.processor = processor

    @override
    def on_save(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if args.should_save:
            output_dir = os.path.join(args.output_dir, f"{PREFIX_CHECKPOINT_DIR}-{state.global_step}")
            self.processor.save_pretrained(output_dir)

    @override
    def on_train_end(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if args.should_save:
            self.processor.save_pretrained(args.output_dir)


class PissaConvertCallback(TrainerCallback):
    r"""A callback for converting the PiSSA adapter to a normal one."""

    @override
    def on_train_begin(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if args.should_save:
            model = kwargs.pop("model")
            pissa_init_dir = os.path.join(args.output_dir, "pissa_init")
            logger.info_rank0(f"Initial PiSSA adapter will be saved at: {pissa_init_dir}.")
            if isinstance(model, PeftModel):
                init_lora_weights = getattr(model.peft_config["default"], "init_lora_weights")
                setattr(model.peft_config["default"], "init_lora_weights", True)
                model.save_pretrained(pissa_init_dir, safe_serialization=args.save_safetensors)
                setattr(model.peft_config["default"], "init_lora_weights", init_lora_weights)

    @override
    def on_train_end(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if args.should_save:
            model = kwargs.pop("model")
            pissa_init_dir = os.path.join(args.output_dir, "pissa_init")
            pissa_backup_dir = os.path.join(args.output_dir, "pissa_backup")
            pissa_convert_dir = os.path.join(args.output_dir, "pissa_converted")
            logger.info_rank0(f"Converted PiSSA adapter will be saved at: {pissa_convert_dir}.")
            # 1. save a pissa backup with init_lora_weights: True
            # 2. save a converted lora with init_lora_weights: pissa
            # 3. load the pissa backup with init_lora_weights: True
            # 4. delete the initial adapter and change init_lora_weights to pissa
            if isinstance(model, PeftModel):
                init_lora_weights = getattr(model.peft_config["default"], "init_lora_weights")
                setattr(model.peft_config["default"], "init_lora_weights", True)
                model.save_pretrained(pissa_backup_dir, safe_serialization=args.save_safetensors)
                setattr(model.peft_config["default"], "init_lora_weights", init_lora_weights)
                model.save_pretrained(
                    pissa_convert_dir,
                    safe_serialization=args.save_safetensors,
                    path_initial_model_for_weight_conversion=pissa_init_dir,
                )
                model.load_adapter(pissa_backup_dir, "default", is_trainable=True)
                model.set_adapter("default")
                setattr(model.peft_config["default"], "init_lora_weights", init_lora_weights)


class LogCallback(TrainerCallback):
    r"""A callback for logging training and evaluation status."""

    def __init__(self) -> None:
        # Progress
        self.start_time = 0
        self.cur_steps = 0
        self.max_steps = 0
        self.elapsed_time = ""
        self.remaining_time = ""
        self.thread_pool: Optional[ThreadPoolExecutor] = None
        # Status
        self.aborted = False
        self.do_train = False
        # Web UI
        self.webui_mode = is_env_enabled("LLAMABOARD_ENABLED")
        if self.webui_mode and not use_ray():
            signal.signal(signal.SIGABRT, self._set_abort)
            self.logger_handler = logging.LoggerHandler(os.getenv("LLAMABOARD_WORKDIR"))
            logging.add_handler(self.logger_handler)
            transformers.logging.add_handler(self.logger_handler)

    def _set_abort(self, signum, frame) -> None:
        self.aborted = True

    def _reset(self, max_steps: int = 0) -> None:
        self.start_time = time.time()
        self.cur_steps = 0
        self.max_steps = max_steps
        self.elapsed_time = ""
        self.remaining_time = ""

    def _timing(self, cur_steps: int) -> None:
        cur_time = time.time()
        elapsed_time = cur_time - self.start_time
        avg_time_per_step = elapsed_time / cur_steps if cur_steps != 0 else 0
        remaining_time = (self.max_steps - cur_steps) * avg_time_per_step
        self.cur_steps = cur_steps
        self.elapsed_time = str(timedelta(seconds=int(elapsed_time)))
        self.remaining_time = str(timedelta(seconds=int(remaining_time)))

    def _write_log(self, output_dir: str, logs: dict[str, Any]) -> None:
        with open(os.path.join(output_dir, TRAINER_LOG), "a", encoding="utf-8") as f:
            f.write(json.dumps(logs) + "\n")

    def _create_thread_pool(self, output_dir: str) -> None:
        os.makedirs(output_dir, exist_ok=True)
        self.thread_pool = ThreadPoolExecutor(max_workers=1)

    def _close_thread_pool(self) -> None:
        if self.thread_pool is not None:
            self.thread_pool.shutdown(wait=True)
            self.thread_pool = None

    @override
    def on_init_end(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if (
            args.should_save
            and os.path.exists(os.path.join(args.output_dir, TRAINER_LOG))
            and args.overwrite_output_dir
        ):
            logger.warning_rank0_once("Previous trainer log in this folder will be deleted.")
            os.remove(os.path.join(args.output_dir, TRAINER_LOG))

    @override
    def on_train_begin(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if args.should_save:
            self.do_train = True
            self._reset(max_steps=state.max_steps)
            self._create_thread_pool(output_dir=args.output_dir)

    @override
    def on_train_end(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        self._close_thread_pool()

    @override
    def on_substep_end(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if self.aborted:
            control.should_epoch_stop = True
            control.should_training_stop = True

    @override
    def on_step_end(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if self.aborted:
            control.should_epoch_stop = True
            control.should_training_stop = True

    @override
    def on_evaluate(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if not self.do_train:
            self._close_thread_pool()

    @override
    def on_predict(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if not self.do_train:
            self._close_thread_pool()

    @override
    def on_log(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if not args.should_save:
            return

        self._timing(cur_steps=state.global_step)
        logs = dict(
            current_steps=self.cur_steps,
            total_steps=self.max_steps,
            loss=state.log_history[-1].get("loss"),
            eval_loss=state.log_history[-1].get("eval_loss"),
            predict_loss=state.log_history[-1].get("predict_loss"),
            reward=state.log_history[-1].get("reward"),
            accuracy=state.log_history[-1].get("rewards/accuracies"),
            lr=state.log_history[-1].get("learning_rate"),
            epoch=state.log_history[-1].get("epoch"),
            percentage=round(self.cur_steps / self.max_steps * 100, 2) if self.max_steps != 0 else 100,
            elapsed_time=self.elapsed_time,
            remaining_time=self.remaining_time,
        )
        if state.num_input_tokens_seen:
            logs["throughput"] = round(state.num_input_tokens_seen / (time.time() - self.start_time), 2)
            logs["total_tokens"] = state.num_input_tokens_seen

        if is_env_enabled("RECORD_VRAM"):
            vram_allocated, vram_reserved = get_peak_memory()
            logs["vram_allocated"] = round(vram_allocated / (1024**3), 2)
            logs["vram_reserved"] = round(vram_reserved / (1024**3), 2)

        logs = {k: v for k, v in logs.items() if v is not None}
        if self.webui_mode and all(key in logs for key in ("loss", "lr", "epoch")):
            log_str = f"'loss': {logs['loss']:.4f}, 'learning_rate': {logs['lr']:2.4e}, 'epoch': {logs['epoch']:.2f}"
            for extra_key in ("reward", "accuracy", "throughput"):
                if logs.get(extra_key):
                    log_str += f", '{extra_key}': {logs[extra_key]:.2f}"

            logger.info_rank0("{" + log_str + "}")

        if self.thread_pool is not None:
            self.thread_pool.submit(self._write_log, args.output_dir, logs)

    @override
    def on_prediction_step(
        self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs
    ):
        if self.do_train:
            return

        if self.aborted:
            sys.exit(0)

        if not args.should_save:
            return

        eval_dataloader = kwargs.pop("eval_dataloader", None)
        if has_length(eval_dataloader):
            if self.max_steps == 0:
                self._reset(max_steps=len(eval_dataloader))
                self._create_thread_pool(output_dir=args.output_dir)

            self._timing(cur_steps=self.cur_steps + 1)
            if self.cur_steps % 5 == 0 and self.thread_pool is not None:
                logs = dict(
                    current_steps=self.cur_steps,
                    total_steps=self.max_steps,
                    percentage=round(self.cur_steps / self.max_steps * 100, 2) if self.max_steps != 0 else 100,
                    elapsed_time=self.elapsed_time,
                    remaining_time=self.remaining_time,
                )
                self.thread_pool.submit(self._write_log, args.output_dir, logs)


class ReporterCallback(TrainerCallback):
    r"""A callback for reporting training status to external logger."""

    def __init__(
        self,
        model_args: "ModelArguments",
        data_args: "DataArguments",
        finetuning_args: "FinetuningArguments",
        generating_args: "GeneratingArguments",
    ) -> None:
        self.model_args = model_args
        self.data_args = data_args
        self.finetuning_args = finetuning_args
        self.generating_args = generating_args
        os.environ["WANDB_PROJECT"] = os.getenv("WANDB_PROJECT", "llamafactory")

    @override
    def on_train_begin(self, args: "TrainingArguments", state: "TrainerState", control: "TrainerControl", **kwargs):
        if not state.is_world_process_zero:
            return

        if "wandb" in args.report_to:
            import wandb

            wandb.config.update(
                {
                    "model_args": self.model_args.to_dict(),
                    "data_args": self.data_args.to_dict(),
                    "finetuning_args": self.finetuning_args.to_dict(),
                    "generating_args": self.generating_args.to_dict(),
                }
            )

        if self.finetuning_args.use_swanlab:
            import swanlab  # type: ignore

            swanlab.config.update(
                {
                    "model_args": self.model_args.to_dict(),
                    "data_args": self.data_args.to_dict(),
                    "finetuning_args": self.finetuning_args.to_dict(),
                    "generating_args": self.generating_args.to_dict(),
                }
            )


--- src/llamafactory/chat/chat_model.py ---
# Copyright 2025 THUDM and the LlamaFactory team.
#
# This code is inspired by the THUDM's ChatGLM implementation.
# https://github.com/THUDM/ChatGLM-6B/blob/main/cli_demo.py
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import asyncio
import os
from collections.abc import AsyncGenerator, Generator
from threading import Thread
from typing import TYPE_CHECKING, Any, Optional

from ..extras.constants import EngineName
from ..extras.misc import torch_gc
from ..hparams import get_infer_args


if TYPE_CHECKING:
    from ..data.mm_plugin import AudioInput, ImageInput, VideoInput
    from .base_engine import BaseEngine, Response


def _start_background_loop(loop: "asyncio.AbstractEventLoop") -> None:
    asyncio.set_event_loop(loop)
    loop.run_forever()


class ChatModel:
    r"""General class for chat models. Backed by huggingface or vllm engines.

    Supports both sync and async methods.
    Sync methods: chat(), stream_chat() and get_scores().
    Async methods: achat(), astream_chat() and aget_scores().
    """

    def __init__(self, args: Optional[dict[str, Any]] = None) -> None:
        model_args, data_args, finetuning_args, generating_args = get_infer_args(args)

        if model_args.infer_backend == EngineName.HF:
            from .hf_engine import HuggingfaceEngine

            self.engine: BaseEngine = HuggingfaceEngine(model_args, data_args, finetuning_args, generating_args)
        elif model_args.infer_backend == EngineName.VLLM:
            try:
                from .vllm_engine import VllmEngine

                self.engine: BaseEngine = VllmEngine(model_args, data_args, finetuning_args, generating_args)
            except ImportError as e:
                raise ImportError(
                    "vLLM not install, you may need to run `pip install vllm`\n"
                    "or try to use HuggingFace backend: --infer_backend huggingface"
                ) from e
        elif model_args.infer_backend == EngineName.SGLANG:
            try:
                from .sglang_engine import SGLangEngine

                self.engine: BaseEngine = SGLangEngine(model_args, data_args, finetuning_args, generating_args)
            except ImportError as e:
                raise ImportError(
                    "SGLang not install, you may need to run `pip install sglang[all]`\n"
                    "or try to use HuggingFace backend: --infer_backend huggingface"
                ) from e
        elif model_args.infer_backend == EngineName.KT:
            try:
                from .kt_engine import KTransformersEngine

                self.engine: BaseEngine = KTransformersEngine(model_args, data_args, finetuning_args, generating_args)
            except ImportError as e:
                raise ImportError(
                    "KTransformers not install, you may need to run `pip install ktransformers`\n"
                    "or try to use HuggingFace backend: --infer_backend huggingface"
                ) from e
        else:
            raise NotImplementedError(f"Unknown backend: {model_args.infer_backend}")

        self._loop = asyncio.new_event_loop()
        self._thread = Thread(target=_start_background_loop, args=(self._loop,), daemon=True)
        self._thread.start()

    def chat(
        self,
        messages: list[dict[str, str]],
        system: Optional[str] = None,
        tools: Optional[str] = None,
        images: Optional[list["ImageInput"]] = None,
        videos: Optional[list["VideoInput"]] = None,
        audios: Optional[list["AudioInput"]] = None,
        **input_kwargs,
    ) -> list["Response"]:
        r"""Get a list of responses of the chat model."""
        task = asyncio.run_coroutine_threadsafe(
            self.achat(messages, system, tools, images, videos, audios, **input_kwargs), self._loop
        )
        return task.result()

    async def achat(
        self,
        messages: list[dict[str, str]],
        system: Optional[str] = None,
        tools: Optional[str] = None,
        images: Optional[list["ImageInput"]] = None,
        videos: Optional[list["VideoInput"]] = None,
        audios: Optional[list["AudioInput"]] = None,
        **input_kwargs,
    ) -> list["Response"]:
        r"""Asynchronously get a list of responses of the chat model."""
        return await self.engine.chat(messages, system, tools, images, videos, audios, **input_kwargs)

    def stream_chat(
        self,
        messages: list[dict[str, str]],
        system: Optional[str] = None,
        tools: Optional[str] = None,
        images: Optional[list["ImageInput"]] = None,
        videos: Optional[list["VideoInput"]] = None,
        audios: Optional[list["AudioInput"]] = None,
        **input_kwargs,
    ) -> Generator[str, None, None]:
        r"""Get the response token-by-token of the chat model."""
        generator = self.astream_chat(messages, system, tools, images, videos, audios, **input_kwargs)
        while True:
            try:
                task = asyncio.run_coroutine_threadsafe(generator.__anext__(), self._loop)
                yield task.result()
            except StopAsyncIteration:
                break

    async def astream_chat(
        self,
        messages: list[dict[str, str]],
        system: Optional[str] = None,
        tools: Optional[str] = None,
        images: Optional[list["ImageInput"]] = None,
        videos: Optional[list["VideoInput"]] = None,
        audios: Optional[list["AudioInput"]] = None,
        **input_kwargs,
    ) -> AsyncGenerator[str, None]:
        r"""Asynchronously get the response token-by-token of the chat model."""
        async for new_token in self.engine.stream_chat(
            messages, system, tools, images, videos, audios, **input_kwargs
        ):
            yield new_token

    def get_scores(
        self,
        batch_input: list[str],
        **input_kwargs,
    ) -> list[float]:
        r"""Get a list of scores of the reward model."""
        task = asyncio.run_coroutine_threadsafe(self.aget_scores(batch_input, **input_kwargs), self._loop)
        return task.result()

    async def aget_scores(
        self,
        batch_input: list[str],
        **input_kwargs,
    ) -> list[float]:
        r"""Asynchronously get a list of scores of the reward model."""
        return await self.engine.get_scores(batch_input, **input_kwargs)


def run_chat() -> None:
    if os.name != "nt":
        try:
            import readline  # noqa: F401
        except ImportError:
            print("Install `readline` for a better experience.")

    chat_model = ChatModel()
    messages = []
    print("Welcome to the CLI application, use `clear` to remove the history, use `exit` to exit the application.")

    while True:
        try:
            query = input("\nUser: ")
        except UnicodeDecodeError:
            print("Detected decoding error at the inputs, please set the terminal encoding to utf-8.")
            continue
        except Exception:
            raise

        if query.strip() == "exit":
            break

        if query.strip() == "clear":
            messages = []
            torch_gc()
            print("History has been removed.")
            continue

        messages.append({"role": "user", "content": query})
        print("Assistant: ", end="", flush=True)

        response = ""
        for new_text in chat_model.stream_chat(messages):
            print(new_text, end="", flush=True)
            response += new_text
        print()
        messages.append({"role": "assistant", "content": response})


--- src/llamafactory/webui/chatter.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
import os
from collections.abc import Generator
from contextlib import contextmanager
from typing import TYPE_CHECKING, Any

from transformers.utils import is_torch_npu_available

from ..chat import ChatModel
from ..data import Role
from ..extras.constants import PEFT_METHODS
from ..extras.misc import torch_gc
from ..extras.packages import is_gradio_available
from .common import get_save_dir, load_config
from .locales import ALERTS


if TYPE_CHECKING:
    from ..chat import BaseEngine
    from .manager import Manager


if is_gradio_available():
    import gradio as gr


def _escape_html(text: str) -> str:
    r"""Escape HTML characters."""
    return text.replace("<", "&lt;").replace(">", "&gt;")


def _format_response(text: str, lang: str, escape_html: bool, thought_words: tuple[str, str]) -> str:
    r"""Post-process the response text.

    Based on: https://huggingface.co/spaces/Lyte/DeepSeek-R1-Distill-Qwen-1.5B-Demo-GGUF/blob/main/app.py
    """
    if thought_words[0] not in text:
        return _escape_html(text) if escape_html else text

    text = text.replace(thought_words[0], "")
    result = text.split(thought_words[1], maxsplit=1)
    if len(result) == 1:
        summary = ALERTS["info_thinking"][lang]
        thought, answer = text, ""
    else:
        summary = ALERTS["info_thought"][lang]
        thought, answer = result

    if escape_html:
        thought, answer = _escape_html(thought), _escape_html(answer)

    return (
        f"<details open><summary class='thinking-summary'><span>{summary}</span></summary>\n\n"
        f"<div class='thinking-container'>\n{thought}\n</div>\n</details>{answer}"
    )


@contextmanager
def update_attr(obj: Any, name: str, value: Any):
    old_value = getattr(obj, name, None)
    setattr(obj, name, value)
    yield
    setattr(obj, name, old_value)


class WebChatModel(ChatModel):
    def __init__(self, manager: "Manager", demo_mode: bool = False, lazy_init: bool = True) -> None:
        self.manager = manager
        self.demo_mode = demo_mode
        self.engine: BaseEngine | None = None

        if not lazy_init:  # read arguments from command line
            super().__init__()

        if demo_mode and os.getenv("DEMO_MODEL") and os.getenv("DEMO_TEMPLATE"):  # load demo model
            model_name_or_path = os.getenv("DEMO_MODEL")
            template = os.getenv("DEMO_TEMPLATE")
            infer_backend = os.getenv("DEMO_BACKEND", "huggingface")
            super().__init__(
                dict(model_name_or_path=model_name_or_path, template=template, infer_backend=infer_backend)
            )

    @property
    def loaded(self) -> bool:
        return self.engine is not None

    def load_model(self, data) -> Generator[str, None, None]:
        get = lambda elem_id: data[self.manager.get_elem_by_id(elem_id)]
        lang, model_name, model_path = get("top.lang"), get("top.model_name"), get("top.model_path")
        finetuning_type, checkpoint_path = get("top.finetuning_type"), get("top.checkpoint_path")
        user_config = load_config()

        error = ""
        if self.loaded:
            error = ALERTS["err_exists"][lang]
        elif not model_name:
            error = ALERTS["err_no_model"][lang]
        elif not model_path:
            error = ALERTS["err_no_path"][lang]
        elif self.demo_mode:
            error = ALERTS["err_demo"][lang]

        try:
            json.loads(get("infer.extra_args"))
        except json.JSONDecodeError:
            error = ALERTS["err_json_schema"][lang]

        if error:
            gr.Warning(error)
            yield error
            return

        yield ALERTS["info_loading"][lang]
        args = dict(
            model_name_or_path=model_path,
            cache_dir=user_config.get("cache_dir", None),
            finetuning_type=finetuning_type,
            template=get("top.template"),
            rope_scaling=get("top.rope_scaling") if get("top.rope_scaling") != "none" else None,
            flash_attn="fa2" if get("top.booster") == "flashattn2" else "auto",
            use_unsloth=(get("top.booster") == "unsloth"),
            enable_liger_kernel=(get("top.booster") == "liger_kernel"),
            infer_backend=get("infer.infer_backend"),
            infer_dtype=get("infer.infer_dtype"),
            trust_remote_code=True,
        )
        args.update(json.loads(get("infer.extra_args")))

        # checkpoints
        if checkpoint_path:
            if finetuning_type in PEFT_METHODS:  # list
                args["adapter_name_or_path"] = ",".join(
                    [get_save_dir(model_name, finetuning_type, adapter) for adapter in checkpoint_path]
                )
            else:  # str
                args["model_name_or_path"] = get_save_dir(model_name, finetuning_type, checkpoint_path)

        # quantization
        if get("top.quantization_bit") != "none":
            args["quantization_bit"] = int(get("top.quantization_bit"))
            args["quantization_method"] = get("top.quantization_method")
            args["double_quantization"] = not is_torch_npu_available()

        super().__init__(args)
        yield ALERTS["info_loaded"][lang]

    def unload_model(self, data) -> Generator[str, None, None]:
        lang = data[self.manager.get_elem_by_id("top.lang")]

        if self.demo_mode:
            gr.Warning(ALERTS["err_demo"][lang])
            yield ALERTS["err_demo"][lang]
            return

        yield ALERTS["info_unloading"][lang]
        self.engine = None
        torch_gc()
        yield ALERTS["info_unloaded"][lang]

    @staticmethod
    def append(
        chatbot: list[dict[str, str]],
        messages: list[dict[str, str]],
        role: str,
        query: str,
        escape_html: bool,
    ) -> tuple[list[dict[str, str]], list[dict[str, str]], str]:
        r"""Add the user input to chatbot.

        Inputs: infer.chatbot, infer.messages, infer.role, infer.query, infer.escape_html
        Output: infer.chatbot, infer.messages, infer.query
        """
        return (
            chatbot + [{"role": "user", "content": _escape_html(query) if escape_html else query}],
            messages + [{"role": role, "content": query}],
            "",
        )

    def stream(
        self,
        chatbot: list[dict[str, str]],
        messages: list[dict[str, str]],
        lang: str,
        system: str,
        tools: str,
        image: Any | None,
        video: Any | None,
        audio: Any | None,
        max_new_tokens: int,
        top_p: float,
        temperature: float,
        skip_special_tokens: bool,
        escape_html: bool,
        enable_thinking: bool,
    ) -> Generator[tuple[list[dict[str, str]], list[dict[str, str]]], None, None]:
        r"""Generate output text in stream.

        Inputs: infer.chatbot, infer.messages, infer.system, infer.tools, infer.image, infer.video, ...
        Output: infer.chatbot, infer.messages
        """
        with update_attr(self.engine.template, "enable_thinking", enable_thinking):
            chatbot.append({"role": "assistant", "content": ""})
            response = ""
            for new_text in self.stream_chat(
                messages,
                system,
                tools,
                images=[image] if image else None,
                videos=[video] if video else None,
                audios=[audio] if audio else None,
                max_new_tokens=max_new_tokens,
                top_p=top_p,
                temperature=temperature,
                skip_special_tokens=skip_special_tokens,
            ):
                response += new_text
                if tools:
                    result = self.engine.template.extract_tool(response)
                else:
                    result = response

                if isinstance(result, list):
                    tool_calls = [{"name": tool.name, "arguments": json.loads(tool.arguments)} for tool in result]
                    tool_calls = json.dumps(tool_calls, ensure_ascii=False)
                    output_messages = messages + [{"role": Role.FUNCTION.value, "content": tool_calls}]
                    bot_text = "```json\n" + tool_calls + "\n```"
                else:
                    output_messages = messages + [{"role": Role.ASSISTANT.value, "content": result}]
                    bot_text = _format_response(result, lang, escape_html, self.engine.template.thought_words)

                chatbot[-1] = {"role": "assistant", "content": bot_text}
                yield chatbot, output_messages


--- tests/conftest.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""LlamaFactory test configuration.

Contains shared fixtures, pytest configuration, and custom markers.
"""

import os
import sys

import pytest
import torch
import torch.distributed as dist
from pytest import Config, FixtureRequest, Item, MonkeyPatch

from llamafactory.extras.misc import get_current_device, get_device_count, is_env_enabled
from llamafactory.extras.packages import is_transformers_version_greater_than
from llamafactory.train.test_utils import patch_valuehead_model


CURRENT_DEVICE = get_current_device().type


def pytest_configure(config: Config):
    """Register custom pytest markers."""
    config.addinivalue_line(
        "markers",
        "slow: marks tests as slow (deselect with '-m \"not slow\"' or set RUN_SLOW=1 to run)",
    )
    config.addinivalue_line(
        "markers",
        "runs_on: test requires specific device type, e.g., @pytest.mark.runs_on(['cuda'])",
    )
    config.addinivalue_line(
        "markers",
        "require_distributed(num_devices): allow multi-device execution (default: 2)",
    )


def _handle_runs_on(items: list[Item]):
    """Skip tests on specified device TYPES (cpu/cuda/npu)."""
    for item in items:
        marker = item.get_closest_marker("runs_on")
        if not marker:
            continue

        devices = marker.args[0]
        if isinstance(devices, str):
            devices = [devices]

        if CURRENT_DEVICE not in devices:
            item.add_marker(pytest.mark.skip(reason=f"test requires one of {devices} (current: {CURRENT_DEVICE})"))


def _handle_slow_tests(items: list[Item]):
    """Skip slow tests unless RUN_SLOW is enabled."""
    if not is_env_enabled("RUN_SLOW"):
        skip_slow = pytest.mark.skip(reason="slow test (set RUN_SLOW=1 to run)")
        for item in items:
            if "slow" in item.keywords:
                item.add_marker(skip_slow)


def _get_visible_devices_env() -> str | None:
    """Return device visibility env var name."""
    if CURRENT_DEVICE == "cuda":
        return "CUDA_VISIBLE_DEVICES"
    elif CURRENT_DEVICE == "npu":
        return "ASCEND_RT_VISIBLE_DEVICES"
    else:
        return None


def _handle_device_visibility(items: list[Item]):
    """Handle device visibility based on test markers."""
    env_key = _get_visible_devices_env()
    if env_key is None or CURRENT_DEVICE in ("cpu", "mps"):
        return

    # Parse visible devices
    visible_devices_env = os.environ.get(env_key)
    if visible_devices_env is None:
        available = get_device_count()
    else:
        visible_devices = [v for v in visible_devices_env.split(",") if v != ""]
        available = len(visible_devices)

    for item in items:
        marker = item.get_closest_marker("require_distributed")
        if not marker:
            continue

        required = marker.args[0] if marker.args else 2
        if available < required:
            item.add_marker(pytest.mark.skip(reason=f"test requires {required} devices, but only {available} visible"))


def pytest_collection_modifyitems(config: Config, items: list[Item]):
    """Modify test collection based on markers and environment."""
    # Handle version compatibility (from HEAD)
    skip_bc = pytest.mark.skip(reason="Skip backward compatibility tests")
    for item in items:
        if "tests_v1" in str(item.fspath) and not is_transformers_version_greater_than("4.57.0"):
            item.add_marker(skip_bc)

    _handle_slow_tests(items)
    _handle_runs_on(items)
    _handle_device_visibility(items)


@pytest.fixture(autouse=True)
def _cleanup_distributed_state():
    """Cleanup distributed state after each test."""
    yield
    if dist.is_initialized():
        dist.destroy_process_group()


@pytest.fixture(autouse=True)
def _manage_distributed_env(request: FixtureRequest, monkeypatch: MonkeyPatch) -> None:
    """Set environment variables for distributed tests if specific devices are requested."""
    env_key = _get_visible_devices_env()
    if not env_key:
        return

    # Save old environment for logic checks, monkeypatch handles restoration
    old_value = os.environ.get(env_key)

    marker = request.node.get_closest_marker("require_distributed")
    if marker:  # distributed test
        required = marker.args[0] if marker.args else 2
        specific_devices = marker.args[1] if len(marker.args) > 1 else None

        if specific_devices:
            devices_str = ",".join(map(str, specific_devices))
        else:
            devices_str = ",".join(str(i) for i in range(required))

        monkeypatch.setenv(env_key, devices_str)

        # add project root dir to path for mp run
        project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
        if project_root not in sys.path:
            sys.path.insert(0, project_root)

        os.environ["PYTHONPATH"] = project_root + os.pathsep + os.environ.get("PYTHONPATH", "")

    else:  # non-distributed test
        if old_value:
            visible_devices = [v for v in old_value.split(",") if v != ""]
            monkeypatch.setenv(env_key, visible_devices[0] if visible_devices else "0")
        else:
            monkeypatch.setenv(env_key, "0")

        if CURRENT_DEVICE == "cuda":
            monkeypatch.setattr(torch.cuda, "device_count", lambda: 1)
        elif CURRENT_DEVICE == "npu":
            monkeypatch.setattr(torch.npu, "device_count", lambda: 1)


@pytest.fixture
def fix_valuehead_cpu_loading():
    """Fix valuehead model loading."""
    patch_valuehead_model()


--- tests/version.txt ---
# change if test fails or cache is outdated
0.9.5.103


--- tests/model/test_base.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

import pytest

from llamafactory.train.test_utils import compare_model, load_infer_model, load_reference_model


TINY_LLAMA3 = os.getenv("TINY_LLAMA3", "llamafactory/tiny-random-Llama-3")

TINY_LLAMA_VALUEHEAD = os.getenv("TINY_LLAMA_VALUEHEAD", "llamafactory/tiny-random-Llama-3-valuehead")

INFER_ARGS = {
    "model_name_or_path": TINY_LLAMA3,
    "template": "llama3",
    "infer_dtype": "float16",
}


def test_base():
    model = load_infer_model(**INFER_ARGS)
    ref_model = load_reference_model(TINY_LLAMA3)
    compare_model(model, ref_model)


@pytest.mark.usefixtures("fix_valuehead_cpu_loading")
def test_valuehead():
    model = load_infer_model(add_valuehead=True, **INFER_ARGS)
    ref_model = load_reference_model(TINY_LLAMA_VALUEHEAD, add_valuehead=True)
    compare_model(model, ref_model)


--- tests/e2e/test_chat.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

import pytest

from llamafactory.chat import ChatModel


TINY_LLAMA3 = os.getenv("TINY_LLAMA3", "llamafactory/tiny-random-Llama-3")

INFER_ARGS = {
    "model_name_or_path": TINY_LLAMA3,
    "finetuning_type": "lora",
    "template": "llama3",
    "infer_dtype": "float16",
    "do_sample": False,
    "max_new_tokens": 1,
}

MESSAGES = [
    {"role": "user", "content": "Hi"},
]

EXPECTED_RESPONSE = "_rho"


@pytest.mark.runs_on(["cpu", "mps"])
def test_chat():
    chat_model = ChatModel(INFER_ARGS)
    assert chat_model.chat(MESSAGES)[0].response_text == EXPECTED_RESPONSE


@pytest.mark.runs_on(["cpu", "mps"])
def test_stream_chat():
    chat_model = ChatModel(INFER_ARGS)
    response = ""
    for token in chat_model.stream_chat(MESSAGES):
        response += token

    assert response == EXPECTED_RESPONSE


--- tests/data/test_collator.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

import pytest
import torch
from PIL import Image
from transformers import AutoConfig, AutoModelForVision2Seq

from llamafactory.data import get_template_and_fix_tokenizer
from llamafactory.data.collator import MultiModalDataCollatorForSeq2Seq, prepare_4d_attention_mask
from llamafactory.extras.constants import IGNORE_INDEX
from llamafactory.hparams import get_infer_args
from llamafactory.model import load_tokenizer


TINY_LLAMA3 = os.getenv("TINY_LLAMA3", "llamafactory/tiny-random-Llama-3")


@pytest.mark.runs_on(["cpu", "mps"])
def test_base_collator():
    model_args, data_args, *_ = get_infer_args({"model_name_or_path": TINY_LLAMA3, "template": "default"})
    tokenizer_module = load_tokenizer(model_args)
    template = get_template_and_fix_tokenizer(tokenizer_module["tokenizer"], data_args)
    data_collator = MultiModalDataCollatorForSeq2Seq(
        template=template,
        pad_to_multiple_of=8,
        label_pad_token_id=IGNORE_INDEX,
        **tokenizer_module,
    )
    p = tokenizer_module["tokenizer"].pad_token_id
    q = IGNORE_INDEX
    features = [
        {
            "input_ids": [0, 1, 2, 3, 4, 5],
            "attention_mask": [1, 1, 1, 1, 1, 1],
            "labels": [q, q, 2, 3, 4, 5],
        },
        {
            "input_ids": [6, 7],
            "attention_mask": [1, 1],
            "labels": [q, 7],
        },
    ]
    batch_input = data_collator(features)
    expected_input = {
        "input_ids": [
            [0, 1, 2, 3, 4, 5, p, p],
            [6, 7, p, p, p, p, p, p],
        ],
        "attention_mask": [
            [1, 1, 1, 1, 1, 1, 0, 0],
            [1, 1, 0, 0, 0, 0, 0, 0],
        ],
        "labels": [
            [q, q, 2, 3, 4, 5, q, q],
            [q, 7, q, q, q, q, q, q],
        ],
    }
    for k in batch_input.keys():
        assert batch_input[k].eq(torch.tensor(expected_input[k])).all()


@pytest.mark.runs_on(["cpu", "mps"])
def test_multimodal_collator():
    model_args, data_args, *_ = get_infer_args(
        {"model_name_or_path": "Qwen/Qwen2-VL-2B-Instruct", "template": "qwen2_vl"}
    )
    tokenizer_module = load_tokenizer(model_args)
    template = get_template_and_fix_tokenizer(tokenizer_module["tokenizer"], data_args)
    config = AutoConfig.from_pretrained(model_args.model_name_or_path)
    with torch.device("meta"):
        model = AutoModelForVision2Seq.from_config(config)

    data_collator = MultiModalDataCollatorForSeq2Seq(
        template=template,
        model=model,
        pad_to_multiple_of=4,
        label_pad_token_id=IGNORE_INDEX,
        **tokenizer_module,
    )
    p = tokenizer_module["tokenizer"].pad_token_id
    q = IGNORE_INDEX
    s = tokenizer_module["tokenizer"].convert_tokens_to_ids("<|vision_start|>")
    e = tokenizer_module["tokenizer"].convert_tokens_to_ids("<|vision_end|>")
    m = tokenizer_module["tokenizer"].convert_tokens_to_ids("<|image_pad|>")
    fake_image = Image.new("RGB", (64, 64), (255, 255, 255))

    features = [
        {
            "input_ids": [0, 1, 2, 3],
            "attention_mask": [1, 1, 1, 1],
            "labels": [0, 1, 2, 3],
        },
    ]
    batch_input = data_collator(features)
    expected_input = {
        "input_ids": [
            [0, 1, 2, 3, s, m, m, m, m, e, p, p],
        ],
        "attention_mask": [
            [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],
        ],
        "labels": [
            [0, 1, 2, 3, q, q, q, q, q, q, q, q],
        ],
        "position_ids": [
            [[0, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1]],
            [[0, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1]],
            [[0, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1]],
        ],
        "rope_deltas": [[-8]],
        **tokenizer_module["processor"].image_processor(fake_image),
    }
    assert batch_input.keys() == expected_input.keys()
    for k in batch_input.keys():
        assert batch_input[k].eq(torch.tensor(expected_input[k])).all()


@pytest.mark.runs_on(["cpu"])
def test_4d_attention_mask():
    o = 0.0
    x = torch.finfo(torch.float16).min
    attention_mask_with_indices = torch.tensor(
        [
            [1, 1, 2, 2, 2, 0],
            [1, 2, 2, 3, 3, 3],
        ]
    )
    attention_mask_computed = prepare_4d_attention_mask(attention_mask_with_indices, torch.float16)
    attention_mask_expected = torch.tensor(
        [
            [
                [
                    [o, x, x, x, x, x],
                    [o, o, x, x, x, x],
                    [x, x, o, x, x, x],
                    [x, x, o, o, x, x],
                    [x, x, o, o, o, x],
                    [x, x, x, x, x, x],
                ]
            ],
            [
                [
                    [o, x, x, x, x, x],
                    [x, o, x, x, x, x],
                    [x, o, o, x, x, x],
                    [x, x, x, o, x, x],
                    [x, x, x, o, o, x],
                    [x, x, x, o, o, o],
                ]
            ],
        ],
        dtype=torch.float16,
    )
    assert list(attention_mask_computed.size()) == [2, 1, 6, 6]
    assert torch.all(attention_mask_computed == attention_mask_expected)


if __name__ == "__main__":
    test_multimodal_collator()


--- tests/data/test_converter.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import pytest

from llamafactory.data import Role
from llamafactory.data.converter import get_dataset_converter
from llamafactory.data.parser import DatasetAttr
from llamafactory.hparams import DataArguments


@pytest.mark.runs_on(["cpu", "mps"])
def test_alpaca_converter():
    dataset_attr = DatasetAttr("hf_hub", "llamafactory/tiny-supervised-dataset")
    data_args = DataArguments()
    example = {
        "instruction": "Solve the math problem.",
        "input": "3 + 4",
        "output": "The answer is 7.",
    }
    dataset_converter = get_dataset_converter("alpaca", dataset_attr, data_args)
    assert dataset_converter(example) == {
        "_prompt": [{"role": Role.USER.value, "content": "Solve the math problem.\n3 + 4"}],
        "_response": [{"role": Role.ASSISTANT.value, "content": "The answer is 7."}],
        "_system": "",
        "_tools": "",
        "_images": None,
        "_videos": None,
        "_audios": None,
    }


@pytest.mark.runs_on(["cpu", "mps"])
def test_sharegpt_converter():
    dataset_attr = DatasetAttr("hf_hub", "llamafactory/tiny-supervised-dataset")
    data_args = DataArguments()
    example = {
        "conversations": [
            {"from": "system", "value": "You are a helpful assistant."},
            {"from": "human", "value": "Solve the math problem.\n3 + 4"},
            {"from": "gpt", "value": "The answer is 7."},
        ]
    }
    dataset_converter = get_dataset_converter("sharegpt", dataset_attr, data_args)
    assert dataset_converter(example) == {
        "_prompt": [{"role": Role.USER.value, "content": "Solve the math problem.\n3 + 4"}],
        "_response": [{"role": Role.ASSISTANT.value, "content": "The answer is 7."}],
        "_system": "You are a helpful assistant.",
        "_tools": "",
        "_images": None,
        "_videos": None,
        "_audios": None,
    }


--- tests/eval/test_eval_template.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import pytest

from llamafactory.eval.template import get_eval_template


@pytest.mark.runs_on(["cpu", "mps"])
def test_eval_template_en():
    support_set = [
        {
            "question": "Fewshot question",
            "A": "Fewshot1",
            "B": "Fewshot2",
            "C": "Fewshot3",
            "D": "Fewshot4",
            "answer": "B",
        }
    ]
    example = {
        "question": "Target question",
        "A": "Target1",
        "B": "Target2",
        "C": "Target3",
        "D": "Target4",
        "answer": "C",
    }
    template = get_eval_template(name="en")
    messages = template.format_example(example, support_set=support_set, subject_name="SubName")
    assert messages == [
        {
            "role": "user",
            "content": (
                "The following are multiple choice questions (with answers) about SubName.\n\n"
                "Fewshot question\nA. Fewshot1\nB. Fewshot2\nC. Fewshot3\nD. Fewshot4\nAnswer:"
            ),
        },
        {"role": "assistant", "content": "B"},
        {
            "role": "user",
            "content": "Target question\nA. Target1\nB. Target2\nC. Target3\nD. Target4\nAnswer:",
        },
        {"role": "assistant", "content": "C"},
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_eval_template_zh():
    support_set = [
        {
            "question": "示例问题",
            "A": "示例答案1",
            "B": "示例答案2",
            "C": "示例答案3",
            "D": "示例答案4",
            "answer": "B",
        }
    ]
    example = {
        "question": "目标问题",
        "A": "目标答案1",
        "B": "目标答案2",
        "C": "目标答案3",
        "D": "目标答案4",
        "answer": "C",
    }
    template = get_eval_template(name="zh")
    messages = template.format_example(example, support_set=support_set, subject_name="主题")
    assert messages == [
        {
            "role": "user",
            "content": (
                "以下是中国关于主题考试的单项选择题，请选出其中的正确答案。\n\n"
                "示例问题\nA. 示例答案1\nB. 示例答案2\nC. 示例答案3\nD. 示例答案4\n答案："
            ),
        },
        {"role": "assistant", "content": "B"},
        {
            "role": "user",
            "content": "目标问题\nA. 目标答案1\nB. 目标答案2\nC. 目标答案3\nD. 目标答案4\n答案：",
        },
        {"role": "assistant", "content": "C"},
    ]


--- tests/data/test_formatter.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import json
from datetime import datetime

import pytest

from llamafactory.data.formatter import EmptyFormatter, FunctionFormatter, StringFormatter, ToolFormatter


FUNCTION = {"name": "tool_name", "arguments": {"foo": "bar", "size": 10}}

TOOLS = [
    {
        "name": "test_tool",
        "description": "tool_desc",
        "parameters": {
            "type": "object",
            "properties": {
                "foo": {"type": "string", "description": "foo_desc"},
                "bar": {"type": "number", "description": "bar_desc"},
            },
            "required": ["foo"],
        },
    }
]


@pytest.mark.runs_on(["cpu", "mps"])
def test_empty_formatter():
    formatter = EmptyFormatter(slots=["\n"])
    assert formatter.apply() == ["\n"]


@pytest.mark.runs_on(["cpu", "mps"])
def test_string_formatter():
    formatter = StringFormatter(slots=["<s>", "Human: {{content}}\nAssistant:"])
    assert formatter.apply(content="Hi") == ["<s>", "Human: Hi\nAssistant:"]


@pytest.mark.runs_on(["cpu", "mps"])
def test_function_formatter():
    formatter = FunctionFormatter(slots=["{{content}}", "</s>"], tool_format="default")
    tool_calls = json.dumps(FUNCTION)
    assert formatter.apply(content=tool_calls) == [
        """Action: tool_name\nAction Input: {"foo": "bar", "size": 10}""",
        "</s>",
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_multi_function_formatter():
    formatter = FunctionFormatter(slots=["{{content}}", "</s>"], tool_format="default")
    tool_calls = json.dumps([FUNCTION] * 2)
    assert formatter.apply(content=tool_calls) == [
        """Action: tool_name\nAction Input: {"foo": "bar", "size": 10}\n"""
        """Action: tool_name\nAction Input: {"foo": "bar", "size": 10}""",
        "</s>",
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_default_tool_formatter():
    formatter = ToolFormatter(tool_format="default")
    assert formatter.apply(content=json.dumps(TOOLS)) == [
        "You have access to the following tools:\n"
        "> Tool Name: test_tool\n"
        "Tool Description: tool_desc\n"
        "Tool Args:\n"
        "  - foo (string, required): foo_desc\n"
        "  - bar (number): bar_desc\n\n"
        "Use the following format if using a tool:\n"
        "```\n"
        "Action: tool name (one of [test_tool])\n"
        "Action Input: the input to the tool, in a JSON format representing the kwargs "
        """(e.g. ```{"input": "hello world", "num_beams": 5}```)\n"""
        "```\n"
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_default_tool_extractor():
    formatter = ToolFormatter(tool_format="default")
    result = """Action: test_tool\nAction Input: {"foo": "bar", "size": 10}"""
    assert formatter.extract(result) == [("test_tool", """{"foo": "bar", "size": 10}""")]


@pytest.mark.runs_on(["cpu", "mps"])
def test_default_multi_tool_extractor():
    formatter = ToolFormatter(tool_format="default")
    result = (
        """Action: test_tool\nAction Input: {"foo": "bar", "size": 10}\n"""
        """Action: another_tool\nAction Input: {"foo": "job", "size": 2}"""
    )
    assert formatter.extract(result) == [
        ("test_tool", """{"foo": "bar", "size": 10}"""),
        ("another_tool", """{"foo": "job", "size": 2}"""),
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_glm4_function_formatter():
    formatter = FunctionFormatter(slots=["{{content}}"], tool_format="glm4")
    tool_calls = json.dumps(FUNCTION)
    assert formatter.apply(content=tool_calls) == ["""tool_name\n{"foo": "bar", "size": 10}"""]


@pytest.mark.runs_on(["cpu", "mps"])
def test_glm4_tool_formatter():
    formatter = ToolFormatter(tool_format="glm4")
    assert formatter.apply(content=json.dumps(TOOLS)) == [
        "你是一个名为 ChatGLM 的人工智能助手。你是基于智谱 AI 公司训练的语言模型 GLM-4 模型开发的，"
        "你的任务是针对用户的问题和要求提供适当的答复和支持。\n\n# 可用工具\n\n"
        f"## test_tool\n\n{json.dumps(TOOLS[0], indent=4, ensure_ascii=False)}\n"
        "在调用上述函数时，请使用 Json 格式表示调用的参数。"
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_glm4_tool_extractor():
    formatter = ToolFormatter(tool_format="glm4")
    result = """test_tool\n{"foo": "bar", "size": 10}\n"""
    assert formatter.extract(result) == [("test_tool", """{"foo": "bar", "size": 10}""")]


@pytest.mark.runs_on(["cpu", "mps"])
def test_llama3_function_formatter():
    formatter = FunctionFormatter(slots=["{{content}}<|eot_id|>"], tool_format="llama3")
    tool_calls = json.dumps(FUNCTION)
    assert formatter.apply(content=tool_calls) == [
        """{"name": "tool_name", "parameters": {"foo": "bar", "size": 10}}<|eot_id|>"""
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_llama3_multi_function_formatter():
    formatter = FunctionFormatter(slots=["{{content}}<|eot_id|>"], tool_format="llama3")
    tool_calls = json.dumps([FUNCTION] * 2)
    assert formatter.apply(content=tool_calls) == [
        """[{"name": "tool_name", "parameters": {"foo": "bar", "size": 10}}, """
        """{"name": "tool_name", "parameters": {"foo": "bar", "size": 10}}]"""
        """<|eot_id|>"""
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_llama3_tool_formatter():
    formatter = ToolFormatter(tool_format="llama3")
    date = datetime.now().strftime("%d %b %Y")
    wrapped_tool = {"type": "function", "function": TOOLS[0]}
    assert formatter.apply(content=json.dumps(TOOLS)) == [
        f"Cutting Knowledge Date: December 2023\nToday Date: {date}\n\n"
        "You have access to the following functions. "
        "To call a function, please respond with JSON for a function call. "
        """Respond in the format {"name": function name, "parameters": dictionary of argument name and its value}. """
        f"Do not use variables.\n\n{json.dumps(wrapped_tool, indent=4, ensure_ascii=False)}\n\n"
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_llama3_tool_extractor():
    formatter = ToolFormatter(tool_format="llama3")
    result = """{"name": "test_tool", "parameters": {"foo": "bar", "size": 10}}\n"""
    assert formatter.extract(result) == [("test_tool", """{"foo": "bar", "size": 10}""")]


@pytest.mark.runs_on(["cpu", "mps"])
def test_llama3_multi_tool_extractor():
    formatter = ToolFormatter(tool_format="llama3")
    result = (
        """[{"name": "test_tool", "parameters": {"foo": "bar", "size": 10}}, """
        """{"name": "another_tool", "parameters": {"foo": "job", "size": 2}}]"""
    )
    assert formatter.extract(result) == [
        ("test_tool", """{"foo": "bar", "size": 10}"""),
        ("another_tool", """{"foo": "job", "size": 2}"""),
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_mistral_function_formatter():
    formatter = FunctionFormatter(slots=["[TOOL_CALLS] {{content}}", "</s>"], tool_format="mistral")
    tool_calls = json.dumps(FUNCTION)
    assert formatter.apply(content=tool_calls) == [
        "[TOOL_CALLS] " """[{"name": "tool_name", "arguments": {"foo": "bar", "size": 10}}]""",
        "</s>",
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_mistral_multi_function_formatter():
    formatter = FunctionFormatter(slots=["[TOOL_CALLS] {{content}}", "</s>"], tool_format="mistral")
    tool_calls = json.dumps([FUNCTION] * 2)
    assert formatter.apply(content=tool_calls) == [
        "[TOOL_CALLS] "
        """[{"name": "tool_name", "arguments": {"foo": "bar", "size": 10}}, """
        """{"name": "tool_name", "arguments": {"foo": "bar", "size": 10}}]""",
        "</s>",
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_mistral_tool_formatter():
    formatter = ToolFormatter(tool_format="mistral")
    wrapped_tool = {"type": "function", "function": TOOLS[0]}
    assert formatter.apply(content=json.dumps(TOOLS)) == [
        "[AVAILABLE_TOOLS] " + json.dumps([wrapped_tool], ensure_ascii=False) + "[/AVAILABLE_TOOLS]"
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_mistral_tool_extractor():
    formatter = ToolFormatter(tool_format="mistral")
    result = """{"name": "test_tool", "arguments": {"foo": "bar", "size": 10}}"""
    assert formatter.extract(result) == [("test_tool", """{"foo": "bar", "size": 10}""")]


@pytest.mark.runs_on(["cpu", "mps"])
def test_mistral_multi_tool_extractor():
    formatter = ToolFormatter(tool_format="mistral")
    result = (
        """[{"name": "test_tool", "arguments": {"foo": "bar", "size": 10}}, """
        """{"name": "another_tool", "arguments": {"foo": "job", "size": 2}}]"""
    )
    assert formatter.extract(result) == [
        ("test_tool", """{"foo": "bar", "size": 10}"""),
        ("another_tool", """{"foo": "job", "size": 2}"""),
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_qwen_function_formatter():
    formatter = FunctionFormatter(slots=["{{content}}<|im_end|>\n"], tool_format="qwen")
    tool_calls = json.dumps(FUNCTION)
    assert formatter.apply(content=tool_calls) == [
        """<tool_call>\n{"name": "tool_name", "arguments": {"foo": "bar", "size": 10}}\n</tool_call><|im_end|>\n"""
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_qwen_multi_function_formatter():
    formatter = FunctionFormatter(slots=["{{content}}<|im_end|>\n"], tool_format="qwen")
    tool_calls = json.dumps([FUNCTION] * 2)
    assert formatter.apply(content=tool_calls) == [
        """<tool_call>\n{"name": "tool_name", "arguments": {"foo": "bar", "size": 10}}\n</tool_call>\n"""
        """<tool_call>\n{"name": "tool_name", "arguments": {"foo": "bar", "size": 10}}\n</tool_call>"""
        "<|im_end|>\n"
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_qwen_tool_formatter():
    formatter = ToolFormatter(tool_format="qwen")
    wrapped_tool = {"type": "function", "function": TOOLS[0]}
    assert formatter.apply(content=json.dumps(TOOLS)) == [
        "\n\n# Tools\n\nYou may call one or more functions to assist with the user query.\n\n"
        "You are provided with function signatures within <tools></tools> XML tags:\n<tools>"
        f"\n{json.dumps(wrapped_tool, ensure_ascii=False)}"
        "\n</tools>\n\nFor each function call, return a json object with function name and arguments within "
        """<tool_call></tool_call> XML tags:\n<tool_call>\n{"name": <function-name>, """
        """"arguments": <args-json-object>}\n</tool_call>"""
    ]


@pytest.mark.runs_on(["cpu", "mps"])
def test_qwen_tool_extractor():
    formatter = ToolFormatter(tool_format="qwen")
    result = """<tool_call>\n{"name": "test_tool", "arguments": {"foo": "bar", "size": 10}}\n</tool_call>"""
    assert formatter.extract(result) == [("test_tool", """{"foo": "bar", "size": 10}""")]


@pytest.mark.runs_on(["cpu", "mps"])
def test_qwen_multi_tool_extractor():
    formatter = ToolFormatter(tool_format="qwen")
    result = (
        """<tool_call>\n{"name": "test_tool", "arguments": {"foo": "bar", "size": 10}}\n</tool_call>\n"""
        """<tool_call>\n{"name": "another_tool", "arguments": {"foo": "job", "size": 2}}\n</tool_call>"""
    )
    assert formatter.extract(result) == [
        ("test_tool", """{"foo": "bar", "size": 10}"""),
        ("another_tool", """{"foo": "job", "size": 2}"""),
    ]


--- tests/model/test_freeze.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

import torch

from llamafactory.train.test_utils import load_infer_model, load_train_model


TINY_LLAMA3 = os.getenv("TINY_LLAMA3", "llamafactory/tiny-random-Llama-3")

TRAIN_ARGS = {
    "model_name_or_path": TINY_LLAMA3,
    "stage": "sft",
    "do_train": True,
    "finetuning_type": "freeze",
    "dataset": "llamafactory/tiny-supervised-dataset",
    "dataset_dir": "ONLINE",
    "template": "llama3",
    "cutoff_len": 1024,
    "output_dir": "dummy_dir",
    "overwrite_output_dir": True,
    "fp16": True,
}

INFER_ARGS = {
    "model_name_or_path": TINY_LLAMA3,
    "finetuning_type": "freeze",
    "template": "llama3",
    "infer_dtype": "float16",
}


def test_freeze_train_all_modules():
    model = load_train_model(freeze_trainable_layers=1, **TRAIN_ARGS)
    for name, param in model.named_parameters():
        if name.startswith("model.layers.1."):
            assert param.requires_grad is True
            assert param.dtype == torch.float32
        else:
            assert param.requires_grad is False
            assert param.dtype == torch.float16


def test_freeze_train_extra_modules():
    model = load_train_model(freeze_trainable_layers=1, freeze_extra_modules="embed_tokens,lm_head", **TRAIN_ARGS)
    for name, param in model.named_parameters():
        if name.startswith("model.layers.1.") or any(module in name for module in ["embed_tokens", "lm_head"]):
            assert param.requires_grad is True
            assert param.dtype == torch.float32
        else:
            assert param.requires_grad is False
            assert param.dtype == torch.float16


def test_freeze_inference():
    model = load_infer_model(**INFER_ARGS)
    for param in model.parameters():
        assert param.requires_grad is False
        assert param.dtype == torch.float16


--- tests/model/test_full.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

import torch

from llamafactory.train.test_utils import load_infer_model, load_train_model


TINY_LLAMA3 = os.getenv("TINY_LLAMA3", "llamafactory/tiny-random-Llama-3")

TRAIN_ARGS = {
    "model_name_or_path": TINY_LLAMA3,
    "stage": "sft",
    "do_train": True,
    "finetuning_type": "full",
    "dataset": "llamafactory/tiny-supervised-dataset",
    "dataset_dir": "ONLINE",
    "template": "llama3",
    "cutoff_len": 1024,
    "output_dir": "dummy_dir",
    "overwrite_output_dir": True,
    "fp16": True,
}

INFER_ARGS = {
    "model_name_or_path": TINY_LLAMA3,
    "finetuning_type": "full",
    "template": "llama3",
    "infer_dtype": "float16",
}


def test_full_train():
    model = load_train_model(**TRAIN_ARGS)
    for param in model.parameters():
        assert param.requires_grad is True
        assert param.dtype == torch.float32


def test_full_inference():
    model = load_infer_model(**INFER_ARGS)
    for param in model.parameters():
        assert param.requires_grad is False
        assert param.dtype == torch.float16


--- tests_v1/conftest.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""LlamaFactory test configuration.

Contains shared fixtures, pytest configuration, and custom markers.
"""

import os
import sys

import pytest
import torch
import torch.distributed as dist
from pytest import Config, FixtureRequest, Item, MonkeyPatch

from llamafactory.v1.accelerator.helper import get_current_accelerator, get_device_count
from llamafactory.v1.utils.env import is_env_enabled
from llamafactory.v1.utils.packages import is_transformers_version_greater_than


CURRENT_DEVICE = get_current_accelerator().type


def pytest_configure(config: Config):
    """Register custom pytest markers."""
    config.addinivalue_line(
        "markers",
        "slow: marks tests as slow (deselect with '-m \"not slow\"' or set RUN_SLOW=1 to run)",
    )
    config.addinivalue_line(
        "markers",
        "runs_on: test requires specific device type, e.g., @pytest.mark.runs_on(['cuda'])",
    )
    config.addinivalue_line(
        "markers",
        "require_distributed(num_devices): allow multi-device execution (default: 2)",
    )


def _handle_runs_on(items: list[Item]):
    """Skip tests on specified device TYPES (cpu/cuda/npu)."""
    for item in items:
        marker = item.get_closest_marker("runs_on")
        if not marker:
            continue

        devices = marker.args[0]
        if isinstance(devices, str):
            devices = [devices]

        if CURRENT_DEVICE not in devices:
            item.add_marker(pytest.mark.skip(reason=f"test requires one of {devices} (current: {CURRENT_DEVICE})"))


def _handle_slow_tests(items: list[Item]):
    """Skip slow tests unless RUN_SLOW is enabled."""
    if not is_env_enabled("RUN_SLOW"):
        skip_slow = pytest.mark.skip(reason="slow test (set RUN_SLOW=1 to run)")
        for item in items:
            if "slow" in item.keywords:
                item.add_marker(skip_slow)


def _get_visible_devices_env() -> str | None:
    """Return device visibility env var name."""
    if CURRENT_DEVICE == "cuda":
        return "CUDA_VISIBLE_DEVICES"
    elif CURRENT_DEVICE == "npu":
        return "ASCEND_RT_VISIBLE_DEVICES"
    else:
        return None


def _handle_device_visibility(items: list[Item]):
    """Handle device visibility based on test markers."""
    env_key = _get_visible_devices_env()
    if env_key is None or CURRENT_DEVICE in ("cpu", "mps"):
        return

    # Parse visible devices
    visible_devices_env = os.environ.get(env_key)
    if visible_devices_env is None:
        available = get_device_count()
    else:
        visible_devices = [v for v in visible_devices_env.split(",") if v != ""]
        available = len(visible_devices)

    for item in items:
        marker = item.get_closest_marker("require_distributed")
        if not marker:
            continue

        required = marker.args[0] if marker.args else 2
        if available < required:
            item.add_marker(pytest.mark.skip(reason=f"test requires {required} devices, but only {available} visible"))


def pytest_collection_modifyitems(config: Config, items: list[Item]):
    """Modify test collection based on markers and environment."""
    # Handle version compatibility (from HEAD)
    skip_bc = pytest.mark.skip(reason="Skip backward compatibility tests")
    for item in items:
        if "tests_v1" in str(item.fspath) and not is_transformers_version_greater_than("4.57.0"):
            item.add_marker(skip_bc)

    _handle_slow_tests(items)
    _handle_runs_on(items)
    _handle_device_visibility(items)


@pytest.fixture(autouse=True)
def _cleanup_distributed_state():
    """Cleanup distributed state after each test."""
    yield
    if dist.is_initialized():
        dist.destroy_process_group()


@pytest.fixture(autouse=True)
def _manage_distributed_env(request: FixtureRequest, monkeypatch: MonkeyPatch) -> None:
    """Set environment variables for distributed tests if specific devices are requested."""
    env_key = _get_visible_devices_env()
    if not env_key:
        return

    # Save old environment for logic checks, monkeypatch handles restoration
    old_value = os.environ.get(env_key)

    marker = request.node.get_closest_marker("require_distributed")
    if marker:  # distributed test
        required = marker.args[0] if marker.args else 2
        specific_devices = marker.args[1] if len(marker.args) > 1 else None

        if specific_devices:
            devices_str = ",".join(map(str, specific_devices))
        else:
            devices_str = ",".join(str(i) for i in range(required))

        monkeypatch.setenv(env_key, devices_str)

        # add project root dir to path for mp run
        project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
        if project_root not in sys.path:
            sys.path.insert(0, project_root)

        os.environ["PYTHONPATH"] = project_root + os.pathsep + os.environ.get("PYTHONPATH", "")

    else:  # non-distributed test
        if old_value:
            visible_devices = [v for v in old_value.split(",") if v != ""]
            monkeypatch.setenv(env_key, visible_devices[0] if visible_devices else "0")
        else:
            monkeypatch.setenv(env_key, "0")

        if CURRENT_DEVICE == "cuda":
            monkeypatch.setattr(torch.cuda, "device_count", lambda: 1)
        elif CURRENT_DEVICE == "npu":
            monkeypatch.setattr(torch.npu, "device_count", lambda: 1)


--- tests_v1/config/test_args_parser.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import pathlib
import sys
from unittest.mock import patch

from llamafactory.v1.config.arg_parser import get_args


def test_get_args_from_yaml(tmp_path: pathlib.Path):
    config_yaml = """
        ### model
        model: "llamafactory/tiny-random-qwen2.5"
        trust_remote_code: true
        model_class: "llm"
        kernel_config:
          name: "auto"
          include_kernels: "auto" # choice: null/true/false/auto/kernel_id1,kernel_id2,kernel_id3, default is null
        peft_config:
          name: "lora"
          lora_rank: 0.8
        quant_config: null

        ### data
        dataset: "llamafactory/tiny-supervised-dataset"
        cutoff_len: 2048

        ### training
        output_dir: "outputs/test_run"
        micro_batch_size: 1
        global_batch_size: 1
        learning_rate: 1.0e-4
        bf16: false
        dist_config: null

        ### sample
        sample_backend: "hf"
        max_new_tokens: 128
    """

    config_file = tmp_path / "config.yaml"
    config_file.write_text(config_yaml, encoding="utf-8")

    test_argv = ["test_args_parser.py", str(config_file)]

    with patch.object(sys, "argv", test_argv):
        data_args, model_args, training_args, sample_args = get_args()
        assert training_args.output_dir == "outputs/test_run"
        assert training_args.micro_batch_size == 1
        assert training_args.global_batch_size == 1
        assert training_args.learning_rate == 1.0e-4
        assert training_args.bf16 is False
        assert training_args.dist_config is None
        assert model_args.model == "llamafactory/tiny-random-qwen2.5"
        assert model_args.kernel_config.name == "auto"
        assert model_args.kernel_config.get("include_kernels") == "auto"
        assert model_args.peft_config.name == "lora"
        assert model_args.peft_config.get("lora_rank") == 0.8


--- tests_v1/utils/test_batching_queue.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torch

from llamafactory.v1.utils.batching_queue import DynamicBatchSizeBuffer, TextBatchingQueue


def create_sample(length: int):
    """Helper to create a mock sample with a specific token length."""
    return {"input_ids": torch.ones(length), "attention_mask": torch.ones(length)}


class TestDynamicBatchSizeBuffer:
    def test_append_and_token_count(self):
        buffer = DynamicBatchSizeBuffer()
        buffer.append(create_sample(10))
        buffer.append(create_sample(20))

        assert len(buffer) == 2
        assert buffer.total_token_count == 30

    def test_get_samples_within_budget(self):
        buffer = DynamicBatchSizeBuffer()
        buffer.append(create_sample(10))
        buffer.append(create_sample(10))
        buffer.append(create_sample(50))  # This one is large

        # Request 25 tokens. Should get the first two (20 tokens total)
        samples = buffer.get_samples(max_tokens_per_iteration=25)
        assert len(samples) == 2

    def test_force_return_first_sample(self):
        buffer = DynamicBatchSizeBuffer()
        buffer.append(create_sample(100))

        # Even though budget is 50, force=True (default) should return the 100-token sample
        samples = buffer.get_samples(max_tokens_per_iteration=50, force=True)
        assert len(samples) == 1
        assert len(samples[0]["input_ids"]) == 100

    def test_flush_removes_used_samples(self):
        buffer = DynamicBatchSizeBuffer()
        buffer.append(create_sample(10))
        buffer.append(create_sample(20))

        # Take the first sample
        buffer.get_samples(max_tokens_per_iteration=15)
        buffer.flush()

        assert len(buffer) == 1
        assert buffer.total_token_count == 20
        # The remaining sample should now be at the start
        remaining = buffer.get_samples(max_tokens_per_iteration=50)
        assert len(remaining[0]["input_ids"]) == 20


class TestTextBatchingQueue:
    def test_is_full_filled(self):
        queue = TextBatchingQueue(token_micro_bsz=100, buffer_size=2)

        queue.put_item(create_sample(10))
        assert not queue.is_full_filled()  # Only 1 sample, buffer_size=2

        queue.put_item(create_sample(10))
        assert not queue.is_full_filled()  # 2 samples, but only 20 tokens (min 100)

        queue.put_item(create_sample(90))
        assert queue.is_full_filled()  # Meets both conditions

    def test_warmup_logic(self):
        # token_micro_bsz=1000, starts at 200, reaches 1000 at step 10
        queue = TextBatchingQueue(token_micro_bsz=1000, bsz_warmup_steps=10, bsz_warmup_init_mbtoken=200)

        # Step 0: should be init value
        assert queue.get_cur_token_micro_bsz() == 200

        # Step 5: halfway through warmup (200 + (800 * 5/10)) = 600
        queue._step = 5
        assert queue.get_cur_token_micro_bsz() == 600

        # Step 11: past warmup
        queue._step = 11
        assert queue.get_cur_token_micro_bsz() == 1000

    def test_get_micro_batch_integration(self):
        queue = TextBatchingQueue(token_micro_bsz=50, buffer_size=1)
        queue.put_item(create_sample(20))
        queue.put_item(create_sample(20))
        queue.put_item(create_sample(20))

        # At step 0 (warmup not triggered as bsz_warmup_steps is -1 default),
        # it should take samples up to 50 tokens.
        batch = queue.get_micro_batch(step=0)

        assert len(batch) == 2
        assert queue.empty() is False

        batch_2 = queue.get_micro_batch(step=1)
        assert len(batch_2) == 1
        assert queue.empty() is True


--- tests_v1/sampler/test_cli_sampler.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import pytest

from llamafactory.v1.config import ModelArguments, SampleArguments
from llamafactory.v1.core.model_engine import ModelEngine
from llamafactory.v1.samplers.cli_sampler import SyncSampler


@pytest.mark.runs_on(["cuda", "npu"])
def test_sync_sampler():
    model_args = ModelArguments(model="Qwen/Qwen3-4B-Instruct-2507", template="qwen3_nothink")
    sample_args = SampleArguments()
    model_engine = ModelEngine(model_args)
    sampler = SyncSampler(sample_args, model_args, model_engine.model, model_engine.renderer)
    messages = [{"role": "user", "content": [{"type": "text", "value": "Say 'This is a test.'"}]}]
    response = ""
    for new_text in sampler.generate(messages):
        response += new_text

    print(response)
    assert model_engine.renderer.parse_message(response) == {
        "role": "assistant",
        "content": [{"type": "text", "value": "This is a test."}],
    }


if __name__ == "__main__":
    test_sync_sampler()


--- tests_v1/core/test_data_engine.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import random

import pytest
from datasets import load_dataset

from llamafactory.v1.config.data_args import DataArguments
from llamafactory.v1.core.data_engine import DataEngine


@pytest.mark.parametrize("num_samples", [16])
def test_map_dataset(num_samples: int):
    data_args = DataArguments(dataset="llamafactory/v1-sft-demo")
    data_engine = DataEngine(data_args)
    original_data = load_dataset("llamafactory/v1-sft-demo", split="train")
    indexes = random.choices(range(len(data_engine)), k=num_samples)
    for index in indexes:
        print(data_engine[index])
        assert data_engine[index] == {"_dataset_name": "default", **original_data[index]}


if __name__ == "__main__":
    test_map_dataset(1)


--- tests_v1/accelerator/test_interface.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

import pytest
import torch.multiprocessing as mp

from llamafactory.v1.accelerator.helper import ReduceOp
from llamafactory.v1.accelerator.interface import DistributedInterface
from llamafactory.v1.utils.env import find_available_port
from llamafactory.v1.utils.pytest import dist_env


def _all_reduce_tests(local_rank: int, world_size: int, master_port: int):
    with dist_env(local_rank, world_size, master_port):
        rank = DistributedInterface().get_rank()
        world_size = DistributedInterface().get_world_size()
        assert world_size == 2

        y_sum = DistributedInterface().all_reduce(rank + 1.0, op=ReduceOp.SUM)
        assert y_sum == pytest.approx(3.0)

        y_mean = DistributedInterface().all_reduce(rank + 1.0, op=ReduceOp.MEAN)
        assert y_mean == pytest.approx(1.5)

        y_max = DistributedInterface().all_reduce(rank + 1.0, op=ReduceOp.MAX)
        assert y_max == pytest.approx(2.0)

        z = DistributedInterface().all_gather(rank + 1.0)
        assert z == pytest.approx([1.0, 2.0])

        z = DistributedInterface().broadcast(rank + 1.0)
        assert z == pytest.approx(1.0)


def test_all_device():
    assert DistributedInterface().get_rank() == int(os.getenv("RANK", "0"))
    assert DistributedInterface().get_world_size() == int(os.getenv("WORLD_SIZE", "1"))
    assert DistributedInterface().get_local_rank() == int(os.getenv("LOCAL_RANK", "0"))
    assert DistributedInterface().get_local_world_size() == int(os.getenv("LOCAL_WORLD_SIZE", "1"))


@pytest.mark.runs_on(["cuda", "npu"])
@pytest.mark.require_distributed(2)
def test_multi_device():
    master_port = find_available_port()
    mp.spawn(_all_reduce_tests, args=(2, master_port), nprocs=2)


--- tests_v1/core/test_model_loader.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import torch

from llamafactory.v1.config.model_args import ModelArguments, PluginConfig
from llamafactory.v1.core.model_engine import ModelEngine


def test_tiny_qwen():
    from transformers import Qwen2Config, Qwen2ForCausalLM, Qwen2TokenizerFast

    model_args = ModelArguments(model="llamafactory/tiny-random-qwen2.5")
    model_engine = ModelEngine(model_args)
    assert isinstance(model_engine.processor, Qwen2TokenizerFast)
    assert isinstance(model_engine.model_config, Qwen2Config)
    assert isinstance(model_engine.model, Qwen2ForCausalLM)
    assert model_engine.model.dtype == torch.bfloat16


def test_tiny_qwen_with_kernel_plugin():
    from transformers import Qwen2ForCausalLM

    from llamafactory.v1.plugins.model_plugins.kernels.ops.rms_norm.npu_rms_norm import npu_rms_norm_forward

    model_args = ModelArguments(
        model="llamafactory/tiny-random-qwen2.5", kernel_config=PluginConfig(name="auto", include_kernels="auto")
    )
    model_engine = ModelEngine(model_args)
    # test enable apply kernel plugin
    if hasattr(torch, "npu"):
        assert model_engine.model.model.layers[0].input_layernorm.forward.__code__ == npu_rms_norm_forward.__code__
    else:
        assert model_engine.model.model.layers[0].input_layernorm.forward.__code__ != npu_rms_norm_forward.__code__

    assert isinstance(model_engine.model, Qwen2ForCausalLM)


if __name__ == "__main__":
    test_tiny_qwen()
    test_tiny_qwen_with_kernel_plugin()


--- tests_v1/plugins/data_plugins/test_converter.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import random

import pytest
from datasets import load_dataset

from llamafactory.v1.config.data_args import DataArguments
from llamafactory.v1.core.data_engine import DataEngine
from llamafactory.v1.plugins.data_plugins.converter import DataConverterPlugin


@pytest.mark.parametrize("num_samples", [16])
def test_alpaca_converter(num_samples: int):
    data_args = DataArguments(dataset="llamafactory/v1-dataset-info/tiny-supervised-dataset.yaml")
    data_engine = DataEngine(data_args)
    original_data = load_dataset("llamafactory/tiny-supervised-dataset", split="train")
    indexes = random.choices(range(len(data_engine)), k=num_samples)
    for index in indexes:
        print(data_engine[index])
        expected_data = {
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "value": original_data[index]["instruction"] + original_data[index]["input"]}
                    ],
                    "loss_weight": 0.0,
                },
                {
                    "role": "assistant",
                    "content": [{"type": "text", "value": original_data[index]["output"]}],
                    "loss_weight": 1.0,
                },
            ]
        }
        assert data_engine[index] == {"_dataset_name": "tiny_dataset", **expected_data}


def test_sharegpt_converter():
    example = {
        "conversations": [
            {"from": "system", "value": "System"},
            {"from": "human", "value": "User"},
            {"from": "function_call", "value": "1"},
            {"from": "observation", "value": "Observation"},
            {"from": "gpt", "value": "Assistant"},
        ]
    }
    expected_data = {
        "messages": [
            {"role": "system", "content": [{"type": "text", "value": "System"}], "loss_weight": 0.0},
            {"role": "user", "content": [{"type": "text", "value": "User"}], "loss_weight": 0.0},
            {"role": "assistant", "content": [{"type": "tool_call", "value": "1"}], "loss_weight": 1.0},
            {"role": "tool", "content": [{"type": "text", "value": "Observation"}], "loss_weight": 0.0},
            {"role": "assistant", "content": [{"type": "text", "value": "Assistant"}], "loss_weight": 1.0},
        ]
    }
    assert DataConverterPlugin("sharegpt")(example) == expected_data


@pytest.mark.parametrize("num_samples", [16])
def test_pair_converter(num_samples: int):
    data_args = DataArguments(dataset="llamafactory/v1-dataset-info/orca-dpo-pairs.yaml")
    data_engine = DataEngine(data_args)
    original_data = load_dataset("HuggingFaceH4/orca_dpo_pairs", split="train_prefs")
    indexes = random.choices(range(len(data_engine)), k=num_samples)
    for index in indexes:
        print(data_engine[index])
        print(original_data[index])
        expected_data = {
            "chosen_messages": [
                {
                    "role": "system",
                    "content": [{"type": "text", "value": original_data[index]["chosen"][0]["content"]}],
                    "loss_weight": 0.0,
                },
                {
                    "role": "user",
                    "content": [{"type": "text", "value": original_data[index]["chosen"][1]["content"]}],
                    "loss_weight": 0.0,
                },
                {
                    "role": "assistant",
                    "content": [{"type": "text", "value": original_data[index]["chosen"][2]["content"]}],
                    "loss_weight": 1.0,
                },
            ],
            "rejected_messages": [
                {
                    "role": "system",
                    "content": [{"type": "text", "value": original_data[index]["rejected"][0]["content"]}],
                    "loss_weight": 0.0,
                },
                {
                    "role": "user",
                    "content": [{"type": "text", "value": original_data[index]["rejected"][1]["content"]}],
                    "loss_weight": 0.0,
                },
                {
                    "role": "assistant",
                    "content": [{"type": "text", "value": original_data[index]["rejected"][2]["content"]}],
                    "loss_weight": 1.0,
                },
            ],
        }
        assert data_engine[index] == {"_dataset_name": "tiny_dataset", **expected_data}


if __name__ == "__main__":
    test_alpaca_converter(1)
    test_sharegpt_converter()
    test_pair_converter(1)


--- tests_v1/core/utils/test_data_loader.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Integration tests for DataLoader with different combinations of packing and dynamic batching.

Tests the 4 scenarios:
a) non pack + non dynamic.
b) non pack + dynamic.
c) pack + non dynamic.
d) pack + dynamic.
"""

# import torch
# from torch.utils.data import DataLoader as TorchDataLoader
# from torch.utils.data import Dataset
# from transformers import AutoTokenizer

# from llamafactory.v1.config.data_args import DataArguments
# from llamafactory.v1.core.data_engine import DataEngine
# from llamafactory.v1.core.utils.data_collator import DefaultCollator
# from llamafactory.v1.core.utils.data_loader import DataLoader
# from llamafactory.v1.plugins.data_plugins.rendering import QwenTemplate
# from llamafactory.v1.utils.batching_queue import TextBatchingQueue


# class TensorDataset(Dataset):
#     """Wrapper dataset that converts DataEngine samples to tensor format."""

#     def __init__(self, data_engine: DataEngine, processor, template, max_samples: int = None):
#         self.data_engine = data_engine
#         self.processor = processor
#         self.template = template
#         self.max_samples = max_samples or len(data_engine)
#         self.tokenizer = processor.tokenizer if hasattr(processor, "tokenizer") else processor

#     def __len__(self):
#         return min(self.max_samples, len(self.data_engine))

#     def __getitem__(self, idx):
#         # Get sample from DataEngine
#         sample = self.data_engine[idx]

#         # Extract messages from sample
#         # DataEngine returns samples with format like {"messages": [...], ...}
#         # For llamafactory/v1-sft-demo, the format should have "messages" field
#         messages = None
#         if "messages" in sample:
#             messages = sample["messages"]
#         elif "conversations" in sample:
#             messages = sample["conversations"]
#         elif "conversation" in sample:
#             messages = sample["conversation"]
#         else:
#             # Try to find message-like fields (skip _dataset_name)
#             for key, value in sample.items():
#                 if key.startswith("_"):
#                     continue
#                 if isinstance(value, list) and len(value) > 0:
#                     # Check if it looks like a message list
#                     if isinstance(value[0], dict) and "role" in value[0]:
#                         messages = value
#                         break

#         if messages is None:
#             raise ValueError(f"Could not find messages in sample: {list(sample.keys())}")

#         # Encode messages using template
#         encoded = self.template.encode_messages(self.tokenizer, messages)

#         # Convert to tensors
#         return {
#             "input_ids": torch.tensor(encoded["input_ids"], dtype=torch.long),
#             "attention_mask": torch.tensor(encoded["attention_mask"], dtype=torch.long),
#             "labels": torch.tensor(encoded["labels"], dtype=torch.long),
#         }


# def create_real_dataset(max_samples: int = 20, batch_size: int = 4):
#     """Create a real dataset using DataEngine."""
#     data_args = DataArguments(dataset="llamafactory/v1-sft-demo")
#     data_engine = DataEngine(data_args)

#     # Create processor and template
#     processor = AutoTokenizer.from_pretrained("llamafactory/tiny-random-qwen2.5")
#     template = QwenTemplate()

#     # Create tensor dataset
#     raw_data_dataset = TensorDataset(data_engine, processor, template, max_samples=max_samples)

#     # Create torch DataLoader
#     torch_dataloader = TorchDataLoader(
#         raw_data_dataset,
#         batch_size=batch_size,
#         shuffle=False,
#         collate_fn=lambda x: x,
#     )

#     return torch_dataloader, processor, template


# class TestDataLoaderNonPackNonDynamic:
#     """Test case a) non pack + non dynamic."""

#     def test_basic_functionality(self):
#         """Test DataLoader without packing and without dynamic batching."""
#         # Create real dataset
#         torch_dataloader, processor, template = create_real_dataset(max_samples=80, batch_size=8)

#         # Create collator (non-packing)
#         collator = DefaultCollator(processor=processor, template=template)

#         # Create DataLoader without batching_queue (non-dynamic)
#         data_loader = DataLoader(
#             dataloader=torch_dataloader,
#             collate_fn=collator,
#             num_micro_batch=1,
#             batching_queue=None,
#         )

#         # Iterate and check results
#         batches = list(iter(data_loader))
#         assert len(batches) > 0

#         # Check first batch
#         one_batch = batches[0]
#         micro_batches = one_batch[0]
#         assert "input_ids" in micro_batches
#         assert "attention_mask" in micro_batches
#         assert "labels" in micro_batches
#         assert micro_batches["input_ids"].shape[0] == 1  # batch_size=1
#         assert micro_batches["input_ids"].ndim == 2  # [batch_size, seq_len]


# class TestDataLoaderNonPackDynamic:
#     """Test case b) non pack + dynamic."""

#     def test_basic_functionality(self):
#         """Test DataLoader without packing but with dynamic batching."""
#         # Create real dataset
#         torch_dataloader, processor, template = create_real_dataset(max_samples=80, batch_size=8)
#         collator = DefaultCollator(processor=processor, template=template)

#         # Create batching queue for dynamic batching
#         batching_queue = TextBatchingQueue(
#             token_micro_bsz=120,
#             buffer_size=8,
#         )

#         data_loader = DataLoader(
#             dataloader=torch_dataloader,
#             collate_fn=collator,
#             num_micro_batch=4,
#             batching_queue=batching_queue,
#         )

#         # Iterate and check
#         batches = list(iter(data_loader))
#         micro_batch_tokens_first = [micro_batch["attention_mask"].sum() for micro_batch in batches[0]]
#         assert all(num_tokens <= 120 for num_tokens in micro_batch_tokens_first)
#         assert len(batches) > 0


--- tests_v1/plugins/model_plugins/test_init_plugin.py ---
# Copyright 2025 the LlamaFactory team.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


from llamafactory.v1.accelerator.interface import DistributedInterface
from llamafactory.v1.config.arg_parser import get_args
from llamafactory.v1.core.model_engine import ModelEngine


def test_init_on_meta():
    _, model_args, *_ = get_args(
        dict(
            model="llamafactory/tiny-random-qwen2.5",
            init_config={"name": "init_on_meta"},
        )
    )
    model_engine = ModelEngine(model_args=model_args)
    assert model_engine.model.device.type == "meta"


def test_init_on_rank0():
    _, model_args, *_ = get_args(
        dict(
            model="llamafactory/tiny-random-qwen2.5",
            init_config={"name": "init_on_rank0"},
        )
    )
    model_engine = ModelEngine(model_args=model_args)
    if DistributedInterface().get_rank() == 0:
        assert model_engine.model.device.type == "cpu"
    else:
        assert model_engine.model.device.type == "meta"


def test_init_on_default():
    _, model_args, *_ = get_args(
        dict(
            model="llamafactory/tiny-random-qwen2.5",
            init_config={"name": "init_on_default"},
        )
    )
    model_engine = ModelEngine(model_args=model_args)
    assert model_engine.model.device == DistributedInterface().current_device
