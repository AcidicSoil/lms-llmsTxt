# llms-full (private-aware)
> Built from GitHub files and website pages. Large files may be truncated.

--- docs/install.md ---
Installation is as simple as:

=== "pip"

    ```bash
    pip install pydantic
    ```

=== "uv"

    ```bash
    uv add pydantic
    ```

Pydantic has a few dependencies:

* [`pydantic-core`](https://pypi.org/project/pydantic-core/): Core validation logic for Pydantic written in Rust.
* [`typing-extensions`](https://pypi.org/project/typing-extensions/): Backport of the standard library [typing][] module.
* [`annotated-types`](https://pypi.org/project/annotated-types/): Reusable constraint types to use with [`typing.Annotated`][].

If you've got Python 3.9+ and `pip` installed, you're good to go.

Pydantic is also available on [conda](https://www.anaconda.com) under the [conda-forge](https://conda-forge.org)
channel:

```bash
conda install pydantic -c conda-forge
```

## Optional dependencies

Pydantic has the following optional dependencies:

* `email`: Email validation provided by the [email-validator](https://pypi.org/project/email-validator/) package.
* `timezone`: Fallback IANA time zone database provided by the [tzdata](https://pypi.org/project/tzdata/) package.

To install optional dependencies along with Pydantic:

=== "pip"

    ```bash
    # with the `email` extra:
    pip install 'pydantic[email]'
    # or with `email` and `timezone` extras:
    pip install 'pydantic[email,timezone]'
    ```

=== "uv"

    ```bash
    # with the `email` extra:
    uv add 'pydantic[email]'
    # or with `email` and `timezone` extras:
    uv add 'pydantic[email,timezone]'
    ```

Of course, you can also install requirements manually with `pip install email-validator tzdata`.

## Install from repository

And if you prefer to install Pydantic directly from the repository:

=== "pip"

    ```bash
    pip install 'git+https://github.com/pydantic/pydantic@main'
    # or with `email` and `timezone` extras:
    pip install 'git+https://github.com/pydantic/pydantic@main#egg=pydantic[email,timezone]'
    ```

=== "uv"

    ```bash
    uv add 'git+https://github.com/pydantic/pydantic@main'
    # or with `email` and `timezone` extras:
    uv add 'git+https://github.com/pydantic/pydantic@main#egg=pydantic[email,timezone]'
    ```


## Links discovered
- [`pydantic-core`](https://pypi.org/project/pydantic-core/)
- [`typing-extensions`](https://pypi.org/project/typing-extensions/)
- [`annotated-types`](https://pypi.org/project/annotated-types/)
- [conda](https://www.anaconda.com)
- [conda-forge](https://conda-forge.org)
- [email-validator](https://pypi.org/project/email-validator/)
- [tzdata](https://pypi.org/project/tzdata/)

--- docs/examples/custom_validators.md ---
This page provides example snippets for creating more complex, custom validators in Pydantic.
Many of these examples are adapted from Pydantic issues and discussions, and are intended to showcase
the flexibility and power of Pydantic's validation system.

## Custom `datetime` Validator via [`Annotated`][typing.Annotated] Metadata

In this example, we'll construct a custom validator, attached to an [`Annotated`][typing.Annotated] type,
that ensures a [`datetime`][datetime.datetime] object adheres to a given timezone constraint.

The custom validator supports string specification of the timezone, and will raise an error if the [`datetime`][datetime.datetime] object does not have the correct timezone.

We use `__get_pydantic_core_schema__` in the validator to customize the schema of the annotated type (in this case, [`datetime`][datetime.datetime]), which allows us to add custom validation logic. Notably, we use a `wrap` validator function so that we can perform operations both before and after the default `pydantic` validation of a [`datetime`][datetime.datetime].

```python
import datetime as dt
from dataclasses import dataclass
from pprint import pprint
from typing import Annotated, Any, Callable, Optional

import pytz
from pydantic_core import CoreSchema, core_schema

from pydantic import (
    GetCoreSchemaHandler,
    PydanticUserError,
    TypeAdapter,
    ValidationError,
)


@dataclass(frozen=True)
class MyDatetimeValidator:
    tz_constraint: Optional[str] = None

    def tz_constraint_validator(
        self,
        value: dt.datetime,
        handler: Callable,  # (1)!
    ):
        """Validate tz_constraint and tz_info."""
        # handle naive datetimes
        if self.tz_constraint is None:
            assert (
                value.tzinfo is None
            ), 'tz_constraint is None, but provided value is tz-aware.'
            return handler(value)

        # validate tz_constraint and tz-aware tzinfo
        if self.tz_constraint not in pytz.all_timezones:
            raise PydanticUserError(
                f'Invalid tz_constraint: {self.tz_constraint}',
                code='unevaluable-type-annotation',
            )
        result = handler(value)  # (2)!
        assert self.tz_constraint == str(
            result.tzinfo
        ), f'Invalid tzinfo: {str(result.tzinfo)}, expected: {self.tz_constraint}'

        return result

    def __get_pydantic_core_schema__(
        self,
        source_type: Any,
        handler: GetCoreSchemaHandler,
    ) -> CoreSchema:
        return core_schema.no_info_wrap_validator_function(
            self.tz_constraint_validator,
            handler(source_type),
        )


LA = 'America/Los_Angeles'
ta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator(LA)])
print(
    ta.validate_python(dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LA)))
)
#> 2023-01-01 00:00:00-07:53

LONDON = 'Europe/London'
try:
    ta.validate_python(
        dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LONDON))
    )
except ValidationError as ve:
    pprint(ve.errors(), width=100)
    """
    [{'ctx': {'error': AssertionError('Invalid tzinfo: Europe/London, expected: America/Los_Angeles')},
    'input': datetime.datetime(2023, 1, 1, 0, 0, tzinfo=<DstTzInfo 'Europe/London' LMT-1 day, 23:59:00 STD>),
    'loc': (),
    'msg': 'Assertion failed, Invalid tzinfo: Europe/London, expected: America/Los_Angeles',
    'type': 'assertion_error',
    'url': 'https://errors.pydantic.dev/2.8/v/assertion_error'}]
    """
```

1. The `handler` function is what we call to validate the input with standard `pydantic` validation
2. We call the `handler` function to validate the input with standard `pydantic` validation in this wrap validator

We can also enforce UTC offset constraints in a similar way.  Assuming we have a `lower_bound` and an `upper_bound`, we can create a custom validator to ensure our `datetime` has a UTC offset that is inclusive within the boundary we define:

```python
import datetime as dt
from dataclasses import dataclass
from pprint import pprint
from typing import Annotated, Any, Callable

import pytz
from pydantic_core import CoreSchema, core_schema

from pydantic import GetCoreSchemaHandler, TypeAdapter, ValidationError


@dataclass(frozen=True)
class MyDatetimeValidator:
    lower_bound: int
    upper_bound: int

    def validate_tz_bounds(self, value: dt.datetime, handler: Callable):
        """Validate and test bounds"""
        assert value.utcoffset() is not None, 'UTC offset must exist'
        assert self.lower_bound <= self.upper_bound, 'Invalid bounds'

        result = handler(value)

        hours_offset = value.utcoffset().total_seconds() / 3600
        assert (
            self.lower_bound <= hours_offset <= self.upper_bound
        ), 'Value out of bounds'

        return result

    def __get_pydantic_core_schema__(
        self,
        source_type: Any,
        handler: GetCoreSchemaHandler,
    ) -> CoreSchema:
        return core_schema.no_info_wrap_validator_function(
            self.validate_tz_bounds,
            handler(source_type),
        )


LA = 'America/Los_Angeles'  # UTC-7 or UTC-8
ta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator(-10, -5)])
print(
    ta.validate_python(dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LA)))
)
#> 2023-01-01 00:00:00-07:53

LONDON = 'Europe/London'
try:
    print(
        ta.validate_python(
            dt.datetime(2023, 1, 1, 0, 0, tzinfo=pytz.timezone(LONDON))
        )
    )
except ValidationError as e:
    pprint(e.errors(), width=100)
    """
    [{'ctx': {'error': AssertionError('Value out of bounds')},
    'input': datetime.datetime(2023, 1, 1, 0, 0, tzinfo=<DstTzInfo 'Europe/London' LMT-1 day, 23:59:00 STD>),
    'loc': (),
    'msg': 'Assertion failed, Value out of bounds',
    'type': 'assertion_error',
    'url': 'https://errors.pydantic.dev/2.8/v/assertion_error'}]
    """
```

## Validating Nested Model Fields

Here, we demonstrate two ways to validate a field of a nested model, where the validator utilizes data from the parent model.

In this example, we construct a validator that checks that each user's password is not in a list of forbidden passwords specified by the parent model.

One way to do this is to place a custom validator on the outer model:

```python
from typing_extensions import Self

from pydantic import BaseModel, ValidationError, model_validator


class User(BaseModel):
    username: str
    password: str


class Organization(BaseModel):
    forbidden_passwords: list[str]
    users: list[User]

    @model_validator(mode='after')
    def validate_user_passwords(self) -> Self:
        """Check that user password is not in forbidden list. Raise a validation error if a forbidden password is encountered."""
        for user in self.users:
            current_pw = user.password
            if current_pw in self.forbidden_passwords:
                raise ValueError(
                    f'Password {current_pw} is forbidden. Please choose another password for user {user.username}.'
                )
        return self


data = {
    'forbidden_passwords': ['123'],
    'users': [
        {'username': 'Spartacat', 'password': '123'},
        {'username': 'Iceburgh', 'password': '87'},
    ],
}
try:
    org = Organization(**data)
except ValidationError as e:
    print(e)
    """
    1 validation error for Organization
      Value error, Password 123 is forbidden. Please choose another password for user Spartacat. [type=value_error, input_value={'forbidden_passwords': [...gh', 'password': '87'}]}, input_type=dict]
    """
```

Alternatively, a custom validator can be used in the nested model class (`User`), with the forbidden passwords data from the parent model being passed in via validation context.

!!! warning
    The ability to mutate the context within a validator adds a lot of power to nested validation, but can also lead to confusing or hard-to-debug code. Use this approach at your own risk!

```python
from pydantic import BaseModel, ValidationError, ValidationInfo, field_validator


class User(BaseModel):
    username: str
    password: str

    @field_validator('password', mode='after')
    @classmethod
    def validate_user_passwords(
        cls, password: str, info: ValidationInfo
    ) -> str:
        """Check that user password is not in forbidden list."""
        forbidden_passwords = (
            info.context.get('forbidden_passwords', []) if info.context else []
        )
        if password in forbidden_passwords:
            raise ValueError(f'Password {password} is forbidden.')
        return password


class Organization(BaseModel):
    forbidden_passwords: list[str]
    users: list[User]

    @field_validator('forbidden_passwords', mode='after')
    @classmethod
    def add_context(cls, v: list[str], info: ValidationInfo) -> list[str]:
        if info.context is not None:
            info.context.update({'forbidden_passwords': v})
        return v


data = {
    'forbidden_passwords': ['123'],
    'users': [
        {'username': 'Spartacat', 'password': '123'},
        {'username': 'Iceburgh', 'password': '87'},
    ],
}

try:
    org = Organization.model_validate(data, context={})
except ValidationError as e:
    print(e)
    """
    1 validation error for Organization
    users.0.password
      Value error, Password 123 is forbidden. [type=value_error, input_value='123', input_type=str]
    """
```

Note that if the context property is not included in `model_validate`, then `info.context` will be `None` and the forbidden passwords list will not get added to the context in the above implementation. As such, `validate_user_passwords` would not carry out the desired password validation.

More details about validation context can be found in the [validators documentation](../concepts/validators.md#validation-context).


## Links discovered
- [validators documentation](https://github.com/pydantic/pydantic/blob/main/docs/concepts/validators.md#validation-context)

--- docs/examples/dynamic_models.md ---
Models can be [created dynamically](../concepts/models.md#dynamic-model-creation) using the [`create_model()`][pydantic.create_model]
factory function.

In this example, we will show how to dynamically derive a model from an existing one, making every field optional. To achieve this,
we will make use of the [`model_fields`][pydantic.main.BaseModel.model_fields] model class attribute, and derive new annotations
from the field definitions to be passed to the [`create_model()`][pydantic.create_model] factory. Of course, this example can apply
to any use case where you need to derive a new model from another (remove default values, add aliases, etc).

=== "Python 3.9"

    ```python {lint="skip" linenums="1"}
    from typing import Annotated, Union

    from pydantic import BaseModel, Field, create_model


    def make_fields_optional(model_cls: type[BaseModel]) -> type[BaseModel]:
        new_fields = {}

        for f_name, f_info in model_cls.model_fields.items():
            f_dct = f_info.asdict()
            new_fields[f_name] = (
                Annotated[(Union[f_dct['annotation'], None], *f_dct['metadata'], Field(**f_dct['attributes']))],
                None,
            )

        return create_model(
            f'{type.__name__}Optional',
            __base__=model_cls,  # (1)!
            **new_fields,
        )
    ```

    1. Using the original model as a base will inherit the [validators](../concepts/validators.md), [computed fields](../concepts/fields.md#the-computed_field-decorator), etc.
    The parent fields are overridden by the ones we define.

=== "Python 3.10"

    ```python {lint="skip" requires="3.10" linenums="1"}
    from typing import Annotated

    from pydantic import BaseModel, Field, create_model


    def make_fields_optional(model_cls: type[BaseModel]) -> type[BaseModel]:
        new_fields = {}

        for f_name, f_info in model_cls.model_fields.items():
            f_dct = f_info.asdict()
            new_fields[f_name] = (
                Annotated[(f_dct['annotation'] | None, *f_dct['metadata'], Field(**f_dct['attributes']))],
                None,
            )

        return create_model(
            f'{type.__name__}Optional',
            __base__=model_cls,  # (1)!
            **new_fields,
        )
    ```

    1. Using the original model as a base will inherit the [validators](../concepts/validators.md), [computed fields](../concepts/fields.md#the-computed_field-decorator), etc.
    The parent fields are overridden by the ones we define.

=== "Python 3.11 and above"

    ```python {lint="skip" requires="3.11" linenums="1"}
    from typing import Annotated

    from pydantic import BaseModel, Field, create_model


    def make_fields_optional(model_cls: type[BaseModel]) -> type[BaseModel]:
        new_fields = {}

        for f_name, f_info in model_cls.model_fields.items():
            f_dct = f_info.asdict()
            new_fields[f_name] = (
                Annotated[f_dct['annotation'] | None, *f_dct['metadata'], Field(**f_dct['attributes'])],
                None,
            )

        return create_model(
            f'{type.__name__}Optional',
            __base__=model_cls,  # (1)!
            **new_fields,
        )
    ```

    1. Using the original model as a base will inherit the [validators](../concepts/validators.md), [computed fields](../concepts/fields.md#the-computed_field-decorator), etc.
    The parent fields are overridden by the ones we define.

For each field, we generate a dictionary representation of the [`FieldInfo`][pydantic.fields.FieldInfo] instance
using the [`asdict()`][pydantic.fields.FieldInfo.asdict] method, containing the annotation, metadata and attributes.

With the following model:

```python {lint="skip" test="skip"}
class Model(BaseModel):
    f: Annotated[int, Field(gt=1), WithJsonSchema({'extra': 'data'}), Field(title='F')] = 1
```

The [`FieldInfo`][pydantic.fields.FieldInfo] instance of `f` will have three items in its dictionary representation:

* `annotation`: `int`.
* `metadata`: A list containing the type-specific constraints and other metadata: `[Gt(1), WithJsonSchema({'extra': 'data'})]`.
* `attributes`: The remaining field-specific attributes: `{'title': 'F'}`.

With that in mind, we can recreate an annotation that "simulates" the one from the original model:

=== "Python 3.9 and above"

    ```python {lint="skip" test="skip"}
    new_annotation = Annotated[(
        f_dct['annotation'] | None,  # (1)!
        *f_dct['metadata'],  # (2)!
        Field(**f_dct['attributes']),  # (3)!
    )]
    ```

    1. We create a new annotation from the existing one, but adding `None` as an allowed value
       (in our previous example, this is equivalent to `int | None`).

    2. We unpack the metadata to be reused (in our previous example, this is equivalent to
       specifying `Field(gt=1)` and `WithJsonSchema({'extra': 'data'})` as [`Annotated`][typing.Annotated]
       metadata).

    3. We specify the field-specific attributes by using the [`Field()`][pydantic.Field] function
       (in our previous example, this is equivalent to `Field(title='F')`).

=== "Python 3.11 and above"

    ```python {lint="skip" test="skip"}
    new_annotation = Annotated[
        f_dct['annotation'] | None,  # (1)!
        *f_dct['metadata'],  # (2)!
        Field(**f_dct['attributes']),  # (3)!
    ]
    ```

    1. We create a new annotation from the existing one, but adding `None` as an allowed value
       (in our previous example, this is equivalent to `int | None`).

    2. We unpack the metadata to be reused (in our previous example, this is equivalent to
       specifying `Field(gt=1)` and `WithJsonSchema({'extra': 'data'})` as [`Annotated`][typing.Annotated]
       metadata).

    3. We specify the field-specific attributes by using the [`Field()`][pydantic.Field] function
       (in our previous example, this is equivalent to `Field(title='F')`).

and specify `None` as a default value (the second element of the tuple for the field definition accepted by [`create_model()`][pydantic.create_model]).

Here is a demonstration of our factory function:

```python {lint="skip" test="skip"}
from pydantic import BaseModel, Field


class Model(BaseModel):
    a: Annotated[int, Field(gt=1)]


ModelOptional = make_fields_optional(Model)

m = ModelOptional()
print(m.a)
#> None
```

A couple notes on the implementation:

* Our `make_fields_optional()` function is defined as returning an arbitrary Pydantic model class (`-> type[BaseModel]`).
  An alternative solution can be to use a type variable to preserve the input class:

    === "Python 3.9 and above"

        ```python {lint="skip" test="skip"}
        ModelTypeT = TypeVar('ModelTypeT', bound=type[BaseModel])

        def make_fields_optional(model_cls: ModelTypeT) -> ModelTypeT:
            ...
        ```

    === "Python 3.12 and above"

        ```python {lint="skip" test="skip"}
        def make_fields_optional[ModelTypeT: type[BaseModel]](model_cls: ModelTypeT) -> ModelTypeT:
            ...
        ```

    However, note that static type checkers *won't* be able to understand that all fields are now optional.

* The experimental [`MISSING` sentinel](../concepts/experimental.md#missing-sentinel) can be used as an alternative to `None`
  for the default values. Simply replace `None` by `MISSING` in the new annotation and default value.

* You might be tempted to make a copy of the original [`FieldInfo`][pydantic.fields.FieldInfo] instances, add a
  default and/or perform other mutations, to then reuse it as [`Annotated`][typing.Annotated] metadata. While this
  may work in some cases, it is **not** a supported pattern, and could break or be deprecated at any point. We strongly
  encourage using the pattern from this example instead.


## Links discovered
- [created dynamically](https://github.com/pydantic/pydantic/blob/main/docs/concepts/models.md#dynamic-model-creation)
- [validators](https://github.com/pydantic/pydantic/blob/main/docs/concepts/validators.md)
- [computed fields](https://github.com/pydantic/pydantic/blob/main/docs/concepts/fields.md#the-computed_field-decorator)
- [`MISSING` sentinel](https://github.com/pydantic/pydantic/blob/main/docs/concepts/experimental.md#missing-sentinel)

--- docs/examples/files.md ---
`pydantic` is a great tool for validating data coming from various sources.
In this section, we will look at how to validate data from different types of files.

!!! note
    If you're using any of the below file formats to parse configuration / settings, you might want to
    consider using the [`pydantic-settings`][pydantic_settings] library, which offers builtin
    support for parsing this type of data.

## JSON data

`.json` files are a common way to store key / value data in a human-readable format.
Here is an example of a `.json` file:

```json
{
    "name": "John Doe",
    "age": 30,
    "email": "john@example.com"
}
```

To validate this data, we can use a `pydantic` model:

```python {test="skip"}
import pathlib

from pydantic import BaseModel, EmailStr, PositiveInt


class Person(BaseModel):
    name: str
    age: PositiveInt
    email: EmailStr


json_string = pathlib.Path('person.json').read_text()
person = Person.model_validate_json(json_string)
print(person)
#> name='John Doe' age=30 email='john@example.com'
```

If the data in the file is not valid, `pydantic` will raise a [`ValidationError`][pydantic_core.ValidationError].
Let's say we have the following `.json` file:

```json
{
    "age": -30,
    "email": "not-an-email-address"
}
```

This data is flawed for three reasons:

1. It's missing the `name` field.
2. The `age` field is negative.
3. The `email` field is not a valid email address.

When we try to validate this data, `pydantic` raises a [`ValidationError`][pydantic_core.ValidationError] with all of the
above issues:

```python {test="skip"}
import pathlib

from pydantic import BaseModel, EmailStr, PositiveInt, ValidationError


class Person(BaseModel):
    name: str
    age: PositiveInt
    email: EmailStr


json_string = pathlib.Path('person.json').read_text()
try:
    person = Person.model_validate_json(json_string)
except ValidationError as err:
    print(err)
    """
    3 validation errors for Person
    name
    Field required [type=missing, input_value={'age': -30, 'email': 'not-an-email-address'}, input_type=dict]
        For further information visit https://errors.pydantic.dev/2.10/v/missing
    age
    Input should be greater than 0 [type=greater_than, input_value=-30, input_type=int]
        For further information visit https://errors.pydantic.dev/2.10/v/greater_than
    email
    value is not a valid email address: An email address must have an @-sign. [type=value_error, input_value='not-an-email-address', input_type=str]
    """
```

Often, it's the case that you have an abundance of a certain type of data within a `.json` file.
For example, you might have a list of people:

```json
[
    {
        "name": "John Doe",
        "age": 30,
        "email": "john@example.com"
    },
    {
        "name": "Jane Doe",
        "age": 25,
        "email": "jane@example.com"
    }
]
```

In this case, you can validate the data against a `list[Person]` model:

```python {test="skip"}
import pathlib

from pydantic import BaseModel, EmailStr, PositiveInt, TypeAdapter


class Person(BaseModel):
    name: str
    age: PositiveInt
    email: EmailStr


person_list_adapter = TypeAdapter(list[Person])  # (1)!

json_string = pathlib.Path('people.json').read_text()
people = person_list_adapter.validate_json(json_string)
print(people)
#> [Person(name='John Doe', age=30, email='john@example.com'), Person(name='Jane Doe', age=25, email='jane@example.com')]
```

1. We use [`TypeAdapter`][pydantic.type_adapter.TypeAdapter] to validate a list of `Person` objects.
[`TypeAdapter`][pydantic.type_adapter.TypeAdapter] is a Pydantic construct used to validate data against a single type.

## JSON lines files

Similar to validating a list of objects from a `.json` file, you can validate a list of objects from a `.jsonl` file.
`.jsonl` files are a sequence of JSON objects separated by newlines.

Consider the following `.jsonl` file:

```json
{"name": "John Doe", "age": 30, "email": "john@example.com"}
{"name": "Jane Doe", "age": 25, "email": "jane@example.com"}
```

We can validate this data with a similar approach to the one we used for `.json` files:

```python {test="skip"}
import pathlib

from pydantic import BaseModel, EmailStr, PositiveInt


class Person(BaseModel):
    name: str
    age: PositiveInt
    email: EmailStr


json_lines = pathlib.Path('people.jsonl').read_text().splitlines()
people = [Person.model_validate_json(line) for line in json_lines]
print(people)
#> [Person(name='John Doe', age=30, email='john@example.com'), Person(name='Jane Doe', age=25, email='jane@example.com')]
```

## CSV files

CSV is one of the most common file formats for storing tabular data.
To validate data from a CSV file, you can use the `csv` module from the Python standard library to load
the data and validate it against a Pydantic model.

Consider the following CSV file:

```csv
name,age,email
John Doe,30,john@example.com
Jane Doe,25,jane@example.com
```

Here's how we validate that data:

```python {test="skip"}
import csv

from pydantic import BaseModel, EmailStr, PositiveInt


class Person(BaseModel):
    name: str
    age: PositiveInt
    email: EmailStr


with open('people.csv') as f:
    reader = csv.DictReader(f)
    people = [Person.model_validate(row) for row in reader]

print(people)
#> [Person(name='John Doe', age=30, email='john@example.com'), Person(name='Jane Doe', age=25, email='jane@example.com')]
```

## TOML files

TOML files are often used for configuration due to their simplicity and readability.

Consider the following TOML file:

```toml
name = "John Doe"
age = 30
email = "john@example.com"
```

Here's how we validate that data:

```python {test="skip"}
import tomllib

from pydantic import BaseModel, EmailStr, PositiveInt


class Person(BaseModel):
    name: str
    age: PositiveInt
    email: EmailStr


with open('person.toml', 'rb') as f:
    data = tomllib.load(f)

person = Person.model_validate(data)
print(person)
#> name='John Doe' age=30 email='john@example.com'
```

## YAML files

YAML (YAML Ain't Markup Language) is a human-readable data serialization format that is often used for configuration files.

Consider the following YAML file:

```yaml
name: John Doe
age: 30
email: john@example.com
```

Here's how we validate that data:

```python {test="skip"}
import yaml

from pydantic import BaseModel, EmailStr, PositiveInt


class Person(BaseModel):
    name: str
    age: PositiveInt
    email: EmailStr


with open('person.yaml') as f:
    data = yaml.safe_load(f)

person = Person.model_validate(data)
print(person)
#> name='John Doe' age=30 email='john@example.com'
```

## XML files

XML (eXtensible Markup Language) is a markup language that defines a set of rules for encoding documents in a format that is both human-readable and machine-readable.

Consider the following XML file:

```xml
<?xml version="1.0"?>
<person>
    <name>John Doe</name>
    <age>30</age>
    <email>john@example.com</email>
</person>
```

Here's how we validate that data:

```python {test="skip"}
import xml.etree.ElementTree as ET

from pydantic import BaseModel, EmailStr, PositiveInt


class Person(BaseModel):
    name: str
    age: PositiveInt
    email: EmailStr


tree = ET.parse('person.xml').getroot()
data = {child.tag: child.text for child in tree}
person = Person.model_validate(data)
print(person)
#> name='John Doe' age=30 email='john@example.com'
```

## INI files

INI files are a simple configuration file format that uses sections and key-value pairs. They are commonly used in Windows applications and older software.

Consider the following INI file:

```ini
[PERSON]
name = John Doe
age = 30
email = john@example.com
```

Here's how we validate that data:

```python {test="skip"}
import configparser

from pydantic import BaseModel, EmailStr, PositiveInt


class Person(BaseModel):
    name: str
    age: PositiveInt
    email: EmailStr


config = configparser.ConfigParser()
config.read('person.ini')
person = Person.model_validate(config['PERSON'])
print(person)
#> name='John Doe' age=30 email='john@example.com'
```


--- docs/examples/orms.md ---
Pydantic serves as a great tool for defining models for ORM (object relational mapping) libraries.
ORMs are used to map objects to database tables, and vice versa.

## SQLAlchemy

Pydantic can pair with SQLAlchemy, as it can be used to define the schema of the database models.

!!! warning "Code Duplication"
    If you use Pydantic with SQLAlchemy, you might experience some frustration with code duplication.
    If you find yourself experiencing this difficulty, you might also consider [`SQLModel`](https://sqlmodel.tiangolo.com/) which integrates Pydantic with SQLAlchemy such that much of the code duplication is eliminated.

If you'd prefer to use pure Pydantic with SQLAlchemy, we recommend using Pydantic models alongside of SQLAlchemy models
as shown in the example below. In this case, we take advantage of Pydantic's aliases feature to name a `Column` after a reserved SQLAlchemy field, thus avoiding conflicts.

```python
import sqlalchemy as sa
from sqlalchemy.orm import declarative_base

from pydantic import BaseModel, ConfigDict, Field


class MyModel(BaseModel):
    model_config = ConfigDict(from_attributes=True)

    metadata: dict[str, str] = Field(alias='metadata_')


Base = declarative_base()


class MyTableModel(Base):
    __tablename__ = 'my_table'
    id = sa.Column('id', sa.Integer, primary_key=True)
    # 'metadata' is reserved by SQLAlchemy, hence the '_'
    metadata_ = sa.Column('metadata', sa.JSON)


sql_model = MyTableModel(metadata_={'key': 'val'}, id=1)
pydantic_model = MyModel.model_validate(sql_model)

print(pydantic_model.model_dump())
#> {'metadata': {'key': 'val'}}
print(pydantic_model.model_dump(by_alias=True))
#> {'metadata_': {'key': 'val'}}
```

!!! note
    The example above works because aliases have priority over field names for
    field population. Accessing `SQLModel`'s `metadata` attribute would lead to a `ValidationError`.

<!-- TODO: add examples for Django with Pydantic models -->


## Links discovered
- [`SQLModel`](https://sqlmodel.tiangolo.com/)

--- docs/examples/pydantic_ai.md ---
[Pydantic AI](https://ai.pydantic.dev/) is a Python agent framework built by the Pydantic team that uses Pydantic validation for [structured output](https://ai.pydantic.dev/output/#structured-output) schema generation and validation.
By specifying an `output_type` on an Agent, you can constrain the LLM to return data that matches your Pydantic model schema.

## LLM Structured Output

```python {test="skip"}
from pydantic_ai import Agent

from pydantic import BaseModel, Field, ValidationInfo, field_validator


class City(BaseModel):
    name: str
    country: str
    population: int = Field(description='Estimated population', gt=0)

    @field_validator('country')
    @classmethod
    def country_must_be_valid(cls, v: str, info: ValidationInfo) -> str:
        valid_countries: list[str] = info.context or []
        if v not in valid_countries:
            raise ValueError(f'Unknown country: {v!r}')
        return v


agent = Agent(
    'openai:gpt-5-mini',
    output_type=list[City],
    # Pydantic validation context (not sent to the model)
    validation_context=['Japan', 'United States', 'Germany'],
)

result = agent.run_sync('List the 3 largest cities in Japan')
print(result.output)
#> [City(name='Tokyo', country='Japan', population=13960000), ...]
```


## Links discovered
- [Pydantic AI](https://ai.pydantic.dev/)
- [structured output](https://ai.pydantic.dev/output/#structured-output)

--- docs/examples/queues.md ---
Pydantic is quite helpful for validating data that goes into and comes out of queues. Below,
we'll explore how to validate / serialize data with various queue systems.

## Redis queue

Redis is a popular in-memory data structure store.

In order to run this example locally, you'll first need to [install Redis](https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/)
and start your server up locally.

Here's a simple example of how you can use Pydantic to:

1. Serialize data to push to the queue
2. Deserialize and validate data when it's popped from the queue

```python {test="skip"}
import redis

from pydantic import BaseModel, EmailStr


class User(BaseModel):
    id: int
    name: str
    email: EmailStr


r = redis.Redis(host='localhost', port=6379, db=0)
QUEUE_NAME = 'user_queue'


def push_to_queue(user_data: User) -> None:
    serialized_data = user_data.model_dump_json()
    r.rpush(QUEUE_NAME, serialized_data)
    print(f'Added to queue: {serialized_data}')


user1 = User(id=1, name='John Doe', email='john@example.com')
user2 = User(id=2, name='Jane Doe', email='jane@example.com')

push_to_queue(user1)
#> Added to queue: {"id":1,"name":"John Doe","email":"john@example.com"}

push_to_queue(user2)
#> Added to queue: {"id":2,"name":"Jane Doe","email":"jane@example.com"}


def pop_from_queue() -> None:
    data = r.lpop(QUEUE_NAME)

    if data:
        user = User.model_validate_json(data)
        print(f'Validated user: {repr(user)}')
    else:
        print('Queue is empty')


pop_from_queue()
#> Validated user: User(id=1, name='John Doe', email='john@example.com')

pop_from_queue()
#> Validated user: User(id=2, name='Jane Doe', email='jane@example.com')

pop_from_queue()
#> Queue is empty
```

## RabbitMQ

RabbitMQ is a popular message broker that implements the AMQP protocol.

In order to run this example locally, you'll first need to [install RabbitMQ](https://www.rabbitmq.com/download.html) and start your server.

Here's a simple example of how you can use Pydantic to:

1. Serialize data to push to the queue
2. Deserialize and validate data when it's popped from the queue

First, let's create a sender script.

```python {test="skip"}
import pika

from pydantic import BaseModel, EmailStr


class User(BaseModel):
    id: int
    name: str
    email: EmailStr


connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
channel = connection.channel()
QUEUE_NAME = 'user_queue'
channel.queue_declare(queue=QUEUE_NAME)


def push_to_queue(user_data: User) -> None:
    serialized_data = user_data.model_dump_json()
    channel.basic_publish(
        exchange='',
        routing_key=QUEUE_NAME,
        body=serialized_data,
    )
    print(f'Added to queue: {serialized_data}')


user1 = User(id=1, name='John Doe', email='john@example.com')
user2 = User(id=2, name='Jane Doe', email='jane@example.com')

push_to_queue(user1)
#> Added to queue: {"id":1,"name":"John Doe","email":"john@example.com"}

push_to_queue(user2)
#> Added to queue: {"id":2,"name":"Jane Doe","email":"jane@example.com"}

connection.close()
```

And here's the receiver script.

```python {test="skip"}
import pika

from pydantic import BaseModel, EmailStr


class User(BaseModel):
    id: int
    name: str
    email: EmailStr


def main():
    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
    channel = connection.channel()
    QUEUE_NAME = 'user_queue'
    channel.queue_declare(queue=QUEUE_NAME)

    def process_message(
        ch: pika.channel.Channel,
        method: pika.spec.Basic.Deliver,
        properties: pika.spec.BasicProperties,
        body: bytes,
    ):
        user = User.model_validate_json(body)
        print(f'Validated user: {repr(user)}')
        ch.basic_ack(delivery_tag=method.delivery_tag)

    channel.basic_consume(queue=QUEUE_NAME, on_message_callback=process_message)
    channel.start_consuming()


if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        pass
```

To test this example:

1. Run the receiver script in one terminal to start the consumer.
2. Run the sender script in another terminal to send messages.

## ARQ

ARQ is a fast Redis-based job queue for Python.
It's built on top of Redis and provides a simple way to handle background tasks.

In order to run this example locally, you’ll need to [Install Redis](https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/) and start your server.

Here's a simple example of how you can use Pydantic with ARQ to:

1. Define a model for your job data
2. Serialize data when enqueueing jobs
3. Validate and deserialize data when processing jobs

```python {test="skip"}
import asyncio
from typing import Any

from arq import create_pool
from arq.connections import RedisSettings

from pydantic import BaseModel, EmailStr


class User(BaseModel):
    id: int
    name: str
    email: EmailStr


REDIS_SETTINGS = RedisSettings()


async def process_user(ctx: dict[str, Any], user_data: dict[str, Any]) -> None:
    user = User.model_validate(user_data)
    print(f'Processing user: {repr(user)}')


async def enqueue_jobs(redis):
    user1 = User(id=1, name='John Doe', email='john@example.com')
    user2 = User(id=2, name='Jane Doe', email='jane@example.com')

    await redis.enqueue_job('process_user', user1.model_dump())
    print(f'Enqueued user: {repr(user1)}')

    await redis.enqueue_job('process_user', user2.model_dump())
    print(f'Enqueued user: {repr(user2)}')


class WorkerSettings:
    functions = [process_user]
    redis_settings = REDIS_SETTINGS


async def main():
    redis = await create_pool(REDIS_SETTINGS)
    await enqueue_jobs(redis)


if __name__ == '__main__':
    asyncio.run(main())
```

This script is complete.
It should run "as is" both to enqueue jobs and to process them.
<!-- TODO: kafka, celery, etc - better for SEO, great for new contributors! -->


## Links discovered
- [install Redis](https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/)
- [install RabbitMQ](https://www.rabbitmq.com/download.html)
- [Install Redis](https://redis.io/docs/latest/operate/oss_and_stack/install/install-redis/)

--- docs/examples/requests.md ---
Pydantic models are a great way to validate and serialize data for requests and responses.
Pydantic is instrumental in many web frameworks and libraries, such as FastAPI, Django, Flask, and HTTPX.

## `httpx` requests

[`httpx`](https://www.python-httpx.org/) is an HTTP client for Python 3 with synchronous and asynchronous APIs.
In the below example, we query the [JSONPlaceholder API](https://jsonplaceholder.typicode.com/) to get a user's data and validate it with a Pydantic model.

```python {test="skip"}
import httpx

from pydantic import BaseModel, EmailStr


class User(BaseModel):
    id: int
    name: str
    email: EmailStr


url = 'https://jsonplaceholder.typicode.com/users/1'

response = httpx.get(url)
response.raise_for_status()

user = User.model_validate(response.json())
print(repr(user))
#> User(id=1, name='Leanne Graham', email='Sincere@april.biz')
```

The [`TypeAdapter`][pydantic.type_adapter.TypeAdapter] tool from Pydantic often comes in quite
handy when working with HTTP requests. Consider a similar example where we are validating a list of users:

```python {test="skip"}
from pprint import pprint

import httpx

from pydantic import BaseModel, EmailStr, TypeAdapter


class User(BaseModel):
    id: int
    name: str
    email: EmailStr


url = 'https://jsonplaceholder.typicode.com/users/'  # (1)!

response = httpx.get(url)
response.raise_for_status()

users_list_adapter = TypeAdapter(list[User])

users = users_list_adapter.validate_python(response.json())
pprint([u.name for u in users])
"""
['Leanne Graham',
 'Ervin Howell',
 'Clementine Bauch',
 'Patricia Lebsack',
 'Chelsey Dietrich',
 'Mrs. Dennis Schulist',
 'Kurtis Weissnat',
 'Nicholas Runolfsdottir V',
 'Glenna Reichert',
 'Clementina DuBuque']
"""
```

1. Note, we're querying the `/users/` endpoint here to get a list of users.

<!-- TODO: httpx, flask, Django rest framework, FastAPI -->


## Links discovered
- [`httpx`](https://www.python-httpx.org/)
- [JSONPlaceholder API](https://jsonplaceholder.typicode.com/)

--- docs/index.md ---
# Pydantic Validation

[![CI](https://img.shields.io/github/actions/workflow/status/pydantic/pydantic/ci.yml?branch=main&logo=github&label=CI)](https://github.com/pydantic/pydantic/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)
[![Coverage](https://coverage-badge.samuelcolvin.workers.dev/pydantic/pydantic.svg)](https://github.com/pydantic/pydantic/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)<br>
[![pypi](https://img.shields.io/pypi/v/pydantic.svg)](https://pypi.python.org/pypi/pydantic)
[![CondaForge](https://img.shields.io/conda/v/conda-forge/pydantic.svg)](https://anaconda.org/conda-forge/pydantic)
[![downloads](https://static.pepy.tech/badge/pydantic/month)](https://pepy.tech/project/pydantic)<br>
[![license](https://img.shields.io/github/license/pydantic/pydantic.svg)](https://github.com/pydantic/pydantic/blob/main/LICENSE)
[![llms.txt](https://img.shields.io/badge/llms.txt-green)](https://docs.pydantic.dev/latest/llms.txt)

{{ version }}.

Pydantic is the most widely used data validation library for Python.

Fast and extensible, Pydantic plays nicely with your linters/IDE/brain. Define how data should be in pure, canonical Python 3.9+; validate it with Pydantic.

!!! logfire "Monitor Pydantic with Pydantic Logfire :fire:"
    **[Pydantic Logfire](https://pydantic.dev/logfire)** is an application monitoring tool that is as simple to use and powerful as Pydantic itself.

    Logfire integrates with many popular Python libraries including FastAPI, OpenAI and Pydantic itself, so you can use Logfire to monitor Pydantic validations and understand why some inputs fail validation:

    ```python {title="Monitoring Pydantic with Logfire" test="skip"}
    from datetime import datetime

    import logfire

    from pydantic import BaseModel

    logfire.configure()
    logfire.instrument_pydantic()  # (1)!


    class Delivery(BaseModel):
        timestamp: datetime
        dimensions: tuple[int, int]


    # this will record details of a successful validation to logfire
    m = Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10', '20'])
    print(repr(m.timestamp))
    #> datetime.datetime(2020, 1, 2, 3, 4, 5, tzinfo=TzInfo(UTC))
    print(m.dimensions)
    #> (10, 20)

    Delivery(timestamp='2020-01-02T03:04:05Z', dimensions=['10'])  # (2)!
    ```

    1. Set logfire record all both successful and failed validations, use `record='failure'` to only record failed validations, [learn more](https://logfire.pydantic.dev/docs/integrations/pydantic/).
    2. This will raise a `ValidationError` since there are too few `dimensions`, details of the input data and validation errors will be recorded in Logfire.

    Would give you a view like this in the Logfire platform:

    [![Logfire Pydantic Integration](img/logfire-pydantic-integration.png)](https://logfire.pydantic.dev/docs/guides/web-ui/live/)

    This is just a toy example, but hopefully makes clear the potential value of instrumenting a more complex application.

    **[Learn more about Pydantic Logfire](https://logfire.pydantic.dev/docs/)**

    **Sign up for our newsletter, *The Pydantic Stack*, with updates & tutorials on Pydantic, Logfire, and Pydantic AI:**

      <form method="POST" action="https://eu.customerioforms.com/forms/submit_action?site_id=53d2086c3c4214eaecaa&form_id=14b22611745b458&success_url=https://docs.pydantic.dev/" class="md-typeset" style="display: flex; align-items: center; gap: 0.5rem; max-width: 100%;">
          <input
          type="email"
          id="email_input"
          name="email"
          class="md-input md-input--stretch"
          style="flex: 1; background: var(--md-default-bg-color); color: var(--md-default-fg-color);"
          required
          placeholder="Email"
          data-1p-ignore
          data-lpignore="true"
          data-protonpass-ignore="true"
          data-bwignore="true"
          />
          <input type="hidden" id="source_input" name="source" value="pydantic" />
          <button type="submit" class="md-button md-button--primary">Subscribe</button>
      </form>

## Why use Pydantic?

* **Powered by type hints** &mdash; with Pydantic, schema validation and serialization are controlled by type annotations; less to learn, less code to write, and integration with your IDE and static analysis tools. [Learn more…](why.md#type-hints)
* **Speed** &mdash; Pydantic's core validation logic is written in Rust. As a result, Pydantic is among the fastest data validation libraries for Python. [Learn more…](why.md#performance)
* **JSON Schema** &mdash; Pydantic models can emit JSON Schema, allowing for easy integration with other tools. [Learn more…](why.md#json-schema)
* **Strict** and **Lax** mode &mdash; Pydantic can run in either strict mode (where data is not converted) or lax mode where Pydantic tries to coerce data to the correct type where appropriate. [Learn more…](why.md#strict-lax)
* **Dataclasses**, **TypedDicts** and more &mdash; Pydantic supports validation of many standard library types including `dataclass` and `TypedDict`. [Learn more…](why.md#dataclasses-typeddict-more)
* **Customisation** &mdash; Pydantic allows custom validators and serializers to alter how data is processed in many powerful ways. [Learn more…](why.md#customisation)
* **Ecosystem** &mdash; around 8,000 packages on PyPI use Pydantic, including massively popular libraries like
  *FastAPI*, *huggingface*, *Django Ninja*, *SQLModel*, & *LangChain*. [Learn more…](why.md#ecosystem)
* **Battle tested** &mdash; Pydantic is downloaded over 360M times/month and is used by all FAANG companies and 20 of the 25 largest companies on NASDAQ. If you're trying to do something with Pydantic, someone else has probably already done it. [Learn more…](why.md#using-pydantic)

[Installing Pydantic](install.md) is as simple as: `pip install pydantic`

## Pydantic examples

To see Pydantic at work, let's start with a simple example, creating a custom class that inherits from `BaseModel`:

```python {upgrade="skip" title="Validation Successful" requires="3.10"}
from datetime import datetime

from pydantic import BaseModel, PositiveInt


class User(BaseModel):
    id: int  # (1)!
    name: str = 'John Doe'  # (2)!
    signup_ts: datetime | None  # (3)!
    tastes: dict[str, PositiveInt]  # (4)!


external_data = {
    'id': 123,
    'signup_ts': '2019-06-01 12:22',  # (5)!
    'tastes': {
        'wine': 9,
        b'cheese': 7,  # (6)!
        'cabbage': '1',  # (7)!
    },
}

user = User(**external_data)  # (8)!

print(user.id)  # (9)!
#> 123
print(user.model_dump())  # (10)!
"""
{
    'id': 123,
    'name': 'John Doe',
    'signup_ts': datetime.datetime(2019, 6, 1, 12, 22),
    'tastes': {'wine': 9, 'cheese': 7, 'cabbage': 1},
}
"""
```

1. `id` is of type `int`; the annotation-only declaration tells Pydantic that this field is required. Strings,
   bytes, or floats will be coerced to integers if possible; otherwise an exception will be raised.
2. `name` is a string; because it has a default, it is not required.
3. `signup_ts` is a [`datetime`][datetime.datetime] field that is required, but the value `None` may be provided;
   Pydantic will process either a [Unix timestamp](https://en.wikipedia.org/wiki/Unix_time) integer (e.g. `1496498400`)
   or a string representing the date and time.
4. `tastes` is a dictionary with string keys and positive integer values. The `PositiveInt` type is
   shorthand for `Annotated[int, annotated_types.Gt(0)]`.
5. The input here is an [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601) formatted datetime, but Pydantic will
   convert it to a [`datetime`][datetime.datetime] object.
6. The key here is `bytes`, but Pydantic will take care of coercing it to a string.
7. Similarly, Pydantic will coerce the string `'1'` to the integer `1`.
8. We create instance of `User` by passing our external data to `User` as keyword arguments.
9. We can access fields as attributes of the model.
10. We can convert the model to a dictionary with [`model_dump()`][pydantic.BaseModel.model_dump].

If validation fails, Pydantic will raise an error with a breakdown of what was wrong:

```python {upgrade="skip" title="Validation Error" test="skip" lint="skip"}
# continuing the above example...

from datetime import datetime
from pydantic import BaseModel, PositiveInt, ValidationError


class User(BaseModel):
    id: int
    name: str = 'John Doe'
    signup_ts: datetime | None
    tastes: dict[str, PositiveInt]


external_data = {'id': 'not an int', 'tastes': {}}  # (1)!

try:
    User(**external_data)  # (2)!
except ValidationError as e:
    print(e.errors())
    """
    [
        {
            'type': 'int_parsing',
            'loc': ('id',),
            'msg': 'Input should be a valid integer, unable to parse string as an integer',
            'input': 'not an int',
            'url': 'https://errors.pydantic.dev/2/v/int_parsing',
        },
        {
            'type': 'missing',
            'loc': ('signup_ts',),
            'msg': 'Field required',
            'input': {'id': 'not an int', 'tastes': {}},
            'url': 'https://errors.pydantic.dev/2/v/missing',
        },
    ]
    """
```

1. The input data is wrong here &mdash; `id` is not a valid integer, and `signup_ts` is missing.
2. Trying to instantiate `User` will raise a [`ValidationError`][pydantic_core.ValidationError] with a list of errors.

## Who is using Pydantic?

Hundreds of organisations and packages are using Pydantic. Some of the prominent companies and organizations around the world who are using Pydantic include:

{{ organisations }}

For a more comprehensive list of open-source projects using Pydantic see the
[list of dependents on github](https://github.com/pydantic/pydantic/network/dependents), or you can find some awesome projects using Pydantic in [awesome-pydantic](https://github.com/Kludex/awesome-pydantic).


## Links discovered
- [![CI](https://img.shields.io/github/actions/workflow/status/pydantic/pydantic/ci.yml?branch=main&logo=github&label=CI)
- [![Coverage](https://coverage-badge.samuelcolvin.workers.dev/pydantic/pydantic.svg)
- [![pypi](https://img.shields.io/pypi/v/pydantic.svg)
- [![CondaForge](https://img.shields.io/conda/v/conda-forge/pydantic.svg)
- [![downloads](https://static.pepy.tech/badge/pydantic/month)
- [![license](https://img.shields.io/github/license/pydantic/pydantic.svg)
- [![llms.txt](https://img.shields.io/badge/llms.txt-green)
- [Pydantic Logfire](https://pydantic.dev/logfire)
- [learn more](https://logfire.pydantic.dev/docs/integrations/pydantic/)
- [![Logfire Pydantic Integration](https://github.com/pydantic/pydantic/blob/main/docs/img/logfire-pydantic-integration.png)
- [Learn more about Pydantic Logfire](https://logfire.pydantic.dev/docs/)
- [Learn more…](https://github.com/pydantic/pydantic/blob/main/docs/why.md#type-hints)
- [Learn more…](https://github.com/pydantic/pydantic/blob/main/docs/why.md#performance)
- [Learn more…](https://github.com/pydantic/pydantic/blob/main/docs/why.md#json-schema)
- [Learn more…](https://github.com/pydantic/pydantic/blob/main/docs/why.md#strict-lax)
- [Learn more…](https://github.com/pydantic/pydantic/blob/main/docs/why.md#dataclasses-typeddict-more)
- [Learn more…](https://github.com/pydantic/pydantic/blob/main/docs/why.md#customisation)
- [Learn more…](https://github.com/pydantic/pydantic/blob/main/docs/why.md#ecosystem)
- [Learn more…](https://github.com/pydantic/pydantic/blob/main/docs/why.md#using-pydantic)
- [Installing Pydantic](https://github.com/pydantic/pydantic/blob/main/docs/install.md)
- [Unix timestamp](https://en.wikipedia.org/wiki/Unix_time)
- [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601)
- [list of dependents on github](https://github.com/pydantic/pydantic/network/dependents)
- [awesome-pydantic](https://github.com/Kludex/awesome-pydantic)

--- docs/contributing.md ---
We'd love you to contribute to Pydantic!

## Issues

Questions, feature requests and bug reports are all welcome as [discussions or issues](https://github.com/pydantic/pydantic/issues/new/choose).
**However, to report a security vulnerability, please see our [security policy](https://github.com/pydantic/pydantic/security/policy).**

To make it as simple as possible for us to help you, please include the output of the following call in your issue:

```bash
python -c "import pydantic.version; print(pydantic.version.version_info())"
```

If you're using Pydantic prior to **v2.0** please use:

```bash
python -c "import pydantic.utils; print(pydantic.utils.version_info())"
```

Please try to always include the above unless you're unable to install Pydantic or **know** it's not relevant
to your question or feature request.

## Pull Requests

It should be extremely simple to get started and create a Pull Request.
Pydantic is released regularly so you should see your improvements release in a matter of days or weeks 🚀.

Unless your change is trivial (typo, docs tweak etc.), please create an issue to discuss the change before
creating a pull request.

!!! note "Pydantic V1 is in maintenance mode"
    Pydantic v1 is in maintenance mode, meaning that only bug fixes and security fixes will be accepted.
    New features should be targeted at Pydantic v2.

    To submit a fix to Pydantic v1, use the `1.10.X-fixes` as a target branch.

If you're looking for something to get your teeth into, check out the
["help wanted"](https://github.com/pydantic/pydantic/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)
label on github.

To make contributing as easy and fast as possible, you'll want to run tests and linting locally. Luckily,
Pydantic has few dependencies, doesn't require compiling and tests don't need access to databases, etc.
Because of this, setting up and running the tests should be very simple.

!!! tip
    **tl;dr**: use `make format` to fix formatting, `make` to run tests and linting and `make docs`
    to build the docs.

### Prerequisites

You'll need the following prerequisites:

* Any Python version between **Python 3.9 and 3.12**
* [**uv**](https://docs.astral.sh/uv/getting-started/installation/) or other virtual environment tool
* [**git**](https://git-scm.com/) - For version control
* [**make**](https://www.gnu.org/software/make/) - For running development commands (or use `nmake` on Windows)
* [**Rust**](https://rustup.rs/) - Rust stable (or nightly for coverage)

### Installation and setup

Fork the repository on GitHub and clone your fork locally.

```bash
# Clone your fork and cd into the repo directory
git clone git@github.com:<your username>/pydantic.git
cd pydantic

# Install UV and pre-commit
# We use pipx here, for other options see:
# https://docs.astral.sh/uv/getting-started/installation/
# https://pre-commit.com/#install
# To get pipx itself:
# https://pypa.github.io/pipx/
pipx install uv
pipx install pre-commit

# Install pydantic, dependencies, test dependencies and doc dependencies
make install
```

### Check out a new branch and make your changes

Create a new branch for your changes.

```bash
# Checkout a new branch and make your changes
git switch -c my-new-feature-branch
# Make your changes...
```

### Run tests and linting

Run tests and linting locally to make sure everything is working as expected.

```bash
# Run automated code formatting and linting
make format
# Pydantic uses ruff, an awesome Python linter written in rust
# https://github.com/astral-sh/ruff

# Run tests and linting
make
# There are a few sub-commands in Makefile like `test`, `testcov` and `lint`
# which you might want to use, but generally just `make` should be all you need.
# You can run `make help` to see more options.
```

### Build documentation

If you've made any changes to the documentation (including changes to function signatures, class definitions, or docstrings that will appear in the API documentation), make sure it builds successfully.

We use `mkdocs-material[imaging]` to support social previews (see the [plugin documentation](https://squidfunk.github.io/mkdocs-material/plugins/requirements/image-processing/)).

```bash
# Build documentation
make docs
# If you have changed the documentation, make sure it builds successfully.
# You can also use `uv run mkdocs serve` to serve the documentation at localhost:8000
```

If this isn't working due to issues with the imaging plugin, try commenting out the `social` plugin line in `mkdocs.yml` and running `make docs` again.

#### Updating the documentation

We push a new version of the documentation with each minor release, and we push to a `dev` path with each commit to `main`.

If you're updating the documentation out of cycle with a minor release and want your changes to be reflected on `latest`,
do the following:

1. Open a PR against `main` with your docs changes
2. Once the PR is merged, checkout the `docs-update` branch. This branch should be up to date with the latest patch release.
For example, if the latest release is `v2.9.2`, you should make sure `docs-update` is up to date with the `v2.9.2` tag.
3. Checkout a new branch from `docs-update` and cherry-pick your changes onto this branch.
4. Push your changes and open a PR against `docs-update`.
5. Once the PR is merged, the new docs will be built and deployed.

!!! note
    Maintainer shortcut - as a maintainer, you can skip the second PR and just cherry pick directly onto the `docs-update` branch.

### Commit and push your changes

Commit your changes, push your branch to GitHub, and create a pull request.

Please follow the pull request template and fill in as much information as possible. Link to any relevant issues and include a description of your changes.

When your pull request is ready for review, add a comment with the message "please review" and we'll take a look as soon as we can.

## Documentation style

Documentation is written in Markdown and built using [Material for MkDocs](https://squidfunk.github.io/mkdocs-material/). API documentation is build from docstrings using [mkdocstrings](https://mkdocstrings.github.io/).

### Code documentation

When contributing to Pydantic, please make sure that all code is well documented. The following should be documented using properly formatted docstrings:

* Modules
* Class definitions
* Function definitions
* Module-level variables

Pydantic uses [Google-style docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings) formatted according to [PEP 257](https://www.python.org/dev/peps/pep-0257/) guidelines. (See [Example Google Style Python Docstrings](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html) for further examples.)

[pydocstyle](https://www.pydocstyle.org/en/stable/index.html) is used for linting docstrings. You can run `make format` to check your docstrings.

Where this is a conflict between Google-style docstrings and pydocstyle linting, follow the pydocstyle linting hints.

Class attributes and function arguments should be documented in the format "name: description." When applicable, a return type should be documented with just a description. Types are inferred from the signature.

```python
class Foo:
    """A class docstring.

    Attributes:
        bar: A description of bar. Defaults to "bar".
    """

    bar: str = 'bar'
```

```python
def bar(self, baz: int) -> str:
    """A function docstring.

    Args:
        baz: A description of `baz`.

    Returns:
        A description of the return value.
    """

    return 'bar'
```

You may include example code in docstrings. This code should be complete, self-contained, and runnable. Docstring examples are tested, so make sure they are correct and complete. See [`BeforeValidator`][pydantic.functional_validators.AfterValidator] for an example.

!!! note "Class and instance attributes"
    Class attributes should be documented in the class docstring.

    Instance attributes should be documented as "Args" in the `__init__` docstring.

### Documentation Style

In general, documentation should be written in a friendly, approachable style. It should be easy to read and understand, and should be as concise as possible while still being complete.

Code examples are encouraged, but should be kept short and simple. However, every code example should be complete, self-contained, and runnable. (If you're not sure how to do this, ask for help!) We prefer print output to naked asserts, but if you're testing something that doesn't have a useful print output, asserts are fine.

Pydantic's unit test will test all code examples in the documentation, so it's important that they are correct and complete. When adding a new code example, use the following to test examples and update their formatting and output:

```bash
# Run tests and update code examples
pytest tests/test_docs.py --update-examples
```

## Debugging Python and Rust

If you're working with `pydantic` and `pydantic-core`, you might find it helpful to debug Python and Rust code together.
Here's a quick guide on how to do that. This tutorial is done in VSCode, but you can use similar steps in other IDEs.

<div style="position: relative; padding-bottom: 56.4035546262415%; height: 0;">
    <iframe src="https://www.loom.com/embed/71019f8b92b04839ae233eb70c23c5b5?sid=1ea39ca9-d0cc-494b-8214-159f7cc26190" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;">
    </iframe>
</div>

## Badges

[![Pydantic v1](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json)](https://pydantic.dev)
[![Pydantic v2](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json)](https://pydantic.dev)

Pydantic has a badge that you can use to show that your project uses Pydantic. You can use this badge in your `README.md`:

### With Markdown

```md
[![Pydantic v1](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json)](https://pydantic.dev)

[![Pydantic v2](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json)](https://pydantic.dev)
```

### With reStructuredText

```rst
.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json
    :target: https://pydantic.dev
    :alt: Pydantic

.. image:: https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json
    :target: https://pydantic.dev
    :alt: Pydantic
```

### With HTML

```html
<a href="https://pydantic.dev"><img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json" alt="Pydantic Version 1" style="max-width:100%;"></a>

<a href="https://pydantic.dev"><img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json" alt="Pydantic Version 2" style="max-width:100%;"></a>
```

## Adding your library as part of Pydantic's third party test suite

To be able to identify regressions early during development, Pydantic runs tests on various third-party projects
using Pydantic. We consider adding support for testing new open source projects (that rely heavily on Pydantic) if your said project matches some of the following criteria:

* The project is actively maintained.
* The project makes use of Pydantic internals (e.g. relying on the [`BaseModel`][pydantic.BaseModel] metaclass, typing utilities).
* The project is popular enough (although small projects can still be included depending on how Pydantic is being used).
* The project CI is simple enough to be ported into Pydantic's testing workflow.

If your project meets some of these criteria, you can [open feature request][open feature request]
to discuss the inclusion of your project.

[open feature request]: https://github.com/pydantic/pydantic/issues/new?assignees=&labels=feature+request&projects=&template=feature_request.yml


## Links discovered
- [discussions or issues](https://github.com/pydantic/pydantic/issues/new/choose)
- [security policy](https://github.com/pydantic/pydantic/security/policy)
- ["help wanted"](https://github.com/pydantic/pydantic/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)
- [**uv**](https://docs.astral.sh/uv/getting-started/installation/)
- [**git**](https://git-scm.com/)
- [**make**](https://www.gnu.org/software/make/)
- [**Rust**](https://rustup.rs/)
- [plugin documentation](https://squidfunk.github.io/mkdocs-material/plugins/requirements/image-processing/)
- [Material for MkDocs](https://squidfunk.github.io/mkdocs-material/)
- [mkdocstrings](https://mkdocstrings.github.io/)
- [Google-style docstrings](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings)
- [PEP 257](https://www.python.org/dev/peps/pep-0257/)
- [Example Google Style Python Docstrings](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html)
- [pydocstyle](https://www.pydocstyle.org/en/stable/index.html)
- [![Pydantic v1](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json)
- [![Pydantic v2](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json)
- [<img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v1.json" alt="Pydantic Version 1" style="max-width:100%;">](https://pydantic.dev)
- [<img src="https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json" alt="Pydantic Version 2" style="max-width:100%;">](https://pydantic.dev)

--- tests/plugin/example_plugin.py ---
from pydantic import BaseModel


class MyModel(BaseModel):
    x: int


m = MyModel(x='10')
if m.x != 10:
    raise ValueError('m.x should be 10')

log = []


class ValidatePythonHandler:
    def on_enter(self, *args, **kwargs) -> None:
        log.append(f'on_enter args={args} kwargs={kwargs}')

    def on_success(self, result) -> None:
        log.append(f'on_success result={result}')

    def on_error(self, error) -> None:
        log.append(f'on_error error={error}')


class Plugin:
    def new_schema_validator(self, schema, schema_type, schema_type_path, schema_kind, config, plugin_settings):
        return ValidatePythonHandler(), None, None


plugin = Plugin()


--- tests/typechecking/json_schema_examples.py ---
from pydantic.json_schema import Examples

e_good = Examples([])
e_deprecated = Examples({})  # type: ignore[deprecated]  # pyright: ignore[reportDeprecated]


--- pydantic/class_validators.py ---
"""`class_validators` module is a backport module from V1."""

from ._migration import getattr_migration

__getattr__ = getattr_migration(__name__)


--- pydantic/dataclasses.py ---
"""Provide an enhanced dataclass that performs validation."""

from __future__ import annotations as _annotations

import dataclasses
import functools
import sys
import types
from typing import TYPE_CHECKING, Any, Callable, Generic, Literal, NoReturn, TypeVar, overload
from warnings import warn

from typing_extensions import TypeGuard, dataclass_transform

from ._internal import _config, _decorators, _mock_val_ser, _namespace_utils, _typing_extra
from ._internal import _dataclasses as _pydantic_dataclasses
from ._migration import getattr_migration
from .config import ConfigDict
from .errors import PydanticUserError
from .fields import Field, FieldInfo, PrivateAttr

if TYPE_CHECKING:
    from ._internal._dataclasses import PydanticDataclass
    from ._internal._namespace_utils import MappingNamespace

__all__ = 'dataclass', 'rebuild_dataclass'

_T = TypeVar('_T')

if sys.version_info >= (3, 10):

    @dataclass_transform(field_specifiers=(dataclasses.field, Field, PrivateAttr))
    @overload
    def dataclass(
        *,
        init: Literal[False] = False,
        repr: bool = True,
        eq: bool = True,
        order: bool = False,
        unsafe_hash: bool = False,
        frozen: bool = False,
        config: ConfigDict | type[object] | None = None,
        validate_on_init: bool | None = None,
        kw_only: bool = ...,
        slots: bool = ...,
    ) -> Callable[[type[_T]], type[PydanticDataclass]]:  # type: ignore
        ...

    @dataclass_transform(field_specifiers=(dataclasses.field, Field, PrivateAttr))
    @overload
    def dataclass(
        _cls: type[_T],  # type: ignore
        *,
        init: Literal[False] = False,
        repr: bool = True,
        eq: bool = True,
        order: bool = False,
        unsafe_hash: bool = False,
        frozen: bool | None = None,
        config: ConfigDict | type[object] | None = None,
        validate_on_init: bool | None = None,
        kw_only: bool = ...,
        slots: bool = ...,
    ) -> type[PydanticDataclass]: ...

else:

    @dataclass_transform(field_specifiers=(dataclasses.field, Field, PrivateAttr))
    @overload
    def dataclass(
        *,
        init: Literal[False] = False,
        repr: bool = True,
        eq: bool = True,
        order: bool = False,
        unsafe_hash: bool = False,
        frozen: bool | None = None,
        config: ConfigDict | type[object] | None = None,
        validate_on_init: bool | None = None,
    ) -> Callable[[type[_T]], type[PydanticDataclass]]:  # type: ignore
        ...

    @dataclass_transform(field_specifiers=(dataclasses.field, Field, PrivateAttr))
    @overload
    def dataclass(
        _cls: type[_T],  # type: ignore
        *,
        init: Literal[False] = False,
        repr: bool = True,
        eq: bool = True,
        order: bool = False,
        unsafe_hash: bool = False,
        frozen: bool | None = None,
        config: ConfigDict | type[object] | None = None,
        validate_on_init: bool | None = None,
    ) -> type[PydanticDataclass]: ...


@dataclass_transform(field_specifiers=(dataclasses.field, Field, PrivateAttr))
def dataclass(
    _cls: type[_T] | None = None,
    *,
    init: Literal[False] = False,
    repr: bool = True,
    eq: bool = True,
    order: bool = False,
    unsafe_hash: bool = False,
    frozen: bool | None = None,
    config: ConfigDict | type[object] | None = None,
    validate_on_init: bool | None = None,
    kw_only: bool = False,
    slots: bool = False,
) -> Callable[[type[_T]], type[PydanticDataclass]] | type[PydanticDataclass]:
    """!!! abstract "Usage Documentation"
        [`dataclasses`](../concepts/dataclasses.md)

    A decorator used to create a Pydantic-enhanced dataclass, similar to the standard Python `dataclass`,
    but with added validation.

    This function should be used similarly to `dataclasses.dataclass`.

    Args:
        _cls: The target `dataclass`.
        init: Included for signature compatibility with `dataclasses.dataclass`, and is passed through to
            `dataclasses.dataclass` when appropriate. If specified, must be set to `False`, as pydantic inserts its
            own  `__init__` function.
        repr: A boolean indicating whether to include the field in the `__repr__` output.
        eq: Determines if a `__eq__` method should be generated for the class.
        order: Determines if comparison magic methods should be generated, such as `__lt__`, but not `__eq__`.
        unsafe_hash: Determines if a `__hash__` method should be included in the class, as in `dataclasses.dataclass`.
        frozen: Determines if the generated class should be a 'frozen' `dataclass`, which does not allow its
            attributes to be modified after it has been initialized. If not set, the value from the provided `config` argument will be used (and will default to `False` otherwise).
        config: The Pydantic config to use for the `dataclass`.
        validate_on_init: A deprecated parameter included for backwards compatibility; in V2, all Pydantic dataclasses
            are validated on init.
        kw_only: Determines if `__init__` method parameters must be specified by keyword only. Defaults to `False`.
        slots: Determines if the generated class should be a 'slots' `dataclass`, which does not allow the addition of
            new attributes after instantiation.

    Returns:
        A decorator that accepts a class as its argument and returns a Pydantic `dataclass`.

    Raises:
        AssertionError: Raised if `init` is not `False` or `validate_on_init` is `False`.
    """
    assert init is False, 'pydantic.dataclasses.dataclass only supports init=False'
    assert validate_on_init is not False, 'validate_on_init=False is no longer supported'

    if sys.version_info >= (3, 10):
        kwargs = {'kw_only': kw_only, 'slots': slots}
    else:
        kwargs = {}

    def create_dataclass(cls: type[Any]) -> type[PydanticDataclass]:
        """Create a Pydantic dataclass from a regular dataclass.

        Args:
            cls: The class to create the Pydantic dataclass from.

        Returns:
            A Pydantic dataclass.
        """
        from ._internal._utils import is_model_class

        if is_model_class(cls):
            raise PydanticUserError(
                f'Cannot create a Pydantic dataclass from {cls.__name__} as it is already a Pydantic model',
                code='dataclass-on-model',
            )

        original_cls = cls

        # we warn on conflicting config specifications, but only if the class doesn't have a dataclass base
        # because a dataclass base might provide a __pydantic_config__ attribute that we don't want to warn about
        has_dataclass_base = any(dataclasses.is_dataclass(base) for base in cls.__bases__)
        if not has_dataclass_base and config is not None and hasattr(cls, '__pydantic_config__'):
            warn(
                f'`config` is set via both the `dataclass` decorator and `__pydantic_config__` for dataclass {cls.__name__}. '
                f'The `config` specification from `dataclass` decorator will take priority.',
                category=UserWarning,
                stacklevel=2,
            )

        # if config is not explicitly provided, try to read it from the type
        config_dict = config if config is not None else getattr(cls, '__pydantic_config__', None)
        config_wrapper = _config.ConfigWrapper(config_dict)
        decorators = _decorators.DecoratorInfos.build(cls, replace_wrapped_methods=True)
        decorators.update_from_config(config_wrapper)

        # Keep track of the original __doc__ so that we can restore it after applying the dataclasses decorator
        # Otherwise, classes with no __doc__ will have their signature added into the JSON schema description,
        # since dataclasses.dataclass will set this as the __doc__
        original_doc = cls.__doc__

        if _pydantic_dataclasses.is_stdlib_dataclass(cls):
            # Vanilla dataclasses include a default docstring (representing the class signature),
            # which we don't want to preserve.
            original_doc = None

            # We don't want to add validation to the existing std lib dataclass, so we will subclass it
            #   If the class is generic, we need to make sure the subclass also inherits from Generic
            #   with all the same parameters.
            bases = (cls,)
            if issubclass(cls, Generic):
                generic_base = Generic[cls.__parameters__]  # type: ignore
                bases = bases + (generic_base,)
            cls = types.new_class(cls.__name__, bases)

        # Respect frozen setting from dataclass constructor and fallback to config setting if not provided
        if frozen is not None:
            frozen_ = frozen
            if config_wrapper.frozen:
                # It's not recommended to define both, as the setting from the dataclass decorator will take priority.
                warn(
                    f'`frozen` is set via both the `dataclass` decorator and `config` for dataclass {cls.__name__!r}.'
                    'This is not recommended. The `frozen` specification on `dataclass` will take priority.',
                    category=UserWarning,
                    stacklevel=2,
                )
        else:
            frozen_ = config_wrapper.frozen or False

        # Make Pydantic's `Field()` function compatible with stdlib dataclasses. As we'll decorate
        # `cls` with the stdlib `@dataclass` decorator first, there are two attributes, `kw_only` and
        # `repr` that need to be understood *during* the stdlib creation. We do so in two steps:

        # 1. On the decorated class, wrap `Field()` assignment with `dataclass.field()`, with the
        # two attributes set (done in `as_dataclass_field()`)
        cls_anns = _typing_extra.safe_get_annotations(cls)
        for field_name in cls_anns:
            # We should look for assignments in `__dict__` instead, but for now we follow
            # the same behavior as stdlib dataclasses (see https://github.com/python/cpython/issues/88609)
            field_value = getattr(cls, field_name, None)
            if isinstance(field_value, FieldInfo):
                setattr(cls, field_name, _pydantic_dataclasses.as_dataclass_field(field_value))

        # 2. For bases of `cls` that are stdlib dataclasses, we temporarily patch their fields
        # (see the docstring of the context manager):
        with _pydantic_dataclasses.patch_base_fields(cls):
            cls = dataclasses.dataclass(  # pyright: ignore[reportCallIssue]
                cls,
                # the value of init here doesn't affect anything except that it makes it easier to generate a signature
                init=True,
                repr=repr,
                eq=eq,
                order=order,
                unsafe_hash=unsafe_hash,
                frozen=frozen_,
                **kwargs,
            )

        if config_wrapper.validate_assignment:
            original_setattr = cls.__setattr__

            @functools.wraps(cls.__setattr__)
            def validated_setattr(instance: PydanticDataclass, name: str, value: Any, /) -> None:
                if frozen_:
                    return original_setattr(instance, name, value)  # pyright: ignore[reportCallIssue]
                inst_cls = type(instance)
                attr = getattr(inst_cls, name, None)

                if isinstance(attr, property):
                    attr.__set__(instance, value)
                elif isinstance(attr, functools.cached_property):
                    instance.__dict__.__setitem__(name, value)
                else:
                    inst_cls.__pydantic_validator__.validate_assignment(instance, name, value)

            cls.__setattr__ = validated_setattr.__get__(None, cls)  # type: ignore

            if slots and not hasattr(cls, '__setstate__'):
                # If slots is set, `pickle` (relied on by `copy.copy()`) will use
                # `__setattr__()` to reconstruct the dataclass. However, the custom
                # `__setattr__()` set above relies on `validate_assignment()`, which
                # in turn expects all the field values to be already present on the
                # instance, resulting in attribute errors.
                # As such, we make use of `object.__setattr__()` instead.
                # Note that we do so only if `__setstate__()` isn't already set (this is the
                # case if on top of `slots`, `frozen` is used).

                # Taken from `dataclasses._dataclass_get/setstate()`:
                def _dataclass_getstate(self: Any) -> list[Any]:
                    return [getattr(self, f.name) for f in dataclasses.fields(self)]

                def _dataclass_setstate(self: Any, state: list[Any]) -> None:
                    for field, value in zip(dataclasses.fields(self), state):
                        object.__setattr__(self, field.name, value)

                cls.__getstate__ = _dataclass_getstate  # pyright: ignore[reportAttributeAccessIssue]
                cls.__setstate__ = _dataclass_setstate  # pyright: ignore[reportAttributeAccessIssue]

        # This is an undocumented attribute to distinguish stdlib/Pydantic dataclasses.
        # It should be set as early as possible:
        cls.__is_pydantic_dataclass__ = True
        cls.__pydantic_decorators__ = decorators  # type: ignore
        cls.__doc__ = original_doc
        # Can be non-existent for dynamically created classes:
        firstlineno = getattr(original_cls, '__firstlineno__', None)
        cls.__module__ = original_cls.__module__
        if sys.version_info >= (3, 13) and firstlineno is not None:
            # As per https://docs.python.org/3/reference/datamodel.html#type.__firstlineno__:
            # Setting the `__module__` attribute removes the `__firstlineno__` item from the type’s dictionary.
            original_cls.__firstlineno__ = firstlineno
            cls.__firstlineno__ = firstlineno
        cls.__qualname__ = original_cls.__qualname__
        cls.__pydantic_fields_complete__ = classmethod(_pydantic_fields_complete)
        cls.__pydantic_complete__ = False  # `complete_dataclass` will set it to `True` if successful.
        # TODO `parent_namespace` is currently None, but we could do the same thing as Pydantic models:
        # fetch the parent ns using `parent_frame_namespace` (if the dataclass was defined in a function),
        # and possibly cache it (see the `__pydantic_parent_namespace__` logic for models).
        _pydantic_dataclasses.complete_dataclass(cls, config_wrapper, raise_errors=False)
        return cls

    return create_dataclass if _cls is None else create_dataclass(_cls)


def _pydantic_fields_complete(cls: type[PydanticDataclass]) -> bool:
    """Return whether the fields where successfully collected (i.e. type hints were successfully resolves).

    This is a private property, not meant to be used outside Pydantic.
    """
    return all(field_info._complete for field_info in cls.__pydantic_fields__.values())


__getattr__ = getattr_migration(__name__)

if sys.version_info < (3, 11):
    # Monkeypatch dataclasses.InitVar so that typing doesn't error if it occurs as a type when evaluating type hints
    # Starting in 3.11, typing.get_type_hints will not raise an error if the retrieved type hints are not callable.

    def _call_initvar(*args: Any, **kwargs: Any) -> NoReturn:
        """This function does nothing but raise an error that is as similar as possible to what you'd get
        if you were to try calling `InitVar[int]()` without this monkeypatch. The whole purpose is just
        to ensure typing._type_check does not error if the type hint evaluates to `InitVar[<parameter>]`.
        """
        raise TypeError("'InitVar' object is not callable")

    dataclasses.InitVar.__call__ = _call_initvar


def rebuild_dataclass(
    cls: type[PydanticDataclass],
    *,
    force: bool = False,
    raise_errors: bool = True,
    _parent_namespace_depth: int = 2,
    _types_namespace: MappingNamespace | None = None,
) -> bool | None:
    """Try to rebuild the pydantic-core schema for the dataclass.

    This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
    the initial attempt to build the schema, and automatic rebuilding fails.

    This is analogous to `BaseModel.model_rebuild`.

    Args:
        cls: The class to rebuild the pydantic-core schema for.
        force: Whether to force the rebuilding of the schema, defaults to `False`.
        raise_errors: Whether to raise errors, defaults to `True`.
        _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
        _types_namespace: The types namespace, defaults to `None`.

    Returns:
        Returns `None` if the schema is already "complete" and rebuilding was not required.
        If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.
    """
    if not force and cls.__pydantic_complete__:
        return None

    for attr in ('__pydantic_core_schema__', '__pydantic_validator__', '__pydantic_serializer__'):
        if attr in cls.__dict__ and not isinstance(getattr(cls, attr), _mock_val_ser.MockValSer):
            # Deleting the validator/serializer is necessary as otherwise they can get reused in
            # pydantic-core. Same applies for the core schema that can be reused in schema generation.
            delattr(cls, attr)

    cls.__pydantic_complete__ = False

    if _types_namespace is not None:
        rebuild_ns = _types_namespace
    elif _parent_namespace_depth > 0:
        rebuild_ns = _typing_extra.parent_frame_namespace(parent_depth=_parent_namespace_depth, force=True) or {}
    else:
        rebuild_ns = {}

    ns_resolver = _namespace_utils.NsResolver(
        parent_namespace=rebuild_ns,
    )

    return _pydantic_dataclasses.complete_dataclass(
        cls,
        _config.ConfigWrapper(cls.__pydantic_config__, check=False),
        raise_errors=raise_errors,
        ns_resolver=ns_resolver,
        # We could provide a different config instead (with `'defer_build'` set to `True`)
        # of this explicit `_force_build` argument, but because config can come from the
        # decorator parameter or the `__pydantic_config__` attribute, `complete_dataclass`
        # will overwrite `__pydantic_config__` with the provided config above:
        _force_build=True,
    )


def is_pydantic_dataclass(class_: type[Any], /) -> TypeGuard[type[PydanticDataclass]]:
    """Whether a class is a pydantic dataclass.

    Args:
        class_: The class.

    Returns:
        `True` if the class is a pydantic dataclass, `False` otherwise.
    """
    try:
        return '__is_pydantic_dataclass__' in class_.__dict__ and dataclasses.is_dataclass(class_)
    except AttributeError:
        return False


## Links discovered
- [`dataclasses`](https://github.com/pydantic/pydantic/blob/main/concepts/dataclasses.md)

--- tests/test_dataclasses.py ---
import dataclasses
import inspect
import pickle
import re
import sys
import traceback
from collections.abc import Hashable
from dataclasses import InitVar
from datetime import date, datetime
from functools import cached_property
from pathlib import Path
from typing import (
    Annotated,
    Any,
    Callable,
    ClassVar,
    Generic,
    Literal,
    Optional,
    TypeVar,
    Union,
)

import pytest
from annotated_types import Gt
from dirty_equals import HasRepr
from pydantic_core import ArgsKwargs, SchemaValidator

import pydantic
from pydantic import (
    BaseModel,
    BeforeValidator,
    ConfigDict,
    Field,
    PydanticDeprecatedSince20,
    PydanticUndefinedAnnotation,
    PydanticUserError,
    RootModel,
    TypeAdapter,
    ValidationError,
    ValidationInfo,
    computed_field,
    field_serializer,
    field_validator,
    model_validator,
    with_config,
)
from pydantic._internal._mock_val_ser import MockValSer
from pydantic.dataclasses import is_pydantic_dataclass, rebuild_dataclass
from pydantic.json_schema import model_json_schema


def test_cannot_create_dataclass_from_basemodel_subclass():
    msg = 'Cannot create a Pydantic dataclass from SubModel as it is already a Pydantic model'

    with pytest.raises(PydanticUserError, match=msg):

        @pydantic.dataclasses.dataclass
        class SubModel(BaseModel):
            pass


def test_simple():
    @pydantic.dataclasses.dataclass
    class MyDataclass:
        a: int
        b: float

    d = MyDataclass('1', '2.5')
    assert d.a == 1
    assert d.b == 2.5
    d = MyDataclass(b=10, a=20)
    assert d.a == 20
    assert d.b == 10


def test_model_name():
    @pydantic.dataclasses.dataclass
    class MyDataClass:
        model_name: str

    d = MyDataClass('foo')
    assert d.model_name == 'foo'
    d = MyDataClass(model_name='foo')
    assert d.model_name == 'foo'


def test_value_error():
    @pydantic.dataclasses.dataclass
    class MyDataclass:
        a: int
        b: int

    with pytest.raises(ValidationError) as exc_info:
        MyDataclass(1, 'wrong')

    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'int_parsing',
            'loc': (1,),
            'msg': 'Input should be a valid integer, unable to parse string as an integer',
            'input': 'wrong',
        }
    ]


def test_frozen():
    @pydantic.dataclasses.dataclass(frozen=True)
    class MyDataclass:
        a: int

    d = MyDataclass(1)
    assert d.a == 1

    with pytest.raises(AttributeError):
        d.a = 7


def test_validate_assignment():
    @pydantic.dataclasses.dataclass(config=ConfigDict(validate_assignment=True))
    class MyDataclass:
        a: int

    d = MyDataclass(1)
    assert d.a == 1

    d.a = '7'
    assert d.a == 7


def test_validate_assignment_error():
    @pydantic.dataclasses.dataclass(config=ConfigDict(validate_assignment=True))
    class MyDataclass:
        a: int

    d = MyDataclass(1)

    with pytest.raises(ValidationError) as exc_info:
        d.a = 'xxx'
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'int_parsing',
            'loc': ('a',),
            'msg': 'Input should be a valid integer, unable to parse string as an integer',
            'input': 'xxx',
        }
    ]


def test_not_validate_assignment():
    @pydantic.dataclasses.dataclass
    class MyDataclass:
        a: int

    d = MyDataclass(1)
    assert d.a == 1

    d.a = '7'
    assert d.a == '7'


def test_validate_assignment_value_change():
    @pydantic.dataclasses.dataclass(config=ConfigDict(validate_assignment=True), frozen=False)
    class MyDataclass:
        a: int

        @field_validator('a')
        @classmethod
        def double_a(cls, v: int) -> int:
            return v * 2

    d = MyDataclass(2)
    assert d.a == 4

    d.a = 3
    assert d.a == 6


def test_validate_assignment_properties() -> None:
    """https://github.com/pydantic/pydantic/issues/12112"""

    @pydantic.dataclasses.dataclass(config=ConfigDict(validate_assignment=True))
    class MyDataclass:
        @property
        def prop1(self) -> int:
            return 1

        @prop1.setter
        def prop1(self, value: int) -> None:
            pass

        @computed_field
        @property
        def prop2(self) -> int:
            return 1

        @prop2.setter
        def prop2(self, value: int) -> None:
            pass

        @cached_property
        def prop3(self) -> int:
            return 1

    m = MyDataclass()

    m.prop1 = 1
    m.prop2 = 1
    m.prop3 = 1


@pytest.mark.parametrize(
    'config',
    [
        ConfigDict(validate_assignment=False),
        ConfigDict(extra=None),
        ConfigDict(extra='forbid'),
        ConfigDict(extra='ignore'),
        ConfigDict(validate_assignment=False, extra=None),
        ConfigDict(validate_assignment=False, extra='forbid'),
        ConfigDict(validate_assignment=False, extra='ignore'),
        ConfigDict(validate_assignment=False, extra='allow'),
        ConfigDict(validate_assignment=True, extra='allow'),
    ],
)
def test_validate_assignment_extra_unknown_field_assigned_allowed(config: ConfigDict):
    @pydantic.dataclasses.dataclass(config=config)
    class MyDataclass:
        a: int

    d = MyDataclass(1)
    assert d.a == 1

    d.extra_field = 123
    assert d.extra_field == 123


@pytest.mark.parametrize(
    'config',
    [
        ConfigDict(validate_assignment=True),
        ConfigDict(validate_assignment=True, extra=None),
        ConfigDict(validate_assignment=True, extra='forbid'),
        ConfigDict(validate_assignment=True, extra='ignore'),
    ],
)
def test_validate_assignment_extra_unknown_field_assigned_errors(config: ConfigDict):
    @pydantic.dataclasses.dataclass(config=config)
    class MyDataclass:
        a: int

    d = MyDataclass(1)
    assert d.a == 1

    with pytest.raises(ValidationError) as exc_info:
        d.extra_field = 1.23

    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'no_such_attribute',
            'loc': ('extra_field',),
            'msg': "Object has no attribute 'extra_field'",
            'input': 1.23,
            'ctx': {'attribute': 'extra_field'},
        }
    ]


def test_post_init():
    post_init_called = False

    @pydantic.dataclasses.dataclass
    class MyDataclass:
        a: int

        def __post_init__(self):
            nonlocal post_init_called
            post_init_called = True

    d = MyDataclass('1')
    assert d.a == 1
    assert post_init_called


def test_post_init_validation():
    @dataclasses.dataclass
    class DC:
        a: int

        def __post_init__(self):
            self.a *= 2

    assert DC(a='2').a == '22'
    PydanticDC = pydantic.dataclasses.dataclass(DC)
    assert DC(a='2').a == '22'
    assert PydanticDC(a='2').a == 4


def test_convert_vanilla_dc():
    @dataclasses.dataclass
    class DC:
        a: int
        b: str = dataclasses.field(init=False)

        def __post_init__(self):
            self.a *= 2
            self.b = 'hello'

    dc1 = DC(a='2')
    assert dc1.a == '22'
    assert dc1.b == 'hello'
    PydanticDC = pydantic.dataclasses.dataclass(DC)
    dc2 = DC(a='2')
    assert dc2.a == '22'
    assert dc2.b == 'hello'

    py_dc = PydanticDC(a='2')
    assert py_dc.a == 4
    assert py_dc.b == 'hello'


def test_std_dataclass_with_parent():
    @dataclasses.dataclass
    class DCParent:
        a: int

    @dataclasses.dataclass
    class DC(DCParent):
        b: int

        def __post_init__(self):
            self.a *= 2

    assert dataclasses.asdict(DC(a='2', b='1')) == {'a': '22', 'b': '1'}
    PydanticDC = pydantic.dataclasses.dataclass(DC)
    assert dataclasses.asdict(DC(a='2', b='1')) == {'a': '22', 'b': '1'}
    assert dataclasses.asdict(PydanticDC(a='2', b='1')) == {'a': 4, 'b': 1}


def test_post_init_inheritance_chain():
    parent_post_init_called = False
    post_init_called = False

    @pydantic.dataclasses.dataclass
    class ParentDataclass:
        a: int

        def __post_init__(self):
            nonlocal parent_post_init_called
            parent_post_init_called = True

    @pydantic.dataclasses.dataclass
    class MyDataclass(ParentDataclass):
        b: int

        def __post_init__(self):
            super().__post_init__()
            nonlocal post_init_called
            post_init_called = True

    d = MyDataclass(a=1, b=2)
    assert d.a == 1
    assert d.b == 2
    assert parent_post_init_called
    assert post_init_called


def test_post_init_post_parse():
    with pytest.warns(PydanticDeprecatedSince20, match='Support for `__post_init_post_parse__` has been dropped'):

        @pydantic.dataclasses.dataclass
        class MyDataclass:
            a: int

            def __post_init_post_parse__(self):
                pass


def test_post_init_assignment():
    from dataclasses import field

    # Based on: https://docs.python.org/3/library/dataclasses.html#post-init-processing
    @pydantic.dataclasses.dataclass
    class C:
        a: float
        b: float
        c: float = field(init=False)

        def __post_init__(self):
            self.c = self.a + self.b

    c = C(0.1, 0.2)
    assert c.a == 0.1
    assert c.b == 0.2
    assert c.c == 0.30000000000000004


def test_inheritance():
    @pydantic.dataclasses.dataclass
    class A:
        a: str = None

    a_ = A(a=b'a')
    assert a_.a == 'a'

    @pydantic.dataclasses.dataclass
    class B(A):
        b: int = None

    b = B(a='a', b=12)
    assert b.a == 'a'
    assert b.b == 12

    with pytest.raises(ValidationError):
        B(a='a', b='b')

    a_ = A(a=b'a')
    assert a_.a == 'a'


def test_validate_long_string_error():
    @pydantic.dataclasses.dataclass(config=dict(str_max_length=3))
    class MyDataclass:
        a: str

    with pytest.raises(ValidationError) as exc_info:
        MyDataclass('xxxx')

    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'string_too_long',
            'loc': (0,),
            'msg': 'String should have at most 3 characters',
            'input': 'xxxx',
            'ctx': {'max_length': 3},
        }
    ]


def test_validate_assignment_long_string_error():
    @pydantic.dataclasses.dataclass(config=ConfigDict(str_max_length=3, validate_assignment=True))
    class MyDataclass:
        a: str

    d = MyDataclass('xxx')
    with pytest.raises(ValidationError) as exc_info:
        d.a = 'xxxx'

    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'string_too_long',
            'loc': ('a',),
            'msg': 'String should have at most 3 characters',
            'input': 'xxxx',
            'ctx': {'max_length': 3},
        }
    ]


def test_no_validate_assignment_long_string_error():
    @pydantic.dataclasses.dataclass(config=ConfigDict(str_max_length=3, validate_assignment=False))
    class MyDataclass:
        a: str

    d = MyDataclass('xxx')
    d.a = 'xxxx'

    assert d.a == 'xxxx'


def test_nested_dataclass():
    @pydantic.dataclasses.dataclass
    class Nested:
        number: int

    @pydantic.dataclasses.dataclass
    class Outer:
        n: Nested

    navbar = Outer(n=Nested(number='1'))
    assert isinstance(navbar.n, Nested)
    assert navbar.n.number == 1

    navbar = Outer(n={'number': '3'})
    assert isinstance(navbar.n, Nested)
    assert navbar.n.number == 3

    with pytest.raises(ValidationError) as exc_info:
        Outer(n='not nested')
    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'dataclass_type',
            'loc': ('n',),
            'msg': 'Input should be a dictionary or an instance of Nested',
            'input': 'not nested',
            'ctx': {'class_name': 'Nested'},
        }
    ]

    with pytest.raises(ValidationError) as exc_info:
        Outer(n={'number': 'x'})
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'int_parsing',
            'loc': ('n', 'number'),
            'msg': 'Input should be a valid integer, unable to parse string as an integer',
            'input': 'x',
        }
    ]


def test_arbitrary_types_allowed():
    class Button:
        def __init__(self, href: str):
            self.href = href

    @pydantic.dataclasses.dataclass(config=dict(arbitrary_types_allowed=True))
    class Navbar:
        button: Button

    btn = Button(href='a')
    navbar = Navbar(button=btn)
    assert navbar.button.href == 'a'

    with pytest.raises(ValidationError) as exc_info:
        Navbar(button=('b',))
    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'is_instance_of',
            'loc': ('button',),
            'msg': 'Input should be an instance of test_arbitrary_types_allowed.<locals>.Button',
            'input': ('b',),
            'ctx': {'class': 'test_arbitrary_types_allowed.<locals>.Button'},
        }
    ]


def test_nested_dataclass_model():
    @pydantic.dataclasses.dataclass
    class Nested:
        number: int

    class Outer(BaseModel):
        n: Nested

    navbar = Outer(n=Nested(number='1'))
    assert navbar.n.number == 1


def test_fields():
    @pydantic.dataclasses.dataclass
    class User:
        id: int
        name: str = 'John Doe'
        signup_ts: datetime = None

    user = User(id=123)
    fields = user.__pydantic_fields__

    assert fields['id'].is_required() is True

    assert fields['name'].is_required() is False
    assert fields['name'].default == 'John Doe'

    assert fields['signup_ts'].is_required() is False
    assert fields['signup_ts'].default is None


@pytest.mark.parametrize('field_constructor', [dataclasses.field, pydantic.dataclasses.Field])
def test_default_factory_field(field_constructor: Callable):
    @pydantic.dataclasses.dataclass
    class User:
        id: int
        other: dict[str, str] = field_constructor(default_factory=lambda: {'John': 'Joey'})

    user = User(id=123)

    assert user.id == 123
    assert user.other == {'John': 'Joey'}
    fields = user.__pydantic_fields__

    assert fields['id'].is_required() is True
    assert repr(fields['id'].default) == 'PydanticUndefined'

    assert fields['other'].is_required() is False
    assert fields['other'].default_factory() == {'John': 'Joey'}


def test_default_factory_singleton_field():
    class MySingleton:
        pass

    MY_SINGLETON = MySingleton()

    @pydantic.dataclasses.dataclass(config=dict(arbitrary_types_allowed=True))
    class Foo:
        singleton: MySingleton = dataclasses.field(default_factory=lambda: MY_SINGLETON)

    # Returning a singleton from a default_factory is supported
    assert Foo().singleton is Foo().singleton


def test_schema():
    @pydantic.dataclasses.dataclass
    class User:
        id: int
        name: str = 'John Doe'
        aliases: dict[str, str] = dataclasses.field(default_factory=lambda: {'John': 'Joey'})
        signup_ts: datetime = None
        age: Optional[int] = dataclasses.field(
            default=None, metadata=dict(title='The age of the user', description='do not lie!')
        )
        height: Optional[int] = pydantic.Field(None, title='The height in cm', ge=50, le=300)

    User(id=123)
    assert model_json_schema(User) == {
        'properties': {
            'age': {
                'anyOf': [{'type': 'integer'}, {'type': 'null'}],
                'default': None,
                'title': 'The age of the user',
                'description': 'do not lie!',
            },
            'aliases': {
                'additionalProperties': {'type': 'string'},
                'title': 'Aliases',
                'type': 'object',
            },
            'height': {
                'anyOf': [{'maximum': 300, 'minimum': 50, 'type': 'integer'}, {'type': 'null'}],
                'default': None,
                'title': 'The height in cm',
            },
            'id': {'title': 'Id', 'type': 'integer'},
            'name': {'default': 'John Doe', 'title': 'Name', 'type': 'string'},
            'signup_ts': {'default': None, 'format': 'date-time', 'title': 'Signup Ts', 'type': 'string'},
        },
        'required': ['id'],
        'title': 'User',
        'type': 'object',
    }


def test_nested_schema():
    @pydantic.dataclasses.dataclass
    class Nested:
        number: int

    @pydantic.dataclasses.dataclass
    class Outer:
        n: Nested

    assert model_json_schema(Outer) == {
        '$defs': {
            'Nested': {
                'properties': {'number': {'title': 'Number', 'type': 'integer'}},
                'required': ['number'],
                'title': 'Nested',
                'type': 'object',
            }
        },
        'properties': {'n': {'$ref': '#/$defs/Nested'}},
        'required': ['n'],
        'title': 'Outer',
        'type': 'object',
    }


def test_initvar():
    @pydantic.dataclasses.dataclass
    class TestInitVar:
        x: int
        y: dataclasses.InitVar
        z: Annotated[dataclasses.InitVar[int], Gt(1)]

    tiv = TestInitVar(1, 2, 3)
    assert tiv.x == 1
    with pytest.raises(AttributeError):
        tiv.y

    with pytest.raises(ValidationError):
        TestInitVar(1, 2, 0)


def test_initvar_pydantic_field() -> None:
    @pydantic.dataclasses.dataclass
    class TestInitVar:
        x: InitVar[int] = Field(title='X')

        def __post_init__(self, x: int):
            assert x == 1

    assert TestInitVar.__pydantic_fields__['x'].init_var

    TestInitVar(x=1)


@pytest.mark.xfail(reason='Ideally we should raise an attribute error, like stdlib dataclasses')
def test_initvar_pydantic_field_attribute_access() -> None:
    @pydantic.dataclasses.dataclass
    class TestInitVar:
        x: InitVar[int] = Field(title='X')

    t = TestInitVar(x=1)

    # Currently this returns the `FieldInfo` instance:
    with pytest.raises(AttributeError):
        t.x


def test_derived_field_from_initvar():
    @pydantic.dataclasses.dataclass
    class DerivedWithInitVar:
        plusone: int = dataclasses.field(init=False)
        number: dataclasses.InitVar[int]

        def __post_init__(self, number):
            self.plusone = number + 1

    derived = DerivedWithInitVar('1')
    assert derived.plusone == 2
    with pytest.raises(ValidationError, match='Input should be a valid integer, unable to parse string as an integer'):
        DerivedWithInitVar('Not A Number')


def test_initvars_post_init():
    @pydantic.dataclasses.dataclass
    class PathDataPostInit:
        path: Path
        base_path: dataclasses.InitVar[Optional[Path]] = None

        def __post_init__(self, base_path):
            if base_path is not None:
                self.path = base_path / self.path

    path_data = PathDataPostInit('world')
    assert 'path' in path_data.__dict__
    assert 'base_path' not in path_data.__dict__
    assert path_data.path == Path('world')

    p = PathDataPostInit('world', base_path='/hello')
    assert p.path == Path('/hello/world')


def test_classvar():
    @pydantic.dataclasses.dataclass
    class TestClassVar:
        klassvar: ClassVar = "I'm a Class variable"
        x: int

    tcv = TestClassVar(2)
    assert tcv.klassvar == "I'm a Class variable"


def test_frozenset_field():
    @pydantic.dataclasses.dataclass
    class TestFrozenSet:
        set: frozenset[int]

    test_set = frozenset({1, 2, 3})
    object_under_test = TestFrozenSet(set=test_set)

    assert object_under_test.set == test_set


def test_inheritance_post_init():
    post_init_called = False

    @pydantic.dataclasses.dataclass
    class Base:
        a: int

        def __post_init__(self):
            nonlocal post_init_called
            post_init_called = True

    @pydantic.dataclasses.dataclass
    class Child(Base):
        b: int

    Child(a=1, b=2)
    assert post_init_called


def test_hashable_required():
    @pydantic.dataclasses.dataclass
    class MyDataclass:
        v: Hashable

    MyDataclass(v=None)
    with pytest.raises(ValidationError) as exc_info:
        MyDataclass(v=[])
    assert exc_info.value.errors(include_url=False) == [
        {'input': [], 'loc': ('v',), 'msg': 'Input should be hashable', 'type': 'is_hashable'}
    ]

    with pytest.raises(ValidationError) as exc_info:
        # Should this raise a TypeError instead? https://github.com/pydantic/pydantic/issues/5487
        MyDataclass()
    assert exc_info.value.errors(include_url=False) == [
        {'input': HasRepr('ArgsKwargs(())'), 'loc': ('v',), 'msg': 'Field required', 'type': 'missing'}
    ]


@pytest.mark.parametrize('default', [1, None])
def test_default_value(default):
    @pydantic.dataclasses.dataclass
    class MyDataclass:
        v: int = default

    assert dataclasses.asdict(MyDataclass()) == {'v': default}
    assert dataclasses.asdict(MyDataclass(v=42)) == {'v': 42}


def test_default_value_ellipsis():
    """
    https://github.com/pydantic/pydantic/issues/5488
    """

    @pydantic.dataclasses.dataclass
    class MyDataclass:
        v: int = ...

    assert dataclasses.asdict(MyDataclass(v=42)) == {'v': 42}
    with pytest.raises(ValidationError, match='type=missing'):
        MyDataclass()


def test_override_builtin_dataclass():
    @dataclasses.dataclass
    class File:
        hash: str
        name: Optional[str]
        size: int
        content: Optional[bytes] = None

    ValidFile = pydantic.dataclasses.dataclass(File)

    file = File(hash='xxx', name=b'whatever.txt', size='456')
    valid_file = ValidFile(hash='xxx', name=b'whatever.txt', size='456')

    assert file.name == b'whatever.txt'
    assert file.size == '456'

    assert valid_file.name == 'whatever.txt'
    assert valid_file.size == 456

    assert isinstance(valid_file, File)
    assert isinstance(valid_file, ValidFile)

    with pytest.raises(ValidationError) as e:
        ValidFile(hash=[1], name='name', size=3)

    assert e.value.errors(include_url=False) == [
        {
            'type': 'string_type',
            'loc': ('hash',),
            'msg': 'Input should be a valid string',
            'input': [1],
        },
    ]


def test_override_builtin_dataclass_2():
    @dataclasses.dataclass
    class Meta:
        modified_date: Optional[datetime]
        seen_count: int

    Meta(modified_date='not-validated', seen_count=0)

    @pydantic.dataclasses.dataclass
    @dataclasses.dataclass
    class File(Meta):
        filename: str

    Meta(modified_date='still-not-validated', seen_count=0)

    f = File(filename=b'thefilename', modified_date='2020-01-01T00:00', seen_count='7')
    assert f.filename == 'thefilename'
    assert f.modified_date == datetime(2020, 1, 1, 0, 0)
    assert f.seen_count == 7


def test_override_builtin_dataclass_nested():
    @dataclasses.dataclass
    class Meta:
        modified_date: Optional[datetime]
        seen_count: int

        __pydantic_config__ = {'revalidate_instances': 'always'}

    @dataclasses.dataclass
    class File:
        filename: str
        meta: Meta

    FileChecked = pydantic.dataclasses.dataclass(File)
    f = FileChecked(filename=b'thefilename', meta=Meta(modified_date='2020-01-01T00:00', seen_count='7'))
    assert f.filename == 'thefilename'
    assert f.meta.modified_date == datetime(2020, 1, 1, 0, 0)
    assert f.meta.seen_count == 7

    with pytest.raises(ValidationError) as e:
        FileChecked(filename=b'thefilename', meta=Meta(modified_date='2020-01-01T00:00', seen_count=['7']))
    # insert_assert(e.value.errors(include_url=False))
    assert e.value.errors(include_url=False) == [
        {'type': 'int_type', 'loc': ('meta', 'seen_count'), 'msg': 'Input should be a valid integer', 'input': ['7']}
    ]

    class Foo(
        BaseModel,
    ):
        file: File

    foo = Foo.model_validate(
        {
            'file': {
                'filename': b'thefilename',
                'meta': {'modified_date': '2020-01-01T00:00', 'seen_count': '7'},
            },
        }
    )
    assert foo.file.filename == 'thefilename'
    assert foo.file.meta.modified_date == datetime(2020, 1, 1, 0, 0)
    assert foo.file.meta.seen_count == 7


def test_override_builtin_dataclass_nested_schema():
    @dataclasses.dataclass
    class Meta:
        modified_date: Optional[datetime]
        seen_count: int

    @dataclasses.dataclass
    class File:
        filename: str
        meta: Meta

    FileChecked = pydantic.dataclasses.dataclass(File)
    assert model_json_schema(FileChecked) == {
        '$defs': {
            'Meta': {
                'properties': {
                    'modified_date': {
                        'anyOf': [{'format': 'date-time', 'type': 'string'}, {'type': 'null'}],
                        'title': 'Modified Date',
                    },
                    'seen_count': {'title': 'Seen Count', 'type': 'integer'},
                },
                'required': ['modified_date', 'seen_count'],
                'title': 'Meta',
                'type': 'object',
            }
        },
        'properties': {'filename': {'title': 'Filename', 'type': 'string'}, 'meta': {'$ref': '#/$defs/Meta'}},
        'required': ['filename', 'meta'],
        'title': 'File',
        'type': 'object',
    }


def test_inherit_builtin_dataclass():
    @dataclasses.dataclass
    class Z:
        z: int

    @dataclasses.dataclass
    class Y(Z):
        y: int

    @pydantic.dataclasses.dataclass
    class X(Y):
        x: int

    pika = X(x='2', y='4', z='3')
    assert pika.x == 2
    assert pika.y == 4
    assert pika.z == 3


def test_forward_stdlib_dataclass_params():
    @dataclasses.dataclass(frozen=True)
    class Item:
        name: str

    class Example(BaseModel):
        item: Item
        other: str

        model_config = ConfigDict(arbitrary_types_allowed=True)

    e = Example(item=Item(name='pika'), other='bulbi')
    e.other = 'bulbi2'
    with pytest.raises(dataclasses.FrozenInstanceError):
        e.item.name = 'pika2'


def test_pydantic_callable_field():
    """pydantic callable fields behaviour should be the same as stdlib dataclass"""

    def foo(arg1, arg2):
        return arg1, arg2

    def bar(x: int, y: float, z: str) -> bool:
        return str(x + y) == z

    class PydanticModel(BaseModel):
        required_callable: Callable
        required_callable_2: Callable[[int, float, str], bool]

        default_callable: Callable = foo
        default_callable_2: Callable[[int, float, str], bool] = bar

    @pydantic.dataclasses.dataclass
    class PydanticDataclass:
        required_callable: Callable
        required_callable_2: Callable[[int, float, str], bool]

        default_callable: Callable = foo
        default_callable_2: Callable[[int, float, str], bool] = bar

    @dataclasses.dataclass
    class StdlibDataclass:
        required_callable: Callable
        required_callable_2: Callable[[int, float, str], bool]

        default_callable: Callable = foo
        default_callable_2: Callable[[int, float, str], bool] = bar

    pyd_m = PydanticModel(required_callable=foo, required_callable_2=bar)
    pyd_dc = PydanticDataclass(required_callable=foo, required_callable_2=bar)
    std_dc = StdlibDataclass(required_callable=foo, required_callable_2=bar)

    assert (
        pyd_m.required_callable
        is pyd_m.default_callable
        is pyd_dc.required_callable
        is pyd_dc.default_callable
        is std_dc.required_callable
        is std_dc.default_callable
    )
    assert (
        pyd_m.required_callable_2
        is pyd_m.default_callable_2
        is pyd_dc.required_callable_2
        is pyd_dc.default_callable_2
        is std_dc.required_callable_2
        is std_dc.default_callable_2
    )


def test_pickle_overridden_builtin_dataclass(create_module: Any):
    module = create_module(
        # language=Python
        """\
import dataclasses
import pydantic


@pydantic.dataclasses.dataclass(config=pydantic.config.ConfigDict(validate_assignment=True))
class BuiltInDataclassForPickle:
    value: int
        """
    )
    obj = module.BuiltInDataclassForPickle(value=5)

    pickled_obj = pickle.dumps(obj)
    restored_obj = pickle.loads(pickled_obj)

    assert restored_obj.value == 5
    assert restored_obj == obj

    # ensure the restored dataclass is still a pydantic dataclass
    with pytest.raises(ValidationError):
        restored_obj.value = 'value of a wrong type'


def lazy_cases_for_dataclass_equality_checks():
    """
    The reason for the convoluted structure of this function is to avoid
    creating the classes while collecting tests, which may trigger breakpoints
    etc. while working on one specific test.
    """
    cases = []

    def get_cases():
        if cases:
            return cases  # cases already "built"

        @dataclasses.dataclass(frozen=True)
        class StdLibFoo:
            a: str
            b: int

        @pydantic.dataclasses.dataclass(frozen=True)
        class PydanticFoo:
            a: str
            b: int

        @dataclasses.dataclass(frozen=True)
        class StdLibBar:
            c: StdLibFoo

        @pydantic.dataclasses.dataclass(frozen=True)
        class PydanticBar:
            c: PydanticFoo

        @dataclasses.dataclass(frozen=True)
        class StdLibBaz:
            c: PydanticFoo

        @pydantic.dataclasses.dataclass(frozen=True)
        class PydanticBaz:
            c: StdLibFoo

        foo = StdLibFoo(a='Foo', b=1)
        cases.append((foo, StdLibBar(c=foo)))

        foo = PydanticFoo(a='Foo', b=1)
        cases.append((foo, PydanticBar(c=foo)))

        foo = PydanticFoo(a='Foo', b=1)
        cases.append((foo, StdLibBaz(c=foo)))

        foo = StdLibFoo(a='Foo', b=1)
        cases.append((foo, PydanticBaz(c=foo)))

        return cases

    case_ids = ['stdlib_stdlib', 'pydantic_pydantic', 'pydantic_stdlib', 'stdlib_pydantic']

    def case(i):
        def get_foo_bar():
            return get_cases()[i]

        get_foo_bar.__name__ = case_ids[i]  # get nice names in pytest output
        return get_foo_bar

    return [case(i) for i in range(4)]


@pytest.mark.parametrize('foo_bar_getter', lazy_cases_for_dataclass_equality_checks())
def test_dataclass_equality_for_field_values(foo_bar_getter):
    # Related to issue #2162
    foo, bar = foo_bar_getter()
    assert dataclasses.asdict(foo) == dataclasses.asdict(bar.c)
    assert dataclasses.astuple(foo) == dataclasses.astuple(bar.c)
    assert foo == bar.c


def test_hash_method_preserved() -> None:
    """https://github.com/pydantic/pydantic/issues/2383"""

    @dataclasses.dataclass
    class A:
        s: str

        def __hash__(self):
            return 123

    class B(pydantic.BaseModel):
        a: A

    a = A('')
    b = B(a=a)

    assert hash(a) == 123
    assert hash(b.a) == 123


def test_order_preserved() -> None:
    """https://github.com/pydantic/pydantic/issues/2398"""

    @dataclasses.dataclass(order=True)
    class DC:
        num: int = 42

    class Model(pydantic.BaseModel):
        dc: DC

    real_dc = DC()
    model = Model(dc=real_dc)

    # This works as expected.
    assert real_dc <= real_dc
    assert model.dc <= model.dc
    assert real_dc <= model.dc


def test_default_factory_works_on_subclasses() -> None:
    """https://github.com/pydantic/pydantic/issues/2424"""

    @dataclasses.dataclass
    class Base:
        x: str

    @dataclasses.dataclass
    class Thing(Base):
        y: str = dataclasses.field(default_factory=str)

    assert Thing(x='hi').y == ''

    @pydantic.dataclasses.dataclass
    class ValidatedThing(Base):
        y: str = dataclasses.field(default_factory=str)

    assert Thing(x='hi').y == ''
    assert ValidatedThing(x='hi').y == ''


def test_override_default_stdlib_dataclass() -> None:
    """https://github.com/pydantic/pydantic/issues/11816"""

    @dataclasses.dataclass
    class Test:
        value: int = 1

    @pydantic.dataclasses.dataclass
    class Sub(Test):
        value: int = 2

    assert Sub().value == 2


def test_frozen_preserved_on_model_field() -> None:
    """https://github.com/pydantic/pydantic/issues/2541"""

    @dataclasses.dataclass(frozen=True)
    class Infos:
        id: int

    @dataclasses.dataclass(frozen=True)
    class Item:
        name: str
        infos: Infos

    class Example(BaseModel):
        item: Item

    e = Example.model_validate({'item': {'name': '123', 'infos': {'id': '1'}}})
    assert e.item.name == '123'
    assert e.item.infos.id == 1
    with pytest.raises(dataclasses.FrozenInstanceError):
        e.item.infos.id = 2


def test_complex_nested_vanilla_dataclass():
    @dataclasses.dataclass
    class Span:
        first: int
        last: int

    @dataclasses.dataclass
    class LabeledSpan(Span):
        label: str

    @dataclasses.dataclass
    class BinaryRelation:
        subject: LabeledSpan
        object: LabeledSpan
        label: str

    @dataclasses.dataclass
    class Sentence:
        relations: BinaryRelation

    class M(pydantic.BaseModel):
        s: Sentence

    assert M.model_json_schema() == {
        '$defs': {
            'BinaryRelation': {
                'properties': {
                    'label': {'title': 'Label', 'type': 'string'},
                    'object': {'$ref': '#/$defs/LabeledSpan'},
                    'subject': {'$ref': '#/$defs/LabeledSpan'},
                },
                'required': ['subject', 'object', 'label'],
                'title': 'BinaryRelation',
                'type': 'object',
            },
            'LabeledSpan': {
                'properties': {
                    'first': {'title': 'First', 'type': 'integer'},
                    'label': {'title': 'Label', 'type': 'string'},
                    'last': {'title': 'Last', 'type': 'integer'},
                },
                'required': ['first', 'last', 'label'],
                'title': 'LabeledSpan',
                'type': 'object',
            },
            'Sentence': {
                'properties': {'relations': {'$ref': '#/$defs/BinaryRelation'}},
                'required': ['relations'],
                'title': 'Sentence',
                'type': 'object',
            },
        },
        'properties': {'s': {'$ref': '#/$defs/Sentence'}},
        'required': ['s'],
        'title': 'M',
        'type': 'object',
    }


def test_json_schema_with_computed_field():
    @dataclasses.dataclass
    class MyDataclass:
        x: int

        @computed_field
        @property
        def double_x(self) -> int:
            return 2 * self.x

    class Model(BaseModel):
        dc: MyDataclass

    assert Model.model_json_schema(mode='validation') == {
        '$defs': {
            'MyDataclass': {
                'properties': {'x': {'title': 'X', 'type': 'integer'}},
                'required': ['x'],
                'title': 'MyDataclass',
                'type': 'object',
            }
        },
        'properties': {'dc': {'$ref': '#/$defs/MyDataclass'}},
        'required': ['dc'],
        'title': 'Model',
        'type': 'object',
    }
    assert Model.model_json_schema(mode='serialization') == {
        '$defs': {
            'MyDataclass': {
                'properties': {
                    'double_x': {'readOnly': True, 'title': 'Double X', 'type': 'integer'},
                    'x': {'title': 'X', 'type': 'integer'},
                },
                'required': ['x', 'double_x'],
                'title': 'MyDataclass',
                'type': 'object',
            }
        },
        'properties': {'dc': {'$ref': '#/$defs/MyDataclass'}},
        'required': ['dc'],
        'title': 'Model',
        'type': 'object',
    }


def test_supports_stdlib_dataclass_without_annotations() -> None:
    """https://github.com/pydantic/pydantic/issues/2594"""

    @dataclasses.dataclass
    class Empty:
        pass

    @pydantic.dataclasses.dataclass
    class M:
        e: Empty

    assert isinstance(M(e={}).e, Empty)


def test_schema_description_unset():
    @pydantic.dataclasses.dataclass
    class A:
        x: int

    assert 'description' not in model_json_schema(A)

    @pydantic.dataclasses.dataclass
    @dataclasses.dataclass
    class B:
        x: int

    assert 'description' not in model_json_schema(B)


def test_schema_description_set():
    @pydantic.dataclasses.dataclass
    class A:
        """my description"""

        x: int

    assert model_json_schema(A)['description'] == 'my description'

    @pydantic.dataclasses.dataclass
    @dataclasses.dataclass
    class B:
        """my description"""

        x: int

    assert model_json_schema(A)['description'] == 'my description'


def test_subclass_of_a_dataclass_supported() -> None:
    """https://github.com/pydantic/pydantic/issues/3011"""

    @dataclasses.dataclass
    class A:
        thing_a: str

    class B(A):
        thing_b: str

    @pydantic.dataclasses.dataclass
    class C:
        thing: A

    b = B('Thing A')
    c = C(thing=b)
    assert c.thing.thing_a == 'Thing A'


def test_dataclass_referenced_twice() -> None:
    """https://github.com/pydantic/pydantic/issues/3162"""

    @dataclasses.dataclass
    class User:
        id: int
        name: str

    class Users(BaseModel):
        user: User
        other_user: User

    assert Users.model_json_schema() == {
        '$defs': {
            'User': {
                'properties': {'id': {'title': 'Id', 'type': 'integer'}, 'name': {'title': 'Name', 'type': 'string'}},
                'required': ['id', 'name'],
                'title': 'User',
                'type': 'object',
            }
        },
        'properties': {'other_user': {'$ref': '#/$defs/User'}, 'user': {'$ref': '#/$defs/User'}},
        'required': ['user', 'other_user'],
        'title': 'Users',
        'type': 'object',
    }


def test_discriminated_union_basemodel_instance_value():
    @pydantic.dataclasses.dataclass
    class A:
        l: Literal['a']  # noqa: E741

    @pydantic.dataclasses.dataclass
    class B:
        l: Literal['b']  # noqa: E741

    @pydantic.dataclasses.dataclass
    class Top:
        sub: Union[A, B] = dataclasses.field(metadata=dict(discriminator='l'))

    t = Top(sub=A(l='a'))
    assert isinstance(t, Top)
    # insert_assert(model_json_schema(Top))
    assert model_json_schema(Top) == {
        'title': 'Top',
        'type': 'object',
        'properties': {
            'sub': {
                'title': 'Sub',
                'discriminator': {'mapping': {'a': '#/$defs/A', 'b': '#/$defs/B'}, 'propertyName': 'l'},
                'oneOf': [{'$ref': '#/$defs/A'}, {'$ref': '#/$defs/B'}],
            }
        },
        'required': ['sub'],
        '$defs': {
            'A': {
                'properties': {'l': {'const': 'a', 'title': 'L', 'type': 'string'}},
                'required': ['l'],
                'title': 'A',
                'type': 'object',
            },
            'B': {
                'properties': {'l': {'const': 'b', 'title': 'L', 'type': 'string'}},
                'required': ['l'],
                'title': 'B',
                'type': 'object',
            },
        },
    }


def test_post_init_after_validation():
    @dataclasses.dataclass
    class SetWrapper:
        set: set[int]

        def __post_init__(self):
            assert isinstance(self.set, set), (
                f"self.set should be a set but it's {self.set!r} of type {type(self.set).__name__}"
            )

    class Model(pydantic.BaseModel):
        set_wrapper: SetWrapper

    model = Model(set_wrapper=SetWrapper({1, 2, 3}))
    json_text = model.model_dump_json()
    assert Model.model_validate_json(json_text).model_dump() == model.model_dump()


def test_new_not_called():
    """
    pydantic dataclasses do not preserve sunder attributes set in __new__
    """

    class StandardClass:
        """Class which modifies instance creation."""

        a: str

        def __new__(cls, *args, **kwargs):
            instance = super().__new__(cls)

            instance._special_property = 1

            return instance

    StandardLibDataclass = dataclasses.dataclass(StandardClass)
    PydanticDataclass = pydantic.dataclasses.dataclass(StandardClass)

    test_string = 'string'

    std_instance = StandardLibDataclass(a=test_string)
    assert std_instance._special_property == 1
    assert std_instance.a == test_string

    pyd_instance = PydanticDataclass(a=test_string)
    assert not hasattr(pyd_instance, '_special_property')
    assert pyd_instance.a == test_string


def test_ignore_extra():
    @pydantic.dataclasses.dataclass(config=ConfigDict(extra='ignore'))
    class Foo:
        x: int

    foo = Foo(**{'x': '1', 'y': '2'})
    assert foo.__dict__ == {'x': 1}


def test_ignore_extra_subclass():
    @pydantic.dataclasses.dataclass(config=ConfigDict(extra='ignore'))
    class Foo:
        x: int

    @pydantic.dataclasses.dataclass(config=ConfigDict(extra='ignore'))
    class Bar(Foo):
        y: int

    bar = Bar(**{'x': '1', 'y': '2', 'z': '3'})
    assert bar.__dict__ == {'x': 1, 'y': 2}


def test_allow_extra():
    @pydantic.dataclasses.dataclass(config=ConfigDict(extra='allow'))
    class Foo:
        x: int

    foo = Foo(**{'x': '1', 'y': '2'})
    assert foo.__dict__ == {'x': 1, 'y': '2'}


def test_allow_extra_subclass():
    @pydantic.dataclasses.dataclass(config=ConfigDict(extra='allow'))
    class Foo:
        x: int

    @pydantic.dataclasses.dataclass(config=ConfigDict(extra='allow'))
    class Bar(Foo):
        y: int

    bar = Bar(**{'x': '1', 'y': '2', 'z': '3'})
    assert bar.__dict__ == {'x': 1, 'y': 2, 'z': '3'}


def test_forbid_extra():
    @pydantic.dataclasses.dataclass(config=ConfigDict(extra='forbid'))
    class Foo:
        x: int

    msg = re.escape("Unexpected keyword argument [type=unexpected_keyword_argument, input_value='2', input_type=str]")

    with pytest.raises(ValidationError, match=msg):
        Foo(**{'x': '1', 'y': '2'})


def test_self_reference_dataclass():
    @pydantic.dataclasses.dataclass
    class MyDataclass:
        self_reference: Optional['MyDataclass'] = None

    assert MyDataclass.__pydantic_fields__['self_reference'].annotation == Optional[MyDataclass]

    instance = MyDataclass(self_reference=MyDataclass(self_reference=MyDataclass()))
    assert TypeAdapter(MyDataclass).dump_python(instance) == {
        'self_reference': {'self_reference': {'self_reference': None}}
    }

    with pytest.raises(ValidationError) as exc_info:
        MyDataclass(self_reference=1)

    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'dataclass_type',
            'loc': ('self_reference',),
            'msg': 'Input should be a dictionary or an instance of MyDataclass',
            'input': 1,
            'ctx': {'class_name': 'MyDataclass'},
        }
    ]


def test_cyclic_reference_dataclass(create_module):
    @pydantic.dataclasses.dataclass(config=ConfigDict(extra='forbid'))
    class D1:
        d2: Optional['D2'] = None

    @create_module
    def module():
        from typing import Optional

        import pydantic

        @pydantic.dataclasses.dataclass(config=pydantic.ConfigDict(extra='forbid'))
        class D2:
            d1: Optional['D1'] = None

    # Ensure D2 is in the local namespace; note everything works even though it wasn't _defined_ in this namespace
    D2 = module.D2

    # Confirm D1 and D2 require rebuilding
    assert isinstance(D1.__pydantic_validator__, MockValSer)
    assert isinstance(D2.__pydantic_validator__, MockValSer)

    # Note: the rebuilds of D1 and D2 happen automatically, and works since it grabs the locals here as the namespace,
    # which contains D1 and D2
    instance = D1(d2=D2(d1=D1(d2=D2(d1=D1()))))

    # Confirm D1 and D2 have been rebuilt
    assert isinstance(D1.__pydantic_validator__, SchemaValidator)
    assert isinstance(D2.__pydantic_validator__, SchemaValidator)

    assert TypeAdapter(D1).dump_python(instance) == {'d2': {'d1': {'d2': {'d1': {'d2': None}}}}}

    with pytest.raises(ValidationError) as exc_info:
        D2(d1=D2())
    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'dataclass_type',
            'loc': ('d1',),
            'msg': 'Input should be a dictionary or an instance of D1',
            'input': D2(d1=None),
            'ctx': {'class_name': 'D1'},
        }
    ]

    with pytest.raises(ValidationError) as exc_info:
        TypeAdapter(D1).validate_python(dict(d2=dict(d1=dict(d2=dict(d2=dict())))))
    assert exc_info.value.errors(include_url=False) == [
        {
            'input': {},
            'loc': ('d2', 'd1', 'd2', 'd2'),
            'msg': 'Unexpected keyword argument',
            'type': 'unexpected_keyword_argument',
        }
    ]


def test_cross_module_cyclic_reference_dataclass(create_module):
    @pydantic.dataclasses.dataclass(config=ConfigDict(extra='forbid'))
    class D1:
        d2: Optional['D2'] = None  # noqa F821

    @create_module
    def module():
        from typing import Optional

        import pydantic

        @pydantic.dataclasses.dataclass(config=pydantic.ConfigDict(extra='forbid'))
        class D2:
            d1: Optional['D1'] = None

    # Since D2 is not in locals, it will not be picked up by the auto-rebuild:
    with pytest.raises(
        PydanticUserError,
        match=re.escape(
            '`D1` is not fully defined; you should define `D2`, then call `pydantic.dataclasses.rebuild_dataclass(D1)`.'
        ),
    ):
        D1()

    # Explicitly rebuild D1, specifying the appropriate types namespace
    rebuild_dataclass(D1, _types_namespace={'D2': module.D2, 'D1': D1})

    # Confirm D2 still requires a rebuild (it will happen automatically)
    assert isinstance(module.D2.__pydantic_validator__, MockValSer)

    instance = D1(d2=module.D2(d1=D1(d2=module.D2(d1=D1()))))

    # Confirm auto-rebuild of D2 has now happened
    assert isinstance(module.D2.__pydantic_validator__, SchemaValidator)

    assert TypeAdapter(D1).dump_python(instance) == {'d2': {'d1': {'d2': {'d1': {'d2': None}}}}}

    with pytest.raises(ValidationError) as exc_info:
        module.D2(d1=module.D2())
    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'dataclass_type',
            'input': module.D2(d1=None),
            'loc': ('d1',),
            'msg': 'Input should be a dictionary or an instance of D1',
            'ctx': {'class_name': 'D1'},
        }
    ]

    with pytest.raises(ValidationError) as exc_info:
        TypeAdapter(D1).validate_python(dict(d2=dict(d1=dict(d2=dict(d2=dict())))))
    assert exc_info.value.errors(include_url=False) == [
        {
            'input': {},
            'loc': ('d2', 'd1', 'd2', 'd2'),
            'msg': 'Unexpected keyword argument',
            'type': 'unexpected_keyword_argument',
        }
    ]


@pytest.mark.parametrize(
    'dataclass_decorator',
    [
        pydantic.dataclasses.dataclass,
        dataclasses.dataclass,
    ],
    ids=['pydantic', 'stdlib'],
)
def test_base_dataclasses_annotations_resolving(create_module, dataclass_decorator: Callable):
    @create_module
    def module():
        import dataclasses
        from typing import NewType

        OddInt = NewType('OddInt', int)

        @dataclasses.dataclass
        class D1:
            d1: 'OddInt'
            s: str

            __pydantic_config__ = {'str_to_lower': True}

    @dataclass_decorator
    class D2(module.D1):
        d2: int

    assert TypeAdapter(D2).validate_python({'d1': 1, 'd2': 2, 's': 'ABC'}) == D2(d1=1, d2=2, s='abc')


@pytest.mark.parametrize(
    'dataclass_decorator',
    [
        pydantic.dataclasses.dataclass,
        dataclasses.dataclass,
    ],
    ids=['pydantic', 'stdlib'],
)
def test_base_dataclasses_annotations_resolving_with_override(create_module, dataclass_decorator: Callable):
    @create_module
    def module1():
        import dataclasses
        from typing import NewType

        IDType = NewType('IDType', int)

        @dataclasses.dataclass
        class D1:
            db_id: 'IDType'

            __pydantic_config__ = {'str_to_lower': True}

    @create_module
    def module2():
        import dataclasses
        from typing import NewType

        IDType = NewType('IDType', str)

        @dataclasses.dataclass
        class D2:
            db_id: 'IDType'
            s: str

            __pydantic_config__ = {'str_to_lower': False}

    @dataclass_decorator
    class D3(module1.D1, module2.D2): ...

    assert TypeAdapter(D3).validate_python({'db_id': 42, 's': 'ABC'}) == D3(db_id=42, s='abc')


@pytest.mark.skipif(sys.version_info < (3, 10), reason='kw_only is not available in python < 3.10')
def test_kw_only():
    @pydantic.dataclasses.dataclass(kw_only=True)
    class A:
        a: int | None = None
        b: str

    with pytest.raises(ValidationError):
        A(1, '')

    assert A(b='hi').b == 'hi'


@pytest.mark.skipif(sys.version_info < (3, 10), reason='kw_only is not available in python < 3.10')
def test_kw_only_subclass():
    @pydantic.dataclasses.dataclass
    class A:
        x: int
        y: int = pydantic.Field(default=0, kw_only=True)

    @pydantic.dataclasses.dataclass
    class B(A):
        z: int

    assert B(1, 2) == B(x=1, y=0, z=2)
    assert B(1, y=2, z=3) == B(x=1, y=2, z=3)


@pytest.mark.parametrize('field_constructor', [pydantic.dataclasses.Field, dataclasses.field])
def test_repr_false(field_constructor: Callable):
    @pydantic.dataclasses.dataclass
    class A:
        visible_field: str
        hidden_field: str = field_constructor(repr=False)

    instance = A(visible_field='this_should_be_included', hidden_field='this_should_not_be_included')
    assert "visible_field='this_should_be_included'" in repr(instance)
    assert "hidden_field='this_should_not_be_included'" not in repr(instance)


def dataclass_decorators(include_identity: bool = False, exclude_combined: bool = False):
    decorators = [pydantic.dataclasses.dataclass, dataclasses.dataclass]
    ids = ['pydantic', 'stdlib']

    if not exclude_combined:

        def combined_decorator(cls):
            """
            Should be equivalent to:
            @pydantic.dataclasses.dataclass
            @dataclasses.dataclass
            """
            return pydantic.dataclasses.dataclass(dataclasses.dataclass(cls))

        decorators.append(combined_decorator)
        ids.append('combined')

    if include_identity:

        def identity_decorator(cls):
            return cls

        decorators.append(identity_decorator)
        ids.append('identity')

    return {'argvalues': decorators, 'ids': ids}


@pytest.mark.skipif(sys.version_info < (3, 10), reason='kw_only is not available in python < 3.10')
@pytest.mark.parametrize('decorator1', **dataclass_decorators(exclude_combined=True))
@pytest.mark.parametrize('decorator2', **dataclass_decorators(exclude_combined=True))
def test_kw_only_inheritance(decorator1, decorator2):
    # Exclude combined from the decorators since it doesn't know how to accept kw_only
    @decorator1(kw_only=True)
    class Parent:
        x: int

    @decorator2
    class Child(Parent):
        y: int

    child = Child(1, x=2)
    assert child.x == 2
    assert child.y == 1


def test_kw_only_inheritance_on_field() -> None:
    @dataclasses.dataclass
    class A:
        x: int = Field(kw_only=True)

    @pydantic.dataclasses.dataclass
    class B(A):
        pass

    if sys.version_info >= (3, 10):  # On 3.9, we ignore kw_only.
        with pytest.raises(ValidationError):
            B(1)


def test_repr_inheritance() -> None:
    @dataclasses.dataclass
    class A:
        a: int = Field(repr=False)

    @pydantic.dataclasses.dataclass
    class B(A):
        pass

    assert repr(B(a=1)).endswith('B()')


@pytest.mark.skipif(sys.version_info < (3, 14), reason='`doc` added in 3.14')
def test_description_as_doc_in_slots() -> None:
    @pydantic.dataclasses.dataclass(slots=True)
    class A:
        a: int = Field(description='a doc')

    assert A.__slots__ == {'a': 'a doc'}


def test_extra_forbid_list_no_error():
    @pydantic.dataclasses.dataclass(config=dict(extra='forbid'))
    class Bar: ...

    @pydantic.dataclasses.dataclass
    class Foo:
        a: list[Bar]

    assert isinstance(Foo(a=[Bar()]).a[0], Bar)


def test_extra_forbid_list_error():
    @pydantic.dataclasses.dataclass(config=ConfigDict(extra='forbid'))
    class Bar: ...

    with pytest.raises(ValidationError, match=r'a\s+Unexpected keyword argument'):
        Bar(a=1)


def test_field_validator():
    @pydantic.dataclasses.dataclass
    class MyDataclass:
        a: int
        b: float

        @field_validator('b')
        @classmethod
        def double_b(cls, v):
            return v * 2

    d = MyDataclass('1', '2.5')
    assert d.a == 1
    assert d.b == 5.0


def test_model_validator_before():
    @pydantic.dataclasses.dataclass
    class MyDataclass:
        a: int
        b: float

        @model_validator(mode='before')
        @classmethod
        def double_b(cls, v: ArgsKwargs):
            v.kwargs['b'] *= 2
            return v

    d = MyDataclass('1', b='2')
    assert d.a == 1
    assert d.b == 22.0


def test_model_validator_after():
    @pydantic.dataclasses.dataclass
    class MyDataclass:
        a: int
        b: float

        @model_validator(mode='after')
        def double_b(self) -> 'MyDataclass':
            self.b *= 2
            return self

    d = MyDataclass('1', b='2')
    assert d.a == 1
    assert d.b == 4


def test_parent_post_init():
    """
    Test that the parent's __post_init__ gets called
    and the order in which it gets called relative to validation.

    In V1 we called it before validation, in V2 it gets called after.
    """

    @dataclasses.dataclass
    class A:
        a: float

        def __post_init__(self):
            self.a *= 2

    assert A(a=1.2).a == 2.4

    @pydantic.dataclasses.dataclass
    class B(A):
        @field_validator('a')
        @classmethod
        def validate_a(cls, value, _):
            value += 3
            return value

    assert B(a=1).a == 8  # (1 + 3) * 2 = 8


def test_subclass_post_init_order():
    @dataclasses.dataclass
    class A:
        a: float

    @pydantic.dataclasses.dataclass
    class B(A):
        def __post_init__(self):
            self.a *= 2

        @field_validator('a')
        @classmethod
        def validate_a(cls, value):
            value += 3
            return value

    assert B(a=1).a == 8  # (1 + 3) * 2 = 8


def test_subclass_post_init_inheritance():
    @dataclasses.dataclass
    class A:
        a: int

    @pydantic.dataclasses.dataclass
    class B(A):
        def __post_init__(self):
            self.a *= 2

        @field_validator('a')
        @classmethod
        def validate_a(cls, value):
            value += 3
            return value

    @pydantic.dataclasses.dataclass
    class C(B):
        def __post_init__(self):
            self.a *= 3

    assert C(1).a == 12  # (1 + 3) * 3


def test_config_as_type_deprecated():
    class Config:
        validate_assignment = True

    with pytest.warns(
        PydanticDeprecatedSince20, match='Support for class-based `config` is deprecated, use ConfigDict instead.'
    ):

        @pydantic.dataclasses.dataclass(config=Config)
        class MyDataclass:
            a: int

    assert MyDataclass.__pydantic_config__ == ConfigDict(validate_assignment=True)


def test_validator_info_field_name_data_before():
    """
    Test accessing info.field_name and info.data
    We only test the `before` validator because they
    all share the same implementation.
    """

    @pydantic.dataclasses.dataclass
    class Model:
        a: str
        b: str

        @field_validator('b', mode='before')
        @classmethod
        def check_a(cls, v: Any, info: ValidationInfo) -> Any:
            assert v == b'but my barbaz is better'
            assert info.field_name == 'b'
            assert info.data == {'a': 'your foobar is good'}
            return 'just kidding!'

    assert Model(a=b'your foobar is good', b=b'but my barbaz is better').b == 'just kidding!'


@pytest.mark.parametrize(
    'decorator1, expected_parent, expected_child',
    [
        (
            pydantic.dataclasses.dataclass,
            ['parent before', 'parent', 'parent after'],
            ['parent before', 'child', 'parent after', 'child before', 'child after'],
        ),
        (dataclasses.dataclass, [], ['parent before', 'child', 'parent after', 'child before', 'child after']),
    ],
    ids=['pydantic', 'stdlib'],
)
def test_inheritance_replace(decorator1: Callable[[Any], Any], expected_parent: list[str], expected_child: list[str]):
    """We promise that if you add a validator
    with the same _function_ name as an existing validator
    it replaces the existing validator and is run instead of it.
    """

    @decorator1
    class Parent:
        a: list[str]

        @field_validator('a')
        @classmethod
        def parent_val_before(cls, v: list[str]):
            v.append('parent before')
            return v

        @field_validator('a')
        @classmethod
        def val(cls, v: list[str]):
            v.append('parent')
            return v

        @field_validator('a')
        @classmethod
        def parent_val_after(cls, v: list[str]):
            v.append('parent after')
            return v

    @pydantic.dataclasses.dataclass
    class Child(Parent):
        @field_validator('a')
        @classmethod
        def child_val_before(cls, v: list[str]):
            v.append('child before')
            return v

        @field_validator('a')
        @classmethod
        def val(cls, v: list[str]):
            v.append('child')
            return v

        @field_validator('a')
        @classmethod
        def child_val_after(cls, v: list[str]):
            v.append('child after')
            return v

    assert Parent(a=[]).a == expected_parent
    assert Child(a=[]).a == expected_child


@pytest.mark.parametrize(
    'decorator1',
    [
        pydantic.dataclasses.dataclass,
        dataclasses.dataclass,
    ],
    ids=['pydantic', 'stdlib'],
)
@pytest.mark.parametrize(
    'default',
    [1, dataclasses.field(default=1), Field(default=1)],
    ids=['1', 'dataclasses.field(default=1)', 'pydantic.Field(default=1)'],
)
def test_dataclasses_inheritance_default_value_is_not_deleted(
    decorator1: Callable[[Any], Any], default: Literal[1]
) -> None:
    @decorator1
    class Parent:
        a: int = default

    # stdlib dataclasses don't support Pydantic's `Field()`:
    if decorator1 is pydantic.dataclasses.dataclass:
        assert Parent.a == 1
        assert Parent().a == 1

    @pydantic.dataclasses.dataclass
    class Child(Parent):
        pass

    assert Child.a == 1
    assert Child().a == 1


def test_dataclasses_inheritance_bare_class_not_used() -> None:
    """https://github.com/pydantic/pydantic/issues/12045"""

    class BareClass:
        a: int = Field(kw_only=True)

    @pydantic.dataclasses.dataclass
    class DC(BareClass):
        pass

    assert len(DC.__dataclass_fields__) == 0
    assert len(DC.__pydantic_fields__) == 0


def test_dataclasses_type_override_pydantic_field() -> None:
    """https://github.com/pydantic/pydantic/issues/12045.

    `B.a` used to be typed as `str`, only if `pydantic.Field()` was being used on `A.a`.
    """

    @dataclasses.dataclass
    class A:
        a: int = Field()

    @pydantic.dataclasses.dataclass
    class B(A):
        a: str = dataclasses.field()

    assert B(a='test').a == 'test'


def test_dataclass_config_validate_default():
    @pydantic.dataclasses.dataclass
    class Model:
        x: int = -1

        @field_validator('x')
        @classmethod
        def force_x_positive(cls, v):
            assert v > 0
            return v

    assert Model().x == -1

    @pydantic.dataclasses.dataclass(config=ConfigDict(validate_default=True))
    class ValidatingModel(Model):
        pass

    with pytest.raises(ValidationError) as exc_info:
        ValidatingModel()
    assert exc_info.value.errors(include_url=False) == [
        {
            'ctx': {'error': HasRepr(repr(AssertionError('assert -1 > 0')))},
            'input': -1,
            'loc': ('x',),
            'msg': 'Assertion failed, assert -1 > 0',
            'type': 'assertion_error',
        }
    ]


@pytest.mark.parametrize('dataclass_decorator', **dataclass_decorators())
def test_unparametrized_generic_dataclass(dataclass_decorator):
    T = TypeVar('T')

    @dataclass_decorator
    class GenericDataclass(Generic[T]):
        x: T

    # In principle we could call GenericDataclass(...) below, but this won't do validation
    # for standard dataclasses, so we just use TypeAdapter to get validation for each.
    validator = pydantic.TypeAdapter(GenericDataclass)

    assert validator.validate_python({'x': None}).x is None
    assert validator.validate_python({'x': 1}).x == 1

    with pytest.raises(ValidationError) as exc_info:
        validator.validate_python({'y': None})
    assert exc_info.value.errors(include_url=False) == [
        {'input': {'y': None}, 'loc': ('x',), 'msg': 'Field required', 'type': 'missing'}
    ]


@pytest.mark.parametrize('dataclass_decorator', **dataclass_decorators())
@pytest.mark.parametrize(
    'annotation,input_value,error,output_value',
    [
        (int, 1, False, 1),
        (str, 'a', False, 'a'),
        (
            int,
            'a',
            True,
            [
                {
                    'input': 'a',
                    'loc': ('x',),
                    'msg': 'Input should be a valid integer, unable to parse string as an integer',
                    'type': 'int_parsing',
                }
            ],
        ),
    ],
)
def test_parametrized_generic_dataclass(dataclass_decorator, annotation, input_value, error, output_value):
    T = TypeVar('T')

    @dataclass_decorator
    class GenericDataclass(Generic[T]):
        x: T

    # Need to use TypeAdapter here because GenericDataclass[annotation] will be a GenericAlias, which delegates
    # method calls to the (non-parametrized) origin class. This is essentially a limitation of typing._GenericAlias.
    validator = pydantic.TypeAdapter(GenericDataclass[annotation])

    if not error:
        assert validator.validate_python({'x': input_value}).x == output_value
    else:
        with pytest.raises(ValidationError) as exc_info:
            validator.validate_python({'x': input_value})
        assert exc_info.value.errors(include_url=False) == output_value


def test_multiple_parametrized_generic_dataclasses():
    T = TypeVar('T')

    @pydantic.dataclasses.dataclass
    class GenericDataclass(Generic[T]):
        x: T

    validator1 = pydantic.TypeAdapter(GenericDataclass[int])
    validator2 = pydantic.TypeAdapter(GenericDataclass[str])

    # verify that generic parameters are showing up in the type ref for generic dataclasses
    # this can probably be removed if the schema changes in some way that makes this part of the test fail
    assert '[int:' in validator1.core_schema['ref']
    assert '[str:' in validator2.core_schema['ref']

    assert validator1.validate_python({'x': 1}).x == 1
    assert validator2.validate_python({'x': 'hello world'}).x == 'hello world'

    with pytest.raises(ValidationError) as exc_info:
        validator2.validate_python({'x': 1})
    assert exc_info.value.errors(include_url=False) == [
        {'input': 1, 'loc': ('x',), 'msg': 'Input should be a valid string', 'type': 'string_type'}
    ]
    with pytest.raises(ValidationError) as exc_info:
        validator1.validate_python({'x': 'hello world'})
    assert exc_info.value.errors(include_url=False) == [
        {
            'input': 'hello world',
            'loc': ('x',),
            'msg': 'Input should be a valid integer, unable to parse string as an integer',
            'type': 'int_parsing',
        }
    ]


@pytest.mark.parametrize('dataclass_decorator', **dataclass_decorators(include_identity=True))
def test_pydantic_dataclass_preserves_metadata(dataclass_decorator: Callable[[Any], Any]) -> None:
    @dataclass_decorator
    class FooStd:
        """Docstring"""

    FooPydantic = pydantic.dataclasses.dataclass(FooStd)

    assert FooPydantic.__module__ == FooStd.__module__
    assert FooPydantic.__name__ == FooStd.__name__
    assert FooPydantic.__qualname__ == FooStd.__qualname__


def test_recursive_dataclasses_gh_4509(create_module) -> None:
    @create_module
    def module():
        import dataclasses

        import pydantic

        @dataclasses.dataclass
        class Recipe:
            author: 'Cook'

        @dataclasses.dataclass
        class Cook:
            recipes: list[Recipe]

        @pydantic.dataclasses.dataclass
        class Foo(Cook):
            pass

    gordon = module.Cook([])

    burger = module.Recipe(author=gordon)

    me = module.Foo([burger])

    assert me.recipes == [burger]


def test_dataclass_alias_generator():
    def alias_generator(name: str) -> str:
        return 'alias_' + name

    @pydantic.dataclasses.dataclass(config=ConfigDict(alias_generator=alias_generator))
    class User:
        name: str
        score: int = Field(alias='my_score')

    user = User(**{'alias_name': 'test name', 'my_score': 2})
    assert user.name == 'test name'
    assert user.score == 2

    with pytest.raises(ValidationError) as exc_info:
        User(name='test name', score=2)
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'missing',
            'loc': ('alias_name',),
            'msg': 'Field required',
            'input': ArgsKwargs((), {'name': 'test name', 'score': 2}),
        },
        {
            'type': 'missing',
            'loc': ('my_score',),
            'msg': 'Field required',
            'input': ArgsKwargs((), {'name': 'test name', 'score': 2}),
        },
    ]


def test_init_vars_inheritance():
    init_vars = []

    @pydantic.dataclasses.dataclass
    class Foo:
        init: 'InitVar[int]'

    @pydantic.dataclasses.dataclass
    class Bar(Foo):
        arg: int

        def __post_init__(self, init: int) -> None:
            init_vars.append(init)

    bar = Bar(init=1, arg=2)
    assert TypeAdapter(Bar).dump_python(bar) == {'arg': 2}
    assert init_vars == [1]

    with pytest.raises(ValidationError) as exc_info:
        Bar(init='a', arg=2)
    assert exc_info.value.errors(include_url=False) == [
        {
            'input': 'a',
            'loc': ('init',),
            'msg': 'Input should be a valid integer, unable to parse string as an integer',
            'type': 'int_parsing',
        }
    ]


@pytest.mark.skipif(not hasattr(pydantic.dataclasses, '_call_initvar'), reason='InitVar was not modified')
@pytest.mark.parametrize('remove_monkeypatch', [True, False])
def test_init_vars_call_monkeypatch(remove_monkeypatch, monkeypatch):
    # Parametrizing like this allows us to test that the behavior is the same with or without the monkeypatch

    if remove_monkeypatch:
        monkeypatch.delattr(InitVar, '__call__')

    InitVar(int)  # this is what is produced by InitVar[int]; note monkeypatching __call__ doesn't break this

    with pytest.raises(TypeError, match="'InitVar' object is not callable") as exc:
        InitVar[int]()

    # Check that the custom __call__ was called precisely if the monkeypatch was not removed
    stack_depth = len(traceback.extract_tb(exc.value.__traceback__))
    assert stack_depth == 1 if remove_monkeypatch else 2


@pytest.mark.parametrize('decorator1', **dataclass_decorators())
@pytest.mark.parametrize('decorator2', **dataclass_decorators())
def test_decorators_in_model_field(decorator1, decorator2):
    @decorator1
    class Demo1:
        int1: int

        @field_validator('int1', mode='before')
        def set_int_1(cls, v):
            return v + 100

        @field_serializer('int1')
        def serialize_int_1(self, v):
            return v + 10

    @decorator2
    class Demo2(Demo1):
        int2: int

        @field_validator('int2', mode='before')
        def set_int_2(cls, v):
            return v + 200

        @field_serializer('int2')
        def serialize_int_2(self, v):
            return v + 20

    class Model(BaseModel):
        x: Demo2

    m = Model.model_validate(dict(x=dict(int1=1, int2=2)))
    assert m.x.int1 == 101
    assert m.x.int2 == 202

    assert m.model_dump() == {'x': {'int1': 111, 'int2': 222}}


@pytest.mark.parametrize('decorator1', **dataclass_decorators())
@pytest.mark.parametrize('decorator2', **dataclass_decorators())
def test_vanilla_dataclass_decorators_in_type_adapter(decorator1, decorator2):
    @decorator1
    class Demo1:
        int1: int

        @field_validator('int1', mode='before')
        def set_int_1(cls, v):
            return v + 100

        @field_serializer('int1')
        def serialize_int_1(self, v):
            return v + 10

    @decorator2
    class Demo2(Demo1):
        int2: int

        @field_validator('int2', mode='before')
        def set_int_2(cls, v):
            return v + 200

        @field_serializer('int2')
        def serialize_int_2(self, v):
            return v + 20

    adapter = TypeAdapter(Demo2)

    m = adapter.validate_python(dict(int1=1, int2=2))
    assert m.int1 == 101
    assert m.int2 == 202

    assert adapter.dump_python(m) == {'int1': 111, 'int2': 222}


@pytest.mark.parametrize(
    'dataclass_decorator',
    [
        pydantic.dataclasses.dataclass,
        dataclasses.dataclass,
    ],
    ids=['pydantic', 'stdlib'],
)
@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python >= 3.10')
def test_dataclass_slots(dataclass_decorator):
    @dataclass_decorator(slots=True)
    class Model:
        a: str
        b: str

    dc = TypeAdapter(Model).validate_python({'a': 'foo', 'b': 'bar'})
    assert dc.a == 'foo'
    assert dc.b == 'bar'


# Must be defined at the module level to be picklable:
@pydantic.dataclasses.dataclass(slots=True, config={'validate_assignment': True})
class DataclassSlotsValidateAssignment:
    a: int


@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python >= 3.10')
def test_dataclass_slots_validate_assignment():
    """https://github.com/pydantic/pydantic/issues/11768"""

    m = DataclassSlotsValidateAssignment(1)
    m_pickle = pickle.loads(pickle.dumps(m))
    assert m_pickle.a == 1
    with pytest.raises(ValidationError):
        m.a = 'not_an_int'


@pytest.mark.parametrize(
    'dataclass_decorator',
    [
        pydantic.dataclasses.dataclass,
        dataclasses.dataclass,
    ],
    ids=['pydantic', 'stdlib'],
)
@pytest.mark.skipif(sys.version_info < (3, 10), reason='slots are only supported for dataclasses in Python >= 3.10')
def test_dataclass_slots_mixed(dataclass_decorator):
    @dataclass_decorator(slots=True)
    class Model:
        x: int
        y: dataclasses.InitVar[str]
        z: ClassVar[str] = 'z-classvar'

    @dataclass_decorator
    class SubModel(Model):
        x2: int
        y2: dataclasses.InitVar[str]
        z2: ClassVar[str] = 'z2-classvar'

    dc = TypeAdapter(SubModel).validate_python({'x': 1, 'y': 'a', 'x2': 2, 'y2': 'b'})
    assert dc.x == 1
    assert dc.x2 == 2
    assert SubModel.z == 'z-classvar'
    assert SubModel.z2 == 'z2-classvar'


def test_rebuild_dataclass():
    @pydantic.dataclasses.dataclass
    class MyDataClass:
        x: str

    assert rebuild_dataclass(MyDataClass) is None

    @pydantic.dataclasses.dataclass
    class MyDataClass1:
        d2: Optional['Foo'] = None  # noqa F821

    with pytest.raises(PydanticUndefinedAnnotation, match="name 'Foo' is not defined"):
        rebuild_dataclass(MyDataClass1, _parent_namespace_depth=0)

    @pydantic.dataclasses.dataclass
    class MyDataClass2:
        x: 'Foo'  # noqa F821

    assert not MyDataClass2.__pydantic_complete__
    assert rebuild_dataclass(MyDataClass2, _types_namespace={'Foo': int})
    assert MyDataClass2.__pydantic_complete__


@pytest.mark.parametrize(
    'dataclass_decorator',
    [
        pydantic.dataclasses.dataclass,
        dataclasses.dataclass,
    ],
    ids=['pydantic', 'stdlib'],
)
def test_model_config(dataclass_decorator: Any) -> None:
    @dataclass_decorator
    class Model:
        x: str
        __pydantic_config__ = ConfigDict(str_to_lower=True)

    ta = TypeAdapter(Model)
    assert ta.validate_python({'x': 'ABC'}).x == 'abc'


def test_model_config_override_in_decorator() -> None:
    with pytest.warns(
        UserWarning, match='`config` is set via both the `dataclass` decorator and `__pydantic_config__`'
    ):

        @pydantic.dataclasses.dataclass(config=ConfigDict(str_to_lower=False, str_strip_whitespace=True))
        class Model:
            x: str
            __pydantic_config__ = ConfigDict(str_to_lower=True)

        ta = TypeAdapter(Model)
        assert ta.validate_python({'x': 'ABC '}).x == 'ABC'


def test_model_config_override_in_decorator_empty_config() -> None:
    with pytest.warns(
        UserWarning, match='`config` is set via both the `dataclass` decorator and `__pydantic_config__`'
    ):

        @pydantic.dataclasses.dataclass(config=ConfigDict())
        class Model:
            x: str
            __pydantic_config__ = ConfigDict(str_to_lower=True)

        ta = TypeAdapter(Model)
        assert ta.validate_python({'x': 'ABC '}).x == 'ABC '


def test_dataclasses_with_config_decorator():
    @dataclasses.dataclass
    @with_config(ConfigDict(str_to_lower=True))
    class Model1:
        x: str

    ta = TypeAdapter(Model1)
    assert ta.validate_python({'x': 'ABC'}).x == 'abc'

    @with_config(ConfigDict(str_to_lower=True))
    @dataclasses.dataclass
    class Model2:
        x: str

    ta = TypeAdapter(Model2)
    assert ta.validate_python({'x': 'ABC'}).x == 'abc'


def test_pydantic_field_annotation():
    @pydantic.dataclasses.dataclass
    class Model:
        x: Annotated[int, Field(gt=0)]

    with pytest.raises(ValidationError) as exc_info:
        Model(x=-1)
    assert exc_info.value.errors(include_url=False) == [
        {
            'ctx': {'gt': 0},
            'input': -1,
            'loc': ('x',),
            'msg': 'Input should be greater than 0',
            'type': 'greater_than',
        }
    ]


def test_combined_field_annotations():
    """
    This test is included to document the fact that `Field` and `field` can be used together.
    That said, if you mix them like this, there is a good chance you'll run into surprising behavior/bugs.

    (E.g., `x: Annotated[int, Field(gt=1, validate_default=True)] = field(default=0)` doesn't cause an error)

    I would generally advise against doing this, and if we do change the behavior in the future to somehow merge
    pydantic.FieldInfo and dataclasses.Field in a way that changes runtime behavior for existing code, I would probably
    consider it a bugfix rather than a breaking change.
    """

    @pydantic.dataclasses.dataclass
    class Model:
        x: Annotated[int, Field(gt=1)] = dataclasses.field(default=1)

    assert Model().x == 1

    with pytest.raises(ValidationError) as exc_info:
        Model(x=0)
    assert exc_info.value.errors(include_url=False) == [
        {
            'ctx': {'gt': 1},
            'input': 0,
            'loc': ('x',),
            'msg': 'Input should be greater than 1',
            'type': 'greater_than',
        }
    ]


def test_dataclass_field_default_factory_with_init():
    @pydantic.dataclasses.dataclass
    class Model:
        x: int = dataclasses.field(default_factory=lambda: 3, init=False)

    m = Model()
    assert 'x' in Model.__pydantic_fields__
    assert m.x == 3
    assert RootModel[Model](m).model_dump() == {'x': 3}


def test_dataclass_field_default_with_init():
    @pydantic.dataclasses.dataclass
    class Model:
        x: int = dataclasses.field(default=3, init=False)

    m = Model()
    assert 'x' in Model.__pydantic_fields__
    assert m.x == 3
    assert RootModel[Model](m).model_dump() == {'x': 3}


def test_metadata():
    @dataclasses.dataclass
    class Test:
        value: int = dataclasses.field(metadata={'info': 'Some int value', 'json_schema_extra': {'a': 'b'}})

    PydanticTest = pydantic.dataclasses.dataclass(Test)

    assert TypeAdapter(PydanticTest).json_schema() == {
        'properties': {'value': {'a': 'b', 'title': 'Value', 'type': 'integer'}},
        'required': ['value'],
        'title': 'Test',
        'type': 'object',
    }


def test_signature():
    @pydantic.dataclasses.dataclass
    class Model:
        x: int
        y: str = 'y'
        z: float = dataclasses.field(default=1.0)
        a: float = dataclasses.field(default_factory=float)
        b: float = Field(default=1.0)
        c: float = Field(default_factory=float)
        d: int = dataclasses.field(metadata={'alias': 'dd'}, default=1)

    assert str(inspect.signature(Model)) == (
        "(x: int, y: str = 'y', z: float = 1.0, a: float = <factory>, b: float = 1.0, c: float = <factory>, dd: int = 1) -> None"
    )


def test_inherited_dataclass_signature():
    @pydantic.dataclasses.dataclass
    class A:
        a: int

    @pydantic.dataclasses.dataclass
    class B(A):
        b: int

    assert str(inspect.signature(A)) == '(a: int) -> None'
    assert str(inspect.signature(B)) == '(a: int, b: int) -> None'


def test_dataclasses_with_slots_and_default():
    @pydantic.dataclasses.dataclass(slots=True)
    class A:
        a: int = 0

    assert A().a == 0

    @pydantic.dataclasses.dataclass(slots=True)
    class B:
        b: int = Field(1)

    assert B().b == 1


@pytest.mark.parametrize('decorator1', **dataclass_decorators())
def test_annotated_before_validator_called_once(decorator1):
    count = 0

    def convert(value: int) -> str:
        nonlocal count
        count += 1
        return str(value)

    IntToStr = Annotated[str, BeforeValidator(convert)]

    @decorator1
    class A:
        a: IntToStr

    assert count == 0
    TypeAdapter(A).validate_python({'a': 123})
    assert count == 1


def test_is_pydantic_dataclass():
    @pydantic.dataclasses.dataclass
    class PydanticDataclass:
        a: int

    @dataclasses.dataclass
    class StdLibDataclass:
        b: int

    assert is_pydantic_dataclass(PydanticDataclass) is True
    assert is_pydantic_dataclass(StdLibDataclass) is False


def test_can_inherit_stdlib_dataclasses_with_defaults():
    @dataclasses.dataclass
    class Base:
        a: None = None

    class Model(BaseModel, Base):
        pass

    assert Model().a is None


def test_can_inherit_stdlib_dataclasses_default_factories_and_use_them():
    """This test documents that default factories are not supported"""

    @dataclasses.dataclass
    class Base:
        a: str = dataclasses.field(default_factory=lambda: 'TEST')

    class Model(BaseModel, Base):
        pass

    with pytest.raises(ValidationError):
        assert Model().a == 'TEST'


def test_can_inherit_stdlib_dataclasses_default_factories_and_provide_a_value():
    @dataclasses.dataclass
    class Base:
        a: str = dataclasses.field(default_factory=lambda: 'TEST')

    class Model(BaseModel, Base):
        pass

    assert Model(a='NOT_THE_SAME').a == 'NOT_THE_SAME'


def test_can_inherit_stdlib_dataclasses_with_dataclass_fields():
    @dataclasses.dataclass
    class Base:
        a: int = dataclasses.field(default=5)

    class Model(BaseModel, Base):
        pass

    assert Model().a == 5


def test_alias_with_dashes():
    """Test for fix issue #7226."""

    @pydantic.dataclasses.dataclass
    class Foo:
        some_var: str = Field(alias='some-var')

    obj = Foo(**{'some-var': 'some_value'})
    assert obj.some_var == 'some_value'


def test_validate_strings():
    @pydantic.dataclasses.dataclass
    class Nested:
        d: date

    class Model(BaseModel):
        n: Nested

    assert Model.model_validate_strings({'n': {'d': '2017-01-01'}}).n.d == date(2017, 1, 1)


@pytest.mark.parametrize('field_constructor', [dataclasses.field, pydantic.dataclasses.Field])
@pytest.mark.parametrize('extra', ['ignore', 'forbid'])
def test_init_false_not_in_signature(extra, field_constructor):
    @pydantic.dataclasses.dataclass(config=ConfigDict(extra=extra))
    class MyDataclass:
        a: int = field_constructor(init=False, default=-1)
        b: int = pydantic.dataclasses.Field(default=2)

    signature = inspect.signature(MyDataclass)
    # `a` should not be in the __init__
    assert 'a' not in signature.parameters.keys()
    assert 'b' in signature.parameters.keys()


init_test_cases = [
    ({'a': 2, 'b': -1}, 'ignore', {'a': 2, 'b': 1}),
    ({'a': 2}, 'ignore', {'a': 2, 'b': 1}),
    (
        {'a': 2, 'b': -1},
        'forbid',
        [
            {
                'type': 'unexpected_keyword_argument',
                'loc': ('b',),
                'msg': 'Unexpected keyword argument',
                'input': -1,
            }
        ],
    ),
    ({'a': 2}, 'forbid', {'a': 2, 'b': 1}),
]


@pytest.mark.parametrize('field_constructor', [dataclasses.field, pydantic.dataclasses.Field])
@pytest.mark.parametrize(
    'input_data,extra,expected',
    init_test_cases,
)
def test_init_false_with_post_init(input_data, extra, expected, field_constructor):
    @pydantic.dataclasses.dataclass(config=ConfigDict(extra=extra))
    class MyDataclass:
        a: int
        b: int = field_constructor(init=False)

        def __post_init__(self):
            self.b = 1

    if isinstance(expected, list):
        with pytest.raises(ValidationError) as exc_info:
            MyDataclass(**input_data)

        assert exc_info.value.errors(include_url=False) == expected
    else:
        assert dataclasses.asdict(MyDataclass(**input_data)) == expected


@pytest.mark.parametrize('field_constructor', [dataclasses.field, pydantic.dataclasses.Field])
@pytest.mark.parametrize(
    'input_data,extra,expected',
    init_test_cases,
)
def test_init_false_with_default(input_data, extra, expected, field_constructor):
    @pydantic.dataclasses.dataclass(config=ConfigDict(extra=extra))
    class MyDataclass:
        a: int
        b: int = field_constructor(init=False, default=1)

    if isinstance(expected, list):
        with pytest.raises(ValidationError) as exc_info:
            MyDataclass(**input_data)

        assert exc_info.value.errors(include_url=False) == expected
    else:
        assert dataclasses.asdict(MyDataclass(**input_data)) == expected


def test_disallow_extra_allow_and_init_false() -> None:
    with pytest.raises(PydanticUserError, match='This combination is not allowed.'):

        @pydantic.dataclasses.dataclass(config=ConfigDict(extra='allow'))
        class A:
            a: int = Field(init=False, default=1)


def test_disallow_init_false_and_init_var_true() -> None:
    with pytest.raises(PydanticUserError, match='mutually exclusive.'):

        @pydantic.dataclasses.dataclass
        class Foo:
            bar: str = Field(init=False, init_var=True)


def test_annotations_valid_for_field_inheritance() -> None:
    # testing https://github.com/pydantic/pydantic/issues/8670

    @pydantic.dataclasses.dataclass()
    class A:
        a: int = pydantic.dataclasses.Field()

    @pydantic.dataclasses.dataclass()
    class B(A): ...

    assert B.__pydantic_fields__['a'].annotation is int

    assert B(a=1).a == 1


def test_annotations_valid_for_field_inheritance_with_existing_field() -> None:
    # variation on testing https://github.com/pydantic/pydantic/issues/8670

    @pydantic.dataclasses.dataclass()
    class A:
        a: int = pydantic.dataclasses.Field()

    @pydantic.dataclasses.dataclass()
    class B(A):
        b: str = pydantic.dataclasses.Field()

    assert B.__pydantic_fields__['a'].annotation is int
    assert B.__pydantic_fields__['b'].annotation is str

    b = B(a=1, b='b')
    assert b.a == 1
    assert b.b == 'b'


def test_annotation_with_double_override() -> None:
    @pydantic.dataclasses.dataclass()
    class A:
        a: int
        b: int
        c: int = pydantic.dataclasses.Field()
        d: int = pydantic.dataclasses.Field()

    # note, the order of fields is different here, as to test that the annotation
    # is correctly set on the field no matter the base's default / current class's default
    @pydantic.dataclasses.dataclass()
    class B(A):
        a: str
        c: str
        b: str = pydantic.dataclasses.Field()
        d: str = pydantic.dataclasses.Field()

    @pydantic.dataclasses.dataclass()
    class C(B): ...

    for class_ in [B, C]:
        instance = class_(a='a', b='b', c='c', d='d')
        for field_name in ['a', 'b', 'c', 'd']:
            assert class_.__pydantic_fields__[field_name].annotation is str
            assert getattr(instance, field_name) == field_name


def test_schema_valid_for_inner_generic() -> None:
    T = TypeVar('T')

    @pydantic.dataclasses.dataclass()
    class Inner(Generic[T]):
        x: T

    @pydantic.dataclasses.dataclass()
    class Outer:
        inner: Inner[int]

    assert Outer(inner={'x': 1}).inner.x == 1
    # note, this isn't Inner[Int] like it is for the BaseModel case, but the type of x is substituted, which is the important part
    assert Outer.__pydantic_core_schema__['schema']['fields'][0]['schema']['cls'] == Inner
    assert (
        Outer.__pydantic_core_schema__['schema']['fields'][0]['schema']['schema']['fields'][0]['schema']['type']
        == 'int'
    )


def test_validation_works_for_cyclical_forward_refs() -> None:
    @pydantic.dataclasses.dataclass()
    class X:
        y: Union['Y', None]

    @pydantic.dataclasses.dataclass()
    class Y:
        x: Union[X, None]

    assert Y(x={'y': None}).x.y is None


def test_annotated_with_field_default_factory() -> None:
    """
    https://github.com/pydantic/pydantic/issues/9947
    """

    field = dataclasses.field

    @pydantic.dataclasses.dataclass()
    class A:
        a: Annotated[int, Field(default_factory=lambda: 1)]
        b: Annotated[int, Field(default_factory=lambda: 1)] = Field()
        c: Annotated[int, Field(default_factory=lambda: 2), Field(default_factory=lambda: 1)] = Field()
        d: Annotated[int, Field] = Field(default_factory=lambda: 2)
        e: int = Field(default_factory=lambda: 2)
        f: Annotated[int, Field(default_factory=lambda: 1)] = Field(default_factory=lambda: 2)

    # check the same tests for dataclasses.field
    @pydantic.dataclasses.dataclass()
    class B:
        a: Annotated[int, Field(default_factory=lambda: 1)]
        b: Annotated[int, Field(default_factory=lambda: 1)] = field()
        c: Annotated[int, field(default_factory=lambda: 2), Field(default_factory=lambda: 1)] = field()
        d: Annotated[int, field] = Field(default_factory=lambda: 2)
        e: int = field(default_factory=lambda: 2)
        f: Annotated[int, Field(default_factory=lambda: 1)] = field(default_factory=lambda: 2)

    for cls in (A, B):
        instance = cls()  # type: ignore
        field_names = ('a', 'b', 'c', 'd', 'e', 'f')
        results = (1, 1, 1, 2, 2, 2)
        for field_name, result in zip(field_names, results):
            assert getattr(instance, field_name) == result


def test_simple_frozen() -> None:
    @pydantic.dataclasses.dataclass(frozen=True)
    class MyDataclass:
        x: str

    inst = MyDataclass('hello')

    with pytest.raises(dataclasses.FrozenInstanceError, match="cannot assign to field 'x'"):
        inst.x = 'other'

    @pydantic.dataclasses.dataclass(config=ConfigDict(frozen=True))
    class MyDataclass2:
        x: str

    inst = MyDataclass2('hello')

    with pytest.raises(dataclasses.FrozenInstanceError, match="cannot assign to field 'x'"):
        inst.x = 'other'


def test_frozen_with_validate_assignment() -> None:
    """Test for https://github.com/pydantic/pydantic/issues/10041."""

    @pydantic.dataclasses.dataclass(frozen=True, config=ConfigDict(validate_assignment=True))
    class MyDataclass:
        x: str

    inst = MyDataclass('hello')

    with pytest.raises(dataclasses.FrozenInstanceError, match="cannot assign to field 'x'"):
        inst.x = 'other'

    @pydantic.dataclasses.dataclass(config=ConfigDict(frozen=True, validate_assignment=True))
    class MyDataclass2:
        x: str

    inst = MyDataclass2('hello')

    with pytest.raises(dataclasses.FrozenInstanceError, match="cannot assign to field 'x'"):
        inst.x = 'other'


def test_warns_on_double_frozen() -> None:
    with pytest.warns(UserWarning, match='`frozen` is set via both the `dataclass` decorator and `config`'):

        @pydantic.dataclasses.dataclass(frozen=True, config=ConfigDict(frozen=True))
        class DC:
            x: int


def test_warns_on_double_config() -> None:
    with pytest.warns(
        UserWarning, match='`config` is set via both the `dataclass` decorator and `__pydantic_config__`'
    ):

        @pydantic.dataclasses.dataclass(config=ConfigDict(title='from decorator'))
        class Foo:
            __pydantic_config__ = ConfigDict(title='from __pydantic_config__')


def test_config_pushdown_vanilla_dc() -> None:
    class ArbitraryType:
        pass

    @dataclasses.dataclass
    class DC:
        a: ArbitraryType

    class Model(BaseModel):
        model_config = ConfigDict(arbitrary_types_allowed=True)

        dc: DC


def test_deferred_dataclass_fields_available() -> None:
    # This aligns with deferred Pydantic models:
    @pydantic.dataclasses.dataclass(config={'defer_build': True})
    class A:
        a: int

    assert 'a' in A.__pydantic_fields__  # pyright: ignore[reportAttributeAccessIssue]


def test_dataclass_fields_rebuilt_before_schema_generation() -> None:
    """https://github.com/pydantic/pydantic/issues/11947"""

    def update_schema(schema: dict[str, Any]) -> None:
        schema['test'] = schema['title']

    @pydantic.dataclasses.dataclass
    class A:
        a: """Annotated[
            Forward,
            Field(field_title_generator=lambda name, _: name, json_schema_extra=update_schema)
        ]""" = True

    Forward = bool

    ta = TypeAdapter(A)

    assert ta.json_schema()['properties']['a']['test'] == 'a'


def test_dataclass_field_exclude() -> None:
    @pydantic.dataclasses.dataclass
    class Foo:
        foo: str = Field(exclude=True)
        bar: int = Field(exclude_if=lambda x: x > 1)

    ta = TypeAdapter(Foo)

    assert ta.dump_python(Foo(foo='bar', bar=1)) == {'bar': 1}
    assert ta.dump_python(Foo(foo='bar', bar=1), exclude={'bar'}) == {}
    assert ta.dump_python(Foo(foo='bar', bar=2)) == {}

    assert ta.dump_json(Foo(foo='bar', bar=1)).decode('utf-8') == '{"bar":1}'
    assert ta.dump_json(Foo(foo='bar', bar=1), exclude={'bar'}).decode('utf-8') == '{}'
    assert ta.dump_json(Foo(foo='bar', bar=2)).decode('utf-8') == '{}'


@pytest.mark.skipif(sys.version_info < (3, 10), reason='kw_only is not available in python >= 3.10')
def test_dataclass_field_override_kw_only() -> None:
    """https://github.com/pydantic/pydantic/issues/12736"""

    @pydantic.dataclasses.dataclass(kw_only=True)
    class Foo:
        a: int = Field(kw_only=False)

    a_param = inspect.signature(Foo).parameters['a']

    assert a_param.kind is inspect.Parameter.POSITIONAL_OR_KEYWORD
    assert a_param.default is inspect.Parameter.empty


## Links discovered
- [Model](https://github.com/pydantic/pydantic/blob/main/tests/m.md)

--- tests/test_validators_dataclass.py ---
from dataclasses import asdict, is_dataclass
from typing import Any

import pytest
from dirty_equals import HasRepr

from pydantic import ValidationError, field_validator, model_validator
from pydantic.dataclasses import dataclass


def test_simple():
    @dataclass
    class MyDataclass:
        a: str

        @field_validator('a')
        @classmethod
        def change_a(cls, v):
            return v + ' changed'

    assert MyDataclass(a='this is foobar good').a == 'this is foobar good changed'


def test_validate_before():
    @dataclass
    class MyDataclass:
        a: list[int]

        @field_validator('a', mode='before')
        @classmethod
        def check_a1(cls, v: list[Any]) -> list[Any]:
            v.append('123')
            return v

        @field_validator('a')
        @classmethod
        def check_a2(cls, v: list[int]) -> list[int]:
            v.append(456)
            return v

    assert MyDataclass(a=[1, 2]).a == [1, 2, 123, 456]


def test_validate_multiple():
    @dataclass
    class MyDataclass:
        a: str
        b: str

        @field_validator('a', 'b')
        @classmethod
        def check_a_and_b(cls, v, info):
            if len(v) < 4:
                raise ValueError(f'{info.field_name} is too short')
            return v + 'x'

    assert asdict(MyDataclass(a='1234', b='5678')) == {'a': '1234x', 'b': '5678x'}

    with pytest.raises(ValidationError) as exc_info:
        MyDataclass(a='x', b='x')
    assert exc_info.value.errors(include_url=False) == [
        {
            'ctx': {'error': HasRepr(repr(ValueError('a is too short')))},
            'input': 'x',
            'loc': ('a',),
            'msg': 'Value error, a is too short',
            'type': 'value_error',
        },
        {
            'ctx': {'error': HasRepr(repr(ValueError('b is too short')))},
            'input': 'x',
            'loc': ('b',),
            'msg': 'Value error, b is too short',
            'type': 'value_error',
        },
    ]


def test_type_error():
    @dataclass
    class MyDataclass:
        a: str
        b: str

        @field_validator('a', 'b')
        @classmethod
        def check_a_and_b(cls, v, info):
            if len(v) < 4:
                raise TypeError(f'{info.field_name} is too short')
            return v + 'x'

    assert asdict(MyDataclass(a='1234', b='5678')) == {'a': '1234x', 'b': '5678x'}

    with pytest.raises(TypeError, match='a is too short'):
        MyDataclass(a='x', b='x')


def test_classmethod():
    @dataclass
    class MyDataclass:
        a: str

        @field_validator('a')
        @classmethod
        def check_a(cls, v):
            assert cls is MyDataclass and is_dataclass(MyDataclass)
            return v

    m = MyDataclass(a='this is foobar good')
    assert m.a == 'this is foobar good'
    m.check_a('x')


def test_validate_parent():
    @dataclass
    class Parent:
        a: str

        @field_validator('a')
        @classmethod
        def change_a(cls, v):
            return v + ' changed'

    @dataclass
    class Child(Parent):
        pass

    assert Parent(a='this is foobar good').a == 'this is foobar good changed'
    assert Child(a='this is foobar good').a == 'this is foobar good changed'


def test_inheritance_replace():
    @dataclass
    class Parent:
        a: int

        @field_validator('a')
        @classmethod
        def add_to_a(cls, v):
            return v + 1

    @dataclass
    class Child(Parent):
        @field_validator('a')
        @classmethod
        def add_to_a(cls, v):
            return v + 5

    assert Child(a=0).a == 5


def test_model_validator():
    root_val_values: list[Any] = []

    @dataclass
    class MyDataclass:
        a: int
        b: str

        @field_validator('b')
        @classmethod
        def repeat_b(cls, v: str) -> str:
            return v * 2

        @model_validator(mode='after')
        def root_validator(self) -> 'MyDataclass':
            root_val_values.append(asdict(self))
            if 'snap' in self.b:
                raise ValueError('foobar')
            self.b = 'changed'
            return self

    assert asdict(MyDataclass(a='123', b='bar')) == {'a': 123, 'b': 'changed'}

    with pytest.raises(ValidationError) as exc_info:
        MyDataclass(1, b='snap dragon')
    assert root_val_values == [{'a': 123, 'b': 'barbar'}, {'a': 1, 'b': 'snap dragonsnap dragon'}]

    assert exc_info.value.errors(include_url=False) == [
        {
            'ctx': {'error': HasRepr(repr(ValueError('foobar')))},
            'input': HasRepr("ArgsKwargs((1,), {'b': 'snap dragon'})"),
            'loc': (),
            'msg': 'Value error, foobar',
            'type': 'value_error',
        }
    ]


--- pydantic/deprecated/class_validators.py ---
"""Old `@validator` and `@root_validator` function validators from V1."""

from __future__ import annotations as _annotations

from functools import partial, partialmethod
from types import FunctionType
from typing import TYPE_CHECKING, Any, Callable, Literal, TypeVar, Union, overload
from warnings import warn

from typing_extensions import Protocol, TypeAlias, deprecated

from .._internal import _decorators, _decorators_v1
from ..errors import PydanticUserError
from ..warnings import PydanticDeprecatedSince20

_ALLOW_REUSE_WARNING_MESSAGE = '`allow_reuse` is deprecated and will be ignored; it should no longer be necessary'


if TYPE_CHECKING:

    class _OnlyValueValidatorClsMethod(Protocol):
        def __call__(self, __cls: Any, __value: Any) -> Any: ...

    class _V1ValidatorWithValuesClsMethod(Protocol):
        def __call__(self, __cls: Any, __value: Any, values: dict[str, Any]) -> Any: ...

    class _V1ValidatorWithValuesKwOnlyClsMethod(Protocol):
        def __call__(self, __cls: Any, __value: Any, *, values: dict[str, Any]) -> Any: ...

    class _V1ValidatorWithKwargsClsMethod(Protocol):
        def __call__(self, __cls: Any, **kwargs: Any) -> Any: ...

    class _V1ValidatorWithValuesAndKwargsClsMethod(Protocol):
        def __call__(self, __cls: Any, values: dict[str, Any], **kwargs: Any) -> Any: ...

    class _V1RootValidatorClsMethod(Protocol):
        def __call__(
            self, __cls: Any, __values: _decorators_v1.RootValidatorValues
        ) -> _decorators_v1.RootValidatorValues: ...

    V1Validator = Union[
        _OnlyValueValidatorClsMethod,
        _V1ValidatorWithValuesClsMethod,
        _V1ValidatorWithValuesKwOnlyClsMethod,
        _V1ValidatorWithKwargsClsMethod,
        _V1ValidatorWithValuesAndKwargsClsMethod,
        _decorators_v1.V1ValidatorWithValues,
        _decorators_v1.V1ValidatorWithValuesKwOnly,
        _decorators_v1.V1ValidatorWithKwargs,
        _decorators_v1.V1ValidatorWithValuesAndKwargs,
    ]

    V1RootValidator = Union[
        _V1RootValidatorClsMethod,
        _decorators_v1.V1RootValidatorFunction,
    ]

    _PartialClsOrStaticMethod: TypeAlias = Union[classmethod[Any, Any, Any], staticmethod[Any, Any], partialmethod[Any]]

    # Allow both a V1 (assumed pre=False) or V2 (assumed mode='after') validator
    # We lie to type checkers and say we return the same thing we get
    # but in reality we return a proxy object that _mostly_ behaves like the wrapped thing
    _V1ValidatorType = TypeVar('_V1ValidatorType', V1Validator, _PartialClsOrStaticMethod)
    _V1RootValidatorFunctionType = TypeVar(
        '_V1RootValidatorFunctionType',
        _decorators_v1.V1RootValidatorFunction,
        _V1RootValidatorClsMethod,
        _PartialClsOrStaticMethod,
    )
else:
    # See PyCharm issues https://youtrack.jetbrains.com/issue/PY-21915
    # and https://youtrack.jetbrains.com/issue/PY-51428
    DeprecationWarning = PydanticDeprecatedSince20


@deprecated(
    'Pydantic V1 style `@validator` validators are deprecated.'
    ' You should migrate to Pydantic V2 style `@field_validator` validators,'
    ' see the migration guide for more details',
    category=None,
)
def validator(
    __field: str,
    *fields: str,
    pre: bool = False,
    each_item: bool = False,
    always: bool = False,
    check_fields: bool | None = None,
    allow_reuse: bool = False,
) -> Callable[[_V1ValidatorType], _V1ValidatorType]:
    """Decorate methods on the class indicating that they should be used to validate fields.

    Args:
        __field (str): The first field the validator should be called on; this is separate
            from `fields` to ensure an error is raised if you don't pass at least one.
        *fields (str): Additional field(s) the validator should be called on.
        pre (bool, optional): Whether this validator should be called before the standard
            validators (else after). Defaults to False.
        each_item (bool, optional): For complex objects (sets, lists etc.) whether to validate
            individual elements rather than the whole object. Defaults to False.
        always (bool, optional): Whether this method and other validators should be called even if
            the value is missing. Defaults to False.
        check_fields (bool | None, optional): Whether to check that the fields actually exist on the model.
            Defaults to None.
        allow_reuse (bool, optional): Whether to track and raise an error if another validator refers to
            the decorated function. Defaults to False.

    Returns:
        Callable: A decorator that can be used to decorate a
            function to be used as a validator.
    """
    warn(
        'Pydantic V1 style `@validator` validators are deprecated.'
        ' You should migrate to Pydantic V2 style `@field_validator` validators,'
        ' see the migration guide for more details',
        DeprecationWarning,
        stacklevel=2,
    )

    if allow_reuse is True:  # pragma: no cover
        warn(_ALLOW_REUSE_WARNING_MESSAGE, DeprecationWarning, stacklevel=2)
    fields = __field, *fields
    if isinstance(fields[0], FunctionType):
        raise PydanticUserError(
            '`@validator` should be used with fields and keyword arguments, not bare. '
            "E.g. usage should be `@validator('<field_name>', ...)`",
            code='decorator-missing-arguments',
        )
    elif not all(isinstance(field, str) for field in fields):
        raise PydanticUserError(
            '`@validator` fields should be passed as separate string args. '
            "E.g. usage should be `@validator('<field_name_1>', '<field_name_2>', ...)`",
            code='decorator-invalid-fields',
        )

    mode: Literal['before', 'after'] = 'before' if pre is True else 'after'

    def dec(f: Any) -> _decorators.PydanticDescriptorProxy[Any]:
        if _decorators.is_instance_method_from_sig(f):
            raise PydanticUserError(
                '`@validator` cannot be applied to instance methods', code='validator-instance-method'
            )
        # auto apply the @classmethod decorator
        f = _decorators.ensure_classmethod_based_on_signature(f)
        wrap = _decorators_v1.make_generic_v1_field_validator
        validator_wrapper_info = _decorators.ValidatorDecoratorInfo(
            fields=fields,
            mode=mode,
            each_item=each_item,
            always=always,
            check_fields=check_fields,
        )
        return _decorators.PydanticDescriptorProxy(f, validator_wrapper_info, shim=wrap)

    return dec  # type: ignore[return-value]


@overload
def root_validator(
    *,
    # if you don't specify `pre` the default is `pre=False`
    # which means you need to specify `skip_on_failure=True`
    skip_on_failure: Literal[True],
    allow_reuse: bool = ...,
) -> Callable[
    [_V1RootValidatorFunctionType],
    _V1RootValidatorFunctionType,
]: ...


@overload
def root_validator(
    *,
    # if you specify `pre=True` then you don't need to specify
    # `skip_on_failure`, in fact it is not allowed as an argument!
    pre: Literal[True],
    allow_reuse: bool = ...,
) -> Callable[
    [_V1RootValidatorFunctionType],
    _V1RootValidatorFunctionType,
]: ...


@overload
def root_validator(
    *,
    # if you explicitly specify `pre=False` then you
    # MUST specify `skip_on_failure=True`
    pre: Literal[False],
    skip_on_failure: Literal[True],
    allow_reuse: bool = ...,
) -> Callable[
    [_V1RootValidatorFunctionType],
    _V1RootValidatorFunctionType,
]: ...


@deprecated(
    'Pydantic V1 style `@root_validator` validators are deprecated.'
    ' You should migrate to Pydantic V2 style `@model_validator` validators,'
    ' see the migration guide for more details',
    category=None,
)
def root_validator(
    *__args,
    pre: bool = False,
    skip_on_failure: bool = False,
    allow_reuse: bool = False,
) -> Any:
    """Decorate methods on a model indicating that they should be used to validate (and perhaps
    modify) data either before or after standard model parsing/validation is performed.

    Args:
        pre (bool, optional): Whether this validator should be called before the standard
            validators (else after). Defaults to False.
        skip_on_failure (bool, optional): Whether to stop validation and return as soon as a
            failure is encountered. Defaults to False.
        allow_reuse (bool, optional): Whether to track and raise an error if another validator
            refers to the decorated function. Defaults to False.

    Returns:
        Any: A decorator that can be used to decorate a function to be used as a root_validator.
    """
    warn(
        'Pydantic V1 style `@root_validator` validators are deprecated.'
        ' You should migrate to Pydantic V2 style `@model_validator` validators,'
        ' see the migration guide for more details',
        DeprecationWarning,
        stacklevel=2,
    )

    if __args:
        # Ensure a nice error is raised if someone attempts to use the bare decorator
        return root_validator()(*__args)  # type: ignore

    if allow_reuse is True:  # pragma: no cover
        warn(_ALLOW_REUSE_WARNING_MESSAGE, DeprecationWarning, stacklevel=2)
    mode: Literal['before', 'after'] = 'before' if pre is True else 'after'
    if pre is False and skip_on_failure is not True:
        raise PydanticUserError(
            'If you use `@root_validator` with pre=False (the default) you MUST specify `skip_on_failure=True`.'
            ' Note that `@root_validator` is deprecated and should be replaced with `@model_validator`.',
            code='root-validator-pre-skip',
        )

    wrap = partial(_decorators_v1.make_v1_generic_root_validator, pre=pre)

    def dec(f: Callable[..., Any] | classmethod[Any, Any, Any] | staticmethod[Any, Any]) -> Any:
        if _decorators.is_instance_method_from_sig(f):
            raise TypeError('`@root_validator` cannot be applied to instance methods')
        # auto apply the @classmethod decorator
        res = _decorators.ensure_classmethod_based_on_signature(f)
        dec_info = _decorators.RootValidatorDecoratorInfo(mode=mode)
        return _decorators.PydanticDescriptorProxy(res, dec_info, shim=wrap)

    return dec


--- pydantic/v1/class_validators.py ---
import warnings
from collections import ChainMap
from functools import partial, partialmethod, wraps
from itertools import chain
from types import FunctionType
from typing import TYPE_CHECKING, Any, Callable, Dict, Iterable, List, Optional, Set, Tuple, Type, Union, overload

from pydantic.v1.errors import ConfigError
from pydantic.v1.typing import AnyCallable
from pydantic.v1.utils import ROOT_KEY, in_ipython

if TYPE_CHECKING:
    from pydantic.v1.typing import AnyClassMethod


class Validator:
    __slots__ = 'func', 'pre', 'each_item', 'always', 'check_fields', 'skip_on_failure'

    def __init__(
        self,
        func: AnyCallable,
        pre: bool = False,
        each_item: bool = False,
        always: bool = False,
        check_fields: bool = False,
        skip_on_failure: bool = False,
    ):
        self.func = func
        self.pre = pre
        self.each_item = each_item
        self.always = always
        self.check_fields = check_fields
        self.skip_on_failure = skip_on_failure


if TYPE_CHECKING:
    from inspect import Signature

    from pydantic.v1.config import BaseConfig
    from pydantic.v1.fields import ModelField
    from pydantic.v1.types import ModelOrDc

    ValidatorCallable = Callable[[Optional[ModelOrDc], Any, Dict[str, Any], ModelField, Type[BaseConfig]], Any]
    ValidatorsList = List[ValidatorCallable]
    ValidatorListDict = Dict[str, List[Validator]]

_FUNCS: Set[str] = set()
VALIDATOR_CONFIG_KEY = '__validator_config__'
ROOT_VALIDATOR_CONFIG_KEY = '__root_validator_config__'


def validator(
    *fields: str,
    pre: bool = False,
    each_item: bool = False,
    always: bool = False,
    check_fields: bool = True,
    whole: Optional[bool] = None,
    allow_reuse: bool = False,
) -> Callable[[AnyCallable], 'AnyClassMethod']:
    """
    Decorate methods on the class indicating that they should be used to validate fields
    :param fields: which field(s) the method should be called on
    :param pre: whether or not this validator should be called before the standard validators (else after)
    :param each_item: for complex objects (sets, lists etc.) whether to validate individual elements rather than the
      whole object
    :param always: whether this method and other validators should be called even if the value is missing
    :param check_fields: whether to check that the fields actually exist on the model
    :param allow_reuse: whether to track and raise an error if another validator refers to the decorated function
    """
    if not fields:
        raise ConfigError('validator with no fields specified')
    elif isinstance(fields[0], FunctionType):
        raise ConfigError(
            "validators should be used with fields and keyword arguments, not bare. "  # noqa: Q000
            "E.g. usage should be `@validator('<field_name>', ...)`"
        )
    elif not all(isinstance(field, str) for field in fields):
        raise ConfigError(
            "validator fields should be passed as separate string args. "  # noqa: Q000
            "E.g. usage should be `@validator('<field_name_1>', '<field_name_2>', ...)`"
        )

    if whole is not None:
        warnings.warn(
            'The "whole" keyword argument is deprecated, use "each_item" (inverse meaning, default False) instead',
            DeprecationWarning,
        )
        assert each_item is False, '"each_item" and "whole" conflict, remove "whole"'
        each_item = not whole

    def dec(f: AnyCallable) -> 'AnyClassMethod':
        f_cls = _prepare_validator(f, allow_reuse)
        setattr(
            f_cls,
            VALIDATOR_CONFIG_KEY,
            (
                fields,
                Validator(func=f_cls.__func__, pre=pre, each_item=each_item, always=always, check_fields=check_fields),
            ),
        )
        return f_cls

    return dec


@overload
def root_validator(_func: AnyCallable) -> 'AnyClassMethod':
    ...


@overload
def root_validator(
    *, pre: bool = False, allow_reuse: bool = False, skip_on_failure: bool = False
) -> Callable[[AnyCallable], 'AnyClassMethod']:
    ...


def root_validator(
    _func: Optional[AnyCallable] = None, *, pre: bool = False, allow_reuse: bool = False, skip_on_failure: bool = False
) -> Union['AnyClassMethod', Callable[[AnyCallable], 'AnyClassMethod']]:
    """
    Decorate methods on a model indicating that they should be used to validate (and perhaps modify) data either
    before or after standard model parsing/validation is performed.
    """
    if _func:
        f_cls = _prepare_validator(_func, allow_reuse)
        setattr(
            f_cls, ROOT_VALIDATOR_CONFIG_KEY, Validator(func=f_cls.__func__, pre=pre, skip_on_failure=skip_on_failure)
        )
        return f_cls

    def dec(f: AnyCallable) -> 'AnyClassMethod':
        f_cls = _prepare_validator(f, allow_reuse)
        setattr(
            f_cls, ROOT_VALIDATOR_CONFIG_KEY, Validator(func=f_cls.__func__, pre=pre, skip_on_failure=skip_on_failure)
        )
        return f_cls

    return dec


def _prepare_validator(function: AnyCallable, allow_reuse: bool) -> 'AnyClassMethod':
    """
    Avoid validators with duplicated names since without this, validators can be overwritten silently
    which generally isn't the intended behaviour, don't run in ipython (see #312) or if allow_reuse is False.
    """
    f_cls = function if isinstance(function, classmethod) else classmethod(function)
    if not in_ipython() and not allow_reuse:
        ref = (
            getattr(f_cls.__func__, '__module__', '<No __module__>')
            + '.'
            + getattr(f_cls.__func__, '__qualname__', f'<No __qualname__: id:{id(f_cls.__func__)}>')
        )
        if ref in _FUNCS:
            raise ConfigError(f'duplicate validator function "{ref}"; if this is intended, set `allow_reuse=True`')
        _FUNCS.add(ref)
    return f_cls


class ValidatorGroup:
    def __init__(self, validators: 'ValidatorListDict') -> None:
        self.validators = validators
        self.used_validators = {'*'}

    def get_validators(self, name: str) -> Optional[Dict[str, Validator]]:
        self.used_validators.add(name)
        validators = self.validators.get(name, [])
        if name != ROOT_KEY:
            validators += self.validators.get('*', [])
        if validators:
            return {getattr(v.func, '__name__', f'<No __name__: id:{id(v.func)}>'): v for v in validators}
        else:
            return None

    def check_for_unused(self) -> None:
        unused_validators = set(
            chain.from_iterable(
                (
                    getattr(v.func, '__name__', f'<No __name__: id:{id(v.func)}>')
                    for v in self.validators[f]
                    if v.check_fields
                )
                for f in (self.validators.keys() - self.used_validators)
            )
        )
        if unused_validators:
            fn = ', '.join(unused_validators)
            raise ConfigError(
                f"Validators defined with incorrect fields: {fn} "  # noqa: Q000
                f"(use check_fields=False if you're inheriting from the model and intended this)"
            )


def extract_validators(namespace: Dict[str, Any]) -> Dict[str, List[Validator]]:
    validators: Dict[str, List[Validator]] = {}
    for var_name, value in namespace.items():
        validator_config = getattr(value, VALIDATOR_CONFIG_KEY, None)
        if validator_config:
            fields, v = validator_config
            for field in fields:
                if field in validators:
                    validators[field].append(v)
                else:
                    validators[field] = [v]
    return validators


def extract_root_validators(namespace: Dict[str, Any]) -> Tuple[List[AnyCallable], List[Tuple[bool, AnyCallable]]]:
    from inspect import signature

    pre_validators: List[AnyCallable] = []
    post_validators: List[Tuple[bool, AnyCallable]] = []
    for name, value in namespace.items():
        validator_config: Optional[Validator] = getattr(value, ROOT_VALIDATOR_CONFIG_KEY, None)
        if validator_config:
            sig = signature(validator_config.func)
            args = list(sig.parameters.keys())
            if args[0] == 'self':
                raise ConfigError(
                    f'Invalid signature for root validator {name}: {sig}, "self" not permitted as first argument, '
                    f'should be: (cls, values).'
                )
            if len(args) != 2:
                raise ConfigError(f'Invalid signature for root validator {name}: {sig}, should be: (cls, values).')
            # check function signature
            if validator_config.pre:
                pre_validators.append(validator_config.func)
            else:
                post_validators.append((validator_config.skip_on_failure, validator_config.func))
    return pre_validators, post_validators


def inherit_validators(base_validators: 'ValidatorListDict', validators: 'ValidatorListDict') -> 'ValidatorListDict':
    for field, field_validators in base_validators.items():
        if field not in validators:
            validators[field] = []
        validators[field] += field_validators
    return validators


def make_generic_validator(validator: AnyCallable) -> 'ValidatorCallable':
    """
    Make a generic function which calls a validator with the right arguments.

    Unfortunately other approaches (eg. return a partial of a function that builds the arguments) is slow,
    hence this laborious way of doing things.

    It's done like this so validators don't all need **kwargs in their signature, eg. any combination of
    the arguments "values", "fields" and/or "config" are permitted.
    """
    from inspect import signature

    if not isinstance(validator, (partial, partialmethod)):
        # This should be the default case, so overhead is reduced
        sig = signature(validator)
        args = list(sig.parameters.keys())
    else:
        # Fix the generated argument lists of partial methods
        sig = signature(validator.func)
        args = [
            k
            for k in signature(validator.func).parameters.keys()
            if k not in validator.args | validator.keywords.keys()
        ]

    first_arg = args.pop(0)
    if first_arg == 'self':
        raise ConfigError(
            f'Invalid signature for validator {validator}: {sig}, "self" not permitted as first argument, '
            f'should be: (cls, value, values, config, field), "values", "config" and "field" are all optional.'
        )
    elif first_arg == 'cls':
        # assume the second argument is value
        return wraps(validator)(_generic_validator_cls(validator, sig, set(args[1:])))
    else:
        # assume the first argument was value which has already been removed
        return wraps(validator)(_generic_validator_basic(validator, sig, set(args)))


def prep_validators(v_funcs: Iterable[AnyCallable]) -> 'ValidatorsList':
    return [make_generic_validator(f) for f in v_funcs if f]


all_kwargs = {'values', 'field', 'config'}


def _generic_validator_cls(validator: AnyCallable, sig: 'Signature', args: Set[str]) -> 'ValidatorCallable':
    # assume the first argument is value
    has_kwargs = False
    if 'kwargs' in args:
        has_kwargs = True
        args -= {'kwargs'}

    if not args.issubset(all_kwargs):
        raise ConfigError(
            f'Invalid signature for validator {validator}: {sig}, should be: '
            f'(cls, value, values, config, field), "values", "config" and "field" are all optional.'
        )

    if has_kwargs:
        return lambda cls, v, values, field, config: validator(cls, v, values=values, field=field, config=config)
    elif args == set():
        return lambda cls, v, values, field, config: validator(cls, v)
    elif args == {'values'}:
        return lambda cls, v, values, field, config: validator(cls, v, values=values)
    elif args == {'field'}:
        return lambda cls, v, values, field, config: validator(cls, v, field=field)
    elif args == {'config'}:
        return lambda cls, v, values, field, config: validator(cls, v, config=config)
    elif args == {'values', 'field'}:
        return lambda cls, v, values, field, config: validator(cls, v, values=values, field=field)
    elif args == {'values', 'config'}:
        return lambda cls, v, values, field, config: validator(cls, v, values=values, config=config)
    elif args == {'field', 'config'}:
        return lambda cls, v, values, field, config: validator(cls, v, field=field, config=config)
    else:
        # args == {'values', 'field', 'config'}
        return lambda cls, v, values, field, config: validator(cls, v, values=values, field=field, config=config)


def _generic_validator_basic(validator: AnyCallable, sig: 'Signature', args: Set[str]) -> 'ValidatorCallable':
    has_kwargs = False
    if 'kwargs' in args:
        has_kwargs = True
        args -= {'kwargs'}

    if not args.issubset(all_kwargs):
        raise ConfigError(
            f'Invalid signature for validator {validator}: {sig}, should be: '
            f'(value, values, config, field), "values", "config" and "field" are all optional.'
        )

    if has_kwargs:
        return lambda cls, v, values, field, config: validator(v, values=values, field=field, config=config)
    elif args == set():
        return lambda cls, v, values, field, config: validator(v)
    elif args == {'values'}:
        return lambda cls, v, values, field, config: validator(v, values=values)
    elif args == {'field'}:
        return lambda cls, v, values, field, config: validator(v, field=field)
    elif args == {'config'}:
        return lambda cls, v, values, field, config: validator(v, config=config)
    elif args == {'values', 'field'}:
        return lambda cls, v, values, field, config: validator(v, values=values, field=field)
    elif args == {'values', 'config'}:
        return lambda cls, v, values, field, config: validator(v, values=values, config=config)
    elif args == {'field', 'config'}:
        return lambda cls, v, values, field, config: validator(v, field=field, config=config)
    else:
        # args == {'values', 'field', 'config'}
        return lambda cls, v, values, field, config: validator(v, values=values, field=field, config=config)


def gather_all_validators(type_: 'ModelOrDc') -> Dict[str, 'AnyClassMethod']:
    all_attributes = ChainMap(*[cls.__dict__ for cls in type_.__mro__])  # type: ignore[arg-type,var-annotated]
    return {
        k: v
        for k, v in all_attributes.items()
        if hasattr(v, VALIDATOR_CONFIG_KEY) or hasattr(v, ROOT_VALIDATOR_CONFIG_KEY)
    }


--- pydantic/_internal/_dataclasses.py ---
"""Private logic for creating pydantic dataclasses."""

from __future__ import annotations as _annotations

import copy
import dataclasses
import sys
import warnings
from collections.abc import Generator
from contextlib import contextmanager
from functools import partial
from typing import TYPE_CHECKING, Any, ClassVar, Protocol, cast

from pydantic_core import (
    ArgsKwargs,
    SchemaSerializer,
    SchemaValidator,
    core_schema,
)
from typing_extensions import TypeAlias, TypeIs

from ..errors import PydanticUndefinedAnnotation
from ..fields import FieldInfo
from ..plugin._schema_validator import PluggableSchemaValidator, create_schema_validator
from ..warnings import PydanticDeprecatedSince20
from . import _config, _decorators
from ._fields import collect_dataclass_fields
from ._generate_schema import GenerateSchema, InvalidSchemaError
from ._generics import get_standard_typevars_map
from ._mock_val_ser import set_dataclass_mocks
from ._namespace_utils import NsResolver
from ._signature import generate_pydantic_signature
from ._utils import LazyClassAttribute

if TYPE_CHECKING:
    from _typeshed import DataclassInstance as StandardDataclass

    from ..config import ConfigDict

    class PydanticDataclass(StandardDataclass, Protocol):
        """A protocol containing attributes only available once a class has been decorated as a Pydantic dataclass.

        Attributes:
            __pydantic_config__: Pydantic-specific configuration settings for the dataclass.
            __pydantic_complete__: Whether dataclass building is completed, or if there are still undefined fields.
            __pydantic_core_schema__: The pydantic-core schema used to build the SchemaValidator and SchemaSerializer.
            __pydantic_decorators__: Metadata containing the decorators defined on the dataclass.
            __pydantic_fields__: Metadata about the fields defined on the dataclass.
            __pydantic_serializer__: The pydantic-core SchemaSerializer used to dump instances of the dataclass.
            __pydantic_validator__: The pydantic-core SchemaValidator used to validate instances of the dataclass.
        """

        __pydantic_config__: ClassVar[ConfigDict]
        __pydantic_complete__: ClassVar[bool]
        __pydantic_core_schema__: ClassVar[core_schema.CoreSchema]
        __pydantic_decorators__: ClassVar[_decorators.DecoratorInfos]
        __pydantic_fields__: ClassVar[dict[str, FieldInfo]]
        __pydantic_serializer__: ClassVar[SchemaSerializer]
        __pydantic_validator__: ClassVar[SchemaValidator | PluggableSchemaValidator]

        @classmethod
        def __pydantic_fields_complete__(cls) -> bool: ...


def set_dataclass_fields(
    cls: type[StandardDataclass],
    config_wrapper: _config.ConfigWrapper,
    ns_resolver: NsResolver | None = None,
) -> None:
    """Collect and set `cls.__pydantic_fields__`.

    Args:
        cls: The class.
        config_wrapper: The config wrapper instance.
        ns_resolver: Namespace resolver to use when getting dataclass annotations.
    """
    typevars_map = get_standard_typevars_map(cls)
    fields = collect_dataclass_fields(
        cls, ns_resolver=ns_resolver, typevars_map=typevars_map, config_wrapper=config_wrapper
    )

    cls.__pydantic_fields__ = fields  # type: ignore


def complete_dataclass(
    cls: type[Any],
    config_wrapper: _config.ConfigWrapper,
    *,
    raise_errors: bool = True,
    ns_resolver: NsResolver | None = None,
    _force_build: bool = False,
) -> bool:
    """Finish building a pydantic dataclass.

    This logic is called on a class which has already been wrapped in `dataclasses.dataclass()`.

    This is somewhat analogous to `pydantic._internal._model_construction.complete_model_class`.

    Args:
        cls: The class.
        config_wrapper: The config wrapper instance.
        raise_errors: Whether to raise errors, defaults to `True`.
        ns_resolver: The namespace resolver instance to use when collecting dataclass fields
            and during schema building.
        _force_build: Whether to force building the dataclass, no matter if
            [`defer_build`][pydantic.config.ConfigDict.defer_build] is set.

    Returns:
        `True` if building a pydantic dataclass is successfully completed, `False` otherwise.

    Raises:
        PydanticUndefinedAnnotation: If `raise_error` is `True` and there is an undefined annotations.
    """
    original_init = cls.__init__

    # dataclass.__init__ must be defined here so its `__qualname__` can be changed since functions can't be copied,
    # and so that the mock validator is used if building was deferred:
    def __init__(__dataclass_self__: PydanticDataclass, *args: Any, **kwargs: Any) -> None:
        __tracebackhide__ = True
        s = __dataclass_self__
        s.__pydantic_validator__.validate_python(ArgsKwargs(args, kwargs), self_instance=s)

    __init__.__qualname__ = f'{cls.__qualname__}.__init__'

    cls.__init__ = __init__  # type: ignore
    cls.__pydantic_config__ = config_wrapper.config_dict  # type: ignore

    set_dataclass_fields(cls, config_wrapper=config_wrapper, ns_resolver=ns_resolver)

    if not _force_build and config_wrapper.defer_build:
        set_dataclass_mocks(cls)
        return False

    if hasattr(cls, '__post_init_post_parse__'):
        warnings.warn(
            'Support for `__post_init_post_parse__` has been dropped, the method will not be called',
            PydanticDeprecatedSince20,
        )

    typevars_map = get_standard_typevars_map(cls)
    gen_schema = GenerateSchema(
        config_wrapper,
        ns_resolver=ns_resolver,
        typevars_map=typevars_map,
    )

    # set __signature__ attr only for the class, but not for its instances
    # (because instances can define `__call__`, and `inspect.signature` shouldn't
    # use the `__signature__` attribute and instead generate from `__call__`).
    cls.__signature__ = LazyClassAttribute(
        '__signature__',
        partial(
            generate_pydantic_signature,
            # It's important that we reference the `original_init` here,
            # as it is the one synthesized by the stdlib `dataclass` module:
            init=original_init,
            fields=cls.__pydantic_fields__,  # type: ignore
            validate_by_name=config_wrapper.validate_by_name,
            extra=config_wrapper.extra,
            is_dataclass=True,
        ),
    )

    try:
        schema = gen_schema.generate_schema(cls)
    except PydanticUndefinedAnnotation as e:
        if raise_errors:
            raise
        set_dataclass_mocks(cls, f'`{e.name}`')
        return False

    core_config = config_wrapper.core_config(title=cls.__name__)

    try:
        schema = gen_schema.clean_schema(schema)
    except InvalidSchemaError:
        set_dataclass_mocks(cls)
        return False

    # We are about to set all the remaining required properties expected for this cast;
    # __pydantic_decorators__ and __pydantic_fields__ should already be set
    cls = cast('type[PydanticDataclass]', cls)

    cls.__pydantic_core_schema__ = schema
    cls.__pydantic_validator__ = create_schema_validator(
        schema, cls, cls.__module__, cls.__qualname__, 'dataclass', core_config, config_wrapper.plugin_settings
    )
    cls.__pydantic_serializer__ = SchemaSerializer(schema, core_config)
    cls.__pydantic_complete__ = True
    return True


def is_stdlib_dataclass(cls: type[Any], /) -> TypeIs[type[StandardDataclass]]:
    """Returns `True` if the class is a stdlib dataclass and *not* a Pydantic dataclass.

    Unlike the stdlib `dataclasses.is_dataclass()` function, this does *not* include subclasses
    of a dataclass that are themselves not dataclasses.

    Args:
        cls: The class.

    Returns:
        `True` if the class is a stdlib dataclass, `False` otherwise.
    """
    return '__dataclass_fields__' in cls.__dict__ and not hasattr(cls, '__pydantic_validator__')


def as_dataclass_field(pydantic_field: FieldInfo) -> dataclasses.Field[Any]:
    field_args: dict[str, Any] = {'default': pydantic_field}

    # Needed because if `doc` is set, the dataclass slots will be a dict (field name -> doc) instead of a tuple:
    if sys.version_info >= (3, 14) and pydantic_field.description is not None:
        field_args['doc'] = pydantic_field.description

    # Needed as the stdlib dataclass module processes kw_only in a specific way during class construction:
    if sys.version_info >= (3, 10) and pydantic_field.kw_only is not None:
        field_args['kw_only'] = pydantic_field.kw_only

    # Needed as the stdlib dataclass modules generates `__repr__()` during class construction:
    if pydantic_field.repr is not True:
        field_args['repr'] = pydantic_field.repr

    return dataclasses.field(**field_args)


DcFields: TypeAlias = dict[str, dataclasses.Field[Any]]


@contextmanager
def patch_base_fields(cls: type[Any]) -> Generator[None]:
    """Temporarily patch the stdlib dataclasses bases of `cls` if the Pydantic `Field()` function is used.

    When creating a Pydantic dataclass, it is possible to inherit from stdlib dataclasses, where
    the Pydantic `Field()` function is used. To create this Pydantic dataclass, we first apply
    the stdlib `@dataclass` decorator on it. During the construction of the stdlib dataclass,
    the `kw_only` and `repr` field arguments need to be understood by the stdlib *during* the
    dataclass construction. To do so, we temporarily patch the fields dictionary of the affected
    bases.

    For instance, with the following example:

    ```python {test="skip" lint="skip"}
    import dataclasses as stdlib_dc

    import pydantic
    import pydantic.dataclasses as pydantic_dc

    @stdlib_dc.dataclass
    class A:
        a: int = pydantic.Field(repr=False)

    # Notice that the `repr` attribute of the dataclass field is `True`:
    A.__dataclass_fields__['a']
    #> dataclass.Field(default=FieldInfo(repr=False), repr=True, ...)

    @pydantic_dc.dataclass
    class B(A):
        b: int = pydantic.Field(repr=False)
    ```

    When passing `B` to the stdlib `@dataclass` decorator, it will look for fields in the parent classes
    and reuse them directly. When this context manager is active, `A` will be temporarily patched to be
    equivalent to:

    ```python {test="skip" lint="skip"}
    @stdlib_dc.dataclass
    class A:
        a: int = stdlib_dc.field(default=Field(repr=False), repr=False)
    ```

    !!! note
        This is only applied to the bases of `cls`, and not `cls` itself. The reason is that the Pydantic
        dataclass decorator "owns" `cls` (in the previous example, `B`). As such, we instead modify the fields
        directly (in the previous example, we simply do `setattr(B, 'b', as_dataclass_field(pydantic_field))`).

    !!! note
        This approach is far from ideal, and can probably be the source of unwanted side effects/race conditions.
        The previous implemented approach was mutating the `__annotations__` dict of `cls`, which is no longer a
        safe operation in Python 3.14+, and resulted in unexpected behavior with field ordering anyway.
    """
    # A list of two-tuples, the first element being a reference to the
    # dataclass fields dictionary, the second element being a mapping between
    # the field names that were modified, and their original `Field`:
    original_fields_list: list[tuple[DcFields, DcFields]] = []

    for base in cls.__mro__[1:]:
        dc_fields: dict[str, dataclasses.Field[Any]] = base.__dict__.get('__dataclass_fields__', {})
        dc_fields_with_pydantic_field_defaults = {
            field_name: field
            for field_name, field in dc_fields.items()
            if isinstance(field.default, FieldInfo)
            # Only do the patching if one of the affected attributes is set:
            and (field.default.description is not None or field.default.kw_only or field.default.repr is not True)
        }
        if dc_fields_with_pydantic_field_defaults:
            original_fields_list.append((dc_fields, dc_fields_with_pydantic_field_defaults))
            for field_name, field in dc_fields_with_pydantic_field_defaults.items():
                default = cast(FieldInfo, field.default)
                # `dataclasses.Field` isn't documented as working with `copy.copy()`.
                # It is a class with `__slots__`, so should work (and we hope for the best):
                new_dc_field = copy.copy(field)
                # For base fields, no need to set `doc` from `FieldInfo.description`, this is only relevant
                # for the class under construction and handled in `as_dataclass_field()`.
                if sys.version_info >= (3, 10) and default.kw_only:
                    new_dc_field.kw_only = True
                if default.repr is not True:
                    new_dc_field.repr = default.repr
                dc_fields[field_name] = new_dc_field

    try:
        yield
    finally:
        for fields, original_fields in original_fields_list:
            for field_name, original_field in original_fields.items():
                fields[field_name] = original_field


--- pydantic/v1/dataclasses.py ---
"""
The main purpose is to enhance stdlib dataclasses by adding validation
A pydantic dataclass can be generated from scratch or from a stdlib one.

Behind the scene, a pydantic dataclass is just like a regular one on which we attach
a `BaseModel` and magic methods to trigger the validation of the data.
`__init__` and `__post_init__` are hence overridden and have extra logic to be
able to validate input data.

When a pydantic dataclass is generated from scratch, it's just a plain dataclass
with validation triggered at initialization

The tricky part if for stdlib dataclasses that are converted after into pydantic ones e.g.

```py
@dataclasses.dataclass
class M:
    x: int

ValidatedM = pydantic.dataclasses.dataclass(M)
```

We indeed still want to support equality, hashing, repr, ... as if it was the stdlib one!

```py
assert isinstance(ValidatedM(x=1), M)
assert ValidatedM(x=1) == M(x=1)
```

This means we **don't want to create a new dataclass that inherits from it**
The trick is to create a wrapper around `M` that will act as a proxy to trigger
validation without altering default `M` behaviour.
"""
import copy
import dataclasses
import sys
from contextlib import contextmanager
from functools import wraps

try:
    from functools import cached_property
except ImportError:
    # cached_property available only for python3.8+
    pass

from typing import TYPE_CHECKING, Any, Callable, ClassVar, Dict, Generator, Optional, Type, TypeVar, Union, overload

from typing_extensions import dataclass_transform

from pydantic.v1.class_validators import gather_all_validators
from pydantic.v1.config import BaseConfig, ConfigDict, Extra, get_config
from pydantic.v1.error_wrappers import ValidationError
from pydantic.v1.errors import DataclassTypeError
from pydantic.v1.fields import Field, FieldInfo, Required, Undefined
from pydantic.v1.main import create_model, validate_model
from pydantic.v1.utils import ClassAttribute

if TYPE_CHECKING:
    from pydantic.v1.main import BaseModel
    from pydantic.v1.typing import CallableGenerator, NoArgAnyCallable

    DataclassT = TypeVar('DataclassT', bound='Dataclass')

    DataclassClassOrWrapper = Union[Type['Dataclass'], 'DataclassProxy']

    class Dataclass:
        # stdlib attributes
        __dataclass_fields__: ClassVar[Dict[str, Any]]
        __dataclass_params__: ClassVar[Any]  # in reality `dataclasses._DataclassParams`
        __post_init__: ClassVar[Callable[..., None]]

        # Added by pydantic
        __pydantic_run_validation__: ClassVar[bool]
        __post_init_post_parse__: ClassVar[Callable[..., None]]
        __pydantic_initialised__: ClassVar[bool]
        __pydantic_model__: ClassVar[Type[BaseModel]]
        __pydantic_validate_values__: ClassVar[Callable[['Dataclass'], None]]
        __pydantic_has_field_info_default__: ClassVar[bool]  # whether a `pydantic.Field` is used as default value

        def __init__(self, *args: object, **kwargs: object) -> None:
            pass

        @classmethod
        def __get_validators__(cls: Type['Dataclass']) -> 'CallableGenerator':
            pass

        @classmethod
        def __validate__(cls: Type['DataclassT'], v: Any) -> 'DataclassT':
            pass


__all__ = [
    'dataclass',
    'set_validation',
    'create_pydantic_model_from_dataclass',
    'is_builtin_dataclass',
    'make_dataclass_validator',
]

_T = TypeVar('_T')

if sys.version_info >= (3, 10):

    @dataclass_transform(field_specifiers=(dataclasses.field, Field))
    @overload
    def dataclass(
        *,
        init: bool = True,
        repr: bool = True,
        eq: bool = True,
        order: bool = False,
        unsafe_hash: bool = False,
        frozen: bool = False,
        config: Union[ConfigDict, Type[object], None] = None,
        validate_on_init: Optional[bool] = None,
        use_proxy: Optional[bool] = None,
        kw_only: bool = ...,
    ) -> Callable[[Type[_T]], 'DataclassClassOrWrapper']:
        ...

    @dataclass_transform(field_specifiers=(dataclasses.field, Field))
    @overload
    def dataclass(
        _cls: Type[_T],
        *,
        init: bool = True,
        repr: bool = True,
        eq: bool = True,
        order: bool = False,
        unsafe_hash: bool = False,
        frozen: bool = False,
        config: Union[ConfigDict, Type[object], None] = None,
        validate_on_init: Optional[bool] = None,
        use_proxy: Optional[bool] = None,
        kw_only: bool = ...,
    ) -> 'DataclassClassOrWrapper':
        ...

else:

    @dataclass_transform(field_specifiers=(dataclasses.field, Field))
    @overload
    def dataclass(
        *,
        init: bool = True,
        repr: bool = True,
        eq: bool = True,
        order: bool = False,
        unsafe_hash: bool = False,
        frozen: bool = False,
        config: Union[ConfigDict, Type[object], None] = None,
        validate_on_init: Optional[bool] = None,
        use_proxy: Optional[bool] = None,
    ) -> Callable[[Type[_T]], 'DataclassClassOrWrapper']:
        ...

    @dataclass_transform(field_specifiers=(dataclasses.field, Field))
    @overload
    def dataclass(
        _cls: Type[_T],
        *,
        init: bool = True,
        repr: bool = True,
        eq: bool = True,
        order: bool = False,
        unsafe_hash: bool = False,
        frozen: bool = False,
        config: Union[ConfigDict, Type[object], None] = None,
        validate_on_init: Optional[bool] = None,
        use_proxy: Optional[bool] = None,
    ) -> 'DataclassClassOrWrapper':
        ...


@dataclass_transform(field_specifiers=(dataclasses.field, Field))
def dataclass(
    _cls: Optional[Type[_T]] = None,
    *,
    init: bool = True,
    repr: bool = True,
    eq: bool = True,
    order: bool = False,
    unsafe_hash: bool = False,
    frozen: bool = False,
    config: Union[ConfigDict, Type[object], None] = None,
    validate_on_init: Optional[bool] = None,
    use_proxy: Optional[bool] = None,
    kw_only: bool = False,
) -> Union[Callable[[Type[_T]], 'DataclassClassOrWrapper'], 'DataclassClassOrWrapper']:
    """
    Like the python standard lib dataclasses but with type validation.
    The result is either a pydantic dataclass that will validate input data
    or a wrapper that will trigger validation around a stdlib dataclass
    to avoid modifying it directly
    """
    the_config = get_config(config)

    def wrap(cls: Type[Any]) -> 'DataclassClassOrWrapper':
        should_use_proxy = (
            use_proxy
            if use_proxy is not None
            else (
                is_builtin_dataclass(cls)
                and (cls.__bases__[0] is object or set(dir(cls)) == set(dir(cls.__bases__[0])))
            )
        )
        if should_use_proxy:
            dc_cls_doc = ''
            dc_cls = DataclassProxy(cls)
            default_validate_on_init = False
        else:
            dc_cls_doc = cls.__doc__ or ''  # needs to be done before generating dataclass
            if sys.version_info >= (3, 10):
                dc_cls = dataclasses.dataclass(
                    cls,
                    init=init,
                    repr=repr,
                    eq=eq,
                    order=order,
                    unsafe_hash=unsafe_hash,
                    frozen=frozen,
                    kw_only=kw_only,
                )
            else:
                dc_cls = dataclasses.dataclass(  # type: ignore
                    cls, init=init, repr=repr, eq=eq, order=order, unsafe_hash=unsafe_hash, frozen=frozen
                )
            default_validate_on_init = True

        should_validate_on_init = default_validate_on_init if validate_on_init is None else validate_on_init
        _add_pydantic_validation_attributes(cls, the_config, should_validate_on_init, dc_cls_doc)
        dc_cls.__pydantic_model__.__try_update_forward_refs__(**{cls.__name__: cls})
        return dc_cls

    if _cls is None:
        return wrap

    return wrap(_cls)


@contextmanager
def set_validation(cls: Type['DataclassT'], value: bool) -> Generator[Type['DataclassT'], None, None]:
    original_run_validation = cls.__pydantic_run_validation__
    try:
        cls.__pydantic_run_validation__ = value
        yield cls
    finally:
        cls.__pydantic_run_validation__ = original_run_validation


class DataclassProxy:
    __slots__ = '__dataclass__'

    def __init__(self, dc_cls: Type['Dataclass']) -> None:
        object.__setattr__(self, '__dataclass__', dc_cls)

    def __call__(self, *args: Any, **kwargs: Any) -> Any:
        with set_validation(self.__dataclass__, True):
            return self.__dataclass__(*args, **kwargs)

    def __getattr__(self, name: str) -> Any:
        return getattr(self.__dataclass__, name)

    def __setattr__(self, __name: str, __value: Any) -> None:
        return setattr(self.__dataclass__, __name, __value)

    def __instancecheck__(self, instance: Any) -> bool:
        return isinstance(instance, self.__dataclass__)

    def __copy__(self) -> 'DataclassProxy':
        return DataclassProxy(copy.copy(self.__dataclass__))

    def __deepcopy__(self, memo: Any) -> 'DataclassProxy':
        return DataclassProxy(copy.deepcopy(self.__dataclass__, memo))


def _add_pydantic_validation_attributes(  # noqa: C901 (ignore complexity)
    dc_cls: Type['Dataclass'],
    config: Type[BaseConfig],
    validate_on_init: bool,
    dc_cls_doc: str,
) -> None:
    """
    We need to replace the right method. If no `__post_init__` has been set in the stdlib dataclass
    it won't even exist (code is generated on the fly by `dataclasses`)
    By default, we run validation after `__init__` or `__post_init__` if defined
    """
    init = dc_cls.__init__

    @wraps(init)
    def handle_extra_init(self: 'Dataclass', *args: Any, **kwargs: Any) -> None:
        if config.extra == Extra.ignore:
            init(self, *args, **{k: v for k, v in kwargs.items() if k in self.__dataclass_fields__})

        elif config.extra == Extra.allow:
            for k, v in kwargs.items():
                self.__dict__.setdefault(k, v)
            init(self, *args, **{k: v for k, v in kwargs.items() if k in self.__dataclass_fields__})

        else:
            init(self, *args, **kwargs)

    if hasattr(dc_cls, '__post_init__'):
        try:
            post_init = dc_cls.__post_init__.__wrapped__  # type: ignore[attr-defined]
        except AttributeError:
            post_init = dc_cls.__post_init__

        @wraps(post_init)
        def new_post_init(self: 'Dataclass', *args: Any, **kwargs: Any) -> None:
            if config.post_init_call == 'before_validation':
                post_init(self, *args, **kwargs)

            if self.__class__.__pydantic_run_validation__:
                self.__pydantic_validate_values__()
                if hasattr(self, '__post_init_post_parse__'):
                    self.__post_init_post_parse__(*args, **kwargs)

            if config.post_init_call == 'after_validation':
                post_init(self, *args, **kwargs)

        setattr(dc_cls, '__init__', handle_extra_init)
        setattr(dc_cls, '__post_init__', new_post_init)

    else:

        @wraps(init)
        def new_init(self: 'Dataclass', *args: Any, **kwargs: Any) -> None:
            handle_extra_init(self, *args, **kwargs)

            if self.__class__.__pydantic_run_validation__:
                self.__pydantic_validate_values__()

            if hasattr(self, '__post_init_post_parse__'):
                # We need to find again the initvars. To do that we use `__dataclass_fields__` instead of
                # public method `dataclasses.fields`

                # get all initvars and their default values
                initvars_and_values: Dict[str, Any] = {}
                for i, f in enumerate(self.__class__.__dataclass_fields__.values()):
                    if f._field_type is dataclasses._FIELD_INITVAR:  # type: ignore[attr-defined]
                        try:
                            # set arg value by default
                            initvars_and_values[f.name] = args[i]
                        except IndexError:
                            initvars_and_values[f.name] = kwargs.get(f.name, f.default)

                self.__post_init_post_parse__(**initvars_and_values)

        setattr(dc_cls, '__init__', new_init)

    setattr(dc_cls, '__pydantic_run_validation__', ClassAttribute('__pydantic_run_validation__', validate_on_init))
    setattr(dc_cls, '__pydantic_initialised__', False)
    setattr(dc_cls, '__pydantic_model__', create_pydantic_model_from_dataclass(dc_cls, config, dc_cls_doc))
    setattr(dc_cls, '__pydantic_validate_values__', _dataclass_validate_values)
    setattr(dc_cls, '__validate__', classmethod(_validate_dataclass))
    setattr(dc_cls, '__get_validators__', classmethod(_get_validators))

    if dc_cls.__pydantic_model__.__config__.validate_assignment and not dc_cls.__dataclass_params__.frozen:
        setattr(dc_cls, '__setattr__', _dataclass_validate_assignment_setattr)


def _get_validators(cls: 'DataclassClassOrWrapper') -> 'CallableGenerator':
    yield cls.__validate__


def _validate_dataclass(cls: Type['DataclassT'], v: Any) -> 'DataclassT':
    with set_validation(cls, True):
        if isinstance(v, cls):
            v.__pydantic_validate_values__()
            return v
        elif isinstance(v, (list, tuple)):
            return cls(*v)
        elif isinstance(v, dict):
            return cls(**v)
        else:
            raise DataclassTypeError(class_name=cls.__name__)


def create_pydantic_model_from_dataclass(
    dc_cls: Type['Dataclass'],
    config: Type[Any] = BaseConfig,
    dc_cls_doc: Optional[str] = None,
) -> Type['BaseModel']:
    field_definitions: Dict[str, Any] = {}
    for field in dataclasses.fields(dc_cls):
        default: Any = Undefined
        default_factory: Optional['NoArgAnyCallable'] = None
        field_info: FieldInfo

        if field.default is not dataclasses.MISSING:
            default = field.default
        elif field.default_factory is not dataclasses.MISSING:
            default_factory = field.default_factory
        else:
            default = Required

        if isinstance(default, FieldInfo):
            field_info = default
            dc_cls.__pydantic_has_field_info_default__ = True
        else:
            field_info = Field(default=default, default_factory=default_factory, **field.metadata)

        field_definitions[field.name] = (field.type, field_info)

    validators = gather_all_validators(dc_cls)
    model: Type['BaseModel'] = create_model(
        dc_cls.__name__,
        __config__=config,
        __module__=dc_cls.__module__,
        __validators__=validators,
        __cls_kwargs__={'__resolve_forward_refs__': False},
        **field_definitions,
    )
    model.__doc__ = dc_cls_doc if dc_cls_doc is not None else dc_cls.__doc__ or ''
    return model


if sys.version_info >= (3, 8):

    def _is_field_cached_property(obj: 'Dataclass', k: str) -> bool:
        return isinstance(getattr(type(obj), k, None), cached_property)

else:

    def _is_field_cached_property(obj: 'Dataclass', k: str) -> bool:
        return False


def _dataclass_validate_values(self: 'Dataclass') -> None:
    # validation errors can occur if this function is called twice on an already initialised dataclass.
    # for example if Extra.forbid is enabled, it would consider __pydantic_initialised__ an invalid extra property
    if getattr(self, '__pydantic_initialised__'):
        return
    if getattr(self, '__pydantic_has_field_info_default__', False):
        # We need to remove `FieldInfo` values since they are not valid as input
        # It's ok to do that because they are obviously the default values!
        input_data = {
            k: v
            for k, v in self.__dict__.items()
            if not (isinstance(v, FieldInfo) or _is_field_cached_property(self, k))
        }
    else:
        input_data = {k: v for k, v in self.__dict__.items() if not _is_field_cached_property(self, k)}
    d, _, validation_error = validate_model(self.__pydantic_model__, input_data, cls=self.__class__)
    if validation_error:
        raise validation_error
    self.__dict__.update(d)
    object.__setattr__(self, '__pydantic_initialised__', True)


def _dataclass_validate_assignment_setattr(self: 'Dataclass', name: str, value: Any) -> None:
    if self.__pydantic_initialised__:
        d = dict(self.__dict__)
        d.pop(name, None)
        known_field = self.__pydantic_model__.__fields__.get(name, None)
        if known_field:
            value, error_ = known_field.validate(value, d, loc=name, cls=self.__class__)
            if error_:
                raise ValidationError([error_], self.__class__)

    object.__setattr__(self, name, value)


def is_builtin_dataclass(_cls: Type[Any]) -> bool:
    """
    Whether a class is a stdlib dataclass
    (useful to discriminated a pydantic dataclass that is actually a wrapper around a stdlib dataclass)

    we check that
    - `_cls` is a dataclass
    - `_cls` is not a processed pydantic dataclass (with a basemodel attached)
    - `_cls` is not a pydantic dataclass inheriting directly from a stdlib dataclass
    e.g.
    ```
    @dataclasses.dataclass
    class A:
        x: int

    @pydantic.dataclasses.dataclass
    class B(A):
        y: int
    ```
    In this case, when we first check `B`, we make an extra check and look at the annotations ('y'),
    which won't be a superset of all the dataclass fields (only the stdlib fields i.e. 'x')
    """
    return (
        dataclasses.is_dataclass(_cls)
        and not hasattr(_cls, '__pydantic_model__')
        and set(_cls.__dataclass_fields__).issuperset(set(getattr(_cls, '__annotations__', {})))
    )


def make_dataclass_validator(dc_cls: Type['Dataclass'], config: Type[BaseConfig]) -> 'CallableGenerator':
    """
    Create a pydantic.dataclass from a builtin dataclass to add type validation
    and yield the validators
    It retrieves the parameters of the dataclass and forwards them to the newly created dataclass
    """
    yield from _get_validators(dataclass(dc_cls, config=config, use_proxy=True))


--- pydantic/_internal/_internal_dataclass.py ---
import sys

# `slots` is available on Python >= 3.10
if sys.version_info >= (3, 10):
    slots_true = {'slots': True}
else:
    slots_true = {}


--- tests/typechecking/pipeline_api.py ---
import datetime
from typing import Annotated

from pydantic.experimental.pipeline import validate_as

# TODO: since Pyright 1.1.384, support for PEP 746 was disabled.
# `a1` and `a2` should have a `pyright: ignore[reportInvalidTypeArguments]` comment.
a1 = Annotated[str, validate_as(int)]
a2 = Annotated[str, validate_as(str).transform(lambda x: int(x))]
a3 = Annotated[float, validate_as(float).gt(0)]  # should be able to compare float to int

a4 = Annotated[datetime.datetime, validate_as(datetime.datetime).datetime_tz_naive()]
a5 = Annotated[datetime.datetime, validate_as(str).datetime_tz_naive()]  # pyright: ignore[reportAttributeAccessIssue]
a6 = Annotated[
    datetime.datetime,
    (
        validate_as(str).transform(str.strip).validate_as(datetime.datetime).datetime_tz_naive()
        | validate_as(int).transform(datetime.datetime.fromtimestamp).datetime_tz_aware()
    ),
]


--- release/README.md ---
# Release Instructions

**Note:** *This should only apply to maintainers when preparing for and publishing a new release.*

## Prerequisites

* gh` cli is installed - see [installation instructions](https://docs.github.com/en/github-cli/github-cli/quickstart)
    * Run `gh auth login` to authenticate with GitHub, which is needed for the API calls made in the release process.

## Semi-automated Release Process

1. Run `uv run release/prepare.py {VERSION}` from the root of the repository. This will:
   * Update the version number in the `version.py` file and run `uv lock -P pydantic` to update the lock file.
   * Add a new section to HISTORY.md with a title containing the version number tag and current date.
   * If you just want to see the effect of the script without making any changes, you can add the `--dry-run` flag.
2. Curate the changes in HISTORY.md:
   * make sure the markdown is valid; in particular, check text that should be in `code-blocks` is.
   * mark any breaking changes with `**Breaking Change:**`
   * curate the list of pydantic-core updates in the `packaging` section:
     * check the corresponding Pydantic-core releases for any highlights to manually add to the history
   * deduplicate the `packaging` entries to include only the most recent version bumps for each package
3. Run `uv run release/push.py` from the root of the repository. This will:
   * Create a PR with the changes you made in the previous steps.
   * Add a label to the PR to indicate that it's a release PR.
   * Open a draft release on GitHub with the changes you made in the previous steps.
4. Review the PR and merge it.
5. Publish the release and wait for the CI to finish building and publishing the new version.

## Manual Release Process

To create a new release:

1. Edit `pydantic/version.py` to set the new version number and run `uv lock -P pydantic`
2. Add a new section to HISTORY.md with a title containing the version number tag and current date in this format , `## {version} ({date})` example: `## v2.11.0a2 (2025-02-10)`.
3. Copy the changes generated by GitHub and paste them in the new section of HISTORY.md.
4. **Important:** curate the changes in `HISTORY.md`:
   * make sure the markdown is valid; in particular, check text that should be in `code-blocks` is.
   * mark any breaking changes with `**Breaking Change:**`
   * curate the list of pydantic-core updates in the `packaging` section:
     * check the corresponding pydantic-core releases for any highlights to manually add to the history
   * deduplicate the `packaging` entries to include only the most recent version bumps for each package
5. Create a pull request with these changes.
6. Once the pull request is merged, create a new release on GitHub:
   * the tag should be `v{VERSION}`
   * the title should be `v{VERSION} {DATE}`
   * the body should contain:
     * a copy-paste of the `HISTORY.md` section you prepared previously, plus
     * a full changelog link in the form `Full Changelog: https://github.com/pydantic/pydantic/compare/v{PREV_VERSION}...v{VERSION}/`
7. Ask @samuelcolvin, or @dmontagu to approve the release once CI has run.


## Links discovered
- [installation instructions](https://docs.github.com/en/github-cli/github-cli/quickstart)

--- release/prepare.py ---
"""Automate the version bump and changelog update process."""

import argparse
import json
import re
import warnings
from datetime import date
from pathlib import Path

import requests

from release.shared import (
    GITHUB_TOKEN,
    HISTORY_FILE,
    PACKAGE_VERSION_FILE,
    REPO,
    run_command,
)

ROOT_DIR = Path(__file__).parent.parent


def update_version(new_version: str, dry_run: bool) -> None:
    """Update the version in the giving py version file."""
    version_file_path = ROOT_DIR / PACKAGE_VERSION_FILE
    content = version_file_path.read_text(encoding='utf-8')

    # Regex to match the VERSION assignment
    pattern = r'(VERSION\s*=\s*[\'\"])([^\"^\']+)([\'\"])'
    version_stm = re.search(pattern, content)
    if not version_stm:
        print(
            'Could not find the version assignment in the version file. '
            "Please make sure the version file has a line like `VERSION: Final = '1.2.3'`."
        )
        raise SystemExit(1)
    old_version = version_stm.group(2)
    if old_version == new_version:
        warnings.warn('The new version is the same as the old version. The script might not have any effect.')
    old_version_stm = ''.join(version_stm.groups())
    new_version_stm = old_version_stm.replace(old_version, new_version)

    if dry_run:
        print(f'Updating version in version file at "{PACKAGE_VERSION_FILE}"')
        print('--- Before ---')
        print(old_version_stm)
        print('--- After ---')
        print(new_version_stm)
        print('Running in dry mode, lock file is not updated.')
        return

    version_file_path.write_text(content.replace(old_version_stm, new_version_stm), encoding='utf-8')
    run_command('uv', 'lock', '-P', 'pydantic')


def get_notes(new_version: str) -> str:
    """Fetch auto-generated release notes from github."""
    last_tag = run_command('git', 'describe', '--tags', '--abbrev=0')
    auth_token = GITHUB_TOKEN

    data = {'target_committish': 'main', 'previous_tag_name': last_tag, 'tag_name': f'v{new_version}'}
    response = requests.post(
        f'https://api.github.com/repos/{REPO}/releases/generate-notes',
        headers={
            'Accept': 'application/vnd.github+json',
            'Authorization': f'Bearer {auth_token}',
            'x-github-api-version': '2022-11-28',
        },
        data=json.dumps(data),
        timeout=100,
    )
    response.raise_for_status()

    body = response.json()['body']
    body = body.replace('<!-- Release notes generated using configuration in .github/release.yml at main -->\n\n', '')

    # Add one level to all headers so they match HISTORY.md, and add trailing newline
    body = re.sub(pattern='^(#+ .+?)$', repl=r'#\1\n', string=body, flags=re.MULTILINE)

    # Ensure a blank line before headers
    body = re.sub(pattern='([^\n])(\n#+ .+?\n)', repl=r'\1\n\2', string=body)

    # Render PR links nicely
    body = re.sub(
        pattern=f'https://github.com/{REPO}/pull/(\\d+)',
        repl=f'[#\\1](https://github.com/{REPO}/pull/\\1)',
        string=body,
    )

    # Remove "full changelog" link
    body = re.sub(
        pattern=r'\*\*Full Changelog\*\*: https://.*$',
        repl='',
        string=body,
    )

    return body.strip()


def update_history(new_version: str, dry_run: bool, force_update: bool) -> None:
    """Generate release notes and prepend them to HISTORY.md."""
    history_path = ROOT_DIR / HISTORY_FILE
    history_content = history_path.read_text(encoding='utf8')

    # use ( to avoid matching beta versions
    if f'## v{new_version} (' in history_content and not force_update:
        warnings.warn(
            f'WARNING: v{new_version} already in history, {HISTORY_FILE} not updated. \n'
            'Use --force or -f to update the history file anyway.'
        )
        return

    date_today_str = f'{date.today():%Y-%m-%d}'
    title = f'v{new_version} ({date_today_str})'
    notes = get_notes(new_version)
    new_chunk = f'## {title}\n\n[GitHub release](https://github.com/{REPO}/releases/tag/v{new_version})\n\n{notes}\n\n'
    if dry_run:
        print(f'Would add the following to {history_path}:\n{new_chunk}')
    history = new_chunk + history_content

    if not dry_run:
        history_path.write_text(history)
        print(f'\nSUCCESS: added "{title}" section to {history_path.relative_to(ROOT_DIR)}')

    citation_path = ROOT_DIR / 'CITATION.cff'
    citation_text = citation_path.read_text()

    citation_text = re.sub(r'(?<=\nversion: ).*', f'v{new_version}', citation_text)
    citation_text = re.sub(r'(?<=date-released: ).*', date_today_str, citation_text)
    if dry_run:
        print(
            f'Would update version=v{new_version} and date-released={date_today_str} in '
            f'{citation_path.relative_to(ROOT_DIR)}'
        )
        print(f'Updated content:\n{citation_text}')
    else:
        citation_path.write_text(citation_text)
        print(
            f'SUCCESS: updated version=v{new_version} and date-released={date_today_str} '
            f'in {citation_path.relative_to(ROOT_DIR)}'
        )


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    # For easier iteration, can generate the release notes without saving
    parser.add_argument('version', help='New version number to release.')
    parser.add_argument(
        '-d',
        '--dry-run',
        help='print changes to terminal without saving to version file and the history document.',
        action='store_true',
    )
    parser.add_argument(
        '-f',
        '--force',
        help='Force the update of the version and history file.',
        action='store_true',
    )
    args = parser.parse_args()

    version = args.version
    _dry_run = args.dry_run
    _force_update = args.force

    update_version(version, _dry_run)
    if not _dry_run:
        print(f'Updated version to v{version} in the python version file.')

    update_history(version, _dry_run, _force_update)


## Links discovered
- [#\\1](https://github.com/{REPO}/pull/\\1)
- [GitHub release](https://github.com/{REPO}/releases/tag/v{new_version})

--- release/push.py ---
"""Automate the release draft + PR creation process."""

import re
from pathlib import Path
from subprocess import CalledProcessError

import requests

from release.shared import (
    GITHUB_TOKEN,
    HISTORY_FILE,
    REPO,
    run_command,
)

ROOT_DIR = Path(__file__).parent.parent
HISTORY_RELEASE_HEAD_REGEX = r'^## v(\d+\.\d+\.\d+[a-zA-Z0-9]*)\s'


def get_latest_version_from_changelog() -> str:
    """Get the most recently listed version from the changelog."""
    with open(ROOT_DIR / HISTORY_FILE, encoding='utf8') as f:
        for line in f:
            match = re.match(HISTORY_RELEASE_HEAD_REGEX, line)
            if match:
                return match.group(1)
    raise ValueError('Latest version not found in changelog')


def get_latest_release_notes_from_changelog() -> str:
    """Get the release notes for the latest version from the changelog."""
    with open(ROOT_DIR / HISTORY_FILE, encoding='utf8') as f:
        for line in f:
            match = re.match(HISTORY_RELEASE_HEAD_REGEX, line)
            if match:
                break
        else:
            raise ValueError('Latest version not found in changelog')

        release_notes_li: list[str] = []
        for line in f:
            if re.match(HISTORY_RELEASE_HEAD_REGEX, line):
                break
            release_notes_li.append(line)
    return ''.join(release_notes_li)


def commit_and_push_changes(rl_version: str) -> None:
    """Commit and push changes to a new branch."""
    branch_name = f'release/v{rl_version}'
    run_command('git', 'checkout', '-b', branch_name)
    run_command('git', 'add', '-A')
    try:
        run_command('git', 'commit', '-m', f'Bump version to v{rl_version}')
    except CalledProcessError as e:
        print('No changes related to version bump. Are you sure that you have run prepare.py?')
        raise e
    run_command('git', 'push', 'origin', branch_name)


def open_pull_request(rl_version: str):
    """Open a pull request on GitHub."""
    url = f'https://api.github.com/repos/{REPO}/pulls'
    headers = {'Authorization': f'token {GITHUB_TOKEN}'}
    data = {
        'title': f'Release v{rl_version}',
        'head': f'release/v{rl_version}',
        'base': 'main',
        'body': f'Bumping version to v{rl_version}.',
    }
    response = requests.post(url, json=data, headers=headers, timeout=10)
    try:
        response.raise_for_status()
    except requests.exceptions.HTTPError as e:
        print(f'HTTP error occurred: {e}')
        print(f'Response content: {response.content.decode()}')
        raise e
    return response.json()['html_url']


def create_version_tag(rl_version: str):
    """Create a version tag."""
    run_command('git', 'tag', f'v{rl_version}')
    run_command('git', 'push', 'origin', f'v{rl_version}')


def create_github_release(new_version: str, notes: str):
    """Create a new release on GitHub."""
    url = f'https://api.github.com/repos/{REPO}/releases'

    data = {
        'tag_name': f'v{new_version}',
        'name': f'v{new_version}',
        'body': notes,
        'draft': True,
    }

    response = requests.post(
        url,
        headers={
            'Authorization': f'Bearer {GITHUB_TOKEN}',
            'Accept': 'application/vnd.github+json',
        },
        json=data,
        timeout=10,
    )
    try:
        response.raise_for_status()
    except requests.exceptions.HTTPError as e:
        print(f'HTTP error occurred: {e}')
        print(f'Response content: {response.content.decode()}')
        raise e


def create_github_release_draft(rl_version: str, rl_release_notes: str):
    """Create a GitHub release draft."""
    url = f'https://api.github.com/repos/{REPO}/releases'
    headers = {'Authorization': f'token {GITHUB_TOKEN}'}
    data = {
        'tag_name': f'v{rl_version}',
        'name': f'v{rl_version}',
        'body': rl_release_notes,
        'draft': True,
        'prerelease': False,
    }
    response = requests.post(url, json=data, headers=headers, timeout=10)
    try:
        response.raise_for_status()
    except requests.exceptions.HTTPError as e:
        print(f'HTTP error occurred: {e}')
        print(f'Response content: {response.content.decode()}')
        raise e
    release_url = response.json()['html_url']
    # Publishing happens in the edit page
    edit_url = release_url.replace('/releases/tag/', '/releases/edit/')
    return edit_url


if __name__ == '__main__':
    version = get_latest_version_from_changelog()
    release_notes = get_latest_release_notes_from_changelog()

    commit_and_push_changes(version)
    pr_url = open_pull_request(version)
    print(f'Opened PR: {pr_url}')

    create_version_tag(version)
    draft_url = create_github_release_draft(version, release_notes)
    print(f'Release draft created: {draft_url}')

    print(f'SUCCESS: Completed release process for v{version}')


--- release/shared.py ---
"""This module contains shared variables and functions for the release scripts."""

import subprocess


def run_command(*args: str) -> str:
    """Run a shell command and return the output."""
    p = subprocess.run(args, stdout=subprocess.PIPE, check=True, encoding='utf-8')
    return p.stdout.strip()


REPO = 'pydantic/pydantic'
HISTORY_FILE = 'HISTORY.md'
PACKAGE_VERSION_FILE = 'pydantic/version.py'
GITHUB_TOKEN = run_command('gh', 'auth', 'token')


--- tests/benchmarks/basemodel_eq_performance.py ---
from __future__ import annotations

import dataclasses
import enum
import gc
import itertools
import operator
import sys
import textwrap
import timeit
from collections.abc import Iterable, Sized
from importlib import metadata
from typing import TYPE_CHECKING, Any, Callable, Generic, TypeVar

# Do not import additional dependencies at top-level
if TYPE_CHECKING:
    import matplotlib.pyplot as plt
    import numpy as np
    from matplotlib import axes, figure

import pydantic

PYTHON_VERSION = '.'.join(map(str, sys.version_info))
PYDANTIC_VERSION = metadata.version('pydantic')


# New implementation of pydantic.BaseModel.__eq__ to test


class OldImplementationModel(pydantic.BaseModel, frozen=True):
    def __eq__(self, other: Any) -> bool:
        if isinstance(other, pydantic.BaseModel):
            # When comparing instances of generic types for equality, as long as all field values are equal,
            # only require their generic origin types to be equal, rather than exact type equality.
            # This prevents headaches like MyGeneric(x=1) != MyGeneric[Any](x=1).
            self_type = self.__pydantic_generic_metadata__['origin'] or self.__class__
            other_type = other.__pydantic_generic_metadata__['origin'] or other.__class__

            return (
                self_type == other_type
                and self.__dict__ == other.__dict__
                and self.__pydantic_private__ == other.__pydantic_private__
                and self.__pydantic_extra__ == other.__pydantic_extra__
            )
        else:
            return NotImplemented  # delegate to the other item in the comparison


class DictComprehensionEqModel(pydantic.BaseModel, frozen=True):
    def __eq__(self, other: Any) -> bool:
        if isinstance(other, pydantic.BaseModel):
            # When comparing instances of generic types for equality, as long as all field values are equal,
            # only require their generic origin types to be equal, rather than exact type equality.
            # This prevents headaches like MyGeneric(x=1) != MyGeneric[Any](x=1).
            self_type = self.__pydantic_generic_metadata__['origin'] or self.__class__
            other_type = other.__pydantic_generic_metadata__['origin'] or other.__class__

            field_names = type(self).model_fields.keys()

            return (
                self_type == other_type
                and ({k: self.__dict__[k] for k in field_names} == {k: other.__dict__[k] for k in field_names})
                and self.__pydantic_private__ == other.__pydantic_private__
                and self.__pydantic_extra__ == other.__pydantic_extra__
            )
        else:
            return NotImplemented  # delegate to the other item in the comparison


class ItemGetterEqModel(pydantic.BaseModel, frozen=True):
    def __eq__(self, other: Any) -> bool:
        if isinstance(other, pydantic.BaseModel):
            # When comparing instances of generic types for equality, as long as all field values are equal,
            # only require their generic origin types to be equal, rather than exact type equality.
            # This prevents headaches like MyGeneric(x=1) != MyGeneric[Any](x=1).
            self_type = self.__pydantic_generic_metadata__['origin'] or self.__class__
            other_type = other.__pydantic_generic_metadata__['origin'] or other.__class__

            model_fields = type(self).model_fields.keys()
            getter = operator.itemgetter(*model_fields) if model_fields else lambda _: None

            return (
                self_type == other_type
                and getter(self.__dict__) == getter(other.__dict__)
                and self.__pydantic_private__ == other.__pydantic_private__
                and self.__pydantic_extra__ == other.__pydantic_extra__
            )
        else:
            return NotImplemented  # delegate to the other item in the comparison


class ItemGetterEqModelFastPath(pydantic.BaseModel, frozen=True):
    def __eq__(self, other: Any) -> bool:
        if isinstance(other, pydantic.BaseModel):
            # When comparing instances of generic types for equality, as long as all field values are equal,
            # only require their generic origin types to be equal, rather than exact type equality.
            # This prevents headaches like MyGeneric(x=1) != MyGeneric[Any](x=1).
            self_type = self.__pydantic_generic_metadata__['origin'] or self.__class__
            other_type = other.__pydantic_generic_metadata__['origin'] or other.__class__

            # Perform common checks first
            if not (
                self_type == other_type
                and self.__pydantic_private__ == other.__pydantic_private__
                and self.__pydantic_extra__ == other.__pydantic_extra__
            ):
                return False

            # Fix GH-7444 by comparing only pydantic fields
            # We provide a fast-path for performance: __dict__ comparison is *much* faster
            # See tests/benchmarks/test_basemodel_eq_performances.py and GH-7825 for benchmarks
            if self.__dict__ == other.__dict__:
                # If the check above passes, then pydantic fields are equal, we can return early
                return True
            else:
                # Else, we need to perform a more detailed, costlier comparison
                model_fields = type(self).model_fields.keys()
                getter = operator.itemgetter(*model_fields) if model_fields else lambda _: None
                return getter(self.__dict__) == getter(other.__dict__)
        else:
            return NotImplemented  # delegate to the other item in the comparison


K = TypeVar('K')
V = TypeVar('V')


# We need a sentinel value for missing fields when comparing models
# Models are equals if-and-only-if they miss the same fields, and since None is a legitimate value
# we can't default to None
# We use the single-value enum trick to allow correct typing when using a sentinel
class _SentinelType(enum.Enum):
    SENTINEL = enum.auto()


_SENTINEL = _SentinelType.SENTINEL


@dataclasses.dataclass
class _SafeGetItemProxy(Generic[K, V]):
    """Wrapper redirecting `__getitem__` to `get` and a sentinel value

    This makes is safe to use in `operator.itemgetter` when some keys may be missing
    """

    wrapped: dict[K, V]

    def __getitem__(self, key: K, /) -> V | _SentinelType:
        return self.wrapped.get(key, _SENTINEL)

    def __contains__(self, key: K, /) -> bool:
        return self.wrapped.__contains__(key)


class SafeItemGetterEqModelFastPath(pydantic.BaseModel, frozen=True):
    def __eq__(self, other: Any) -> bool:
        if isinstance(other, pydantic.BaseModel):
            # When comparing instances of generic types for equality, as long as all field values are equal,
            # only require their generic origin types to be equal, rather than exact type equality.
            # This prevents headaches like MyGeneric(x=1) != MyGeneric[Any](x=1).
            self_type = self.__pydantic_generic_metadata__['origin'] or self.__class__
            other_type = other.__pydantic_generic_metadata__['origin'] or other.__class__

            # Perform common checks first
            if not (
                self_type == other_type
                and self.__pydantic_private__ == other.__pydantic_private__
                and self.__pydantic_extra__ == other.__pydantic_extra__
            ):
                return False

            # Fix GH-7444 by comparing only pydantic fields
            # We provide a fast-path for performance: __dict__ comparison is *much* faster
            # See tests/benchmarks/test_basemodel_eq_performances.py and GH-7825 for benchmarks
            if self.__dict__ == other.__dict__:
                # If the check above passes, then pydantic fields are equal, we can return early
                return True
            else:
                # Else, we need to perform a more detailed, costlier comparison
                model_fields = type(self).model_fields.keys()
                getter = operator.itemgetter(*model_fields) if model_fields else lambda _: None
                return getter(_SafeGetItemProxy(self.__dict__)) == getter(_SafeGetItemProxy(other.__dict__))
        else:
            return NotImplemented  # delegate to the other item in the comparison


class ItemGetterEqModelFastPathFallback(pydantic.BaseModel, frozen=True):
    def __eq__(self, other: Any) -> bool:
        if isinstance(other, pydantic.BaseModel):
            # When comparing instances of generic types for equality, as long as all field values are equal,
            # only require their generic origin types to be equal, rather than exact type equality.
            # This prevents headaches like MyGeneric(x=1) != MyGeneric[Any](x=1).
            self_type = self.__pydantic_generic_metadata__['origin'] or self.__class__
            other_type = other.__pydantic_generic_metadata__['origin'] or other.__class__

            # Perform common checks first
            if not (
                self_type == other_type
                and self.__pydantic_private__ == other.__pydantic_private__
                and self.__pydantic_extra__ == other.__pydantic_extra__
            ):
                return False

            # Fix GH-7444 by comparing only pydantic fields
            # We provide a fast-path for performance: __dict__ comparison is *much* faster
            # See tests/benchmarks/test_basemodel_eq_performances.py and GH-7825 for benchmarks
            if self.__dict__ == other.__dict__:
                # If the check above passes, then pydantic fields are equal, we can return early
                return True
            else:
                # Else, we need to perform a more detailed, costlier comparison
                model_fields = type(self).model_fields.keys()
                getter = operator.itemgetter(*model_fields) if model_fields else lambda _: None
                try:
                    return getter(self.__dict__) == getter(other.__dict__)
                except KeyError:
                    return getter(_SafeGetItemProxy(self.__dict__)) == getter(_SafeGetItemProxy(other.__dict__))
        else:
            return NotImplemented  # delegate to the other item in the comparison


IMPLEMENTATIONS = {
    # Commented out because it is too slow for benchmark to complete in reasonable time
    # "dict comprehension": DictComprehensionEqModel,
    'itemgetter': ItemGetterEqModel,
    'itemgetter+fastpath': ItemGetterEqModelFastPath,
    # Commented-out because it is too slow to run with run_benchmark_random_unequal
    #'itemgetter+safety+fastpath': SafeItemGetterEqModelFastPath,
    'itemgetter+fastpath+safe-fallback': ItemGetterEqModelFastPathFallback,
}

# Benchmark running & plotting code


def plot_all_benchmark(
    bases: dict[str, type[pydantic.BaseModel]],
    sizes: list[int],
) -> figure.Figure:
    import matplotlib.pyplot as plt

    n_rows, n_cols = len(BENCHMARKS), 2
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 4))

    for row, (name, benchmark) in enumerate(BENCHMARKS.items()):
        for col, mimic_cached_property in enumerate([False, True]):
            plot_benchmark(
                f'{name}, {mimic_cached_property=}',
                benchmark,
                bases=bases,
                sizes=sizes,
                mimic_cached_property=mimic_cached_property,
                ax=axes[row, col],
            )
    for ax in axes.ravel():
        ax.legend()
    fig.suptitle(f'python {PYTHON_VERSION}, pydantic {PYDANTIC_VERSION}')
    return fig


def plot_benchmark(
    title: str,
    benchmark: Callable,
    bases: dict[str, type[pydantic.BaseModel]],
    sizes: list[int],
    mimic_cached_property: bool,
    ax: axes.Axes | None = None,
):
    import matplotlib.pyplot as plt
    import numpy as np

    ax = ax or plt.gca()
    arr_sizes = np.asarray(sizes)

    baseline = benchmark(
        title=f'{title}, baseline',
        base=OldImplementationModel,
        sizes=sizes,
        mimic_cached_property=mimic_cached_property,
    )
    ax.plot(sizes, baseline / baseline, label='baseline')
    for name, base in bases.items():
        times = benchmark(
            title=f'{title}, {name}',
            base=base,
            sizes=sizes,
            mimic_cached_property=mimic_cached_property,
        )
        mask_valid = ~np.isnan(times)
        ax.plot(arr_sizes[mask_valid], times[mask_valid] / baseline[mask_valid], label=name)

    ax.set_title(title)
    ax.set_xlabel('Number of pydantic fields')
    ax.set_ylabel('Average time relative to baseline')
    return ax


class SizedIterable(Sized, Iterable):
    pass


def run_benchmark_nodiff(
    title: str,
    base: type[pydantic.BaseModel],
    sizes: SizedIterable,
    mimic_cached_property: bool,
    n_execution: int = 10_000,
    n_repeat: int = 5,
) -> np.ndarray:
    setup = textwrap.dedent(
        """
        import pydantic

        Model = pydantic.create_model(
            "Model",
            __base__=Base,
            **{f'x{i}': (int, i) for i in range(%(size)d)}
        )
        left = Model()
        right = Model()
        """
    )
    if mimic_cached_property:
        # Mimic functools.cached_property editing __dict__
        # NOTE: we must edit both objects, otherwise the dict don't have the same size and
        # dict.__eq__ has a very fast path. This makes our timing comparison incorrect
        # However, the value must be different, otherwise *our* __dict__ == right.__dict__
        # fast-path prevents our correct code from running
        setup += textwrap.dedent(
            """
            object.__setattr__(left, 'cache', None)
            object.__setattr__(right, 'cache', -1)
            """
        )
    statement = 'left == right'
    namespace = {'Base': base}
    return run_benchmark(
        title,
        setup=setup,
        statement=statement,
        n_execution=n_execution,
        n_repeat=n_repeat,
        globals=namespace,
        params={'size': sizes},
    )


def run_benchmark_first_diff(
    title: str,
    base: type[pydantic.BaseModel],
    sizes: SizedIterable,
    mimic_cached_property: bool,
    n_execution: int = 10_000,
    n_repeat: int = 5,
) -> np.ndarray:
    setup = textwrap.dedent(
        """
        import pydantic

        Model = pydantic.create_model(
            "Model",
            __base__=Base,
            **{f'x{i}': (int, i) for i in range(%(size)d)}
        )
        left = Model()
        right = Model(f0=-1) if %(size)d > 0 else Model()
        """
    )
    if mimic_cached_property:
        # Mimic functools.cached_property editing __dict__
        # NOTE: we must edit both objects, otherwise the dict don't have the same size and
        # dict.__eq__ has a very fast path. This makes our timing comparison incorrect
        # However, the value must be different, otherwise *our* __dict__ == right.__dict__
        # fast-path prevents our correct code from running
        setup += textwrap.dedent(
            """
            object.__setattr__(left, 'cache', None)
            object.__setattr__(right, 'cache', -1)
            """
        )
    statement = 'left == right'
    namespace = {'Base': base}
    return run_benchmark(
        title,
        setup=setup,
        statement=statement,
        n_execution=n_execution,
        n_repeat=n_repeat,
        globals=namespace,
        params={'size': sizes},
    )


def run_benchmark_last_diff(
    title: str,
    base: type[pydantic.BaseModel],
    sizes: SizedIterable,
    mimic_cached_property: bool,
    n_execution: int = 10_000,
    n_repeat: int = 5,
) -> np.ndarray:
    setup = textwrap.dedent(
        """
        import pydantic

        Model = pydantic.create_model(
            "Model",
            __base__=Base,
            # shift the range() so that there is a field named size
            **{f'x{i}': (int, i) for i in range(1, %(size)d + 1)}
        )
        left = Model()
        right = Model(f%(size)d=-1) if %(size)d > 0 else Model()
        """
    )
    if mimic_cached_property:
        # Mimic functools.cached_property editing __dict__
        # NOTE: we must edit both objects, otherwise the dict don't have the same size and
        # dict.__eq__ has a very fast path. This makes our timing comparison incorrect
        # However, the value must be different, otherwise *our* __dict__ == right.__dict__
        # fast-path prevents our correct code from running
        setup += textwrap.dedent(
            """
            object.__setattr__(left, 'cache', None)
            object.__setattr__(right, 'cache', -1)
            """
        )
    statement = 'left == right'
    namespace = {'Base': base}
    return run_benchmark(
        title,
        setup=setup,
        statement=statement,
        n_execution=n_execution,
        n_repeat=n_repeat,
        globals=namespace,
        params={'size': sizes},
    )


def run_benchmark_random_unequal(
    title: str,
    base: type[pydantic.BaseModel],
    sizes: SizedIterable,
    mimic_cached_property: bool,
    n_samples: int = 100,
    n_execution: int = 1_000,
    n_repeat: int = 5,
) -> np.ndarray:
    import numpy as np

    setup = textwrap.dedent(
        """
        import pydantic

        Model = pydantic.create_model(
            "Model",
            __base__=Base,
            **{f'x{i}': (int, i) for i in range(%(size)d)}
        )
        left = Model()
        right = Model(f%(field)d=-1)
        """
    )
    if mimic_cached_property:
        # Mimic functools.cached_property editing __dict__
        # NOTE: we must edit both objects, otherwise the dict don't have the same size and
        # dict.__eq__ has a very fast path. This makes our timing comparison incorrect
        # However, the value must be different, otherwise *our* __dict__ == right.__dict__
        # fast-path prevents our correct code from running
        setup += textwrap.dedent(
            """
            object.__setattr__(left, 'cache', None)
            object.__setattr__(right, 'cache', -1)
            """
        )
    statement = 'left == right'
    namespace = {'Base': base}
    arr_sizes = np.fromiter(sizes, dtype=int)
    mask_valid_sizes = arr_sizes > 0
    arr_valid_sizes = arr_sizes[mask_valid_sizes]  # we can't support 0 when sampling the field
    rng = np.random.default_rng()
    arr_fields = rng.integers(arr_valid_sizes, size=(n_samples, *arr_valid_sizes.shape))
    # broadcast the sizes against their sample, so we can iterate on (size, field) tuple
    # as parameters of the timing test
    arr_size_broadcast, _ = np.meshgrid(arr_valid_sizes, arr_fields[:, 0])

    results = run_benchmark(
        title,
        setup=setup,
        statement=statement,
        n_execution=n_execution,
        n_repeat=n_repeat,
        globals=namespace,
        params={'size': arr_size_broadcast.ravel(), 'field': arr_fields.ravel()},
    )
    times = np.empty(arr_sizes.shape, dtype=float)
    times[~mask_valid_sizes] = np.nan
    times[mask_valid_sizes] = results.reshape((n_samples, *arr_valid_sizes.shape)).mean(axis=0)
    return times


BENCHMARKS = {
    'All field equals': run_benchmark_nodiff,
    'First field unequal': run_benchmark_first_diff,
    'Last field unequal': run_benchmark_last_diff,
    'Random unequal field': run_benchmark_random_unequal,
}


def run_benchmark(
    title: str,
    setup: str,
    statement: str,
    n_execution: int = 10_000,
    n_repeat: int = 5,
    globals: dict[str, Any] | None = None,
    progress_bar: bool = True,
    params: dict[str, SizedIterable] | None = None,
) -> np.ndarray:
    import numpy as np
    import tqdm.auto as tqdm

    namespace = globals or {}
    # fast-path
    if not params:
        length = 1
        packed_params = [()]
    else:
        length = len(next(iter(params.values())))
        # This iterator yields a tuple of (key, value) pairs
        # First, make a list of N iterator over (key, value), where the provided values are iterated
        param_pairs = [zip(itertools.repeat(name), value) for name, value in params.items()]
        # Then pack our individual parameter iterator into one
        packed_params = zip(*param_pairs)

    times = [
        # Take the min of the repeats as recommended by timeit doc
        min(
            timeit.Timer(
                setup=setup % dict(local_params),
                stmt=statement,
                globals=namespace,
            ).repeat(repeat=n_repeat, number=n_execution)
        )
        / n_execution
        for local_params in tqdm.tqdm(packed_params, desc=title, total=length, disable=not progress_bar)
    ]
    gc.collect()

    return np.asarray(times, dtype=float)


if __name__ == '__main__':
    # run with `uv run tests/benchmarks/test_basemodel_eq_performance.py`
    import argparse
    import pathlib

    try:
        import matplotlib  # noqa: F401
        import numpy  # noqa: F401
        import tqdm  # noqa: F401
    except ImportError as err:
        raise ImportError(
            'This benchmark additionally depends on numpy, matplotlib and tqdm. '
            'Install those in your environment to run the benchmark.'
        ) from err

    parser = argparse.ArgumentParser(
        description='Test the performance of various BaseModel.__eq__ implementations fixing GH-7444.'
    )
    parser.add_argument(
        '-o',
        '--output-path',
        default=None,
        type=pathlib.Path,
        help=(
            'Output directory or file in which to save the benchmark results. '
            'If a directory is passed, a default filename is used.'
        ),
    )
    parser.add_argument(
        '--min-n-fields',
        type=int,
        default=0,
        help=('Test the performance of BaseModel.__eq__ on models with at least this number of fields. Defaults to 0.'),
    )
    parser.add_argument(
        '--max-n-fields',
        type=int,
        default=100,
        help=('Test the performance of BaseModel.__eq__ on models with up to this number of fields. Defaults to 100.'),
    )

    args = parser.parse_args()

    import matplotlib.pyplot as plt

    sizes = list(range(args.min_n_fields, args.max_n_fields))
    fig = plot_all_benchmark(IMPLEMENTATIONS, sizes=sizes)
    plt.tight_layout()

    if args.output_path is None:
        plt.show()
    else:
        if args.output_path.suffix:
            filepath = args.output_path
        else:
            filepath = args.output_path / f'eq-benchmark_python-{PYTHON_VERSION.replace(".", "-")}.png'
        fig.savefig(
            filepath,
            dpi=200,
            facecolor='white',
            transparent=False,
        )
        print(f'wrote {filepath!s}', file=sys.stderr)


## Links discovered
- [Any](https://github.com/pydantic/pydantic/blob/main/tests/benchmarks/x=1.md)

--- tests/benchmarks/generate_north_star_data.py ---
from datetime import datetime
from typing import Any, Callable, TypeVar, Union

from faker import Faker

f = Faker()
Faker.seed(0)


T = TypeVar('T')

## Helper functions

# by default faker uses upper bound of now for datetime, which
# is not helpful for reproducing benchmark data
_END_DATETIME = datetime(2023, 1, 1, 0, 0, 0, 0)


def one_of(*callables: Callable[[], Any]) -> Any:
    return f.random.choice(callables)()


def list_of(callable: Callable[[], T], max_length: int) -> list[T]:
    return [callable() for _ in range(f.random_int(max=max_length))]


def lax_int(*args: Any, **kwargs: Any) -> Union[int, float, str]:
    return f.random.choice((int, float, str))(f.random_int(*args, **kwargs))


def lax_float(*args: Any, **kwargs: Any) -> Union[int, float, str]:
    return f.random.choice((int, float, str))(f.pyfloat(*args, **kwargs))


def time_seconds() -> int:
    dt = f.date_time(end_datetime=_END_DATETIME)
    midnight = dt.replace(hour=0, minute=0, second=0, microsecond=0)
    return (dt - midnight).total_seconds()


def time_microseconds() -> float:
    return float(time_seconds()) + (f.random_int(max=999999) * 1e-6)


def time_string() -> str:
    return f.time()


def lax_time() -> Union[int, float, str]:
    return one_of(time_seconds, time_microseconds, time_string)


def date_string() -> str:
    return f.date(end_datetime=_END_DATETIME).format('%Y-%m-%d')


def datetime_timestamp() -> int:
    dt = f.date_time(end_datetime=_END_DATETIME)
    midnight = dt.replace(hour=0, minute=0, second=0, microsecond=0)
    return (dt - midnight).total_seconds()


def datetime_microseconds() -> float:
    return float(datetime_timestamp()) + (f.random_int(max=999999) * 1e-6)


def datetime_str() -> str:
    return f.date_time(end_datetime=_END_DATETIME).isoformat()


def lax_datetime() -> Union[int, float, str]:
    return one_of(datetime_timestamp, datetime_microseconds, datetime_str)


## Sample data generators


def blog() -> dict:
    return {
        'type': 'blog',
        'title': f.text(max_nb_chars=40),
        'post_count': lax_int(),
        'readers': lax_int(),
        'avg_post_rating': lax_float(min_value=0, max_value=5),
        'url': f.url(),
    }


def social_profile() -> dict:
    return {
        'type': 'profile',
        'username': f.user_name(),
        'join_date': date_string(),
        **one_of(facebook_profile, twitter_profile, linkedin_profile),
    }


def facebook_profile() -> dict:
    return {'network': 'facebook', 'friends': lax_int()}


def twitter_profile() -> dict:
    return {'network': 'twitter', 'followers': lax_int()}


def linkedin_profile() -> dict:
    return {'network': 'linkedin', 'connections': min(f.random_int(), 500)}


def website() -> dict:
    return one_of(blog, social_profile)


def person() -> dict:
    return {
        'id': f.uuid4(),
        'name': f.name(),
        'height': str(f.pydecimal(min_value=1, max_value=2, right_digits=2)),
        'entry_created_date': date_string(),
        'entry_created_time': lax_time(),
        'entry_updated_at': lax_datetime(),
        'websites': list_of(website, max_length=5),
    }


def person_data(length: int) -> list[dict]:
    return [person() for _ in range(length)]


--- tests/benchmarks/__init__.py ---


--- tests/benchmarks/shared.py ---
from collections import deque
from collections.abc import Iterable, Sequence
from datetime import date, datetime, time, timedelta
from decimal import Decimal
from enum import Enum, IntEnum
from ipaddress import (
    IPv4Address,
    IPv4Interface,
    IPv4Network,
    IPv6Address,
    IPv6Interface,
    IPv6Network,
)
from pathlib import Path
from re import Pattern
from typing import (
    Any,
    Callable,
    Literal,
    NamedTuple,
    Optional,
    Union,
)
from uuid import UUID, uuid4, uuid5

from typing_extensions import TypedDict

from pydantic import (
    UUID1,
    UUID3,
    UUID4,
    UUID5,
    Base64Bytes,
    Base64Str,
    Base64UrlBytes,
    Base64UrlStr,
    BaseModel,
    ByteSize,
    DirectoryPath,
    FilePath,
    FiniteFloat,
    FutureDate,
    ImportString,
    Json,
    JsonValue,
    NegativeFloat,
    NegativeInt,
    NewPath,
    NonNegativeFloat,
    NonNegativeInt,
    NonPositiveFloat,
    NonPositiveInt,
    OnErrorOmit,
    PastDate,
    PastDatetime,
    PositiveFloat,
    PositiveInt,
    Secret,
    SecretBytes,
    SecretStr,
    StrictBool,
)


class SimpleModel(BaseModel):
    field1: str
    field2: int
    field3: float


class NestedModel(BaseModel):
    field1: str
    field2: list[int]
    field3: dict[str, float]


class OuterModel(BaseModel):
    nested: NestedModel
    optional_nested: Optional[NestedModel]


class ComplexModel(BaseModel):
    field1: Union[str, int, float]
    field2: list[dict[str, Union[int, float]]]
    field3: Optional[list[Union[str, int]]]


class Color(Enum):
    RED = 'red'
    GREEN = 'green'
    BLUE = 'blue'


class ToolEnum(IntEnum):
    spanner = 1
    wrench = 2
    screwdriver = 3


class Point(NamedTuple):
    x: int
    y: int


class User(TypedDict):
    name: str
    id: int


class Foo:
    pass


StdLibTypes = [
    deque,  # collections.deque
    deque[str],  # collections.deque
    deque[int],  # collections.deque
    deque[float],  # collections.deque
    deque[bytes],  # collections.deque
    str,  # str
    int,  # int
    float,  # float
    complex,  # complex
    bool,  # bool
    bytes,  # bytes
    date,  # datetime.date
    datetime,  # datetime.datetime
    time,  # datetime.time
    timedelta,  # datetime.timedelta
    Decimal,  # decimal.Decimal
    Color,  # enum
    ToolEnum,  # int enum
    IPv4Address,  # ipaddress.IPv4Address
    IPv6Address,  # ipaddress.IPv6Address
    IPv4Interface,  # ipaddress.IPv4Interface
    IPv6Interface,  # ipaddress.IPv6Interface
    IPv4Network,  # ipaddress.IPv4Network
    IPv6Network,  # ipaddress.IPv6Network
    Path,  # pathlib.Path
    Pattern,  # typing.Pattern
    UUID,  # uuid.UUID
    uuid4,  # uuid.uuid4
    uuid5,  # uuid.uuid5
    Point,  # named tuple
    list,  # built-in list
    list[int],  # built-in list
    list[str],  # built-in list
    list[bytes],  # built-in list
    list[float],  # built-in list
    dict,  # built-in dict
    dict[str, float],  # built-in dict
    dict[str, bytes],  # built-in dict
    dict[str, int],  # built-in dict
    dict[str, str],  # built-in dict
    User,  # TypedDict
    tuple,  # tuple
    tuple[int, str, float],  # built-in tuple
    set,  # built-in set
    set[int],  # set
    set[str],  # set
    frozenset,  # built-in frozenset
    frozenset[int],  # built-in frozenset
    frozenset[str],  # built-in frozenset
    Optional[int],  # typing.Optional
    Optional[str],  # typing.Optional
    Optional[float],  # typing.Optional
    Optional[bytes],  # typing.Optional
    Optional[bool],  # typing.Optional
    Sequence[int],  # typing.Sequence
    Sequence[str],  # typing.Sequence
    Sequence[bytes],  # typing.Sequence
    Sequence[float],  # typing.Sequence
    Iterable[int],  # typing.Iterable
    Iterable[str],  # typing.Iterable
    Iterable[bytes],  # typing.Iterable
    Iterable[float],  # typing.Iterable
    Callable[[int], int],  # typing.Callable
    Callable[[str], str],  # typing.Callable
    Literal['apple', 'pumpkin'],  # typing.Literal
    type[Foo],  # typing.Type
    Any,  # typing.Any
]

PydanticTypes = [
    StrictBool,
    PositiveInt,
    PositiveFloat,
    NegativeInt,
    NegativeFloat,
    NonNegativeInt,
    NonPositiveInt,
    NonNegativeFloat,
    NonPositiveFloat,
    FiniteFloat,
    UUID1,
    UUID3,
    UUID4,
    UUID5,
    FilePath,
    DirectoryPath,
    NewPath,
    Base64Bytes,
    Base64Str,
    Base64UrlBytes,
    Base64UrlStr,
    JsonValue,
    OnErrorOmit,
    ImportString,
    Json[Any],
    Json[list[int]],
    Json[list[str]],
    Json[list[bytes]],
    Json[list[float]],
    Json[list[Any]],
    Secret[bool],
    Secret[int],
    Secret[float],
    Secret[str],
    Secret[bytes],
    SecretStr,
    SecretBytes,
    ByteSize,
    PastDate,
    FutureDate,
    PastDatetime,
]


class DeferredModel(BaseModel):
    model_config = {'defer_build': True}


def rebuild_model(model: type[BaseModel], raise_errors: bool = True) -> None:
    model.model_rebuild(force=True, _types_namespace={}, raise_errors=raise_errors)


--- tests/benchmarks/test_attribute_access.py ---
from functools import cached_property

import pytest

from pydantic import BaseModel, ConfigDict, ValidationError


class InnerValidateAssignment(BaseModel):
    model_config = ConfigDict(validate_assignment=True)
    inner_field1: str
    inner_field2: int


class Model(BaseModel):
    field1: str
    field2: int
    field3: float
    inner1: InnerValidateAssignment
    inner2: InnerValidateAssignment

    _private_field1: str
    _private_field2: int
    _private_field3: float

    @cached_property
    def prop_cached1(self) -> str:
        return self.field1 + self._private_field1

    @cached_property
    def prop_cached2(self) -> int:
        return self.field2 + self._private_field2

    @cached_property
    def prop_cached3(self) -> float:
        return self.field3 + self._private_field3


def test_setattr(benchmark):
    def set_attrs(m):
        m.field1 = 'test1'
        m.field2 = 43
        m.field3 = 4.0
        m.inner1.inner_field1 = 'test inner1'
        m.inner1.inner_field2 = 421
        m.inner2.inner_field1 = 'test inner2'
        m.inner2.inner_field2 = 422
        m._private_field1 = 'test2'
        m._private_field2 = 44
        m._private_field3 = 5.1
        m.prop_cached1 = 'cache override'
        m.prop_cached2 = 10
        m.prop_cached3 = 10.1

    inner = {'inner_field1': 'test inner', 'inner_field2': 420}
    model = Model(field1='test', field2=42, field3=3.14, inner1=inner, inner2=inner)
    benchmark(set_attrs, model)

    model.field2 = 'bad'  # check benchmark setup
    with pytest.raises(ValidationError):
        model.inner1.field2 = 'bad'


def test_getattr(benchmark):
    def get_attrs(m):
        _ = m.field1
        _ = m.field2
        _ = m.field3
        _ = m.inner1.inner_field1
        _ = m.inner1.inner_field2
        _ = m.inner2.inner_field1
        _ = m.inner2.inner_field2
        _ = m._private_field1
        _ = m._private_field2
        _ = m._private_field3
        _ = m.prop_cached1
        _ = m.prop_cached2
        _ = m.prop_cached3

    inner = {'inner_field1': 'test inner', 'inner_field2': 420}
    model = Model(field1='test1', field2=42, field3=3.14, inner1=inner, inner2=inner)
    model._private_field1 = 'test2'
    model._private_field2 = 43
    model._private_field3 = 4.14
    benchmark(get_attrs, model)


--- tests/benchmarks/test_discriminated_unions.py ---
from __future__ import annotations

from typing import Annotated, Literal, Union

import pytest

from pydantic import BaseModel, Field, TypeAdapter


class NestedState(BaseModel):
    state_type: Literal['nested']
    substate: AnyState


class LoopState(BaseModel):
    state_type: Literal['loop']
    substate: AnyState


class LeafState(BaseModel):
    state_type: Literal['leaf']


AnyState = Annotated[Union[NestedState, LoopState, LeafState], Field(discriminator='state_type')]


@pytest.mark.benchmark
def test_schema_build(benchmark) -> None:
    @benchmark
    def run():
        adapter = TypeAdapter(AnyState)
        assert adapter.core_schema['schema']['type'] == 'tagged-union'


any_state_adapter = TypeAdapter(AnyState)


def build_nested_state(n):
    if n <= 0:
        return {'state_type': 'leaf'}
    else:
        return {'state_type': 'loop', 'substate': {'state_type': 'nested', 'substate': build_nested_state(n - 1)}}


@pytest.mark.benchmark
def test_efficiency_with_highly_nested_examples(benchmark) -> None:
    # can go much higher, but we keep it reasonably low here for a proof of concept
    @benchmark
    def run():
        for i in range(1, 12):
            very_nested_input = build_nested_state(i)
            any_state_adapter.validate_python(very_nested_input)


--- .hyperlint/styles/config/vocabularies/hyperlint/accept.txt ---
validator
Pydantic
validators
namespace
Hyperlint
preprocess
tokenization
tokenizer
tzdata
API
APIs
SDKs
SDK


--- HISTORY.md ---
<!-- markdownlint-disable no-bare-urls -->
<!-- markdownlint-disable descriptive-link-text -->
<!-- markdownlint-disable-next-line first-line-heading -->

## v2.12.5 (2025-11-26)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.5)

This is the fifth 2.12 patch release, addressing an issue with the `MISSING` sentinel and providing several documentation improvements.

The next 2.13 minor release will be published in a couple weeks, and will include a new *polymorphic serialization* feature addressing
the remaining unexpected changes to the *serialize as any* behavior.

* Fix pickle error when using `model_construct()` on a model with `MISSING` as a default value by @ornariece in [#12522](https://github.com/pydantic/pydantic/pull/12522).
* Several updates to the documentation by @Viicos.

## v2.12.4 (2025-11-05)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.4)

This is the fourth 2.12 patch release, fixing more regressions, and reverting a change in the `build()` method
of the [`AnyUrl` and Dsn types](https://docs.pydantic.dev/latest/api/networks/).

This patch release also fixes an issue with the serialization of IP address types, when `serialize_as_any` is used. The next patch release
will try to address the remaining issues with *serialize as any* behavior by introducing a new *polymorphic serialization* feature, that
should be used in most cases in place of *serialize as any*.

* Fix issue with forward references in parent `TypedDict` classes by @Viicos in [#12427](https://github.com/pydantic/pydantic/pull/12427).

    This issue is only relevant on Python 3.14 and greater.

* Exclude fields with `exclude_if` from JSON Schema required fields by @Viicos in [#12430](https://github.com/pydantic/pydantic/pull/12430)
* Revert URL percent-encoding of credentials in the `build()` method
  of the [`AnyUrl` and Dsn types](https://docs.pydantic.dev/latest/api/networks/) by @davidhewitt in
  [pydantic-core#1833](https://github.com/pydantic/pydantic-core/pull/1833).

    This was initially considered as a bugfix, but caused regressions and as such was fully reverted. The next release will include
    an opt-in option to percent-encode components of the URL.

* Add type inference for IP address types by @davidhewitt in [pydantic-core#1868](https://github.com/pydantic/pydantic-core/pull/1868).

    The 2.12 changes to the `serialize_as_any` behavior made it so that IP address types could not properly serialize to JSON.

* Avoid getting default values from defaultdict by @davidhewitt in [pydantic-core#1853](https://github.com/pydantic/pydantic-core/pull/1853).

    This fixes a subtle regression in the validation behavior of the [`collections.defaultdict`](https://docs.python.org/3/library/collections.html#collections.defaultdict)
    type.

* Fix issue with field serializers on nested typed dictionaries by @davidhewitt in [pydantic-core#1879](https://github.com/pydantic/pydantic-core/pull/1879).
* Add more `pydantic-core` builds for the three-threaded version of Python 3.14 by @davidhewitt in [pydantic-core#1864](https://github.com/pydantic/pydantic-core/pull/1864).

## v2.12.3 (2025-10-17)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.3)

### What's Changed

This is the third 2.12 patch release, fixing issues related to the `FieldInfo` class, and reverting a change to the supported
[*after* model validator](https://docs.pydantic.dev/latest/concepts/validators/#model-validators) function signatures.

* Raise a warning when an invalid after model validator function signature is raised by @Viicos in [#12414](https://github.com/pydantic/pydantic/pull/12414).
  Starting in 2.12.0, using class methods for *after* model validators raised an error, but the error wasn't raised concistently. We decided
  to emit a deprecation warning instead.
* Add [`FieldInfo.asdict()`](https://docs.pydantic.dev/latest/api/fields/#pydantic.fields.FieldInfo.asdict) method, improve documentation around `FieldInfo` by @Viicos in [#12411](https://github.com/pydantic/pydantic/pull/12411).
  This also add back support for mutations on `FieldInfo` classes, that are reused as `Annotated` metadata. **However**, note that this is still
  *not* a supported pattern. Instead, please refer to the [added example](https://docs.pydantic.dev/latest/examples/dynamic_models/) in the documentation.

The [blog post](https://pydantic.dev/articles/pydantic-v2-12-release#changes) section on changes was also updated to document the changes related to `serialize_as_any`.

## v2.12.2 (2025-10-14)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.2)

### What's Changed

#### Fixes

* Release a new `pydantic-core` version, as a corrupted CPython 3.10 `manylinux2014_aarch64` wheel got uploaded ([pydantic-core#1843](https://github.com/pydantic/pydantic-core/pull/1843)).
* Fix issue with recursive generic models with a parent model class by @Viicos in [#12398](https://github.com/pydantic/pydantic/pull/12398)

## v2.12.1 (2025-10-13)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.1)

### What's Changed

This is the first 2.12 patch release, addressing most (but not all yet) regressions from the initial 2.12.0 release.

#### Fixes

* Do not evaluate annotations when inspecting validators and serializers by @Viicos in [#12355](https://github.com/pydantic/pydantic/pull/12355)
* Make sure `None` is converted as `NoneType` in Python 3.14 by @Viicos in [#12370](https://github.com/pydantic/pydantic/pull/12370)
* Backport V1 runtime warning when using Python 3.14 by @Viicos in [#12367](https://github.com/pydantic/pydantic/pull/12367)
* Fix error message for invalid validator signatures by @Viicos in [#12366](https://github.com/pydantic/pydantic/pull/12366)
* Populate field name in `ValidationInfo` for validation of default value by @Viicos in [pydantic-core#1826](https://github.com/pydantic/pydantic-core/pull/1826)
* Encode credentials in `MultiHostUrl` builder by @willswire in [pydantic-core#1829](https://github.com/pydantic/pydantic-core/pull/1829)
* Respect field serializers when using `serialize_as_any` serialization flag by @davidhewitt in [pydantic-core#1829](https://github.com/pydantic/pydantic-core/pull/1829)
* Fix various `RootModel` serialization issues by @davidhewitt in [pydantic-core#1836](https://github.com/pydantic/pydantic-core/pull/1836)

### New Contributors

* @willswire made their first contribution in [pydantic-core#1829](https://github.com/pydantic/pydantic-core/pull/1829)

## v2.12.0 (2025-10-07)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.0)

### What's Changed

This is the final 2.12 release. It features the work of 20 external contributors and provides useful new features, along with initial Python 3.14 support.
Several minor changes (considered non-breaking changes according to our [versioning policy](https://docs.pydantic.dev/2.12/version-policy/#pydantic-v2))
are also included in this release. Make sure to look into them before upgrading.

**Note that Pydantic V1 is not compatible with Python 3.14 and greater**.

Changes (see the alpha and beta releases for additional changes since 2.11):

#### Packaging

* Update V1 copy to v1.10.24 by @Viicos in [#12338](https://github.com/pydantic/pydantic/pull/12338)

#### New Features

* Add `extra` parameter to the validate functions by @anvilpete in [#12233](https://github.com/pydantic/pydantic/pull/12233)
* Add `exclude_computed_fields` serialization option by @Viicos in [#12334](https://github.com/pydantic/pydantic/pull/12334)
* Add `preverse_empty_path` URL options by @Viicos in [#12336](https://github.com/pydantic/pydantic/pull/12336)
* Add `union_format` parameter to JSON Schema generation by @Viicos in [#12147](https://github.com/pydantic/pydantic/pull/12147)
* Add `__qualname__` parameter for `create_model` by @Atry in [#12001](https://github.com/pydantic/pydantic/pull/12001)

#### Fixes

* Do not try to infer name from lambda definitions in pipelines API by @Viicos in [#12289](https://github.com/pydantic/pydantic/pull/12289)
* Use proper namespace for functions in `TypeAdapter` by @Viicos in [#12324](https://github.com/pydantic/pydantic/pull/12324)
* Use `Any` for context type annotation in `TypeAdapter` by @inducer in [#12279](https://github.com/pydantic/pydantic/pull/12279)
* Expose `FieldInfo` in `pydantic.fields.__all__` by @Viicos in [#12339](https://github.com/pydantic/pydantic/pull/12339)
* Respect `validation_alias` in `@validate_call` by @Viicos in [#12340](https://github.com/pydantic/pydantic/pull/12340)
* Use `Any` as context annotation in plugin API by @Viicos in [#12341](https://github.com/pydantic/pydantic/pull/12341)
* Use proper `stacklevel` in warnings when possible by @Viicos in [#12342](https://github.com/pydantic/pydantic/pull/12342)

### New Contributors

* @anvilpete made their first contribution in [#12233](https://github.com/pydantic/pydantic/pull/12233)
* @JonathanWindell made their first contribution in [#12327](https://github.com/pydantic/pydantic/pull/12327)
* @inducer made their first contribution in [#12279](https://github.com/pydantic/pydantic/pull/12279)
* @Atry made their first contribution in [#12001](https://github.com/pydantic/pydantic/pull/12001)

## v2.12.0b1 (2025-10-03)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.0b1)

This is the first beta release of the upcoming 2.12 release.

### What's Changed

#### Packaging

* Bump `pydantic-core` to v2.40.1 by @Viicos in [#12314](https://github.com/pydantic/pydantic/pull/12314)

#### New Features

* Add support for `exclude_if` at the field level by @andresliszt in [#12141](https://github.com/pydantic/pydantic/pull/12141)
* Add `ValidateAs` annotation helper by @Viicos in [#11942](https://github.com/pydantic/pydantic/pull/11942)
* Add configuration options for validation and JSON serialization of temporal types by @ollz272 in [#12068](https://github.com/pydantic/pydantic/pull/12068)
* Add support for PEP 728 by @Viicos in [#12179](https://github.com/pydantic/pydantic/pull/12179)
* Add field name in serialization error by @NicolasPllr1 in [pydantic-core#1799](https://github.com/pydantic/pydantic-core/pull/1799)
* Add option to preserve empty URL paths by @davidhewitt in [pydantic-core#1789](https://github.com/pydantic/pydantic-core/pull/1789)

#### Changes

* Raise error if an incompatible `pydantic-core` version is installed by @Viicos in [#12196](https://github.com/pydantic/pydantic/pull/12196)
* Remove runtime warning for experimental features by @Viicos in [#12265](https://github.com/pydantic/pydantic/pull/12265)
* Warn if registering virtual subclasses on Pydantic models by @Viicos in [#11669](https://github.com/pydantic/pydantic/pull/11669)

#### Fixes

* Fix `__getattr__()` behavior on Pydantic models when a property raised an `AttributeError` and extra values are present by @raspuchin in [#12106](https://github.com/pydantic/pydantic/pull/12106)
* Add test to prevent regression with Pydantic models used as annotated metadata by @Viicos in [#12133](https://github.com/pydantic/pydantic/pull/12133)
* Allow to use property setters on Pydantic dataclasses with `validate_assignment` set by @Viicos in [#12173](https://github.com/pydantic/pydantic/pull/12173)
* Fix mypy v2 plugin for upcoming mypy release by @cdce8p in [#12209](https://github.com/pydantic/pydantic/pull/12209)
* Respect custom title in functions JSON Schema by @Viicos in [#11892](https://github.com/pydantic/pydantic/pull/11892)
* Fix `ImportString` JSON serialization for objects with a `name` attribute by @chr1sj0nes in [#12219](https://github.com/pydantic/pydantic/pull/12219)
* Do not error on fields overridden by methods in the mypy plugin by @Viicos in [#12290](https://github.com/pydantic/pydantic/pull/12290)

### New Contributors

* @raspuchin made their first contribution in [#12106](https://github.com/pydantic/pydantic/pull/12106)
* @chr1sj0nes made their first contribution in [#12219](https://github.com/pydantic/pydantic/pull/12219)

## v2.12.0a1 (2025-07-26)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.0a1)

This is the first alpha release of the upcoming 2.12 release, which adds initial support for Python 3.14.

### What's Changed

#### New Features

* Add `__pydantic_on_complete__()` hook that is called once model is fully ready to be used by @DouweM in [#11762](https://github.com/pydantic/pydantic/pull/11762)
* Add initial support for Python 3.14 by @Viicos in [#11991](https://github.com/pydantic/pydantic/pull/11991)
* Add regex patterns to JSON schema for `Decimal` type by @Dima-Bulavenko in [#11987](https://github.com/pydantic/pydantic/pull/11987)
* Add support for `doc` attribute on dataclass fields by @Viicos in [#12077](https://github.com/pydantic/pydantic/pull/12077)
* Add experimental `MISSING` sentinel by @Viicos in [#11883](https://github.com/pydantic/pydantic/pull/11883)

#### Changes

* Allow config and bases to be specified together in `create_model()` by @Viicos in [#11714](https://github.com/pydantic/pydantic/pull/11714)
* Move some field logic out of the `GenerateSchema` class by @Viicos in [#11733](https://github.com/pydantic/pydantic/pull/11733)
* Always make use of `inspect.getsourcelines()` for docstring extraction on Python 3.13 and greater by @Viicos in [#11829](https://github.com/pydantic/pydantic/pull/11829)
* Only support the latest Mypy version by @Viicos in [#11832](https://github.com/pydantic/pydantic/pull/11832)
* Do not implicitly convert after model validators to class methods by @Viicos in [#11957](https://github.com/pydantic/pydantic/pull/11957)
* Refactor `FieldInfo` creation implementation by @Viicos in [#11898](https://github.com/pydantic/pydantic/pull/11898)
* Make `Secret` covariant by @bluenote10 in [#12008](https://github.com/pydantic/pydantic/pull/12008)
* Emit warning when field-specific metadata is used in invalid contexts by @Viicos in [#12028](https://github.com/pydantic/pydantic/pull/12028)

#### Fixes

* Properly fetch plain serializer function when serializing default value in JSON Schema by @Viicos in [#11721](https://github.com/pydantic/pydantic/pull/11721)
* Remove generics cache workaround by @Viicos in [#11755](https://github.com/pydantic/pydantic/pull/11755)
* Remove coercion of decimal constraints by @Viicos in [#11772](https://github.com/pydantic/pydantic/pull/11772)
* Fix crash when expanding root type in the mypy plugin by @Viicos in [#11735](https://github.com/pydantic/pydantic/pull/11735)
* Only mark model as complete once all fields are complete by @DouweM in [#11759](https://github.com/pydantic/pydantic/pull/11759)
* Do not provide `field_name` in validator core schemas by @DouweM in [#11761](https://github.com/pydantic/pydantic/pull/11761)
* Fix issue with recursive generic models by @Viicos in [#11775](https://github.com/pydantic/pydantic/pull/11775)
* Fix qualified name comparison of private attributes during namespace inspection by @karta9821 in [#11803](https://github.com/pydantic/pydantic/pull/11803)
* Make sure Pydantic dataclasses with slots and `validate_assignment` can be unpickled by @Viicos in [#11769](https://github.com/pydantic/pydantic/pull/11769)
* Traverse `function-before` schemas during schema gathering by @Viicos in [#11801](https://github.com/pydantic/pydantic/pull/11801)
* Fix check for stdlib dataclasses by @Viicos in [#11822](https://github.com/pydantic/pydantic/pull/11822)
* Check if `FieldInfo` is complete after applying type variable map by @Viicos in [#11855](https://github.com/pydantic/pydantic/pull/11855)
* Do not delete mock validator/serializer in `model_rebuild()` by @Viicos in [#11890](https://github.com/pydantic/pydantic/pull/11890)
* Rebuild dataclass fields before schema generation by @Viicos in [#11949](https://github.com/pydantic/pydantic/pull/11949)
* Always store the original field assignment on `FieldInfo` by @Viicos in [#11946](https://github.com/pydantic/pydantic/pull/11946)
* Do not use deprecated methods as default field values by @Viicos in [#11914](https://github.com/pydantic/pydantic/pull/11914)
* Allow callable discriminator to be applied on PEP 695 type aliases by @Viicos in [#11941](https://github.com/pydantic/pydantic/pull/11941)
* Suppress core schema generation warning when using `SkipValidation` by @ygsh0816 in [#12002](https://github.com/pydantic/pydantic/pull/12002)
* Do not emit typechecking error for invalid `Field()` default with `validate_default` set to `True` by @Viicos in [#11988](https://github.com/pydantic/pydantic/pull/11988)
* Refactor logic to support Pydantic's `Field()` function in dataclasses by @Viicos in [#12051](https://github.com/pydantic/pydantic/pull/12051)

#### Packaging

* Update project metadata to use PEP 639 by @Viicos in [#11694](https://github.com/pydantic/pydantic/pull/11694)
* Bump `mkdocs-llmstxt` to v0.2.0 by @Viicos in [#11725](https://github.com/pydantic/pydantic/pull/11725)
* Bump `pydantic-core` to v2.35.1 by @Viicos in [#11963](https://github.com/pydantic/pydantic/pull/11963)
* Bump dawidd6/action-download-artifact from 10 to 11 by @dependabot[bot] in [#12033](https://github.com/pydantic/pydantic/pull/12033)
* Bump astral-sh/setup-uv from 5 to 6 by @dependabot[bot] in [#11826](https://github.com/pydantic/pydantic/pull/11826)
* Update mypy to 1.17.0 by @Viicos in [#12076](https://github.com/pydantic/pydantic/pull/12076)

### New Contributors

* @parth-paradkar made their first contribution in [#11695](https://github.com/pydantic/pydantic/pull/11695)
* @dqkqd made their first contribution in [#11739](https://github.com/pydantic/pydantic/pull/11739)
* @fhightower made their first contribution in [#11722](https://github.com/pydantic/pydantic/pull/11722)
* @gbaian10 made their first contribution in [#11766](https://github.com/pydantic/pydantic/pull/11766)
* @DouweM made their first contribution in [#11759](https://github.com/pydantic/pydantic/pull/11759)
* @bowenliang123 made their first contribution in [#11719](https://github.com/pydantic/pydantic/pull/11719)
* @rawwar made their first contribution in [#11799](https://github.com/pydantic/pydantic/pull/11799)
* @karta9821 made their first contribution in [#11803](https://github.com/pydantic/pydantic/pull/11803)
* @jinnovation made their first contribution in [#11834](https://github.com/pydantic/pydantic/pull/11834)
* @zmievsa made their first contribution in [#11861](https://github.com/pydantic/pydantic/pull/11861)
* @Otto-AA made their first contribution in [#11860](https://github.com/pydantic/pydantic/pull/11860)
* @ygsh0816 made their first contribution in [#12002](https://github.com/pydantic/pydantic/pull/12002)
* @lukland made their first contribution in [#12015](https://github.com/pydantic/pydantic/pull/12015)
* @Dima-Bulavenko made their first contribution in [#11987](https://github.com/pydantic/pydantic/pull/11987)
* @GSemikozov made their first contribution in [#12050](https://github.com/pydantic/pydantic/pull/12050)
* @hannah-heywa made their first contribution in [#12082](https://github.com/pydantic/pydantic/pull/12082)

## v2.11.10 (2025-10-04)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.10)

### What's Changed

#### Fixes

* Backport v1.10.24 changes by @Viicos

## v2.11.9 (2025-09-13)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.9)

### What's Changed

#### Fixes

* Backport v1.10.23 changes by @Viicos

## v2.11.8 (2025-09-13)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.8)

### What's Changed

#### Fixes

* Fix mypy plugin for mypy 1.18 by @cdce8p in [#12209](https://github.com/pydantic/pydantic/pull/12209)

## v2.11.7 (2025-06-14)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.7)

### What's Changed

#### Fixes

* Copy `FieldInfo` instance if necessary during `FieldInfo` build by @Viicos in [#11898](https://github.com/pydantic/pydantic/pull/11898)

## v2.11.6 (2025-06-13)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.6)

### What's Changed

#### Fixes

* Rebuild dataclass fields before schema generation by @Viicos in [#11949](https://github.com/pydantic/pydantic/pull/11949)
* Always store the original field assignment on `FieldInfo` by @Viicos in [#11946](https://github.com/pydantic/pydantic/pull/11946)

## v2.11.5 (2025-05-22)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.5)

### What's Changed

#### Fixes

* Check if `FieldInfo` is complete after applying type variable map by @Viicos in [#11855](https://github.com/pydantic/pydantic/pull/11855)
* Do not delete mock validator/serializer in `model_rebuild()` by @Viicos in [#11890](https://github.com/pydantic/pydantic/pull/11890)
* Do not duplicate metadata on model rebuild by @Viicos in [#11902](https://github.com/pydantic/pydantic/pull/11902)

## v2.11.4 (2025-04-29)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.4)

### What's Changed

#### Packaging

* Bump `mkdocs-llmstxt` to v0.2.0 by @Viicos in [#11725](https://github.com/pydantic/pydantic/pull/11725)

#### Changes

* Allow config and bases to be specified together in `create_model()` by @Viicos in [#11714](https://github.com/pydantic/pydantic/pull/11714).
  This change was backported as it was previously possible (although not meant to be supported)
  to provide `model_config` as a field, which would make it possible to provide both configuration
  and bases.

#### Fixes

* Remove generics cache workaround by @Viicos in [#11755](https://github.com/pydantic/pydantic/pull/11755)
* Remove coercion of decimal constraints by @Viicos in [#11772](https://github.com/pydantic/pydantic/pull/11772)
* Fix crash when expanding root type in the mypy plugin by @Viicos in [#11735](https://github.com/pydantic/pydantic/pull/11735)
* Fix issue with recursive generic models by @Viicos in [#11775](https://github.com/pydantic/pydantic/pull/11775)
* Traverse `function-before` schemas during schema gathering by @Viicos in [#11801](https://github.com/pydantic/pydantic/pull/11801)

## v2.11.3 (2025-04-08)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.3)

### What's Changed

#### Packaging

* Update V1 copy to v1.10.21 by @Viicos in [#11706](https://github.com/pydantic/pydantic/pull/11706)

#### Fixes

* Preserve field description when rebuilding model fields by @Viicos in [#11698](https://github.com/pydantic/pydantic/pull/11698)

## v2.11.2 (2025-04-03)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.2)

### What's Changed

#### Fixes

* Bump `pydantic-core` to v2.33.1 by @Viicos in [#11678](https://github.com/pydantic/pydantic/pull/11678)
* Make sure `__pydantic_private__` exists before setting private attributes by @Viicos in [#11666](https://github.com/pydantic/pydantic/pull/11666)
* Do not override `FieldInfo._complete` when using field from parent class by @Viicos in [#11668](https://github.com/pydantic/pydantic/pull/11668)
* Provide the available definitions when applying discriminated unions by @Viicos in [#11670](https://github.com/pydantic/pydantic/pull/11670)
* Do not expand root type in the mypy plugin for variables by @Viicos in [#11676](https://github.com/pydantic/pydantic/pull/11676)
* Mention the attribute name in model fields deprecation message by @Viicos in [#11674](https://github.com/pydantic/pydantic/pull/11674)
* Properly validate parameterized mappings by @Viicos in [#11658](https://github.com/pydantic/pydantic/pull/11658)

## v2.11.1 (2025-03-28)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.1)

### What's Changed

#### Fixes

* Do not override `'definitions-ref'` schemas containing serialization schemas or metadata by @Viicos in [#11644](https://github.com/pydantic/pydantic/pull/11644)

## v2.11.0 (2025-03-27)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0)

### What's Changed

Pydantic v2.11 is a version strongly focused on build time performance of Pydantic models (and core schema generation in general).
See the [blog post](https://pydantic.dev/articles/pydantic-v2-11-release) for more details.

#### Packaging

* Bump `pydantic-core` to v2.33.0 by @Viicos in [#11631](https://github.com/pydantic/pydantic/pull/11631)

#### New Features

* Add `encoded_string()` method to the URL types by @YassinNouh21 in [#11580](https://github.com/pydantic/pydantic/pull/11580)
* Add support for `defer_build` with `@validate_call` decorator by @Viicos in [#11584](https://github.com/pydantic/pydantic/pull/11584)
* Allow `@with_config` decorator to be used with keyword arguments by @Viicos in [#11608](https://github.com/pydantic/pydantic/pull/11608)
* Simplify customization of default value inclusion in JSON Schema generation by @Viicos in [#11634](https://github.com/pydantic/pydantic/pull/11634)
* Add `generate_arguments_schema()` function by @Viicos in [#11572](https://github.com/pydantic/pydantic/pull/11572)

#### Fixes

* Allow generic typed dictionaries to be used for unpacked variadic keyword parameters by @Viicos in [#11571](https://github.com/pydantic/pydantic/pull/11571)
* Fix runtime error when computing model string representation involving cached properties and self-referenced models by @Viicos in [#11579](https://github.com/pydantic/pydantic/pull/11579)
* Preserve other steps when using the ellipsis in the pipeline API by @Viicos in [#11626](https://github.com/pydantic/pydantic/pull/11626)
* Fix deferred discriminator application logic by @Viicos in [#11591](https://github.com/pydantic/pydantic/pull/11591)

### New Contributors

* @cmenon12 made their first contribution in [#11562](https://github.com/pydantic/pydantic/pull/11562)
* @Jeukoh made their first contribution in [#11611](https://github.com/pydantic/pydantic/pull/11611)

## v2.11.0b2 (2025-03-17)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0b2)

### What's Changed

#### Packaging

* Bump `pydantic-core` to v2.32.0 by @Viicos in [#11567](https://github.com/pydantic/pydantic/pull/11567)

#### New Features

* Add experimental support for free threading by @Viicos in [#11516](https://github.com/pydantic/pydantic/pull/11516)

#### Fixes

* Fix `NotRequired` qualifier not taken into account in stringified annotation by @Viicos in [#11559](https://github.com/pydantic/pydantic/pull/11559)

### New Contributors

* @joren485 made their first contribution in [#11547](https://github.com/pydantic/pydantic/pull/11547)

## v2.11.0b1 (2025-03-06)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0b1)

### What's Changed

#### Packaging

* Add a `check_pydantic_core_version()` function by @Viicos in https://github.com/pydantic/pydantic/pull/11324
* Remove `greenlet` development dependency by @Viicos in https://github.com/pydantic/pydantic/pull/11351
* Use the `typing-inspection` library by @Viicos in https://github.com/pydantic/pydantic/pull/11479
* Bump `pydantic-core` to `v2.31.1` by @sydney-runkle in https://github.com/pydantic/pydantic/pull/11526

#### New Features

* Support unsubstituted type variables with both a default and a bound or constraints by @FyZzyss in https://github.com/pydantic/pydantic/pull/10789
* Add a `default_factory_takes_validated_data` property to `FieldInfo` by @Viicos in https://github.com/pydantic/pydantic/pull/11034
* Raise a better error when a generic alias is used inside `type[]` by @Viicos in https://github.com/pydantic/pydantic/pull/11088
* Properly support PEP 695 generics syntax by @Viicos in https://github.com/pydantic/pydantic/pull/11189
* Properly support type variable defaults by @Viicos in https://github.com/pydantic/pydantic/pull/11332
* Add support for validating v6, v7, v8 UUIDs by @astei in https://github.com/pydantic/pydantic/pull/11436
* Improve alias configuration APIs by @sydney-runkle in https://github.com/pydantic/pydantic/pull/11468

#### Changes

* Rework `create_model` field definitions format by @Viicos in https://github.com/pydantic/pydantic/pull/11032
* Raise a deprecation warning when a field is annotated as final with a default value by @Viicos in https://github.com/pydantic/pydantic/pull/11168
* Deprecate accessing `model_fields` and `model_computed_fields` on instances by @Viicos in https://github.com/pydantic/pydantic/pull/11169
* **Breaking Change:** Move core schema generation logic for path types inside the `GenerateSchema` class by @sydney-runkle in https://github.com/pydantic/pydantic/pull/10846
* Remove Python 3.8 Support by @sydney-runkle in https://github.com/pydantic/pydantic/pull/11258
* Optimize calls to `get_type_ref` by @Viicos in https://github.com/pydantic/pydantic/pull/10863
* Disable `pydantic-core` core schema validation by @sydney-runkle in https://github.com/pydantic/pydantic/pull/11271

#### Performance

* Only evaluate `FieldInfo` annotations if required during schema building by @Viicos in https://github.com/pydantic/pydantic/pull/10769
* Improve `__setattr__` performance of Pydantic models by caching setter functions by @MarkusSintonen in https://github.com/pydantic/pydantic/pull/10868
* Improve annotation application performance by @Viicos in https://github.com/pydantic/pydantic/pull/11186
* Improve performance of `_typing_extra` module by @Viicos in https://github.com/pydantic/pydantic/pull/11255
* Refactor and optimize schema cleaning logic by @Viicos in https://github.com/pydantic/pydantic/pull/11244
* Create a single dictionary when creating a `CoreConfig` instance by @sydney-runkle in https://github.com/pydantic/pydantic/pull/11384
* Bump `pydantic-core` and thus use `SchemaValidator` and `SchemaSerializer` caching by @sydney-runkle in https://github.com/pydantic/pydantic/pull/11402
* Reuse cached core schemas for parametrized generic Pydantic models by @MarkusSintonen in https://github.com/pydantic/pydantic/pull/11434

#### Fixes

* Improve `TypeAdapter` instance repr by @sydney-runkle in https://github.com/pydantic/pydantic/pull/10872
* Use the correct frame when instantiating a parametrized `TypeAdapter` by @Viicos in https://github.com/pydantic/pydantic/pull/10893
* Infer final fields with a default value as class variables in the mypy plugin by @Viicos in https://github.com/pydantic/pydantic/pull/11121
* Recursively unpack `Literal` values if using PEP 695 type aliases by @Viicos in https://github.com/pydantic/pydantic/pull/11114
* Override `__subclasscheck__` on `ModelMetaclass` to avoid memory leak and performance issues by @Viicos in https://github.com/pydantic/pydantic/pull/11116
* Remove unused `_extract_get_pydantic_json_schema()` parameter by @Viicos in https://github.com/pydantic/pydantic/pull/11155
* Improve discriminated union error message for invalid union variants by @Viicos in https://github.com/pydantic/pydantic/pull/11161
* Unpack PEP 695 type aliases if using the `Annotated` form by @Viicos in https://github.com/pydantic/pydantic/pull/11109
* Add missing stacklevel in `deprecated_instance_property` warning by @Viicos in https://github.com/pydantic/pydantic/pull/11200
* Copy `WithJsonSchema` schema to avoid sharing mutated data by @thejcannon in https://github.com/pydantic/pydantic/pull/11014
* Do not cache parametrized models when in the process of parametrizing another model by @Viicos in https://github.com/pydantic/pydantic/pull/10704
* Add discriminated union related metadata entries to the `CoreMetadata` definition by @Viicos in https://github.com/pydantic/pydantic/pull/11216
* Consolidate schema definitions logic in the `_Definitions` class by @Viicos in https://github.com/pydantic/pydantic/pull/11208
* Support initializing root model fields with values of the `root` type in the mypy plugin by @Viicos in https://github.com/pydantic/pydantic/pull/11212
* Fix various issues with dataclasses and `use_attribute_docstrings` by @Viicos in https://github.com/pydantic/pydantic/pull/11246
* Only compute normalized decimal places if necessary in `decimal_places_validator` by @misrasaurabh1 in https://github.com/pydantic/pydantic/pull/11281
* Add support for `validation_alias` in the mypy plugin by @Viicos in https://github.com/pydantic/pydantic/pull/11295
* Fix JSON Schema reference collection with `"examples"` keys by @Viicos in https://github.com/pydantic/pydantic/pull/11305
* Do not transform model serializer functions as class methods in the mypy plugin by @Viicos in https://github.com/pydantic/pydantic/pull/11298
* Simplify `GenerateJsonSchema.literal_schema()` implementation by @misrasaurabh1 in https://github.com/pydantic/pydantic/pull/11321
* Add additional allowed schemes for `ClickHouseDsn` by @Maze21127 in https://github.com/pydantic/pydantic/pull/11319
* Coerce decimal constraints to `Decimal` instances by @Viicos in https://github.com/pydantic/pydantic/pull/11350
* Use the correct JSON Schema mode when handling function schemas by @Viicos in https://github.com/pydantic/pydantic/pull/11367
* Improve exception message when encountering recursion errors during type evaluation by @Viicos in https://github.com/pydantic/pydantic/pull/11356
* Always include `additionalProperties: True` for arbitrary dictionary schemas by @austinyu in https://github.com/pydantic/pydantic/pull/11392
* Expose `fallback` parameter in serialization methods by @Viicos in https://github.com/pydantic/pydantic/pull/11398
* Fix path serialization behavior by @sydney-runkle in https://github.com/pydantic/pydantic/pull/11416
* Do not reuse validators and serializers during model rebuild by @Viicos in https://github.com/pydantic/pydantic/pull/11429
* Collect model fields when rebuilding a model by @Viicos in https://github.com/pydantic/pydantic/pull/11388
* Allow cached properties to be altered on frozen models by @Viicos in https://github.com/pydantic/pydantic/pull/11432
* Fix tuple serialization for `Sequence` types by @sydney-runkle in https://github.com/pydantic/pydantic/pull/11435
* Fix: do not check for `__get_validators__` on classes where `__get_pydantic_core_schema__` is also defined by @tlambert03 in https://github.com/pydantic/pydantic/pull/11444
* Allow callable instances to be used as serializers by @Viicos in https://github.com/pydantic/pydantic/pull/11451
* Improve error thrown when overriding field with a property by @sydney-runkle in https://github.com/pydantic/pydantic/pull/11459
* Fix JSON Schema generation with referenceable core schemas holding JSON metadata by @Viicos in https://github.com/pydantic/pydantic/pull/11475
* Support strict specification on union member types by @sydney-runkle in https://github.com/pydantic/pydantic/pull/11481
* Implicitly set `validate_by_name` to `True` when `validate_by_alias` is `False` by @sydney-runkle in https://github.com/pydantic/pydantic/pull/11503
* Change type of `Any` when synthesizing `BaseSettings.__init__` signature in the mypy plugin by @Viicos in https://github.com/pydantic/pydantic/pull/11497
* Support type variable defaults referencing other type variables by @Viicos in https://github.com/pydantic/pydantic/pull/11520
* Fix `ValueError` on year zero by @davidhewitt in https://github.com/pydantic/pydantic-core/pull/1583
* `dataclass` `InitVar` shouldn't be required on serialization by @sydney-runkle in https://github.com/pydantic/pydantic-core/pull/1602

## New Contributors

* @FyZzyss made their first contribution in https://github.com/pydantic/pydantic/pull/10789
* @tamird made their first contribution in https://github.com/pydantic/pydantic/pull/10948
* @felixxm made their first contribution in https://github.com/pydantic/pydantic/pull/11077
* @alexprabhat99 made their first contribution in https://github.com/pydantic/pydantic/pull/11082
* @Kharianne made their first contribution in https://github.com/pydantic/pydantic/pull/11111
* @mdaffad made their first contribution in https://github.com/pydantic/pydantic/pull/11177
* @thejcannon made their first contribution in https://github.com/pydantic/pydantic/pull/11014
* @thomasfrimannkoren made their first contribution in https://github.com/pydantic/pydantic/pull/11251
* @usernameMAI made their first contribution in https://github.com/pydantic/pydantic/pull/11275
* @ananiavito made their first contribution in https://github.com/pydantic/pydantic/pull/11302
* @pawamoy made their first contribution in https://github.com/pydantic/pydantic/pull/11311
* @Maze21127 made their first contribution in https://github.com/pydantic/pydantic/pull/11319
* @kauabh made their first contribution in https://github.com/pydantic/pydantic/pull/11369
* @jaceklaskowski made their first contribution in https://github.com/pydantic/pydantic/pull/11353
* @tmpbeing made their first contribution in https://github.com/pydantic/pydantic/pull/11375
* @petyosi made their first contribution in https://github.com/pydantic/pydantic/pull/11405
* @austinyu made their first contribution in https://github.com/pydantic/pydantic/pull/11392
* @mikeedjones made their first contribution in https://github.com/pydantic/pydantic/pull/11402
* @astei made their first contribution in https://github.com/pydantic/pydantic/pull/11436
* @dsayling made their first contribution in https://github.com/pydantic/pydantic/pull/11522
* @sobolevn made their first contribution in https://github.com/pydantic/pydantic-core/pull/1645

## v2.11.0a2 (2025-02-10)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0a2)

### What's Changed

Pydantic v2.11 is a version strongly focused on build time performance of Pydantic models (and core schema generation in general).
This is another early alpha release, meant to collect early feedback from users having issues with core schema builds.

#### Packaging

* Bump `ruff` from 0.9.2 to 0.9.5 by @Viicos in [#11407](https://github.com/pydantic/pydantic/pull/11407)
* Bump `pydantic-core` to v2.29.0 by @mikeedjones in [#11402](https://github.com/pydantic/pydantic/pull/11402)
* Use locally-built rust with symbols & pgo by @davidhewitt in [#11403](https://github.com/pydantic/pydantic/pull/11403)

#### Performance

* Create a single dictionary when creating a `CoreConfig` instance by @sydney-runkle in [#11384](https://github.com/pydantic/pydantic/pull/11384)

#### Fixes

* Use the correct JSON Schema mode when handling function schemas by @Viicos in [#11367](https://github.com/pydantic/pydantic/pull/11367)
* Fix JSON Schema reference logic with `examples` keys by @Viicos in [#11366](https://github.com/pydantic/pydantic/pull/11366)
* Improve exception message when encountering recursion errors during type evaluation by @Viicos in [#11356](https://github.com/pydantic/pydantic/pull/11356)
* Always include `additionalProperties: True` for arbitrary dictionary schemas by @austinyu in [#11392](https://github.com/pydantic/pydantic/pull/11392)
* Expose `fallback` parameter in serialization methods by @Viicos in [#11398](https://github.com/pydantic/pydantic/pull/11398)
* Fix path serialization behavior by @sydney-runkle in [#11416](https://github.com/pydantic/pydantic/pull/11416)

### New Contributors

* @kauabh made their first contribution in [#11369](https://github.com/pydantic/pydantic/pull/11369)
* @jaceklaskowski made their first contribution in [#11353](https://github.com/pydantic/pydantic/pull/11353)
* @tmpbeing made their first contribution in [#11375](https://github.com/pydantic/pydantic/pull/11375)
* @petyosi made their first contribution in [#11405](https://github.com/pydantic/pydantic/pull/11405)
* @austinyu made their first contribution in [#11392](https://github.com/pydantic/pydantic/pull/11392)
* @mikeedjones made their first contribution in [#11402](https://github.com/pydantic/pydantic/pull/11402)

## v2.11.0a1 (2025-01-30)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.11.0a1)

### What's Changed

Pydantic v2.11 is a version strongly focused on build time performance of Pydantic models (and core schema generation in general).
This is an early alpha release, meant to collect early feedback from users having issues with core schema builds.

#### Packaging

* Bump dawidd6/action-download-artifact from 6 to 7 by @dependabot in [#11018](https://github.com/pydantic/pydantic/pull/11018)
* Re-enable memray related tests on Python 3.12+ by @Viicos in [#11191](https://github.com/pydantic/pydantic/pull/11191)
* Bump astral-sh/setup-uv to 5 by @dependabot in [#11205](https://github.com/pydantic/pydantic/pull/11205)
* Bump `ruff` to v0.9.0 by @sydney-runkle in [#11254](https://github.com/pydantic/pydantic/pull/11254)
* Regular `uv.lock` deps update by @sydney-runkle in [#11333](https://github.com/pydantic/pydantic/pull/11333)
* Add a `check_pydantic_core_version()` function by @Viicos in [#11324](https://github.com/pydantic/pydantic/pull/11324)
* Remove `greenlet` development dependency by @Viicos in [#11351](https://github.com/pydantic/pydantic/pull/11351)
* Bump `pydantic-core` to v2.28.0 by @Viicos in [#11364](https://github.com/pydantic/pydantic/pull/11364)

#### New Features

* Support unsubstituted type variables with both a default and a bound or constraints by @FyZzyss in [#10789](https://github.com/pydantic/pydantic/pull/10789)
* Add a `default_factory_takes_validated_data` property to `FieldInfo` by @Viicos in [#11034](https://github.com/pydantic/pydantic/pull/11034)
* Raise a better error when a generic alias is used inside `type[]` by @Viicos in [#11088](https://github.com/pydantic/pydantic/pull/11088)
* Properly support PEP 695 generics syntax by @Viicos in [#11189](https://github.com/pydantic/pydantic/pull/11189)
* Properly support type variable defaults by @Viicos in [#11332](https://github.com/pydantic/pydantic/pull/11332)

#### Changes

* Rework `create_model` field definitions format by @Viicos in [#11032](https://github.com/pydantic/pydantic/pull/11032)
* Raise a deprecation warning when a field is annotated as final with a default value by @Viicos in [#11168](https://github.com/pydantic/pydantic/pull/11168)
* Deprecate accessing `model_fields` and `model_computed_fields` on instances by @Viicos in [#11169](https://github.com/pydantic/pydantic/pull/11169)
* Move core schema generation logic for path types inside the `GenerateSchema` class by @sydney-runkle in [#10846](https://github.com/pydantic/pydantic/pull/10846)
* Move `deque` schema gen to `GenerateSchema` class by @sydney-runkle in [#11239](https://github.com/pydantic/pydantic/pull/11239)
* Move `Mapping` schema gen to `GenerateSchema` to complete removal of `prepare_annotations_for_known_type` workaround by @sydney-runkle in [#11247](https://github.com/pydantic/pydantic/pull/11247)
* Remove Python 3.8 Support by @sydney-runkle in [#11258](https://github.com/pydantic/pydantic/pull/11258)
* Disable `pydantic-core` core schema validation by @sydney-runkle in [#11271](https://github.com/pydantic/pydantic/pull/11271)

#### Performance

* Only evaluate `FieldInfo` annotations if required during schema building by @Viicos in [#10769](https://github.com/pydantic/pydantic/pull/10769)
* Optimize calls to `get_type_ref` by @Viicos in [#10863](https://github.com/pydantic/pydantic/pull/10863)
* Improve `__setattr__` performance of Pydantic models by caching setter functions by @MarkusSintonen in [#10868](https://github.com/pydantic/pydantic/pull/10868)
* Improve annotation application performance by @Viicos in [#11186](https://github.com/pydantic/pydantic/pull/11186)
* Improve performance of `_typing_extra` module by @Viicos in [#11255](https://github.com/pydantic/pydantic/pull/11255)
* Refactor and optimize schema cleaning logic by @Viicos and @MarkusSintonen in [#11244](https://github.com/pydantic/pydantic/pull/11244)

#### Fixes

* Add validation tests for `_internal/_validators.py` by @tkasuz in [#10763](https://github.com/pydantic/pydantic/pull/10763)
* Improve `TypeAdapter` instance repr by @sydney-runkle in [#10872](https://github.com/pydantic/pydantic/pull/10872)
* Revert "ci: use locally built pydantic-core with debug symbols by @sydney-runkle in [#10942](https://github.com/pydantic/pydantic/pull/10942)
* Re-enable all FastAPI tests by @tamird in [#10948](https://github.com/pydantic/pydantic/pull/10948)
* Fix typo in HISTORY.md. by @felixxm in [#11077](https://github.com/pydantic/pydantic/pull/11077)
* Infer final fields with a default value as class variables in the mypy plugin by @Viicos in [#11121](https://github.com/pydantic/pydantic/pull/11121)
* Recursively unpack `Literal` values if using PEP 695 type aliases by @Viicos in [#11114](https://github.com/pydantic/pydantic/pull/11114)
* Override `__subclasscheck__` on `ModelMetaclass` to avoid memory leak and performance issues by @Viicos in [#11116](https://github.com/pydantic/pydantic/pull/11116)
* Remove unused `_extract_get_pydantic_json_schema()` parameter by @Viicos in [#11155](https://github.com/pydantic/pydantic/pull/11155)
* Add FastAPI and SQLModel to third-party tests by @sydney-runkle in [#11044](https://github.com/pydantic/pydantic/pull/11044)
* Fix conditional expressions syntax for third-party tests by @Viicos in [#11162](https://github.com/pydantic/pydantic/pull/11162)
* Move FastAPI tests to third-party workflow by @Viicos in [#11164](https://github.com/pydantic/pydantic/pull/11164)
* Improve discriminated union error message for invalid union variants by @Viicos in [#11161](https://github.com/pydantic/pydantic/pull/11161)
* Unpack PEP 695 type aliases if using the `Annotated` form by @Viicos in [#11109](https://github.com/pydantic/pydantic/pull/11109)
* Include `openapi-python-client` check in issue creation for third-party failures, use `main` branch by @sydney-runkle in [#11182](https://github.com/pydantic/pydantic/pull/11182)
* Add pandera third-party tests by @Viicos in [#11193](https://github.com/pydantic/pydantic/pull/11193)
* Add ODMantic third-party tests by @sydney-runkle in [#11197](https://github.com/pydantic/pydantic/pull/11197)
* Add missing stacklevel in `deprecated_instance_property` warning by @Viicos in [#11200](https://github.com/pydantic/pydantic/pull/11200)
* Copy `WithJsonSchema` schema to avoid sharing mutated data by @thejcannon in [#11014](https://github.com/pydantic/pydantic/pull/11014)
* Do not cache parametrized models when in the process of parametrizing another model by @Viicos in [#10704](https://github.com/pydantic/pydantic/pull/10704)
* Re-enable Beanie third-party tests by @Viicos in [#11214](https://github.com/pydantic/pydantic/pull/11214)
* Add discriminated union related metadata entries to the `CoreMetadata` definition by @Viicos in [#11216](https://github.com/pydantic/pydantic/pull/11216)
* Consolidate schema definitions logic in the `_Definitions` class by @Viicos in [#11208](https://github.com/pydantic/pydantic/pull/11208)
* Support initializing root model fields with values of the `root` type in the mypy plugin by @Viicos in [#11212](https://github.com/pydantic/pydantic/pull/11212)
* Fix various issues with dataclasses and `use_attribute_docstrings` by @Viicos in [#11246](https://github.com/pydantic/pydantic/pull/11246)
* Only compute normalized decimal places if necessary in `decimal_places_validator` by @misrasaurabh1 in [#11281](https://github.com/pydantic/pydantic/pull/11281)
* Fix two misplaced sentences in validation errors documentation by @ananiavito in [#11302](https://github.com/pydantic/pydantic/pull/11302)
* Fix mkdocstrings inventory example in documentation by @pawamoy in [#11311](https://github.com/pydantic/pydantic/pull/11311)
* Add support for `validation_alias` in the mypy plugin by @Viicos in [#11295](https://github.com/pydantic/pydantic/pull/11295)
* Do not transform model serializer functions as class methods in the mypy plugin by @Viicos in [#11298](https://github.com/pydantic/pydantic/pull/11298)
* Simplify `GenerateJsonSchema.literal_schema()` implementation by @misrasaurabh1 in [#11321](https://github.com/pydantic/pydantic/pull/11321)
* Add additional allowed schemes for `ClickHouseDsn` by @Maze21127 in [#11319](https://github.com/pydantic/pydantic/pull/11319)
* Coerce decimal constraints to `Decimal` instances by @Viicos in [#11350](https://github.com/pydantic/pydantic/pull/11350)
* Fix `ValueError` on year zero by @davidhewitt in [pydantic-core#1583](https://github.com/pydantic/pydantic-core/pull/1583)

### New Contributors

* @FyZzyss made their first contribution in [#10789](https://github.com/pydantic/pydantic/pull/10789)
* @tamird made their first contribution in [#10948](https://github.com/pydantic/pydantic/pull/10948)
* @felixxm made their first contribution in [#11077](https://github.com/pydantic/pydantic/pull/11077)
* @alexprabhat99 made their first contribution in [#11082](https://github.com/pydantic/pydantic/pull/11082)
* @Kharianne made their first contribution in [#11111](https://github.com/pydantic/pydantic/pull/11111)
* @mdaffad made their first contribution in [#11177](https://github.com/pydantic/pydantic/pull/11177)
* @thejcannon made their first contribution in [#11014](https://github.com/pydantic/pydantic/pull/11014)
* @thomasfrimannkoren made their first contribution in [#11251](https://github.com/pydantic/pydantic/pull/11251)
* @usernameMAI made their first contribution in [#11275](https://github.com/pydantic/pydantic/pull/11275)
* @ananiavito made their first contribution in [#11302](https://github.com/pydantic/pydantic/pull/11302)
* @pawamoy made their first contribution in [#11311](https://github.com/pydantic/pydantic/pull/11311)
* @Maze21127 made their first contribution in [#11319](https://github.com/pydantic/pydantic/pull/11319)

## v2.10.6 (2025-01-23)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.6)

### What's Changed

#### Fixes

* Fix JSON Schema reference collection with `'examples'` keys by @Viicos in [#11325](https://github.com/pydantic/pydantic/pull/11325)
* Fix url python serialization by @sydney-runkle in [#11331](https://github.com/pydantic/pydantic/pull/11331)

## v2.10.5 (2025-01-08)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.5)

### What's Changed

#### Fixes

* Remove custom MRO implementation of Pydantic models by @Viicos in [#11184](https://github.com/pydantic/pydantic/pull/11184)
* Fix URL serialization for unions by @sydney-runkle in [#11233](https://github.com/pydantic/pydantic/pull/11233)

## v2.10.4 (2024-12-18)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.4)

### What's Changed

#### Packaging

* Bump `pydantic-core` to v2.27.2 by @davidhewitt in [#11138](https://github.com/pydantic/pydantic/pull/11138)

#### Fixes

* Fix for comparison of `AnyUrl` objects by @alexprabhat99 in [#11082](https://github.com/pydantic/pydantic/pull/11082)
* Properly fetch PEP 695 type params for functions, do not fetch annotations from signature by @Viicos in [#11093](https://github.com/pydantic/pydantic/pull/11093)
* Include JSON Schema input core schema in function schemas by @Viicos in [#11085](https://github.com/pydantic/pydantic/pull/11085)
* Add `len` to `_BaseUrl` to avoid TypeError by @Kharianne in [#11111](https://github.com/pydantic/pydantic/pull/11111)
* Make sure the type reference is removed from the seen references by @Viicos in [#11143](https://github.com/pydantic/pydantic/pull/11143)

### New Contributors

* @FyZzyss made their first contribution in [#10789](https://github.com/pydantic/pydantic/pull/10789)
* @tamird made their first contribution in [#10948](https://github.com/pydantic/pydantic/pull/10948)
* @felixxm made their first contribution in [#11077](https://github.com/pydantic/pydantic/pull/11077)
* @alexprabhat99 made their first contribution in [#11082](https://github.com/pydantic/pydantic/pull/11082)
* @Kharianne made their first contribution in [#11111](https://github.com/pydantic/pydantic/pull/11111)

## v2.10.3 (2024-12-03)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.3)

### What's Changed

#### Fixes

* Set fields when `defer_build` is set on Pydantic dataclasses by @Viicos in [#10984](https://github.com/pydantic/pydantic/pull/10984)
* Do not resolve the JSON Schema reference for `dict` core schema keys by @Viicos in [#10989](https://github.com/pydantic/pydantic/pull/10989)
* Use the globals of the function when evaluating the return type for `PlainSerializer` and `WrapSerializer` functions by @Viicos in [#11008](https://github.com/pydantic/pydantic/pull/11008)
* Fix host required enforcement for urls to be compatible with v2.9 behavior by @sydney-runkle in [#11027](https://github.com/pydantic/pydantic/pull/11027)
* Add a `default_factory_takes_validated_data` property to `FieldInfo` by @Viicos in [#11034](https://github.com/pydantic/pydantic/pull/11034)
* Fix url json schema in `serialization` mode by @sydney-runkle in [#11035](https://github.com/pydantic/pydantic/pull/11035)

## v2.10.2 (2024-11-25)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.2)

### What's Changed

#### Fixes

* Only evaluate FieldInfo annotations if required during schema building by @Viicos in [#10769](https://github.com/pydantic/pydantic/pull/10769)
* Do not evaluate annotations for private fields by @Viicos in [#10962](https://github.com/pydantic/pydantic/pull/10962)
* Support serialization as any for `Secret` types and `Url` types by @sydney-runkle in [#10947](https://github.com/pydantic/pydantic/pull/10947)
* Fix type hint of `Field.default` to be compatible with Python 3.8 and 3.9 by @Viicos in [#10972](https://github.com/pydantic/pydantic/pull/10972)
* Add hashing support for URL types by @sydney-runkle in [#10975](https://github.com/pydantic/pydantic/pull/10975)
* Hide `BaseModel.__replace__` definition from type checkers by @Viicos in [#10979](https://github.com/pydantic/pydantic/pull/10979)

## v2.10.1 (2024-11-21)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.1)

### What's Changed

#### Packaging

* Bump `pydantic-core` version to `v2.27.1` by @sydney-runkle in [#10938](https://github.com/pydantic/pydantic/pull/10938)

#### Fixes

* Use the correct frame when instantiating a parametrized `TypeAdapter` by @Viicos in [#10893](https://github.com/pydantic/pydantic/pull/10893)
* Relax check for validated data in `default_factory` utils by @sydney-runkle in [#10909](https://github.com/pydantic/pydantic/pull/10909)
* Fix type checking issue with `model_fields` and `model_computed_fields` by @sydney-runkle in [#10911](https://github.com/pydantic/pydantic/pull/10911)
* Use the parent configuration during schema generation for stdlib `dataclass`es by @sydney-runkle in [#10928](https://github.com/pydantic/pydantic/pull/10928)
* Use the `globals` of the function when evaluating the return type of serializers and `computed_field`s by @Viicos in [#10929](https://github.com/pydantic/pydantic/pull/10929)
* Fix URL constraint application by @sydney-runkle in [#10922](https://github.com/pydantic/pydantic/pull/10922)
* Fix URL equality with different validation methods by @sydney-runkle in [#10934](https://github.com/pydantic/pydantic/pull/10934)
* Fix JSON schema title when specified as `''` by @sydney-runkle in [#10936](https://github.com/pydantic/pydantic/pull/10936)
* Fix `python` mode serialization for `complex` inference by @sydney-runkle in [pydantic-core#1549](https://github.com/pydantic/pydantic-core/pull/1549)

### New Contributors

## v2.10.0 (2024-11-20)

The code released in v2.10.0 is practically identical to that of v2.10.0b2.

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.0)

See the [v2.10 release blog post](https://pydantic.dev/articles/pydantic-v2-10-release) for the highlights!

### What's Changed

#### Packaging

* Bump `pydantic-core` to `v2.27.0` by @sydney-runkle in [#10825](https://github.com/pydantic/pydantic/pull/10825)
* Replaced pdm with uv by @frfahim in [#10727](https://github.com/pydantic/pydantic/pull/10727)

#### New Features

* Support `fractions.Fraction` by @sydney-runkle in [#10318](https://github.com/pydantic/pydantic/pull/10318)
* Support `Hashable` for json validation by @sydney-runkle in [#10324](https://github.com/pydantic/pydantic/pull/10324)
* Add a `SocketPath` type for `linux` systems by @theunkn0wn1 in [#10378](https://github.com/pydantic/pydantic/pull/10378)
* Allow arbitrary refs in JSON schema `examples` by @sydney-runkle in [#10417](https://github.com/pydantic/pydantic/pull/10417)
* Support `defer_build` for Pydantic dataclasses by @Viicos in [#10313](https://github.com/pydantic/pydantic/pull/10313)
* Adding v1 / v2 incompatibility warning for nested v1 model by @sydney-runkle in [#10431](https://github.com/pydantic/pydantic/pull/10431)
* Add support for unpacked `TypedDict` to type hint variadic keyword arguments with `@validate_call` by @Viicos in [#10416](https://github.com/pydantic/pydantic/pull/10416)
* Support compiled patterns in `protected_namespaces` by @sydney-runkle in [#10522](https://github.com/pydantic/pydantic/pull/10522)
* Add support for `propertyNames` in JSON schema by @FlorianSW in [#10478](https://github.com/pydantic/pydantic/pull/10478)
* Adding `__replace__` protocol for Python 3.13+ support by @sydney-runkle in [#10596](https://github.com/pydantic/pydantic/pull/10596)
* Expose public `sort` method for JSON schema generation by @sydney-runkle in [#10595](https://github.com/pydantic/pydantic/pull/10595)
* Add runtime validation of `@validate_call` callable argument by @kc0506 in [#10627](https://github.com/pydantic/pydantic/pull/10627)
* Add `experimental_allow_partial` support by @samuelcolvin in [#10748](https://github.com/pydantic/pydantic/pull/10748)
* Support default factories taking validated data as an argument by @Viicos in [#10678](https://github.com/pydantic/pydantic/pull/10678)
* Allow subclassing `ValidationError` and `PydanticCustomError` by @Youssefares in [pydantic/pydantic-core#1413](https://github.com/pydantic/pydantic-core/pull/1413)
* Add `trailing-strings` support to `experimental_allow_partial` by @sydney-runkle in [#10825](https://github.com/pydantic/pydantic/pull/10825)
* Add `rebuild()` method for `TypeAdapter` and simplify `defer_build` patterns by @sydney-runkle in [#10537](https://github.com/pydantic/pydantic/pull/10537)
* Improve `TypeAdapter` instance repr by @sydney-runkle in [#10872](https://github.com/pydantic/pydantic/pull/10872)

#### Changes

* Don't allow customization of `SchemaGenerator` until interface is more stable by @sydney-runkle in [#10303](https://github.com/pydantic/pydantic/pull/10303)
* Cleanly `defer_build` on `TypeAdapters`, removing experimental flag by @sydney-runkle in [#10329](https://github.com/pydantic/pydantic/pull/10329)
* Fix `mro` of generic subclass  by @kc0506 in [#10100](https://github.com/pydantic/pydantic/pull/10100)
* Strip whitespaces on JSON Schema title generation by @sydney-runkle in [#10404](https://github.com/pydantic/pydantic/pull/10404)
* Use `b64decode` and `b64encode` for `Base64Bytes` type by @sydney-runkle in [#10486](https://github.com/pydantic/pydantic/pull/10486)
* Relax protected namespace config default by @sydney-runkle in [#10441](https://github.com/pydantic/pydantic/pull/10441)
* Revalidate parametrized generics if instance's origin is subclass of OG class by @sydney-runkle in [#10666](https://github.com/pydantic/pydantic/pull/10666)
* Warn if configuration is specified on the `@dataclass` decorator and with the `__pydantic_config__` attribute by @sydney-runkle in [#10406](https://github.com/pydantic/pydantic/pull/10406)
* Recommend against using `Ellipsis` (...) with `Field` by @Viicos in [#10661](https://github.com/pydantic/pydantic/pull/10661)
* Migrate to subclassing instead of annotated approach for pydantic url types by @sydney-runkle in [#10662](https://github.com/pydantic/pydantic/pull/10662)
* Change JSON schema generation of `Literal`s and `Enums` by @Viicos in [#10692](https://github.com/pydantic/pydantic/pull/10692)
* Simplify unions involving `Any` or `Never` when replacing type variables by @Viicos in [#10338](https://github.com/pydantic/pydantic/pull/10338)
* Do not require padding when decoding `base64` bytes by @bschoenmaeckers in [pydantic/pydantic-core#1448](https://github.com/pydantic/pydantic-core/pull/1448)
* Support dates all the way to 1BC by @changhc in [pydantic/speedate#77](https://github.com/pydantic/speedate/pull/77)

#### Performance

* Schema cleaning: skip unnecessary copies during schema walking by @Viicos in [#10286](https://github.com/pydantic/pydantic/pull/10286)
* Refactor namespace logic for annotations evaluation by @Viicos in [#10530](https://github.com/pydantic/pydantic/pull/10530)
* Improve email regexp on edge cases by @AlekseyLobanov in [#10601](https://github.com/pydantic/pydantic/pull/10601)
* `CoreMetadata` refactor with an emphasis on documentation, schema build time performance, and reducing complexity by @sydney-runkle in [#10675](https://github.com/pydantic/pydantic/pull/10675)

#### Fixes

* Remove guarding check on `computed_field` with `field_serializer` by @nix010 in [#10390](https://github.com/pydantic/pydantic/pull/10390)
* Fix `Predicate` issue in `v2.9.0` by @sydney-runkle in [#10321](https://github.com/pydantic/pydantic/pull/10321)
* Fixing `annotated-types` bound by @sydney-runkle in [#10327](https://github.com/pydantic/pydantic/pull/10327)
* Turn `tzdata` install requirement into optional `timezone` dependency by @jakob-keller in [#10331](https://github.com/pydantic/pydantic/pull/10331)
* Use correct types namespace when building `namedtuple` core schemas by @Viicos in [#10337](https://github.com/pydantic/pydantic/pull/10337)
* Fix evaluation of stringified annotations during namespace inspection by @Viicos in [#10347](https://github.com/pydantic/pydantic/pull/10347)
* Fix `IncEx` type alias definition by @Viicos in [#10339](https://github.com/pydantic/pydantic/pull/10339)
* Do not error when trying to evaluate annotations of private attributes by @Viicos in [#10358](https://github.com/pydantic/pydantic/pull/10358)
* Fix nested type statement by @kc0506 in [#10369](https://github.com/pydantic/pydantic/pull/10369)
* Improve typing of `ModelMetaclass.mro` by @Viicos in [#10372](https://github.com/pydantic/pydantic/pull/10372)
* Fix class access of deprecated `computed_field`s by @Viicos in [#10391](https://github.com/pydantic/pydantic/pull/10391)
* Make sure `inspect.iscoroutinefunction` works on coroutines decorated with `@validate_call` by @MovisLi in [#10374](https://github.com/pydantic/pydantic/pull/10374)
* Fix `NameError` when using `validate_call` with PEP 695 on a class by @kc0506 in [#10380](https://github.com/pydantic/pydantic/pull/10380)
* Fix `ZoneInfo` with various invalid types by @sydney-runkle in [#10408](https://github.com/pydantic/pydantic/pull/10408)
* Fix `PydanticUserError` on empty `model_config` with annotations by @cdwilson in [#10412](https://github.com/pydantic/pydantic/pull/10412)
* Fix variance issue in `_IncEx` type alias, only allow `True` by @Viicos in [#10414](https://github.com/pydantic/pydantic/pull/10414)
* Fix serialization schema generation when using `PlainValidator` by @Viicos in [#10427](https://github.com/pydantic/pydantic/pull/10427)
* Fix schema generation error when serialization schema holds references by @Viicos in [#10444](https://github.com/pydantic/pydantic/pull/10444)
* Inline references if possible when generating schema for `json_schema_input_type` by @Viicos in [#10439](https://github.com/pydantic/pydantic/pull/10439)
* Fix recursive arguments in `Representation` by @Viicos in [#10480](https://github.com/pydantic/pydantic/pull/10480)
* Fix representation for builtin function types by @kschwab in [#10479](https://github.com/pydantic/pydantic/pull/10479)
* Add python validators for decimal constraints (`max_digits` and `decimal_places`) by @sydney-runkle in [#10506](https://github.com/pydantic/pydantic/pull/10506)
* Only fetch `__pydantic_core_schema__` from the current class during schema generation by @Viicos in [#10518](https://github.com/pydantic/pydantic/pull/10518)
* Fix `stacklevel` on deprecation warnings for `BaseModel` by @sydney-runkle in [#10520](https://github.com/pydantic/pydantic/pull/10520)
* Fix warning `stacklevel` in `BaseModel.__init__` by @Viicos in [#10526](https://github.com/pydantic/pydantic/pull/10526)
* Improve error handling for in-evaluable refs for discriminator application by @sydney-runkle in [#10440](https://github.com/pydantic/pydantic/pull/10440)
* Change the signature of `ConfigWrapper.core_config` to take the title directly by @Viicos in [#10562](https://github.com/pydantic/pydantic/pull/10562)
* Do not use the previous config from the stack for dataclasses without config by @Viicos in [#10576](https://github.com/pydantic/pydantic/pull/10576)
* Fix serialization for IP types with `mode='python'` by @sydney-runkle in [#10594](https://github.com/pydantic/pydantic/pull/10594)
* Support constraint application for `Base64Etc` types by @sydney-runkle in [#10584](https://github.com/pydantic/pydantic/pull/10584)
* Fix `validate_call` ignoring `Field` in `Annotated` by @kc0506 in [#10610](https://github.com/pydantic/pydantic/pull/10610)
* Raise an error when `Self` is invalid by @kc0506 in [#10609](https://github.com/pydantic/pydantic/pull/10609)
* Using `core_schema.InvalidSchema` instead of metadata injection + checks by @sydney-runkle in [#10523](https://github.com/pydantic/pydantic/pull/10523)
* Tweak type alias logic by @kc0506 in [#10643](https://github.com/pydantic/pydantic/pull/10643)
* Support usage of `type` with `typing.Self` and type aliases by @kc0506 in [#10621](https://github.com/pydantic/pydantic/pull/10621)
* Use overloads for `Field` and `PrivateAttr` functions by @Viicos in [#10651](https://github.com/pydantic/pydantic/pull/10651)
* Clean up the `mypy` plugin implementation by @Viicos in [#10669](https://github.com/pydantic/pydantic/pull/10669)
* Properly check for `typing_extensions` variant of `TypeAliasType` by @Daraan in [#10713](https://github.com/pydantic/pydantic/pull/10713)
* Allow any mapping in `BaseModel.model_copy()` by @Viicos in [#10751](https://github.com/pydantic/pydantic/pull/10751)
* Fix `isinstance` behavior for urls by @sydney-runkle in [#10766](https://github.com/pydantic/pydantic/pull/10766)
* Ensure `cached_property` can be set on Pydantic models by @Viicos in [#10774](https://github.com/pydantic/pydantic/pull/10774)
* Fix equality checks for primitives in literals by @sydney-runkle in [pydantic/pydantic-core#1459](https://github.com/pydantic/pydantic-core/pull/1459)
* Properly enforce `host_required` for URLs by @Viicos in [pydantic/pydantic-core#1488](https://github.com/pydantic/pydantic-core/pull/1488)
* Fix when `coerce_numbers_to_str` enabled and string has invalid Unicode character by @andrey-berenda in [pydantic/pydantic-core#1515](https://github.com/pydantic/pydantic-core/pull/1515)
* Fix serializing `complex` values in `Enum`s by @changhc in [pydantic/pydantic-core#1524](https://github.com/pydantic/pydantic-core/pull/1524)
* Refactor `_typing_extra` module by @Viicos in [#10725](https://github.com/pydantic/pydantic/pull/10725)
* Support intuitive equality for urls by @sydney-runkle in [#10798](https://github.com/pydantic/pydantic/pull/10798)
* Add `bytearray` to `TypeAdapter.validate_json` signature by @samuelcolvin in [#10802](https://github.com/pydantic/pydantic/pull/10802)
* Ensure class access of method descriptors is performed when used as a default with `Field` by @Viicos in [#10816](https://github.com/pydantic/pydantic/pull/10816)
* Fix circular import with `validate_call` by @sydney-runkle in [#10807](https://github.com/pydantic/pydantic/pull/10807)
* Fix error when using type aliases referencing other type aliases by @Viicos in [#10809](https://github.com/pydantic/pydantic/pull/10809)
* Fix `IncEx` type alias to be compatible with mypy by @Viicos in [#10813](https://github.com/pydantic/pydantic/pull/10813)
* Make `__signature__` a lazy property, do not deepcopy defaults by @Viicos in [#10818](https://github.com/pydantic/pydantic/pull/10818)
* Make `__signature__` lazy for dataclasses, too by @sydney-runkle in [#10832](https://github.com/pydantic/pydantic/pull/10832)
* Subclass all single host url classes from `AnyUrl` to preserve behavior from v2.9 by @sydney-runkle in [#10856](https://github.com/pydantic/pydantic/pull/10856)

### New Contributors

* @jakob-keller made their first contribution in [#10331](https://github.com/pydantic/pydantic/pull/10331)
* @MovisLi made their first contribution in [#10374](https://github.com/pydantic/pydantic/pull/10374)
* @joaopalmeiro made their first contribution in [#10405](https://github.com/pydantic/pydantic/pull/10405)
* @theunkn0wn1 made their first contribution in [#10378](https://github.com/pydantic/pydantic/pull/10378)
* @cdwilson made their first contribution in [#10412](https://github.com/pydantic/pydantic/pull/10412)
* @dlax made their first contribution in [#10421](https://github.com/pydantic/pydantic/pull/10421)
* @kschwab made their first contribution in [#10479](https://github.com/pydantic/pydantic/pull/10479)
* @santibreo made their first contribution in [#10453](https://github.com/pydantic/pydantic/pull/10453)
* @FlorianSW made their first contribution in [#10478](https://github.com/pydantic/pydantic/pull/10478)
* @tkasuz made their first contribution in [#10555](https://github.com/pydantic/pydantic/pull/10555)
* @AlekseyLobanov made their first contribution in [#10601](https://github.com/pydantic/pydantic/pull/10601)
* @NiclasvanEyk made their first contribution in [#10667](https://github.com/pydantic/pydantic/pull/10667)
* @mschoettle made their first contribution in [#10677](https://github.com/pydantic/pydantic/pull/10677)
* @Daraan made their first contribution in [#10713](https://github.com/pydantic/pydantic/pull/10713)
* @k4nar made their first contribution in [#10736](https://github.com/pydantic/pydantic/pull/10736)
* @UriyaHarpeness made their first contribution in [#10740](https://github.com/pydantic/pydantic/pull/10740)
* @frfahim made their first contribution in [#10727](https://github.com/pydantic/pydantic/pull/10727)

## v2.10.0b2 (2024-11-13)

Pre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.0b2) for details.

## v2.10.0b1 (2024-11-06)

Pre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.10.0b1) for details.

<!-- package description limit -->

## v2.9.2 (2024-09-17)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.9.2)

### What's Changed

#### Fixes

* Do not error when trying to evaluate annotations of private attributes by @Viicos in [#10358](https://github.com/pydantic/pydantic/pull/10358)
* Adding notes on designing sound `Callable` discriminators by @sydney-runkle in [#10400](https://github.com/pydantic/pydantic/pull/10400)
* Fix serialization schema generation when using `PlainValidator` by @Viicos in [#10427](https://github.com/pydantic/pydantic/pull/10427)
* Fix `Union` serialization warnings by @sydney-runkle in [pydantic/pydantic-core#1449](https://github.com/pydantic/pydantic-core/pull/1449)
* Fix variance issue in `_IncEx` type alias, only allow `True` by @Viicos in [#10414](https://github.com/pydantic/pydantic/pull/10414)
* Fix `ZoneInfo` validation with various invalid types by @sydney-runkle in [#10408](https://github.com/pydantic/pydantic/pull/10408)

## v2.9.1 (2024-09-09)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.9.1)

### What's Changed

#### Fixes

* Fix Predicate issue in v2.9.0 by @sydney-runkle in [#10321](https://github.com/pydantic/pydantic/pull/10321)
* Fixing `annotated-types` bound to `>=0.6.0` by @sydney-runkle in [#10327](https://github.com/pydantic/pydantic/pull/10327)
* Turn `tzdata` install requirement into optional `timezone` dependency by @jakob-keller in [#10331](https://github.com/pydantic/pydantic/pull/10331)
* Fix `IncExc` type alias definition by @Viicos in [#10339](https://github.com/pydantic/pydantic/pull/10339)
* Use correct types namespace when building namedtuple core schemas by @Viicos in [#10337](https://github.com/pydantic/pydantic/pull/10337)
* Fix evaluation of stringified annotations during namespace inspection by @Viicos in [#10347](https://github.com/pydantic/pydantic/pull/10347)
* Fix tagged union serialization with alias generators by @sydney-runkle in [pydantic/pydantic-core#1442](https://github.com/pydantic/pydantic-core/pull/1442)

## v2.9.0 (2024-09-05)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.9.0)

The code released in v2.9.0 is practically identical to that of v2.9.0b2.

### What's Changed

#### Packaging

* Bump `ruff` to `v0.5.0` and `pyright` to `v1.1.369` by @sydney-runkle in [#9801](https://github.com/pydantic/pydantic/pull/9801)
* Bump `pydantic-extra-types` to `v2.9.0` by @sydney-runkle in [#9832](https://github.com/pydantic/pydantic/pull/9832)
* Support compatibility with `pdm v2.18.1` by @Viicos in [#10138](https://github.com/pydantic/pydantic/pull/10138)
* Bump `v1` version stub to `v1.10.18` by @sydney-runkle in [#10214](https://github.com/pydantic/pydantic/pull/10214)
* Bump `pydantic-core` to `v2.23.2` by @sydney-runkle in [#10311](https://github.com/pydantic/pydantic/pull/10311)

#### New Features

* Add support for `ZoneInfo` by @Youssefares in [#9896](https://github.com/pydantic/pydantic/pull/9896)
* Add `Config.val_json_bytes` by @josh-newman in [#9770](https://github.com/pydantic/pydantic/pull/9770)
* Add DSN for Snowflake by @aditkumar72 in [#10128](https://github.com/pydantic/pydantic/pull/10128)
* Support `complex` number by @changhc in [#9654](https://github.com/pydantic/pydantic/pull/9654)
* Add support for `annotated_types.Not` by @aditkumar72 in [#10210](https://github.com/pydantic/pydantic/pull/10210)
* Allow `WithJsonSchema` to inject `$ref`s w/ `http` or `https` links by @dAIsySHEng1 in [#9863](https://github.com/pydantic/pydantic/pull/9863)
* Allow validators to customize validation JSON schema by @Viicos in [#10094](https://github.com/pydantic/pydantic/pull/10094)
* Support parametrized `PathLike` types by @nix010 in [#9764](https://github.com/pydantic/pydantic/pull/9764)
* Add tagged union serializer that attempts to use `str` or `callable` discriminators to select the correct serializer by @sydney-runkle in in [pydantic/pydantic-core#1397](https://github.com/pydantic/pydantic-core/pull/1397)

#### Changes

* Breaking Change: Merge `dict` type `json_schema_extra` by @sydney-runkle in [#9792](https://github.com/pydantic/pydantic/pull/9792)
    * For more info (how to replicate old behavior) on this change, see [here](https://docs.pydantic.dev/dev/concepts/json_schema/#merging-json_schema_extra)
* Refactor annotation injection for known (often generic) types by @sydney-runkle in [#9979](https://github.com/pydantic/pydantic/pull/9979)
* Move annotation compatibility errors to validation phase by @sydney-runkle in [#9999](https://github.com/pydantic/pydantic/pull/9999)
* Improve runtime errors for string constraints like `pattern` for incompatible types by @sydney-runkle in [#10158](https://github.com/pydantic/pydantic/pull/10158)
* Remove `'allOf'` JSON schema workarounds by @dpeachey in [#10029](https://github.com/pydantic/pydantic/pull/10029)
* Remove `typed_dict_cls` data from `CoreMetadata` by @sydney-runkle in [#10180](https://github.com/pydantic/pydantic/pull/10180)
* Deprecate passing a dict to the `Examples` class by @Viicos in [#10181](https://github.com/pydantic/pydantic/pull/10181)
* Remove `initial_metadata` from internal metadata construct by @sydney-runkle in [#10194](https://github.com/pydantic/pydantic/pull/10194)
* Use `re.Pattern.search` instead of `re.Pattern.match` for consistency with `rust` behavior by @tinez in [pydantic/pydantic-core#1368](https://github.com/pydantic/pydantic-core/pull/1368)
* Show value of wrongly typed data in `pydantic-core` serialization warning by @BoxyUwU in [pydantic/pydantic-core#1377](https://github.com/pydantic/pydantic-core/pull/1377)
* Breaking Change: in `pydantic-core`, change `metadata` type hint in core schemas from `Any` -> `Dict[str, Any] | None` by @sydney-runkle in [pydantic/pydantic-core#1411](https://github.com/pydantic/pydantic-core/pull/1411)
* Raise helpful warning when `self` isn't returned from model validator by @sydney-runkle in [#10255](https://github.com/pydantic/pydantic/pull/10255)

#### Performance

* Initial start at improving import times for modules, using caching primarily by @sydney-runkle in [#10009](https://github.com/pydantic/pydantic/pull/10009)
* Using cached internal import for `BaseModel` by @sydney-runkle in [#10013](https://github.com/pydantic/pydantic/pull/10013)
* Simplify internal generics logic - remove generator overhead by @sydney-runkle in [#10059](https://github.com/pydantic/pydantic/pull/10059)
* Remove default module globals from types namespace by @sydney-runkle in [#10123](https://github.com/pydantic/pydantic/pull/10123)
* Performance boost: skip caching parent namespaces in most cases by @sydney-runkle in [#10113](https://github.com/pydantic/pydantic/pull/10113)
* Update ns stack with already copied ns by @sydney-runkle in [#10267](https://github.com/pydantic/pydantic/pull/10267)

##### Minor Internal Improvements

* ⚡️ Speed up `multiple_of_validator()` by 31% in `pydantic/_internal/_validators.py` by @misrasaurabh1 in [#9839](https://github.com/pydantic/pydantic/pull/9839)
* ⚡️ Speed up `ModelPrivateAttr.__set_name__()` by 18% in `pydantic/fields.py` by @misrasaurabh1 in [#9841](https://github.com/pydantic/pydantic/pull/9841)
* ⚡️ Speed up `dataclass()` by 7% in `pydantic/dataclasses.py` by @misrasaurabh1 in [#9843](https://github.com/pydantic/pydantic/pull/9843)
* ⚡️ Speed up function `_field_name_for_signature` by 37% in `pydantic/_internal/_signature.py` by @misrasaurabh1 in [#9951](https://github.com/pydantic/pydantic/pull/9951)
* ⚡️ Speed up method `GenerateSchema._unpack_refs_defs` by 26% in `pydantic/_internal/_generate_schema.py` by @misrasaurabh1 in [#9949](https://github.com/pydantic/pydantic/pull/9949)
* ⚡️ Speed up function `apply_each_item_validators` by 100% in `pydantic/_internal/_generate_schema.py` by @misrasaurabh1 in [#9950](https://github.com/pydantic/pydantic/pull/9950)
* ⚡️ Speed up method `ConfigWrapper.core_config` by 28% in `pydantic/_internal/_config.py` by @misrasaurabh1 in [#9953](https://github.com/pydantic/pydantic/pull/9953)

#### Fixes

* Respect `use_enum_values` on `Literal` types by @kwint in [#9787](https://github.com/pydantic/pydantic/pull/9787)
* Prevent type error for exotic `BaseModel/RootModel` inheritance by @dmontagu in [#9913](https://github.com/pydantic/pydantic/pull/9913)
* Fix typing issue with field_validator-decorated methods by @dmontagu in [#9914](https://github.com/pydantic/pydantic/pull/9914)
* Replace `str` type annotation with `Any` in validator factories in documentation on validators by @maximilianfellhuber in [#9885](https://github.com/pydantic/pydantic/pull/9885)
* Fix `ComputedFieldInfo.wrapped_property` pointer when a property setter is assigned by @tlambert03 in [#9892](https://github.com/pydantic/pydantic/pull/9892)
* Fix recursive typing of `main.IncEnx` by @tlambert03 in [#9924](https://github.com/pydantic/pydantic/pull/9924)
* Allow usage of `type[Annotated[...]]` by @Viicos in [#9932](https://github.com/pydantic/pydantic/pull/9932)
* `mypy` plugin: handle frozen fields on a per-field basis by @dmontagu in [#9935](https://github.com/pydantic/pydantic/pull/9935)
* Fix typo in `invalid-annotated-type` error code by @sydney-runkle in [#9948](https://github.com/pydantic/pydantic/pull/9948)
* Simplify schema generation for `uuid`, `url`, and `ip` types by @sydney-runkle in [#9975](https://github.com/pydantic/pydantic/pull/9975)
* Move `date` schemas to `_generate_schema.py` by @sydney-runkle in [#9976](https://github.com/pydantic/pydantic/pull/9976)
* Move `decimal.Decimal` validation to `_generate_schema.py` by @sydney-runkle in [#9977](https://github.com/pydantic/pydantic/pull/9977)
* Simplify IP address schema in `_std_types_schema.py` by @sydney-runkle in [#9959](https://github.com/pydantic/pydantic/pull/9959)
* Fix type annotations for some potentially generic `GenerateSchema.match_type` options by @sydney-runkle in [#9961](https://github.com/pydantic/pydantic/pull/9961)
* Add class name to "has conflict" warnings by @msabramo in [#9964](https://github.com/pydantic/pydantic/pull/9964)
* Fix `dataclass` ignoring `default_factory` passed in Annotated by @kc0506 in [#9971](https://github.com/pydantic/pydantic/pull/9971)
* Fix `Sequence` ignoring `discriminator` by @kc0506 in [#9980](https://github.com/pydantic/pydantic/pull/9980)
* Fix typing for `IPvAnyAddress` and `IPvAnyInterface` by @haoyun in [#9990](https://github.com/pydantic/pydantic/pull/9990)
* Fix false positives on v1 models in `mypy` plugin for `from_orm` check requiring from_attributes=True config by @radekwlsk in [#9938](https://github.com/pydantic/pydantic/pull/9938)
* Apply `strict=True` to `__init__` in `mypy` plugin by @kc0506 in [#9998](https://github.com/pydantic/pydantic/pull/9998)
* Refactor application of `deque` annotations by @sydney-runkle in [#10018](https://github.com/pydantic/pydantic/pull/10018)
* Raise a better user error when failing to evaluate a forward reference by @Viicos in [#10030](https://github.com/pydantic/pydantic/pull/10030)
* Fix evaluation of `__pydantic_extra__` annotation in specific circumstances by @Viicos in [#10070](https://github.com/pydantic/pydantic/pull/10070)
* Fix `frozen` enforcement for `dataclasses` by @sydney-runkle in [#10066](https://github.com/pydantic/pydantic/pull/10066)
* Remove logic to handle unused `__get_pydantic_core_schema__` signature by @Viicos in [#10075](https://github.com/pydantic/pydantic/pull/10075)
* Use `is_annotated` consistently by @Viicos in [#10095](https://github.com/pydantic/pydantic/pull/10095)
* Fix `PydanticDeprecatedSince26` typo by @kc0506 in [#10101](https://github.com/pydantic/pydantic/pull/10101)
* Improve `pyright` tests, refactor model decorators signatures by @Viicos in [#10092](https://github.com/pydantic/pydantic/pull/10092)
* Fix `ip` serialization logic by @sydney-runkle in [#10112](https://github.com/pydantic/pydantic/pull/10112)
* Warn when frozen defined twice for `dataclasses` by @mochi22 in [#10082](https://github.com/pydantic/pydantic/pull/10082)
* Do not compute JSON Schema default when plain serializers are used with `when_used` set to `'json-unless-none'` and the default value is `None` by @Viicos in [#10121](https://github.com/pydantic/pydantic/pull/10121)
* Fix `ImportString` special cases by @sydney-runkle in [#10137](https://github.com/pydantic/pydantic/pull/10137)
* Blacklist default globals to support exotic user code with `__` prefixed annotations by @sydney-runkle in [#10136](https://github.com/pydantic/pydantic/pull/10136)
* Handle `nullable` schemas with `serialization` schema available during JSON Schema generation by @Viicos in [#10132](https://github.com/pydantic/pydantic/pull/10132)
* Reorganize `BaseModel` annotations by @kc0506 in [#10110](https://github.com/pydantic/pydantic/pull/10110)
* Fix core schema simplification when serialization schemas are involved in specific scenarios by @Viicos in [#10155](https://github.com/pydantic/pydantic/pull/10155)
* Add support for stringified annotations when using `PrivateAttr` with `Annotated` by @Viicos in [#10157](https://github.com/pydantic/pydantic/pull/10157)
* Fix JSON Schema `number` type for literal and enum schemas by @Viicos in [#10172](https://github.com/pydantic/pydantic/pull/10172)
* Fix JSON Schema generation of fields with plain validators in serialization mode by @Viicos in [#10167](https://github.com/pydantic/pydantic/pull/10167)
* Fix invalid JSON Schemas being generated for functions in certain scenarios by @Viicos in [#10188](https://github.com/pydantic/pydantic/pull/10188)
* Make sure generated JSON Schemas are valid in tests by @Viicos in [#10182](https://github.com/pydantic/pydantic/pull/10182)
* Fix key error with custom serializer by @sydney-runkle in [#10200](https://github.com/pydantic/pydantic/pull/10200)
* Add 'wss' for allowed schemes in NatsDsn by @swelborn in [#10224](https://github.com/pydantic/pydantic/pull/10224)
* Fix `Mapping` and `MutableMapping` annotations to use mapping schema instead of dict schema by @sydney-runkle in [#10020](https://github.com/pydantic/pydantic/pull/10020)
* Fix JSON Schema generation for constrained dates by @Viicos in [#10185](https://github.com/pydantic/pydantic/pull/10185)
* Fix discriminated union bug regression when using enums by @kfreezen in [pydantic/pydantic-core#1286](https://github.com/pydantic/pydantic-core/pull/1286)
* Fix `field_serializer` with computed field when using `*` by @nix010 in [pydantic/pydantic-core#1349](https://github.com/pydantic/pydantic-core/pull/1349)
* Try each option in `Union` serializer before inference by @sydney-runkle in [pydantic/pydantic-core#1398](https://github.com/pydantic/pydantic-core/pull/1398)
* Fix `float` serialization behavior in `strict` mode by @sydney-runkle in [pydantic/pydantic-core#1400](https://github.com/pydantic/pydantic-core/pull/1400)
* Introduce `exactness` into Decimal validation logic to improve union validation behavior by @sydney-runkle in in [pydantic/pydantic-core#1405](https://github.com/pydantic/pydantic-core/pull/1405)
* Fix new warnings assertions to use `pytest.warns()` by @mgorny in [#10241](https://github.com/pydantic/pydantic/pull/10241)
* Fix a crash when cleaning the namespace in `ModelMetaclass` by @Viicos in [#10242](https://github.com/pydantic/pydantic/pull/10242)
* Fix parent namespace issue with model rebuilds by @sydney-runkle in [#10257](https://github.com/pydantic/pydantic/pull/10257)
* Remove defaults filter for namespace by @sydney-runkle in [#10261](https://github.com/pydantic/pydantic/pull/10261)
* Use identity instead of equality after validating model in `__init__` by @Viicos in [#10264](https://github.com/pydantic/pydantic/pull/10264)
* Support `BigInt` serialization for `int` subclasses by @kxx317 in [pydantic/pydantic-core#1417](https://github.com/pydantic/pydantic-core/pull/1417)
* Support signature for wrap validators without `info` by @sydney-runkle in [#10277](https://github.com/pydantic/pydantic/pull/10277)
* Ensure `__pydantic_complete__` is set when rebuilding `dataclasses` by @Viicos in [#10291](https://github.com/pydantic/pydantic/pull/10291)
* Respect `schema_generator` config value in `TypeAdapter` by @sydney-runkle in [#10300](https://github.com/pydantic/pydantic/pull/10300)

### New Contributors

#### `pydantic`

* @kwint made their first contribution in [#9787](https://github.com/pydantic/pydantic/pull/9787)
* @seekinginfiniteloop made their first contribution in [#9822](https://github.com/pydantic/pydantic/pull/9822)
* @a-alexander made their first contribution in [#9848](https://github.com/pydantic/pydantic/pull/9848)
* @maximilianfellhuber made their first contribution in [#9885](https://github.com/pydantic/pydantic/pull/9885)
* @karmaBonfire made their first contribution in [#9945](https://github.com/pydantic/pydantic/pull/9945)
* @s-rigaud made their first contribution in [#9958](https://github.com/pydantic/pydantic/pull/9958)
* @msabramo made their first contribution in [#9964](https://github.com/pydantic/pydantic/pull/9964)
* @DimaCybr made their first contribution in [#9972](https://github.com/pydantic/pydantic/pull/9972)
* @kc0506 made their first contribution in [#9971](https://github.com/pydantic/pydantic/pull/9971)
* @haoyun made their first contribution in [#9990](https://github.com/pydantic/pydantic/pull/9990)
* @radekwlsk made their first contribution in [#9938](https://github.com/pydantic/pydantic/pull/9938)
* @dpeachey made their first contribution in [#10029](https://github.com/pydantic/pydantic/pull/10029)
* @BoxyUwU made their first contribution in [#10085](https://github.com/pydantic/pydantic/pull/10085)
* @mochi22 made their first contribution in [#10082](https://github.com/pydantic/pydantic/pull/10082)
* @aditkumar72 made their first contribution in [#10128](https://github.com/pydantic/pydantic/pull/10128)
* @changhc made their first contribution in [#9654](https://github.com/pydantic/pydantic/pull/9654)
* @insumanth made their first contribution in [#10229](https://github.com/pydantic/pydantic/pull/10229)
* @AdolfoVillalobos made their first contribution in [#10240](https://github.com/pydantic/pydantic/pull/10240)
* @bllchmbrs made their first contribution in [#10270](https://github.com/pydantic/pydantic/pull/10270)

#### `pydantic-core`

* @kfreezen made their first contribution in [pydantic/pydantic-core#1286](https://github.com/pydantic/pydantic-core/pull/1286)
* @tinez made their first contribution in [pydantic/pydantic-core#1368](https://github.com/pydantic/pydantic-core/pull/1368)
* @fft001 made their first contribution in [pydantic/pydantic-core#1362](https://github.com/pydantic/pydantic-core/pull/1362)
* @nix010 made their first contribution in [pydantic/pydantic-core#1349](https://github.com/pydantic/pydantic-core/pull/1349)
* @BoxyUwU made their first contribution in [pydantic/pydantic-core#1379](https://github.com/pydantic/pydantic-core/pull/1379)
* @candleindark made their first contribution in [pydantic/pydantic-core#1404](https://github.com/pydantic/pydantic-core/pull/1404)
* @changhc made their first contribution in [pydantic/pydantic-core#1331](https://github.com/pydantic/pydantic-core/pull/1331)

## v2.9.0b2 (2024-08-30)

Pre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.9.0b2) for details.

## v2.9.0b1 (2024-08-26)

Pre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.9.0b1) for details.

## v2.8.2 (2024-07-03)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.8.2)

### What's Changed

#### Fixes

* Fix issue with assertion caused by pluggable schema validator by @dmontagu in [#9838](https://github.com/pydantic/pydantic/pull/9838)

## v2.8.1 (2024-07-03)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.8.1)

### What's Changed

#### Packaging

* Bump `ruff` to `v0.5.0` and `pyright` to `v1.1.369` by @sydney-runkle in [#9801](https://github.com/pydantic/pydantic/pull/9801)
* Bump `pydantic-core` to `v2.20.1`, `pydantic-extra-types` to `v2.9.0` by @sydney-runkle in [#9832](https://github.com/pydantic/pydantic/pull/9832)

#### Fixes

* Fix breaking change in `to_snake` from v2.7 -> v2.8 by @sydney-runkle in [#9812](https://github.com/pydantic/pydantic/pull/9812)
* Fix list constraint json schema application by @sydney-runkle in [#9818](https://github.com/pydantic/pydantic/pull/9818)
* Support time duration more than 23 by @nix010 in [pydantic/speedate#64](https://github.com/pydantic/speedate/pull/64)
* Fix millisecond fraction being handled with the wrong scale by @davidhewitt in [pydantic/speedate#65](https://github.com/pydantic/speedate/pull/65)
* Handle negative fractional durations correctly by @sydney-runkle in [pydantic/speedate#71](https://github.com/pydantic/speedate/pull/71)

## v2.8.0 (2024-07-01)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.8.0)

The code released in v2.8.0 is functionally identical to that of v2.8.0b1.

### What's Changed

#### Packaging

* Update citation version automatically with new releases by @sydney-runkle in [#9673](https://github.com/pydantic/pydantic/pull/9673)
* Bump pyright to `v1.1.367` and add type checking tests for pipeline API by @adriangb in [#9674](https://github.com/pydantic/pydantic/pull/9674)
* Update `pydantic.v1` stub to `v1.10.17` by @sydney-runkle in [#9707](https://github.com/pydantic/pydantic/pull/9707)
* General package updates to prep for `v2.8.0b1` by @sydney-runkle in [#9741](https://github.com/pydantic/pydantic/pull/9741)
* Bump `pydantic-core` to `v2.20.0` by @sydney-runkle in [#9745](https://github.com/pydantic/pydantic/pull/9745)
* Add support for Python 3.13 by @sydney-runkle in [#9743](https://github.com/pydantic/pydantic/pull/9743)
* Update `pdm` version used for `pdm.lock` to v2.16.1 by @sydney-runkle in [#9761](https://github.com/pydantic/pydantic/pull/9761)
* Update to `ruff` `v0.4.8` by @Viicos in [#9585](https://github.com/pydantic/pydantic/pull/9585)

#### New Features

* Experimental: support `defer_build` for `TypeAdapter` by @MarkusSintonen in [#8939](https://github.com/pydantic/pydantic/pull/8939)
* Implement `deprecated` field in json schema by @NeevCohen in [#9298](https://github.com/pydantic/pydantic/pull/9298)
* Experimental: Add pipeline API by @adriangb in [#9459](https://github.com/pydantic/pydantic/pull/9459)
* Add support for programmatic title generation by @NeevCohen in [#9183](https://github.com/pydantic/pydantic/pull/9183)
* Implement `fail_fast` feature by @uriyyo in [#9708](https://github.com/pydantic/pydantic/pull/9708)
* Add `ser_json_inf_nan='strings'` mode to produce valid JSON by @josh-newman in [pydantic/pydantic-core#1307](https://github.com/pydantic/pydantic-core/pull/1307)

#### Changes

* Add warning when "alias" is set in ignored `Annotated` field by @nix010 in [#9170](https://github.com/pydantic/pydantic/pull/9170)
* Support serialization of some serializable defaults in JSON schema by @sydney-runkle in [#9624](https://github.com/pydantic/pydantic/pull/9624)
* Relax type specification for `__validators__` values in `create_model` by @sydney-runkle in [#9697](https://github.com/pydantic/pydantic/pull/9697)
* **Breaking Change:** Improve `smart` union matching logic by @sydney-runkle in [pydantic/pydantic-core#1322](https://github.com/pydantic/pydantic-core/pull/1322)
You can read more about our `smart` union matching logic [here](https://docs.pydantic.dev/dev/concepts/unions/#smart-mode). In some cases, if the old behavior
is desired, you can switch to `left-to-right` mode and change the order of your `Union` members.

#### Performance

##### Internal Improvements

* ⚡️ Speed up `_display_error_loc()` by 25% in `pydantic/v1/error_wrappers.py` by @misrasaurabh1 in [#9653](https://github.com/pydantic/pydantic/pull/9653)
* ⚡️ Speed up `_get_all_json_refs()` by 34% in `pydantic/json_schema.py` by @misrasaurabh1 in [#9650](https://github.com/pydantic/pydantic/pull/9650)
* ⚡️ Speed up `is_pydantic_dataclass()` by 41% in `pydantic/dataclasses.py` by @misrasaurabh1 in [#9652](https://github.com/pydantic/pydantic/pull/9652)
* ⚡️ Speed up `to_snake()` by 27% in `pydantic/alias_generators.py` by @misrasaurabh1 in [#9747](https://github.com/pydantic/pydantic/pull/9747)
* ⚡️ Speed up `unwrap_wrapped_function()` by 93% in `pydantic/_internal/_decorators.py` by @misrasaurabh1 in [#9727](https://github.com/pydantic/pydantic/pull/9727)

#### Fixes

* Replace `__spec__.parent` with `__package__` by @hramezani in [#9331](https://github.com/pydantic/pydantic/pull/9331)
* Fix Outputted Model JSON Schema for `Sequence` type by @anesmemisevic in [#9303](https://github.com/pydantic/pydantic/pull/9303)
* Fix typing of `_frame_depth` by @Viicos in [#9353](https://github.com/pydantic/pydantic/pull/9353)
* Make `ImportString` json schema compatible by @amitschang in [#9344](https://github.com/pydantic/pydantic/pull/9344)
* Hide private attributes (`PrivateAttr`) from `__init__` signature in type checkers by @idan22moral in [#9293](https://github.com/pydantic/pydantic/pull/9293)
* Make detection of `TypeVar` defaults robust to the CPython `PEP-696` implementation by @AlexWaygood in [#9426](https://github.com/pydantic/pydantic/pull/9426)
* Fix usage of `PlainSerializer` with builtin types by @Viicos in [#9450](https://github.com/pydantic/pydantic/pull/9450)
* Add more robust custom validation examples by @ChrisPappalardo in [#9468](https://github.com/pydantic/pydantic/pull/9468)
* Fix ignored `strict` specification for `StringConstraint(strict=False)` by @vbmendes in [#9476](https://github.com/pydantic/pydantic/pull/9476)
* **Breaking Change:** Use PEP 570 syntax by @Viicos in [#9479](https://github.com/pydantic/pydantic/pull/9479)
* Use `Self` where possible by @Viicos in [#9479](https://github.com/pydantic/pydantic/pull/9479)
* Do not alter `RootModel.model_construct` signature in the `mypy` plugin by @Viicos in [#9480](https://github.com/pydantic/pydantic/pull/9480)
* Fixed type hint of `validation_context` by @OhioDschungel6 in [#9508](https://github.com/pydantic/pydantic/pull/9508)
* Support context being passed to TypeAdapter's `dump_json`/`dump_python` by @alexcouper in [#9495](https://github.com/pydantic/pydantic/pull/9495)
* Updates type signature for `Field()` constructor by @bjmc in [#9484](https://github.com/pydantic/pydantic/pull/9484)
* Improve builtin alias generators by @sydney-runkle in [#9561](https://github.com/pydantic/pydantic/pull/9561)
* Fix typing of `TypeAdapter` by @Viicos in [#9570](https://github.com/pydantic/pydantic/pull/9570)
* Add fallback default value for private fields in `__setstate__` of BaseModel by @anhpham1509 in [#9584](https://github.com/pydantic/pydantic/pull/9584)
* Support `PEP 746` by @adriangb in [#9587](https://github.com/pydantic/pydantic/pull/9587)
* Allow validator and serializer functions to have default values by @Viicos in [#9478](https://github.com/pydantic/pydantic/pull/9478)
* Fix bug with mypy plugin's handling of covariant `TypeVar` fields by @dmontagu in [#9606](https://github.com/pydantic/pydantic/pull/9606)
* Fix multiple annotation / constraint application logic by @sydney-runkle in [#9623](https://github.com/pydantic/pydantic/pull/9623)
* Respect `regex` flags in validation and json schema by @sydney-runkle in [#9591](https://github.com/pydantic/pydantic/pull/9591)
* Fix type hint on `IpvAnyAddress` by @sydney-runkle in [#9640](https://github.com/pydantic/pydantic/pull/9640)
* Allow a field specifier on `__pydantic_extra__` by @dmontagu in [#9659](https://github.com/pydantic/pydantic/pull/9659)
* Use normalized case for file path comparison by @sydney-runkle in [#9737](https://github.com/pydantic/pydantic/pull/9737)
* Modify constraint application logic to allow field constraints on `Optional[Decimal]` by @lazyhope in [#9754](https://github.com/pydantic/pydantic/pull/9754)
* `validate_call` type params fix by @sydney-runkle in [#9760](https://github.com/pydantic/pydantic/pull/9760)
* Check all warnings returned by pytest.warns() by @s-t-e-v-e-n-k in [#9702](https://github.com/pydantic/pydantic/pull/9702)
* Reuse `re.Pattern` object in regex patterns to allow for regex flags by @sydney-runkle in [pydantic/pydantic-core#1318](https://github.com/pydantic/pydantic-core/pull/1318)

### New Contributors

* @idan22moral made their first contribution in [#9294](https://github.com/pydantic/pydantic/pull/9294)
* @anesmemisevic made their first contribution in [#9303](https://github.com/pydantic/pydantic/pull/9303)
* @max-muoto made their first contribution in [#9338](https://github.com/pydantic/pydantic/pull/9338)
* @amitschang made their first contribution in [#9344](https://github.com/pydantic/pydantic/pull/9344)
* @paulmartin91 made their first contribution in [#9410](https://github.com/pydantic/pydantic/pull/9410)
* @OhioDschungel6 made their first contribution in [#9405](https://github.com/pydantic/pydantic/pull/9405)
* @AlexWaygood made their first contribution in [#9426](https://github.com/pydantic/pydantic/pull/9426)
* @kinuax made their first contribution in [#9433](https://github.com/pydantic/pydantic/pull/9433)
* @antoni-jamiolkowski made their first contribution in [#9431](https://github.com/pydantic/pydantic/pull/9431)
* @candleindark made their first contribution in [#9448](https://github.com/pydantic/pydantic/pull/9448)
* @nix010 made their first contribution in [#9170](https://github.com/pydantic/pydantic/pull/9170)
* @tomy0000000 made their first contribution in [#9457](https://github.com/pydantic/pydantic/pull/9457)
* @vbmendes made their first contribution in [#9470](https://github.com/pydantic/pydantic/pull/9470)
* @micheleAlberto made their first contribution in [#9471](https://github.com/pydantic/pydantic/pull/9471)
* @ChrisPappalardo made their first contribution in [#9468](https://github.com/pydantic/pydantic/pull/9468)
* @blueTurtz made their first contribution in [#9475](https://github.com/pydantic/pydantic/pull/9475)
* @WinterBlue16 made their first contribution in [#9477](https://github.com/pydantic/pydantic/pull/9477)
* @bittner made their first contribution in [#9500](https://github.com/pydantic/pydantic/pull/9500)
* @alexcouper made their first contribution in [#9495](https://github.com/pydantic/pydantic/pull/9495)
* @bjmc made their first contribution in [#9484](https://github.com/pydantic/pydantic/pull/9484)
* @pjvv made their first contribution in [#9529](https://github.com/pydantic/pydantic/pull/9529)
* @nedbat made their first contribution in [#9530](https://github.com/pydantic/pydantic/pull/9530)
* @gunnellEvan made their first contribution in [#9469](https://github.com/pydantic/pydantic/pull/9469)
* @jaymbans made their first contribution in [#9531](https://github.com/pydantic/pydantic/pull/9531)
* @MarcBresson made their first contribution in [#9534](https://github.com/pydantic/pydantic/pull/9534)
* @anhpham1509 made their first contribution in [#9584](https://github.com/pydantic/pydantic/pull/9584)
* @K-dash made their first contribution in [#9595](https://github.com/pydantic/pydantic/pull/9595)
* @s-t-e-v-e-n-k made their first contribution in [#9527](https://github.com/pydantic/pydantic/pull/9527)
* @airwoodix made their first contribution in [#9506](https://github.com/pydantic/pydantic/pull/9506)
* @misrasaurabh1 made their first contribution in [#9653](https://github.com/pydantic/pydantic/pull/9653)
* @AlessandroMiola made their first contribution in [#9740](https://github.com/pydantic/pydantic/pull/9740)
* @mylapallilavanyaa made their first contribution in [#9746](https://github.com/pydantic/pydantic/pull/9746)
* @lazyhope made their first contribution in [#9754](https://github.com/pydantic/pydantic/pull/9754)
* @YassinNouh21 made their first contribution in [#9759](https://github.com/pydantic/pydantic/pull/9759)

## v2.8.0b1 (2024-06-27)

Pre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.8.0b1) for details.

## v2.7.4 (2024-06-12)

[Github release](https://github.com/pydantic/pydantic/releases/tag/v2.7.4)

### What's Changed

#### Packaging

* Bump `pydantic.v1` to `v1.10.16` reference by @sydney-runkle in [#9639](https://github.com/pydantic/pydantic/pull/9639)

#### Fixes

* Specify `recursive_guard` as kwarg in `FutureRef._evaluate` by @vfazio in [#9612](https://github.com/pydantic/pydantic/pull/9612)

## v2.7.3 (2024-06-03)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.7.3)

### What's Changed

#### Packaging

* Bump `pydantic-core` to `v2.18.4` by @sydney-runkle in [#9550](https://github.com/pydantic/pydantic/pull/9550)

#### Fixes

* Fix u style unicode strings in python @samuelcolvin in [pydantic/jiter#110](https://github.com/pydantic/jiter/pull/110)

## v2.7.2 (2024-05-28)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.7.2)

### What's Changed

#### Packaging

* Bump `pydantic-core` to `v2.18.3` by @sydney-runkle in [#9515](https://github.com/pydantic/pydantic/pull/9515)

#### Fixes

* Replace `__spec__.parent` with `__package__` by @hramezani in [#9331](https://github.com/pydantic/pydantic/pull/9331)
* Fix validation of `int`s with leading unary minus by @RajatRajdeep in [pydantic/pydantic-core#1291](https://github.com/pydantic/pydantic-core/pull/1291)
* Fix `str` subclass validation for enums by @sydney-runkle in [pydantic/pydantic-core#1273](https://github.com/pydantic/pydantic-core/pull/1273)
* Support `BigInt`s in `Literal`s and `Enum`s by @samuelcolvin in [pydantic/pydantic-core#1297](https://github.com/pydantic/pydantic-core/pull/1297)
* Fix: uuid - allow `str` subclass as input by @davidhewitt in [pydantic/pydantic-core#1296](https://github.com/pydantic/pydantic-core/pull/1296)

## v2.7.1 (2024-04-23)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.7.1)

### What's Changed

#### Packaging

* Bump `pydantic-core` to `v2.18.2` by @sydney-runkle in [#9307](https://github.com/pydantic/pydantic/pull/9307)

#### New Features

* Ftp and Websocket connection strings support by @CherrySuryp in [#9205](https://github.com/pydantic/pydantic/pull/9205)

#### Changes

* Use field description for RootModel schema description when there is `…` by @LouisGobert in [#9214](https://github.com/pydantic/pydantic/pull/9214)

#### Fixes

* Fix `validation_alias` behavior with `model_construct` for `AliasChoices` and `AliasPath` by @sydney-runkle in [#9223](https://github.com/pydantic/pydantic/pull/9223)
* Revert `typing.Literal` and import it outside the TYPE_CHECKING block by @frost-nzcr4 in [#9232](https://github.com/pydantic/pydantic/pull/9232)
* Fix `Secret` serialization schema, applicable for unions by @sydney-runkle in [#9240](https://github.com/pydantic/pydantic/pull/9240)
* Fix `strict` application to `function-after` with `use_enum_values` by @sydney-runkle in [#9279](https://github.com/pydantic/pydantic/pull/9279)
* Address case where `model_construct` on a class which defines `model_post_init` fails with `AttributeError` by @babygrimes in [#9168](https://github.com/pydantic/pydantic/pull/9168)
* Fix `model_json_schema` with config types by @NeevCohen in [#9287](https://github.com/pydantic/pydantic/pull/9287)
* Support multiple zeros as an `int` by @samuelcolvin in [pydantic/pydantic-core#1269](https://github.com/pydantic/pydantic-core/pull/1269)
* Fix validation of `int`s with leading unary plus by @cknv in [pydantic/pydantic-core#1272](https://github.com/pydantic/pydantic-core/pull/1272)
* Fix interaction between `extra != 'ignore'` and `from_attributes=True` by @davidhewitt in [pydantic/pydantic-core#1276](https://github.com/pydantic/pydantic-core/pull/1276)
* Handle error from `Enum`'s `missing` function as `ValidationError` by @sydney-runkle in [pydantic/pydantic-core#1274](https://github.com/pydantic/pydantic-core/pull/1754)
* Fix memory leak with `Iterable` validation by @davidhewitt in [pydantic/pydantic-core#1271](https://github.com/pydantic/pydantic-core/pull/1751)

### New Contributors

* @zzstoatzz made their first contribution in [#9219](https://github.com/pydantic/pydantic/pull/9219)
* @frost-nzcr4 made their first contribution in [#9232](https://github.com/pydantic/pydantic/pull/9232)
* @CherrySuryp made their first contribution in [#9205](https://github.com/pydantic/pydantic/pull/9205)
* @vagenas made their first contribution in [#9268](https://github.com/pydantic/pydantic/pull/9268)
* @ollz272 made their first contribution in [#9262](https://github.com/pydantic/pydantic/pull/9262)
* @babygrimes made their first contribution in [#9168](https://github.com/pydantic/pydantic/pull/9168)
* @swelborn made their first contribution in [#9296](https://github.com/pydantic/pydantic/pull/9296)
* @kf-novi made their first contribution in [#9236](https://github.com/pydantic/pydantic/pull/9236)
* @lgeiger made their first contribution in [#9288](https://github.com/pydantic/pydantic/pull/9288)

## v2.7.0 (2024-04-11)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.7.0)

The code released in v2.7.0 is practically identical to that of v2.7.0b1.

### What's Changed

#### Packaging

* Reorganize `pyproject.toml` sections by @Viicos in [#8899](https://github.com/pydantic/pydantic/pull/8899)
* Bump `pydantic-core` to `v2.18.1` by @sydney-runkle in [#9211](https://github.com/pydantic/pydantic/pull/9211)
* Adopt `jiter` `v0.2.0` by @samuelcolvin in [pydantic/pydantic-core#1250](https://github.com/pydantic/pydantic-core/pull/1250)

#### New Features

* Extract attribute docstrings from `FieldInfo.description` by @Viicos in [#6563](https://github.com/pydantic/pydantic/pull/6563)
* Add a `with_config` decorator to comply with typing spec by @Viicos in [#8611](https://github.com/pydantic/pydantic/pull/8611)
* Allow an optional separator splitting the value and unit of the result of `ByteSize.human_readable` by @jks15satoshi in [#8706](https://github.com/pydantic/pydantic/pull/8706)
* Add generic `Secret` base type by @conradogarciaberrotaran in [#8519](https://github.com/pydantic/pydantic/pull/8519)
* Make use of `Sphinx` inventories for cross references in docs by @Viicos in [#8682](https://github.com/pydantic/pydantic/pull/8682)
* Add environment variable to disable plugins by @geospackle in [#8767](https://github.com/pydantic/pydantic/pull/8767)
* Add support for `deprecated` fields by @Viicos in [#8237](https://github.com/pydantic/pydantic/pull/8237)
* Allow `field_serializer('*')` by @ornariece in [#9001](https://github.com/pydantic/pydantic/pull/9001)
* Handle a case when `model_config` is defined as a model property by @alexeyt101 in [#9004](https://github.com/pydantic/pydantic/pull/9004)
* Update `create_model()` to support `typing.Annotated` as input by @wannieman98 in [#8947](https://github.com/pydantic/pydantic/pull/8947)
* Add `ClickhouseDsn` support by @solidguy7 in [#9062](https://github.com/pydantic/pydantic/pull/9062)
* Add support for `re.Pattern[str]` to `pattern` field by @jag-k in [#9053](https://github.com/pydantic/pydantic/pull/9053)
* Support for `serialize_as_any` runtime setting by @sydney-runkle in [#8830](https://github.com/pydantic/pydantic/pull/8830)
* Add support for `typing.Self` by @Youssefares in [#9023](https://github.com/pydantic/pydantic/pull/9023)
* Ability to pass `context` to serialization by @ornariece in [#8965](https://github.com/pydantic/pydantic/pull/8965)
* Add feedback widget to docs with flarelytics integration by @sydney-runkle in [#9129](https://github.com/pydantic/pydantic/pull/9129)
* Support for parsing partial JSON strings in Python by @samuelcolvin in [pydantic/jiter#66](https://github.com/pydantic/jiter/pull/66)

**Finalized in v2.7.0, rather than v2.7.0b1:**

* Add support for field level number to str coercion option by @NeevCohen in [#9137](https://github.com/pydantic/pydantic/pull/9137)
* Update `warnings` parameter for serialization utilities to allow raising a warning by @Lance-Drane in [#9166](https://github.com/pydantic/pydantic/pull/9166)

#### Changes

* Correct docs, logic for `model_construct` behavior with `extra` by @sydney-runkle in [#8807](https://github.com/pydantic/pydantic/pull/8807)
* Improve error message for improper `RootModel` subclasses by @sydney-runkle in [#8857](https://github.com/pydantic/pydantic/pull/8857)
* **Breaking Change:** Use `PEP570` syntax by @Viicos in [#8940](https://github.com/pydantic/pydantic/pull/8940)
* Add `enum` and `type` to the JSON schema for single item literals by @dmontagu in [#8944](https://github.com/pydantic/pydantic/pull/8944)
* Deprecate `update_json_schema` internal function by @sydney-runkle in [#9125](https://github.com/pydantic/pydantic/pull/9125)
* Serialize duration to hour minute second, instead of just seconds by @kakilangit in [pydantic/speedate#50](https://github.com/pydantic/speedate/pull/50)
* Trimming str before parsing to int and float by @hungtsetse in [pydantic/pydantic-core#1203](https://github.com/pydantic/pydantic-core/pull/1203)

#### Performance

* `enum` validator improvements by @samuelcolvin in [#9045](https://github.com/pydantic/pydantic/pull/9045)
* Move `enum` validation and serialization to Rust by @samuelcolvin in [#9064](https://github.com/pydantic/pydantic/pull/9064)
* Improve schema generation for nested dataclasses by @sydney-runkle in [#9114](https://github.com/pydantic/pydantic/pull/9114)
* Fast path for ASCII python string creation in JSON by @samuelcolvin in in [pydantic/jiter#72](https://github.com/pydantic/jiter/pull/72)
* SIMD integer and string JSON parsing on `aarch64`(**Note:** SIMD on x86 will be implemented in a future release) by @samuelcolvin in in [pydantic/jiter#65](https://github.com/pydantic/jiter/pull/65)
* Support JSON `Cow<str>` from `jiter` by @davidhewitt in [pydantic/pydantic-core#1231](https://github.com/pydantic/pydantic-core/pull/1231)
* MAJOR performance improvement: update to PyO3 0.21 final by @davidhewitt in [pydantic/pydantic-core#1248](https://github.com/pydantic/pydantic-core/pull/1248)
* cache Python strings by @samuelcolvin in [pydantic/pydantic-core#1240](https://github.com/pydantic/pydantic-core/pull/1240)

#### Fixes

* Fix strict parsing for some `Sequence`s by @sydney-runkle in [#8614](https://github.com/pydantic/pydantic/pull/8614)
* Add a check on the existence of `__qualname__` by @anci3ntr0ck in [#8642](https://github.com/pydantic/pydantic/pull/8642)
* Handle `__pydantic_extra__` annotation being a string or inherited by @alexmojaki in [#8659](https://github.com/pydantic/pydantic/pull/8659)
* Fix json validation for `NameEmail` by @Holi0317 in [#8650](https://github.com/pydantic/pydantic/pull/8650)
* Fix type-safety of attribute access in `BaseModel` by @bluenote10 in [#8651](https://github.com/pydantic/pydantic/pull/8651)
* Fix bug with `mypy` plugin and `no_strict_optional = True` by @dmontagu in [#8666](https://github.com/pydantic/pydantic/pull/8666)
* Fix `ByteSize` error `type` change by @sydney-runkle in [#8681](https://github.com/pydantic/pydantic/pull/8681)
* Fix inheriting annotations in dataclasses by @sydney-runkle in [#8679](https://github.com/pydantic/pydantic/pull/8679)
* Fix regression in core schema generation for indirect definition references by @dmontagu in [#8702](https://github.com/pydantic/pydantic/pull/8702)
* Fix unsupported types bug with plain validator by @sydney-runkle in [#8710](https://github.com/pydantic/pydantic/pull/8710)
* Reverting problematic fix from 2.6 release, fixing schema building bug by @sydney-runkle in [#8718](https://github.com/pydantic/pydantic/pull/8718)
* fixes `__pydantic_config__` ignored for TypeDict by @13sin in [#8734](https://github.com/pydantic/pydantic/pull/8734)
* Fix test failures with `pytest v8.0.0` due to `pytest.warns()` starting to work inside `pytest.raises()` by @mgorny in [#8678](https://github.com/pydantic/pydantic/pull/8678)
* Use `is_valid_field` from 1.x for `mypy` plugin by @DanielNoord in [#8738](https://github.com/pydantic/pydantic/pull/8738)
* Better-support `mypy` strict equality flag by @dmontagu in [#8799](https://github.com/pydantic/pydantic/pull/8799)
* model_json_schema export with Annotated types misses 'required' parameters by @LouisGobert in [#8793](https://github.com/pydantic/pydantic/pull/8793)
* Fix default inclusion in `FieldInfo.__repr_args__` by @sydney-runkle in [#8801](https://github.com/pydantic/pydantic/pull/8801)
* Fix resolution of forward refs in dataclass base classes that are not present in the subclass module namespace by @matsjoyce-refeyn in [#8751](https://github.com/pydantic/pydantic/pull/8751)
* Fix `BaseModel` type annotations to be resolvable by `typing.get_type_hints` by @devmonkey22 in [#7680](https://github.com/pydantic/pydantic/pull/7680)
* Fix: allow empty string aliases with `AliasGenerator` by @sydney-runkle in [#8810](https://github.com/pydantic/pydantic/pull/8810)
* Fix test along with `date` -> `datetime` timezone assumption fix by @sydney-runkle in [#8823](https://github.com/pydantic/pydantic/pull/8823)
* Fix deprecation warning with usage of `ast.Str` by @Viicos in [#8837](https://github.com/pydantic/pydantic/pull/8837)
* Add missing `deprecated` decorators by @Viicos in [#8877](https://github.com/pydantic/pydantic/pull/8877)
* Fix serialization of `NameEmail` if name includes an email address by @NeevCohen in [#8860](https://github.com/pydantic/pydantic/pull/8860)
* Add information about class in error message of schema generation by @Czaki in [#8917](https://github.com/pydantic/pydantic/pull/8917)
* Make `TypeAdapter`'s typing compatible with special forms by @adriangb in [#8923](https://github.com/pydantic/pydantic/pull/8923)
* Fix issue with config behavior being baked into the ref schema for `enum`s by @dmontagu in [#8920](https://github.com/pydantic/pydantic/pull/8920)
* More helpful error re wrong `model_json_schema` usage by @sydney-runkle in [#8928](https://github.com/pydantic/pydantic/pull/8928)
* Fix nested discriminated union schema gen, pt 2 by @sydney-runkle in [#8932](https://github.com/pydantic/pydantic/pull/8932)
* Fix schema build for nested dataclasses / TypedDicts with discriminators by @sydney-runkle in [#8950](https://github.com/pydantic/pydantic/pull/8950)
* Remove unnecessary logic for definitions schema gen with discriminated unions by @sydney-runkle in [#8951](https://github.com/pydantic/pydantic/pull/8951)
* Fix handling of optionals in `mypy` plugin by @dmontagu in [#9008](https://github.com/pydantic/pydantic/pull/9008)
* Fix `PlainSerializer` usage with std type constructor by @sydney-runkle in [#9031](https://github.com/pydantic/pydantic/pull/9031)
* Remove unnecessary warning for config in plugin by @dmontagu in [#9039](https://github.com/pydantic/pydantic/pull/9039)
* Fix default value serializing by @NeevCohen in [#9066](https://github.com/pydantic/pydantic/pull/9066)
* Fix extra fields check in `Model.__getattr__()` by @NeevCohen in [#9082](https://github.com/pydantic/pydantic/pull/9082)
* Fix `ClassVar` forward ref inherited from parent class by @alexmojaki in [#9097](https://github.com/pydantic/pydantic/pull/9097)
* fix sequence like validator with strict `True` by @andresliszt in [#8977](https://github.com/pydantic/pydantic/pull/8977)
* Improve warning message when a field name shadows a field in a parent model by @chan-vince in [#9105](https://github.com/pydantic/pydantic/pull/9105)
* Do not warn about shadowed fields if they are not redefined in a child class by @chan-vince in [#9111](https://github.com/pydantic/pydantic/pull/9111)
* Fix discriminated union bug with unsubstituted type var by @sydney-runkle in [#9124](https://github.com/pydantic/pydantic/pull/9124)
* Support serialization of `deque` when passed to `Sequence[blah blah blah]` by @sydney-runkle in [#9128](https://github.com/pydantic/pydantic/pull/9128)
* Init private attributes from super-types in `model_post_init` by @Viicos in [#9134](https://github.com/pydantic/pydantic/pull/9134)
* fix `model_construct` with `validation_alias` by @ornariece in [#9144](https://github.com/pydantic/pydantic/pull/9144)
* Ensure json-schema generator handles `Literal` `null` types by @bruno-f-cruz in [#9135](https://github.com/pydantic/pydantic/pull/9135)
* **Fixed in v2.7.0**: Fix allow extra generic by @dmontagu in [#9193](https://github.com/pydantic/pydantic/pull/9193)

### New Contributors

* @hungtsetse made their first contribution in [#8546](https://github.com/pydantic/pydantic/pull/8546)
* @StrawHatDrag0n made their first contribution in [#8583](https://github.com/pydantic/pydantic/pull/8583)
* @anci3ntr0ck made their first contribution in [#8642](https://github.com/pydantic/pydantic/pull/8642)
* @Holi0317 made their first contribution in [#8650](https://github.com/pydantic/pydantic/pull/8650)
* @bluenote10 made their first contribution in [#8651](https://github.com/pydantic/pydantic/pull/8651)
* @ADSteele916 made their first contribution in [#8703](https://github.com/pydantic/pydantic/pull/8703)
* @musicinmybrain made their first contribution in [#8731](https://github.com/pydantic/pydantic/pull/8731)
* @jks15satoshi made their first contribution in [#8706](https://github.com/pydantic/pydantic/pull/8706)
* @13sin made their first contribution in [#8734](https://github.com/pydantic/pydantic/pull/8734)
* @DanielNoord made their first contribution in [#8738](https://github.com/pydantic/pydantic/pull/8738)
* @conradogarciaberrotaran made their first contribution in [#8519](https://github.com/pydantic/pydantic/pull/8519)
* @chris-griffin made their first contribution in [#8775](https://github.com/pydantic/pydantic/pull/8775)
* @LouisGobert made their first contribution in [#8793](https://github.com/pydantic/pydantic/pull/8793)
* @matsjoyce-refeyn made their first contribution in [#8751](https://github.com/pydantic/pydantic/pull/8751)
* @devmonkey22 made their first contribution in [#7680](https://github.com/pydantic/pydantic/pull/7680)
* @adamency made their first contribution in [#8847](https://github.com/pydantic/pydantic/pull/8847)
* @MamfTheKramf made their first contribution in [#8851](https://github.com/pydantic/pydantic/pull/8851)
* @ornariece made their first contribution in [#9001](https://github.com/pydantic/pydantic/pull/9001)
* @alexeyt101 made their first contribution in [#9004](https://github.com/pydantic/pydantic/pull/9004)
* @wannieman98 made their first contribution in [#8947](https://github.com/pydantic/pydantic/pull/8947)
* @solidguy7 made their first contribution in [#9062](https://github.com/pydantic/pydantic/pull/9062)
* @kloczek made their first contribution in [#9047](https://github.com/pydantic/pydantic/pull/9047)
* @jag-k made their first contribution in [#9053](https://github.com/pydantic/pydantic/pull/9053)
* @priya-gitTest made their first contribution in [#9088](https://github.com/pydantic/pydantic/pull/9088)
* @Youssefares made their first contribution in [#9023](https://github.com/pydantic/pydantic/pull/9023)
* @chan-vince made their first contribution in [#9105](https://github.com/pydantic/pydantic/pull/9105)
* @bruno-f-cruz made their first contribution in [#9135](https://github.com/pydantic/pydantic/pull/9135)
* @Lance-Drane made their first contribution in [#9166](https://github.com/pydantic/pydantic/pull/9166)

## v2.7.0b1 (2024-04-03)

Pre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.7.0b1) for details.

## v2.6.4 (2024-03-12)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.4)

### What's Changed

#### Fixes

* Fix usage of `AliasGenerator` with `computed_field` decorator by @sydney-runkle in [#8806](https://github.com/pydantic/pydantic/pull/8806)
* Fix nested discriminated union schema gen, pt 2 by @sydney-runkle in [#8932](https://github.com/pydantic/pydantic/pull/8932)
* Fix bug with no_strict_optional=True caused by API deferral by @dmontagu in [#8826](https://github.com/pydantic/pydantic/pull/8826)

## v2.6.3 (2024-02-27)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.3)

### What's Changed

#### Packaging

* Update `pydantic-settings` version in the docs by @hramezani in [#8906](https://github.com/pydantic/pydantic/pull/8906)

#### Fixes

* Fix discriminated union schema gen bug by @sydney-runkle in [#8904](https://github.com/pydantic/pydantic/pull/8904)

## v2.6.2 (2024-02-23)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.2)

### What's Changed

#### Packaging

* Upgrade to `pydantic-core` 2.16.3 by @sydney-runkle in [#8879](https://github.com/pydantic/pydantic/pull/8879)

#### Fixes

* 'YYYY-MM-DD' date string coerced to datetime shouldn't infer timezone by @sydney-runkle in [pydantic/pydantic-core#1193](https://github.com/pydantic/pydantic-core/pull/1193)

## v2.6.1 (2024-02-05)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.1)

### What's Changed

#### Packaging

* Upgrade to `pydantic-core` 2.16.2 by @sydney-runkle in [#8717](https://github.com/pydantic/pydantic/pull/8717)

#### Fixes

* Fix bug with `mypy` plugin and `no_strict_optional = True` by @dmontagu in [#8666](https://github.com/pydantic/pydantic/pull/8666)
* Fix `ByteSize` error `type` change by @sydney-runkle in [#8681](https://github.com/pydantic/pydantic/pull/8681)
* Fix inheriting `Field` annotations in dataclasses by @sydney-runkle in [#8679](https://github.com/pydantic/pydantic/pull/8679)
* Fix regression in core schema generation for indirect definition references by @dmontagu in [#8702](https://github.com/pydantic/pydantic/pull/8702)
* Fix unsupported types bug with `PlainValidator` by @sydney-runkle in [#8710](https://github.com/pydantic/pydantic/pull/8710)
* Reverting problematic fix from 2.6 release, fixing schema building bug by @sydney-runkle in [#8718](https://github.com/pydantic/pydantic/pull/8718)
* Fix warning for tuple of wrong size in `Union` by @davidhewitt in [pydantic/pydantic-core#1174](https://github.com/pydantic/pydantic-core/pull/1174)
* Fix `computed_field` JSON serializer `exclude_none` behavior by @sydney-runkle in [pydantic/pydantic-core#1187](https://github.com/pydantic/pydantic-core/pull/1187)

## v2.6.0 (2024-01-23)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.0)

The code released in v2.6.0 is practically identical to that of v2.6.0b1.

### What's Changed

#### Packaging

* Check for `email-validator` version >= 2.0 by @commonism in [#6033](https://github.com/pydantic/pydantic/pull/6033)
* Upgrade `ruff`` target version to Python 3.8 by @Elkiwa in [#8341](https://github.com/pydantic/pydantic/pull/8341)
* Update to `pydantic-extra-types==2.4.1` by @yezz123 in [#8478](https://github.com/pydantic/pydantic/pull/8478)
* Update to `pyright==1.1.345` by @Viicos in [#8453](https://github.com/pydantic/pydantic/pull/8453)
* Update pydantic-core from 2.14.6 to 2.16.1, significant changes from these updates are described below, full changelog [here](https://github.com/pydantic/pydantic-core/compare/v2.14.6...v2.16.1)

#### New Features

* Add `NatsDsn` by @ekeew in [#6874](https://github.com/pydantic/pydantic/pull/6874)
* Add `ConfigDict.ser_json_inf_nan` by @davidhewitt in [#8159](https://github.com/pydantic/pydantic/pull/8159)
* Add `types.OnErrorOmit` by @adriangb in [#8222](https://github.com/pydantic/pydantic/pull/8222)
* Support `AliasGenerator` usage by @sydney-runkle in [#8282](https://github.com/pydantic/pydantic/pull/8282)
* Add Pydantic People Page to docs by @sydney-runkle in [#8345](https://github.com/pydantic/pydantic/pull/8345)
* Support `yyyy-MM-DD` datetime parsing by @sydney-runkle in [#8404](https://github.com/pydantic/pydantic/pull/8404)
* Added bits conversions to the `ByteSize` class #8415 by @luca-matei in [#8507](https://github.com/pydantic/pydantic/pull/8507)
* Enable json schema creation with type `ByteSize` by @geospackle in [#8537](https://github.com/pydantic/pydantic/pull/8537)
* Add `eval_type_backport` to handle union operator and builtin generic subscripting in older Pythons by @alexmojaki in [#8209](https://github.com/pydantic/pydantic/pull/8209)
* Add support for `dataclass` fields `init` by @dmontagu in [#8552](https://github.com/pydantic/pydantic/pull/8552)
* Implement pickling for `ValidationError` by @davidhewitt in [pydantic/pydantic-core#1119](https://github.com/pydantic/pydantic-core/pull/1119)
* Add unified tuple validator that can handle "variadic" tuples via PEP-646 by @dmontagu in [pydantic/pydantic-core#865](https://github.com/pydantic/pydantic-core/pull/865)

#### Changes

* Drop Python3.7 support by @hramezani in [#7188](https://github.com/pydantic/pydantic/pull/7188)
* Drop Python 3.7, and PyPy 3.7 and 3.8 by @davidhewitt in [pydantic/pydantic-core#1129](https://github.com/pydantic/pydantic-core/pull/1129)
* Use positional-only `self` in `BaseModel` constructor, so no field name can ever conflict with it by @ariebovenberg in [#8072](https://github.com/pydantic/pydantic/pull/8072)
* Make `@validate_call` return a function instead of a custom descriptor - fixes binding issue with inheritance and adds `self/cls` argument to validation errors by @alexmojaki in [#8268](https://github.com/pydantic/pydantic/pull/8268)
* Exclude `BaseModel` docstring from JSON schema description by @sydney-runkle in [#8352](https://github.com/pydantic/pydantic/pull/8352)
* Introducing `classproperty` decorator for `model_computed_fields` by @Jocelyn-Gas in [#8437](https://github.com/pydantic/pydantic/pull/8437)
* Explicitly raise an error if field names clashes with types by @Viicos in [#8243](https://github.com/pydantic/pydantic/pull/8243)
* Use stricter serializer for unions of simple types by @alexdrydew [pydantic/pydantic-core#1132](https://github.com/pydantic/pydantic-core/pull/1132)

#### Performance

* Add Codspeed profiling Actions workflow  by @lambertsbennett in [#8054](https://github.com/pydantic/pydantic/pull/8054)
* Improve `int` extraction by @samuelcolvin in [pydantic/pydantic-core#1155](https://github.com/pydantic/pydantic-core/pull/1155)
* Improve performance of recursion guard by @samuelcolvin in [pydantic/pydantic-core#1156](https://github.com/pydantic/pydantic-core/pull/1156)
* `dataclass` serialization speedups by @samuelcolvin in [pydantic/pydantic-core#1162](https://github.com/pydantic/pydantic-core/pull/1162)
* Avoid `HashMap` creation when looking up small JSON objects in `LazyIndexMaps` by @samuelcolvin in [pydantic/jiter#55](https://github.com/pydantic/jiter/pull/55)
* use hashbrown to speedup python string caching by @davidhewitt in [pydantic/jiter#51](https://github.com/pydantic/jiter/pull/51)
* Replace `Peak` with more efficient `Peek` by @davidhewitt in [pydantic/jiter#48](https://github.com/pydantic/jiter/pull/48)

#### Fixes

* Move `getattr` warning in deprecated `BaseConfig` by @tlambert03 in [#7183](https://github.com/pydantic/pydantic/pull/7183)
* Only hash `model_fields`, not whole `__dict__` by @alexmojaki in [#7786](https://github.com/pydantic/pydantic/pull/7786)
* Fix mishandling of unions while freezing types in the `mypy` plugin by @dmontagu in [#7411](https://github.com/pydantic/pydantic/pull/7411)
* Fix `mypy` error on untyped `ClassVar` by @vincent-hachin-wmx in [#8138](https://github.com/pydantic/pydantic/pull/8138)
* Only compare pydantic fields in `BaseModel.__eq__` instead of whole `__dict__` by @QuentinSoubeyranAqemia in [#7825](https://github.com/pydantic/pydantic/pull/7825)
* Update `strict` docstring in `model_validate` method. by @LukeTonin in [#8223](https://github.com/pydantic/pydantic/pull/8223)
* Fix overload position of `computed_field` by @Viicos in [#8227](https://github.com/pydantic/pydantic/pull/8227)
* Fix custom type type casting used in multiple attributes by @ianhfc in [#8066](https://github.com/pydantic/pydantic/pull/8066)
* Fix issue not allowing `validate_call` decorator to be dynamically assigned to a class method by @jusexton in [#8249](https://github.com/pydantic/pydantic/pull/8249)
* Fix issue `unittest.mock` deprecation warnings  by @ibleedicare in [#8262](https://github.com/pydantic/pydantic/pull/8262)
* Added tests for the case `JsonValue` contains subclassed primitive values by @jusexton in [#8286](https://github.com/pydantic/pydantic/pull/8286)
* Fix `mypy` error on free before validator (classmethod) by @sydney-runkle in [#8285](https://github.com/pydantic/pydantic/pull/8285)
* Fix `to_snake` conversion by @jevins09 in [#8316](https://github.com/pydantic/pydantic/pull/8316)
* Fix type annotation of `ModelMetaclass.__prepare__` by @slanzmich in [#8305](https://github.com/pydantic/pydantic/pull/8305)
* Disallow `config` specification when initializing a `TypeAdapter` when the annotated type has config already by @sydney-runkle in [#8365](https://github.com/pydantic/pydantic/pull/8365)
* Fix a naming issue with JSON schema for generics parametrized by recursive type aliases by @dmontagu in [#8389](https://github.com/pydantic/pydantic/pull/8389)
* Fix type annotation in pydantic people script by @shenxiangzhuang in [#8402](https://github.com/pydantic/pydantic/pull/8402)
* Add support for field `alias` in `dataclass` signature by @NeevCohen in [#8387](https://github.com/pydantic/pydantic/pull/8387)
* Fix bug with schema generation with `Field(...)` in a forward ref by @dmontagu in [#8494](https://github.com/pydantic/pydantic/pull/8494)
* Fix ordering of keys in `__dict__` with `model_construct` call by @sydney-runkle in [#8500](https://github.com/pydantic/pydantic/pull/8500)
* Fix module `path_type` creation when globals does not contain `__name__` by @hramezani in [#8470](https://github.com/pydantic/pydantic/pull/8470)
* Fix for namespace issue with dataclasses with `from __future__ import annotations` by @sydney-runkle in [#8513](https://github.com/pydantic/pydantic/pull/8513)
* Fix: make function validator types positional-only by @pmmmwh in [#8479](https://github.com/pydantic/pydantic/pull/8479)
* Fix usage of `@deprecated` by @Viicos in [#8294](https://github.com/pydantic/pydantic/pull/8294)
* Add more support for private attributes in `model_construct` call by @sydney-runkle in [#8525](https://github.com/pydantic/pydantic/pull/8525)
* Use a stack for the types namespace by @dmontagu in [#8378](https://github.com/pydantic/pydantic/pull/8378)
* Fix schema-building bug with `TypeAliasType` for types with refs by @dmontagu in [#8526](https://github.com/pydantic/pydantic/pull/8526)
* Support `pydantic.Field(repr=False)` in dataclasses by @tigeryy2 in [#8511](https://github.com/pydantic/pydantic/pull/8511)
* Override `dataclass_transform` behavior for `RootModel` by @Viicos in [#8163](https://github.com/pydantic/pydantic/pull/8163)
* Refactor signature generation for simplicity by @sydney-runkle in [#8572](https://github.com/pydantic/pydantic/pull/8572)
* Fix ordering bug of PlainValidator annotation by @Anvil in [#8567](https://github.com/pydantic/pydantic/pull/8567)
* Fix `exclude_none` for json serialization of `computed_field`s by @sydney-runkle in [pydantic/pydantic-core#1098](https://github.com/pydantic/pydantic-core/pull/1098)
* Support yyyy-MM-DD string for datetimes by @sydney-runkle in [pydantic/pydantic-core#1124](https://github.com/pydantic/pydantic-core/pull/1124)
* Tweak ordering of definitions in generated schemas by @StrawHatDrag0n in [#8583](https://github.com/pydantic/pydantic/pull/8583)

### New Contributors

#### `pydantic`

* @ekeew made their first contribution in [#6874](https://github.com/pydantic/pydantic/pull/6874)
* @lambertsbennett made their first contribution in [#8054](https://github.com/pydantic/pydantic/pull/8054)
* @vincent-hachin-wmx made their first contribution in [#8138](https://github.com/pydantic/pydantic/pull/8138)
* @QuentinSoubeyranAqemia made their first contribution in [#7825](https://github.com/pydantic/pydantic/pull/7825)
* @ariebovenberg made their first contribution in [#8072](https://github.com/pydantic/pydantic/pull/8072)
* @LukeTonin made their first contribution in [#8223](https://github.com/pydantic/pydantic/pull/8223)
* @denisart made their first contribution in [#8231](https://github.com/pydantic/pydantic/pull/8231)
* @ianhfc made their first contribution in [#8066](https://github.com/pydantic/pydantic/pull/8066)
* @eonu made their first contribution in [#8255](https://github.com/pydantic/pydantic/pull/8255)
* @amandahla made their first contribution in [#8263](https://github.com/pydantic/pydantic/pull/8263)
* @ibleedicare made their first contribution in [#8262](https://github.com/pydantic/pydantic/pull/8262)
* @jevins09 made their first contribution in [#8316](https://github.com/pydantic/pydantic/pull/8316)
* @cuu508 made their first contribution in [#8322](https://github.com/pydantic/pydantic/pull/8322)
* @slanzmich made their first contribution in [#8305](https://github.com/pydantic/pydantic/pull/8305)
* @jensenbox made their first contribution in [#8331](https://github.com/pydantic/pydantic/pull/8331)
* @szepeviktor made their first contribution in [#8356](https://github.com/pydantic/pydantic/pull/8356)
* @Elkiwa made their first contribution in [#8341](https://github.com/pydantic/pydantic/pull/8341)
* @parhamfh made their first contribution in [#8395](https://github.com/pydantic/pydantic/pull/8395)
* @shenxiangzhuang made their first contribution in [#8402](https://github.com/pydantic/pydantic/pull/8402)
* @NeevCohen made their first contribution in [#8387](https://github.com/pydantic/pydantic/pull/8387)
* @zby made their first contribution in [#8497](https://github.com/pydantic/pydantic/pull/8497)
* @patelnets made their first contribution in [#8491](https://github.com/pydantic/pydantic/pull/8491)
* @edwardwli made their first contribution in [#8503](https://github.com/pydantic/pydantic/pull/8503)
* @luca-matei made their first contribution in [#8507](https://github.com/pydantic/pydantic/pull/8507)
* @Jocelyn-Gas made their first contribution in [#8437](https://github.com/pydantic/pydantic/pull/8437)
* @bL34cHig0 made their first contribution in [#8501](https://github.com/pydantic/pydantic/pull/8501)
* @tigeryy2 made their first contribution in [#8511](https://github.com/pydantic/pydantic/pull/8511)
* @geospackle made their first contribution in [#8537](https://github.com/pydantic/pydantic/pull/8537)
* @Anvil made their first contribution in [#8567](https://github.com/pydantic/pydantic/pull/8567)
* @hungtsetse made their first contribution in [#8546](https://github.com/pydantic/pydantic/pull/8546)
* @StrawHatDrag0n made their first contribution in [#8583](https://github.com/pydantic/pydantic/pull/8583)

#### `pydantic-core`

* @mariuswinger made their first contribution in [pydantic/pydantic-core#1087](https://github.com/pydantic/pydantic-core/pull/1087)
* @adamchainz made their first contribution in [pydantic/pydantic-core#1090](https://github.com/pydantic/pydantic-core/pull/1090)
* @akx made their first contribution in [pydantic/pydantic-core#1123](https://github.com/pydantic/pydantic-core/pull/1123)

## v2.6.0b1 (2024-01-19)

Pre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.6.0b1) for details.

## v2.5.3 (2023-12-22)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.5.3)

### What's Changed

#### Packaging

* uprev `pydantic-core` to 2.14.6

#### Fixes

* Fix memory leak with recursive definitions creating reference cycles by @davidhewitt in [pydantic/pydantic-core#1125](https://github.com/pydantic/pydantic-core/pull/1125)

## v2.5.2 (2023-11-22)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.5.2)

### What's Changed

#### Packaging

* uprev `pydantic-core` to 2.14.5

#### New Features

* Add `ConfigDict.ser_json_inf_nan` by @davidhewitt in [#8159](https://github.com/pydantic/pydantic/pull/8159)

#### Fixes

* Fix validation of `Literal` from JSON keys when used as `dict` key by @sydney-runkle in [pydantic/pydantic-core#1075](https://github.com/pydantic/pydantic-core/pull/1075)
* Fix bug re `custom_init` on members of `Union` by @sydney-runkle in [pydantic/pydantic-core#1076](https://github.com/pydantic/pydantic-core/pull/1076)
* Fix `JsonValue` `bool` serialization by @sydney-runkle in [#8190](https://github.com/pydantic/pydantic/pull/8159)
* Fix handling of unhashable inputs with `Literal` in `Union`s by @sydney-runkle in [pydantic/pydantic-core#1089](https://github.com/pydantic/pydantic-core/pull/1089)

## v2.5.1 (2023-11-15)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.5.1)

### What's Changed

#### Packaging

* uprev pydantic-core to 2.14.3 by @samuelcolvin in [#8120](https://github.com/pydantic/pydantic/pull/8120)

#### Fixes

* Fix package description limit by @dmontagu in [#8097](https://github.com/pydantic/pydantic/pull/8097)
* Fix `ValidateCallWrapper` error when creating a model which has a @validate_call wrapped field annotation by @sydney-runkle in [#8110](https://github.com/pydantic/pydantic/pull/8110)

## v2.5.0 (2023-11-13)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.5.0)

The code released in v2.5.0 is functionally identical to that of v2.5.0b1.

### What's Changed

#### Packaging

* Update pydantic-core from 2.10.1 to 2.14.1, significant changes from these updates are described below, full changelog [here](https://github.com/pydantic/pydantic-core/compare/v2.10.1...v2.14.1)
* Update to `pyright==1.1.335` by @Viicos in [#8075](https://github.com/pydantic/pydantic/pull/8075)

#### New Features

* Allow plugins to catch non `ValidationError` errors by @adriangb in [#7806](https://github.com/pydantic/pydantic/pull/7806)
* Support `__doc__` argument in `create_model()` by @chris-spann in [#7863](https://github.com/pydantic/pydantic/pull/7863)
* Expose `regex_engine` flag - meaning you can use with the Rust or Python regex libraries in constraints by @utkini in [#7768](https://github.com/pydantic/pydantic/pull/7768)
* Save return type generated from type annotation in `ComputedFieldInfo` by @alexmojaki in [#7889](https://github.com/pydantic/pydantic/pull/7889)
* Adopting `ruff` formatter by @Luca-Blight in [#7930](https://github.com/pydantic/pydantic/pull/7930)
* Added `validation_error_cause` to config by @zakstucke in [#7626](https://github.com/pydantic/pydantic/pull/7626)
* Make path of the item to validate available in plugin by @hramezani in [#7861](https://github.com/pydantic/pydantic/pull/7861)
* Add `CallableDiscriminator` and `Tag` by @dmontagu in [#7983](https://github.com/pydantic/pydantic/pull/7983)
    * `CallableDiscriminator` renamed to `Discriminator` by @dmontagu in [#8047](https://github.com/pydantic/pydantic/pull/8047)
* Make union case tags affect union error messages by @dmontagu in [#8001](https://github.com/pydantic/pydantic/pull/8001)
* Add `examples` and `json_schema_extra` to `@computed_field` by @alexmojaki in [#8013](https://github.com/pydantic/pydantic/pull/8013)
* Add `JsonValue` type by @dmontagu in [#7998](https://github.com/pydantic/pydantic/pull/7998)
* Allow `str` as argument to `Discriminator` by @dmontagu in [#8047](https://github.com/pydantic/pydantic/pull/8047)
* Add `SchemaSerializer.__reduce__` method to enable pickle serialization by @edoakes in [pydantic/pydantic-core#1006](https://github.com/pydantic/pydantic-core/pull/1006)

#### Changes

* **Significant Change:** replace `ultra_strict` with new smart union implementation, the way unions are validated has changed significantly to improve performance and correctness, we have worked hard to absolutely minimise the number of cases where behaviour has changed, see the PR for details - by @davidhewitt in [pydantic/pydantic-core#867](https://github.com/pydantic/pydantic-core/pull/867)
* Add support for instance method reassignment when `extra='allow'` by @sydney-runkle in [#7683](https://github.com/pydantic/pydantic/pull/7683)
* Support JSON schema generation for `Enum` types with no cases by @sydney-runkle in [#7927](https://github.com/pydantic/pydantic/pull/7927)
* Warn if a class inherits from `Generic` before `BaseModel` by @alexmojaki in [#7891](https://github.com/pydantic/pydantic/pull/7891)

#### Performance

* New custom JSON parser, `jiter` by @samuelcolvin in [pydantic/pydantic-core#974](https://github.com/pydantic/pydantic-core/pull/974)
* PGO build for MacOS M1 by @samuelcolvin in [pydantic/pydantic-core#1063](https://github.com/pydantic/pydantic-core/pull/1063)
* Use `__getattr__` for all package imports, improve import time by @samuelcolvin in [#7947](https://github.com/pydantic/pydantic/pull/7947)

#### Fixes

* Fix `mypy` issue with subclasses of `RootModel` by @sydney-runkle in [#7677](https://github.com/pydantic/pydantic/pull/7677)
* Properly rebuild the `FieldInfo` when a forward ref gets evaluated by @dmontagu in [#7698](https://github.com/pydantic/pydantic/pull/7698)
* Fix failure to load `SecretStr` from JSON (regression in v2.4) by @sydney-runkle in [#7729](https://github.com/pydantic/pydantic/pull/7729)
* Fix `defer_build` behavior with `TypeAdapter` by @sydney-runkle in [#7736](https://github.com/pydantic/pydantic/pull/7736)
* Improve compatibility with legacy `mypy` versions by @dmontagu in [#7742](https://github.com/pydantic/pydantic/pull/7742)
* Fix: update `TypeVar` handling when default is not set by @pmmmwh in [#7719](https://github.com/pydantic/pydantic/pull/7719)
* Support specification of `strict` on `Enum` type fields by @sydney-runkle in [#7761](https://github.com/pydantic/pydantic/pull/7761)
* Wrap `weakref.ref` instead of subclassing to fix `cloudpickle` serialization by @edoakes in [#7780](https://github.com/pydantic/pydantic/pull/7780)
* Keep values of private attributes set within `model_post_init` in subclasses by @alexmojaki in [#7775](https://github.com/pydantic/pydantic/pull/7775)
* Add more specific type for non-callable `json_schema_extra` by @alexmojaki in [#7803](https://github.com/pydantic/pydantic/pull/7803)
* Raise an error when deleting frozen (model) fields by @alexmojaki in [#7800](https://github.com/pydantic/pydantic/pull/7800)
* Fix schema sorting bug with default values by @sydney-runkle in [#7817](https://github.com/pydantic/pydantic/pull/7817)
* Use generated alias for aliases that are not specified otherwise by @alexmojaki in [#7802](https://github.com/pydantic/pydantic/pull/7802)
* Support `strict` specification for `UUID` types by @sydney-runkle in [#7865](https://github.com/pydantic/pydantic/pull/7865)
* JSON schema: fix extra parameter handling by @me-and in [#7810](https://github.com/pydantic/pydantic/pull/7810)
* Fix: support `pydantic.Field(kw_only=True)` with inherited dataclasses by @PrettyWood in [#7827](https://github.com/pydantic/pydantic/pull/7827)
* Support `validate_call` decorator for methods in classes with `__slots__` by @sydney-runkle in [#7883](https://github.com/pydantic/pydantic/pull/7883)
* Fix pydantic dataclass problem with `dataclasses.field` default by @hramezani in [#7898](https://github.com/pydantic/pydantic/pull/7898)
* Fix schema generation for generics with union type bounds by @sydney-runkle in [#7899](https://github.com/pydantic/pydantic/pull/7899)
* Fix version for `importlib_metadata` on python 3.7 by @sydney-runkle in [#7904](https://github.com/pydantic/pydantic/pull/7904)
* Support `|` operator (Union) in PydanticRecursiveRef by @alexmojaki in [#7892](https://github.com/pydantic/pydantic/pull/7892)
* Fix `display_as_type` for `TypeAliasType` in python 3.12 by @dmontagu in [#7929](https://github.com/pydantic/pydantic/pull/7929)
* Add support for `NotRequired` generics in `TypedDict` by @sydney-runkle in [#7932](https://github.com/pydantic/pydantic/pull/7932)
* Make generic `TypeAliasType` specifications produce different schema definitions by @alexdrydew in [#7893](https://github.com/pydantic/pydantic/pull/7893)
* Added fix for signature of inherited dataclass by @howsunjow in [#7925](https://github.com/pydantic/pydantic/pull/7925)
* Make the model name generation more robust in JSON schema by @joakimnordling in [#7881](https://github.com/pydantic/pydantic/pull/7881)
* Fix plurals in validation error messages (in tests) by @Iipin in [#7972](https://github.com/pydantic/pydantic/pull/7972)
* `PrivateAttr` is passed from `Annotated` default position by @tabassco in [#8004](https://github.com/pydantic/pydantic/pull/8004)
* Don't decode bytes (which may not be UTF8) when displaying SecretBytes by @alexmojaki in [#8012](https://github.com/pydantic/pydantic/pull/8012)
* Use `classmethod` instead of `classmethod[Any, Any, Any]` by @Mr-Pepe in [#7979](https://github.com/pydantic/pydantic/pull/7979)
* Clearer error on invalid Plugin by @samuelcolvin in [#8023](https://github.com/pydantic/pydantic/pull/8023)
* Correct pydantic dataclasses import by @samuelcolvin in [#8027](https://github.com/pydantic/pydantic/pull/8027)
* Fix misbehavior for models referencing redefined type aliases by @dmontagu in [#8050](https://github.com/pydantic/pydantic/pull/8050)
* Fix `Optional` field with `validate_default` only performing one field validation by @sydney-runkle in [pydantic/pydantic-core#1002](https://github.com/pydantic/pydantic-core/pull/1002)
* Fix `definition-ref` bug with `Dict` keys by @sydney-runkle in [pydantic/pydantic-core#1014](https://github.com/pydantic/pydantic-core/pull/1014)
* Fix bug allowing validation of `bool` types with `coerce_numbers_to_str=True` by @sydney-runkle in [pydantic/pydantic-core#1017](https://github.com/pydantic/pydantic-core/pull/1017)
* Don't accept `NaN` in float and decimal constraints by @davidhewitt in [pydantic/pydantic-core#1037](https://github.com/pydantic/pydantic-core/pull/1037)
* Add `lax_str` and `lax_int` support for enum values not inherited from str/int by @michaelhly in [pydantic/pydantic-core#1015](https://github.com/pydantic/pydantic-core/pull/1015)
* Support subclasses in lists in `Union` of `List` types by @sydney-runkle in [pydantic/pydantic-core#1039](https://github.com/pydantic/pydantic-core/pull/1039)
* Allow validation against `max_digits` and `decimals` to pass if normalized or non-normalized input is valid by @sydney-runkle in [pydantic/pydantic-core#1049](https://github.com/pydantic/pydantic-core/pull/1049)
* Fix: proper pluralization in `ValidationError` messages by @Iipin in [pydantic/pydantic-core#1050](https://github.com/pydantic/pydantic-core/pull/1050)
* Disallow the string `'-'` as `datetime` input by @davidhewitt in [pydantic/speedate#52](https://github.com/pydantic/speedate/pull/52) & [pydantic/pydantic-core#1060](https://github.com/pydantic/pydantic-core/pull/1060)
* Fix: NaN and Inf float serialization by @davidhewitt in [pydantic/pydantic-core#1062](https://github.com/pydantic/pydantic-core/pull/1062)
* Restore manylinux-compatible PGO builds by @davidhewitt in [pydantic/pydantic-core#1068](https://github.com/pydantic/pydantic-core/pull/1068)

### New Contributors

#### `pydantic`

* @schneebuzz made their first contribution in [#7699](https://github.com/pydantic/pydantic/pull/7699)
* @edoakes made their first contribution in [#7780](https://github.com/pydantic/pydantic/pull/7780)
* @alexmojaki made their first contribution in [#7775](https://github.com/pydantic/pydantic/pull/7775)
* @NickG123 made their first contribution in [#7751](https://github.com/pydantic/pydantic/pull/7751)
* @gowthamgts made their first contribution in [#7830](https://github.com/pydantic/pydantic/pull/7830)
* @jamesbraza made their first contribution in [#7848](https://github.com/pydantic/pydantic/pull/7848)
* @laundmo made their first contribution in [#7850](https://github.com/pydantic/pydantic/pull/7850)
* @rahmatnazali made their first contribution in [#7870](https://github.com/pydantic/pydantic/pull/7870)
* @waterfountain1996 made their first contribution in [#7878](https://github.com/pydantic/pydantic/pull/7878)
* @chris-spann made their first contribution in [#7863](https://github.com/pydantic/pydantic/pull/7863)
* @me-and made their first contribution in [#7810](https://github.com/pydantic/pydantic/pull/7810)
* @utkini made their first contribution in [#7768](https://github.com/pydantic/pydantic/pull/7768)
* @bn-l made their first contribution in [#7744](https://github.com/pydantic/pydantic/pull/7744)
* @alexdrydew made their first contribution in [#7893](https://github.com/pydantic/pydantic/pull/7893)
* @Luca-Blight made their first contribution in [#7930](https://github.com/pydantic/pydantic/pull/7930)
* @howsunjow made their first contribution in [#7925](https://github.com/pydantic/pydantic/pull/7925)
* @joakimnordling made their first contribution in [#7881](https://github.com/pydantic/pydantic/pull/7881)
* @icfly2 made their first contribution in [#7976](https://github.com/pydantic/pydantic/pull/7976)
* @Yummy-Yums made their first contribution in [#8003](https://github.com/pydantic/pydantic/pull/8003)
* @Iipin made their first contribution in [#7972](https://github.com/pydantic/pydantic/pull/7972)
* @tabassco made their first contribution in [#8004](https://github.com/pydantic/pydantic/pull/8004)
* @Mr-Pepe made their first contribution in [#7979](https://github.com/pydantic/pydantic/pull/7979)
* @0x00cl made their first contribution in [#8010](https://github.com/pydantic/pydantic/pull/8010)
* @barraponto made their first contribution in [#8032](https://github.com/pydantic/pydantic/pull/8032)

#### `pydantic-core`

* @sisp made their first contribution in [pydantic/pydantic-core#995](https://github.com/pydantic/pydantic-core/pull/995)
* @michaelhly made their first contribution in [pydantic/pydantic-core#1015](https://github.com/pydantic/pydantic-core/pull/1015)

## v2.5.0b1 (2023-11-09)

Pre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.5.0b1) for details.

## v2.4.2 (2023-09-27)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.4.2)

### What's Changed

#### Fixes

* Fix bug with JSON schema for sequence of discriminated union by @dmontagu in [#7647](https://github.com/pydantic/pydantic/pull/7647)
* Fix schema references in discriminated unions by @adriangb in [#7646](https://github.com/pydantic/pydantic/pull/7646)
* Fix json schema generation for recursive models by @adriangb in [#7653](https://github.com/pydantic/pydantic/pull/7653)
* Fix `models_json_schema` for generic models by @adriangb in [#7654](https://github.com/pydantic/pydantic/pull/7654)
* Fix xfailed test for generic model signatures by @adriangb in [#7658](https://github.com/pydantic/pydantic/pull/7658)

### New Contributors

* @austinorr made their first contribution in [#7657](https://github.com/pydantic/pydantic/pull/7657)
* @peterHoburg made their first contribution in [#7670](https://github.com/pydantic/pydantic/pull/7670)

## v2.4.1 (2023-09-26)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.4.1)

### What's Changed

#### Packaging

* Update pydantic-core to 2.10.1 by @davidhewitt in [#7633](https://github.com/pydantic/pydantic/pull/7633)

#### Fixes

* Serialize unsubstituted type vars as `Any` by @adriangb in [#7606](https://github.com/pydantic/pydantic/pull/7606)
* Remove schema building caches by @adriangb in [#7624](https://github.com/pydantic/pydantic/pull/7624)
* Fix an issue where JSON schema extras weren't JSON encoded by @dmontagu in [#7625](https://github.com/pydantic/pydantic/pull/7625)

## v2.4.0 (2023-09-22)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.4.0)

### What's Changed

#### Packaging

* Update pydantic-core to 2.10.0 by @samuelcolvin in [#7542](https://github.com/pydantic/pydantic/pull/7542)

#### New Features

* Add `Base64Url` types by @dmontagu in [#7286](https://github.com/pydantic/pydantic/pull/7286)
* Implement optional `number` to `str` coercion by @lig in [#7508](https://github.com/pydantic/pydantic/pull/7508)
* Allow access to `field_name` and `data` in all validators if there is data and a field name by @samuelcolvin in [#7542](https://github.com/pydantic/pydantic/pull/7542)
* Add `BaseModel.model_validate_strings` and `TypeAdapter.validate_strings` by @hramezani in [#7552](https://github.com/pydantic/pydantic/pull/7552)
* Add Pydantic `plugins` experimental implementation by @lig @samuelcolvin and @Kludex in [#6820](https://github.com/pydantic/pydantic/pull/6820)

#### Changes

* Do not override `model_post_init` in subclass with private attrs by @Viicos in [#7302](https://github.com/pydantic/pydantic/pull/7302)
* Make fields with defaults not required in the serialization schema by default by @dmontagu in [#7275](https://github.com/pydantic/pydantic/pull/7275)
* Mark `Extra` as deprecated by @disrupted in [#7299](https://github.com/pydantic/pydantic/pull/7299)
* Make `EncodedStr` a dataclass by @Kludex in [#7396](https://github.com/pydantic/pydantic/pull/7396)
* Move `annotated_handlers` to be public by @samuelcolvin in [#7569](https://github.com/pydantic/pydantic/pull/7569)

#### Performance

* Simplify flattening and inlining of `CoreSchema` by @adriangb in [#7523](https://github.com/pydantic/pydantic/pull/7523)
* Remove unused copies in `CoreSchema` walking by @adriangb in [#7528](https://github.com/pydantic/pydantic/pull/7528)
* Add caches for collecting definitions and invalid schemas from a CoreSchema by @adriangb in [#7527](https://github.com/pydantic/pydantic/pull/7527)
* Eagerly resolve discriminated unions and cache cases where we can't by @adriangb in [#7529](https://github.com/pydantic/pydantic/pull/7529)
* Replace `dict.get` and `dict.setdefault` with more verbose versions in `CoreSchema` building hot paths by @adriangb in [#7536](https://github.com/pydantic/pydantic/pull/7536)
* Cache invalid `CoreSchema` discovery by @adriangb in [#7535](https://github.com/pydantic/pydantic/pull/7535)
* Allow disabling `CoreSchema` validation for faster startup times by @adriangb in [#7565](https://github.com/pydantic/pydantic/pull/7565)

#### Fixes

* Fix config detection for `TypedDict` from grandparent classes by @dmontagu in [#7272](https://github.com/pydantic/pydantic/pull/7272)
* Fix hash function generation for frozen models with unusual MRO by @dmontagu in [#7274](https://github.com/pydantic/pydantic/pull/7274)
* Make `strict` config overridable in field for Path by @hramezani in [#7281](https://github.com/pydantic/pydantic/pull/7281)
* Use `ser_json_<timedelta|bytes>` on default in `GenerateJsonSchema` by @Kludex in [#7269](https://github.com/pydantic/pydantic/pull/7269)
* Adding a check that alias is validated as an identifier for Python by @andree0 in [#7319](https://github.com/pydantic/pydantic/pull/7319)
* Raise an error when computed field overrides field by @sydney-runkle in [#7346](https://github.com/pydantic/pydantic/pull/7346)
* Fix applying `SkipValidation` to referenced schemas by @adriangb in [#7381](https://github.com/pydantic/pydantic/pull/7381)
* Enforce behavior of private attributes having double leading underscore by @lig in [#7265](https://github.com/pydantic/pydantic/pull/7265)
* Standardize `__get_pydantic_core_schema__` signature by @hramezani in [#7415](https://github.com/pydantic/pydantic/pull/7415)
* Fix generic dataclass fields mutation bug (when using `TypeAdapter`) by @sydney-runkle in [#7435](https://github.com/pydantic/pydantic/pull/7435)
* Fix `TypeError` on `model_validator` in `wrap` mode by @pmmmwh in [#7496](https://github.com/pydantic/pydantic/pull/7496)
* Improve enum error message by @hramezani in [#7506](https://github.com/pydantic/pydantic/pull/7506)
* Make `repr` work for instances that failed initialization when handling `ValidationError`s by @dmontagu in [#7439](https://github.com/pydantic/pydantic/pull/7439)
* Fixed a regular expression denial of service issue by limiting whitespaces by @prodigysml in [#7360](https://github.com/pydantic/pydantic/pull/7360)
* Fix handling of `UUID` values having `UUID.version=None` by @lig in [#7566](https://github.com/pydantic/pydantic/pull/7566)
* Fix `__iter__` returning private `cached_property` info by @sydney-runkle in [#7570](https://github.com/pydantic/pydantic/pull/7570)
* Improvements to version info message by @samuelcolvin in [#7594](https://github.com/pydantic/pydantic/pull/7594)

### New Contributors

* @15498th made their first contribution in [#7238](https://github.com/pydantic/pydantic/pull/7238)
* @GabrielCappelli made their first contribution in [#7213](https://github.com/pydantic/pydantic/pull/7213)
* @tobni made their first contribution in [#7184](https://github.com/pydantic/pydantic/pull/7184)
* @redruin1 made their first contribution in [#7282](https://github.com/pydantic/pydantic/pull/7282)
* @FacerAin made their first contribution in [#7288](https://github.com/pydantic/pydantic/pull/7288)
* @acdha made their first contribution in [#7297](https://github.com/pydantic/pydantic/pull/7297)
* @andree0 made their first contribution in [#7319](https://github.com/pydantic/pydantic/pull/7319)
* @gordonhart made their first contribution in [#7375](https://github.com/pydantic/pydantic/pull/7375)
* @pmmmwh made their first contribution in [#7496](https://github.com/pydantic/pydantic/pull/7496)
* @disrupted made their first contribution in [#7299](https://github.com/pydantic/pydantic/pull/7299)
* @prodigysml made their first contribution in [#7360](https://github.com/pydantic/pydantic/pull/7360)

## v2.3.0 (2023-08-23)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.3.0)

* 🔥 Remove orphaned changes file from repo by @lig in [#7168](https://github.com/pydantic/pydantic/pull/7168)
* Add copy button on documentation by @Kludex in [#7190](https://github.com/pydantic/pydantic/pull/7190)
* Fix docs on JSON type by @Kludex in [#7189](https://github.com/pydantic/pydantic/pull/7189)
* Update mypy 1.5.0 to 1.5.1 in CI by @hramezani in [#7191](https://github.com/pydantic/pydantic/pull/7191)
* fix download links badge by @samuelcolvin in [#7200](https://github.com/pydantic/pydantic/pull/7200)
* add 2.2.1 to changelog by @samuelcolvin in [#7212](https://github.com/pydantic/pydantic/pull/7212)
* Make ModelWrapValidator protocols generic by @dmontagu in [#7154](https://github.com/pydantic/pydantic/pull/7154)
* Correct `Field(..., exclude: bool)` docs by @samuelcolvin in [#7214](https://github.com/pydantic/pydantic/pull/7214)
* Make shadowing attributes a warning instead of an error by @adriangb in [#7193](https://github.com/pydantic/pydantic/pull/7193)
* Document `Base64Str` and `Base64Bytes` by @Kludex in [#7192](https://github.com/pydantic/pydantic/pull/7192)
* Fix `config.defer_build` for serialization first cases by @samuelcolvin in [#7024](https://github.com/pydantic/pydantic/pull/7024)
* clean Model docstrings in JSON Schema by @samuelcolvin in [#7210](https://github.com/pydantic/pydantic/pull/7210)
* fix [#7228](https://github.com/pydantic/pydantic/pull/7228) (typo): docs in `validators.md` to correct `validate_default` kwarg by @lmmx in [#7229](https://github.com/pydantic/pydantic/pull/7229)
* ✅ Implement `tzinfo.fromutc` method for `TzInfo` in `pydantic-core` by @lig in [#7019](https://github.com/pydantic/pydantic/pull/7019)
* Support `__get_validators__` by @hramezani in [#7197](https://github.com/pydantic/pydantic/pull/7197)

## v2.2.1 (2023-08-18)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.2.1)

* Make `xfail`ing test for root model extra stop `xfail`ing by @dmontagu in [#6937](https://github.com/pydantic/pydantic/pull/6937)
* Optimize recursion detection by stopping on the second visit for the same object by @mciucu in [#7160](https://github.com/pydantic/pydantic/pull/7160)
* fix link in docs by @tlambert03 in [#7166](https://github.com/pydantic/pydantic/pull/7166)
* Replace MiMalloc w/ default allocator by @adriangb in [pydantic/pydantic-core#900](https://github.com/pydantic/pydantic-core/pull/900)
* Bump pydantic-core to 2.6.1 and prepare 2.2.1 release by @adriangb in [#7176](https://github.com/pydantic/pydantic/pull/7176)

## v2.2.0 (2023-08-17)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.2.0)

* Split "pipx install" setup command into two commands on the documentation site by @nomadmtb in [#6869](https://github.com/pydantic/pydantic/pull/6869)
* Deprecate `Field.include` by @hramezani in [#6852](https://github.com/pydantic/pydantic/pull/6852)
* Fix typo in default factory error msg by @hramezani in [#6880](https://github.com/pydantic/pydantic/pull/6880)
* Simplify handling of typing.Annotated in GenerateSchema by @dmontagu in [#6887](https://github.com/pydantic/pydantic/pull/6887)
* Re-enable fastapi tests in CI by @dmontagu in [#6883](https://github.com/pydantic/pydantic/pull/6883)
* Make it harder to hit collisions with json schema defrefs by @dmontagu in [#6566](https://github.com/pydantic/pydantic/pull/6566)
* Cleaner error for invalid input to `Path` fields by @samuelcolvin in [#6903](https://github.com/pydantic/pydantic/pull/6903)
* :memo: support Coordinate Type by @yezz123 in [#6906](https://github.com/pydantic/pydantic/pull/6906)
* Fix `ForwardRef` wrapper for py 3.10.0 (shim until bpo-45166) by @randomir in [#6919](https://github.com/pydantic/pydantic/pull/6919)
* Fix misbehavior related to copying of RootModel by @dmontagu in [#6918](https://github.com/pydantic/pydantic/pull/6918)
* Fix issue with recursion error caused by ParamSpec by @dmontagu in [#6923](https://github.com/pydantic/pydantic/pull/6923)
* Add section about Constrained classes to the Migration Guide by @Kludex in [#6924](https://github.com/pydantic/pydantic/pull/6924)
* Use `main` branch for badge links by @Viicos in [#6925](https://github.com/pydantic/pydantic/pull/6925)
* Add test for v1/v2 Annotated discrepancy by @carlbordum in [#6926](https://github.com/pydantic/pydantic/pull/6926)
* Make the v1 mypy plugin work with both v1 and v2 by @dmontagu in [#6921](https://github.com/pydantic/pydantic/pull/6921)
* Fix issue where generic models couldn't be parametrized with BaseModel by @dmontagu in [#6933](https://github.com/pydantic/pydantic/pull/6933)
* Remove xfail for discriminated union with alias by @dmontagu in [#6938](https://github.com/pydantic/pydantic/pull/6938)
* add field_serializer to computed_field by @andresliszt in [#6965](https://github.com/pydantic/pydantic/pull/6965)
* Use union_schema with Type[Union[...]] by @JeanArhancet in [#6952](https://github.com/pydantic/pydantic/pull/6952)
* Fix inherited typeddict attributes / config by @adriangb in [#6981](https://github.com/pydantic/pydantic/pull/6981)
* fix dataclass annotated before validator called twice by @davidhewitt in [#6998](https://github.com/pydantic/pydantic/pull/6998)
* Update test-fastapi deselected tests by @hramezani in [#7014](https://github.com/pydantic/pydantic/pull/7014)
* Fix validator doc format by @hramezani in [#7015](https://github.com/pydantic/pydantic/pull/7015)
* Fix typo in docstring of model_json_schema by @AdamVinch-Federated in [#7032](https://github.com/pydantic/pydantic/pull/7032)
* remove unused "type ignores" with pyright by @samuelcolvin in [#7026](https://github.com/pydantic/pydantic/pull/7026)
* Add benchmark representing FastAPI startup time by @adriangb in [#7030](https://github.com/pydantic/pydantic/pull/7030)
* Fix json_encoders for Enum subclasses by @adriangb in [#7029](https://github.com/pydantic/pydantic/pull/7029)
* Update docstring of `ser_json_bytes` regarding base64 encoding by @Viicos in [#7052](https://github.com/pydantic/pydantic/pull/7052)
* Allow `@validate_call` to work on async methods by @adriangb in [#7046](https://github.com/pydantic/pydantic/pull/7046)
* Fix: mypy error with `Settings` and `SettingsConfigDict` by @JeanArhancet in [#7002](https://github.com/pydantic/pydantic/pull/7002)
* Fix some typos (repeated words and it's/its) by @eumiro in [#7063](https://github.com/pydantic/pydantic/pull/7063)
* Fix the typo in docstring by @harunyasar in [#7062](https://github.com/pydantic/pydantic/pull/7062)
* Docs: Fix broken URL in the pydantic-settings package recommendation by @swetjen in [#6995](https://github.com/pydantic/pydantic/pull/6995)
* Handle constraints being applied to schemas that don't accept it by @adriangb in [#6951](https://github.com/pydantic/pydantic/pull/6951)
* Replace almost_equal_floats with math.isclose by @eumiro in [#7082](https://github.com/pydantic/pydantic/pull/7082)
* bump pydantic-core to 2.5.0 by @davidhewitt in [#7077](https://github.com/pydantic/pydantic/pull/7077)
* Add `short_version` and use it in links by @hramezani in [#7115](https://github.com/pydantic/pydantic/pull/7115)
* 📝 Add usage link to `RootModel` by @Kludex in [#7113](https://github.com/pydantic/pydantic/pull/7113)
* Revert "Fix default port for mongosrv DSNs (#6827)" by @Kludex in [#7116](https://github.com/pydantic/pydantic/pull/7116)
<!-- markdownlint-disable-next-line no-space-in-emphasis -->
* Clarify validate_default and _Unset handling in usage docs and migration guide by @benbenbang in [#6950](https://github.com/pydantic/pydantic/pull/6950)
* Tweak documentation of `Field.exclude` by @Viicos in [#7086](https://github.com/pydantic/pydantic/pull/7086)
* Do not require `validate_assignment` to use `Field.frozen` by @Viicos in [#7103](https://github.com/pydantic/pydantic/pull/7103)
* tweaks to `_core_utils` by @samuelcolvin in [#7040](https://github.com/pydantic/pydantic/pull/7040)
* Make DefaultDict working with set by @hramezani in [#7126](https://github.com/pydantic/pydantic/pull/7126)
* Don't always require typing.Generic as a base for partially parametrized models by @dmontagu in [#7119](https://github.com/pydantic/pydantic/pull/7119)
* Fix issue with JSON schema incorrectly using parent class core schema by @dmontagu in [#7020](https://github.com/pydantic/pydantic/pull/7020)
* Fix xfailed test related to TypedDict and alias_generator by @dmontagu in [#6940](https://github.com/pydantic/pydantic/pull/6940)
* Improve error message for NameEmail by @dmontagu in [#6939](https://github.com/pydantic/pydantic/pull/6939)
* Fix generic computed fields by @dmontagu in [#6988](https://github.com/pydantic/pydantic/pull/6988)
* Reflect namedtuple default values during validation by @dmontagu in [#7144](https://github.com/pydantic/pydantic/pull/7144)
* Update dependencies, fix pydantic-core usage, fix CI issues by @dmontagu in [#7150](https://github.com/pydantic/pydantic/pull/7150)
* Add mypy 1.5.0 by @hramezani in [#7118](https://github.com/pydantic/pydantic/pull/7118)
* Handle non-json native enum values by @adriangb in [#7056](https://github.com/pydantic/pydantic/pull/7056)
* document `round_trip` in Json type documentation  by @jc-louis in [#7137](https://github.com/pydantic/pydantic/pull/7137)
* Relax signature checks to better support builtins and C extension functions as validators by @adriangb in [#7101](https://github.com/pydantic/pydantic/pull/7101)
* add union_mode='left_to_right' by @davidhewitt in [#7151](https://github.com/pydantic/pydantic/pull/7151)
* Include an error message hint for inherited ordering by @yvalencia91 in [#7124](https://github.com/pydantic/pydantic/pull/7124)
* Fix one docs link and resolve some warnings for two others by @dmontagu in [#7153](https://github.com/pydantic/pydantic/pull/7153)
* Include Field extra keys name in warning by @hramezani in [#7136](https://github.com/pydantic/pydantic/pull/7136)

## v2.1.1 (2023-07-25)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.1.1)

* Skip FieldInfo merging when unnecessary by @dmontagu in [#6862](https://github.com/pydantic/pydantic/pull/6862)

## v2.1.0 (2023-07-25)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.1.0)

* Add `StringConstraints` for use as Annotated metadata by @adriangb in [#6605](https://github.com/pydantic/pydantic/pull/6605)
* Try to fix intermittently failing CI by @adriangb in [#6683](https://github.com/pydantic/pydantic/pull/6683)
* Remove redundant example of optional vs default. by @ehiggs-deliverect in [#6676](https://github.com/pydantic/pydantic/pull/6676)
* Docs update by @samuelcolvin in [#6692](https://github.com/pydantic/pydantic/pull/6692)
* Remove the Validate always section in validator docs by @adriangb in [#6679](https://github.com/pydantic/pydantic/pull/6679)
* Fix recursion error in json schema generation by @adriangb in [#6720](https://github.com/pydantic/pydantic/pull/6720)
* Fix incorrect subclass check for secretstr by @AlexVndnblcke in [#6730](https://github.com/pydantic/pydantic/pull/6730)
* update pdm / pdm lockfile to 2.8.0 by @davidhewitt in [#6714](https://github.com/pydantic/pydantic/pull/6714)
* unpin pdm on more CI jobs by @davidhewitt in [#6755](https://github.com/pydantic/pydantic/pull/6755)
* improve source locations for auxiliary packages in docs by @davidhewitt in [#6749](https://github.com/pydantic/pydantic/pull/6749)
* Assume builtins don't accept an info argument by @adriangb in [#6754](https://github.com/pydantic/pydantic/pull/6754)
* Fix bug where calling `help(BaseModelSubclass)` raises errors by @hramezani in [#6758](https://github.com/pydantic/pydantic/pull/6758)
* Fix mypy plugin handling of `@model_validator(mode="after")` by @ljodal in [#6753](https://github.com/pydantic/pydantic/pull/6753)
* update pydantic-core to 2.3.1 by @davidhewitt in [#6756](https://github.com/pydantic/pydantic/pull/6756)
* Mypy plugin for settings by @hramezani in [#6760](https://github.com/pydantic/pydantic/pull/6760)
* Use `contentSchema` keyword for JSON schema by @dmontagu in [#6715](https://github.com/pydantic/pydantic/pull/6715)
* fast-path checking finite decimals by @davidhewitt in [#6769](https://github.com/pydantic/pydantic/pull/6769)
* Docs update by @samuelcolvin in [#6771](https://github.com/pydantic/pydantic/pull/6771)
* Improve json schema doc by @hramezani in [#6772](https://github.com/pydantic/pydantic/pull/6772)
* Update validator docs by @adriangb in [#6695](https://github.com/pydantic/pydantic/pull/6695)
* Fix typehint for wrap validator by @dmontagu in [#6788](https://github.com/pydantic/pydantic/pull/6788)
* 🐛 Fix validation warning for unions of Literal and other type by @lig in [#6628](https://github.com/pydantic/pydantic/pull/6628)
* Update documentation for generics support in V2 by @tpdorsey in [#6685](https://github.com/pydantic/pydantic/pull/6685)
* add pydantic-core build info to `version_info()` by @samuelcolvin in [#6785](https://github.com/pydantic/pydantic/pull/6785)
* Fix pydantic dataclasses that use slots with default values by @dmontagu in [#6796](https://github.com/pydantic/pydantic/pull/6796)
* Fix inheritance of hash function for frozen models by @dmontagu in [#6789](https://github.com/pydantic/pydantic/pull/6789)
* ✨ Add `SkipJsonSchema` annotation by @Kludex in [#6653](https://github.com/pydantic/pydantic/pull/6653)
* Error if an invalid field name is used with Field by @dmontagu in [#6797](https://github.com/pydantic/pydantic/pull/6797)
* Add `GenericModel` to `MOVED_IN_V2` by @adriangb in [#6776](https://github.com/pydantic/pydantic/pull/6776)
* Remove unused code from `docs/usage/types/custom.md` by @hramezani in [#6803](https://github.com/pydantic/pydantic/pull/6803)
* Fix `float` -> `Decimal` coercion precision loss by @adriangb in [#6810](https://github.com/pydantic/pydantic/pull/6810)
* remove email validation from the north star benchmark by @davidhewitt in [#6816](https://github.com/pydantic/pydantic/pull/6816)
* Fix link to mypy by @progsmile in [#6824](https://github.com/pydantic/pydantic/pull/6824)
* Improve initialization hooks example by @hramezani in [#6822](https://github.com/pydantic/pydantic/pull/6822)
* Fix default port for mongosrv DSNs by @dmontagu in [#6827](https://github.com/pydantic/pydantic/pull/6827)
* Improve API documentation, in particular more links between usage and API docs by @samuelcolvin in [#6780](https://github.com/pydantic/pydantic/pull/6780)
* update pydantic-core to 2.4.0 by @davidhewitt in [#6831](https://github.com/pydantic/pydantic/pull/6831)
* Fix `annotated_types.MaxLen` validator for custom sequence types by @ImogenBits in [#6809](https://github.com/pydantic/pydantic/pull/6809)
* Update V1 by @hramezani in [#6833](https://github.com/pydantic/pydantic/pull/6833)
* Make it so callable JSON schema extra works by @dmontagu in [#6798](https://github.com/pydantic/pydantic/pull/6798)
* Fix serialization issue with `InstanceOf` by @dmontagu in [#6829](https://github.com/pydantic/pydantic/pull/6829)
* Add back support for `json_encoders` by @adriangb in [#6811](https://github.com/pydantic/pydantic/pull/6811)
* Update field annotations when building the schema by @dmontagu in [#6838](https://github.com/pydantic/pydantic/pull/6838)
* Use `WeakValueDictionary` to fix generic memory leak by @dmontagu in [#6681](https://github.com/pydantic/pydantic/pull/6681)
* Add `config.defer_build` to optionally make model building lazy by @samuelcolvin in [#6823](https://github.com/pydantic/pydantic/pull/6823)
* delegate `UUID` serialization to pydantic-core by @davidhewitt in [#6850](https://github.com/pydantic/pydantic/pull/6850)
* Update `json_encoders` docs by @adriangb in [#6848](https://github.com/pydantic/pydantic/pull/6848)
* Fix error message for `staticmethod`/`classmethod` order with validate_call by @dmontagu in [#6686](https://github.com/pydantic/pydantic/pull/6686)
* Improve documentation for `Config` by @samuelcolvin in [#6847](https://github.com/pydantic/pydantic/pull/6847)
* Update serialization doc to mention `Field.exclude` takes priority over call-time `include/exclude` by @hramezani in [#6851](https://github.com/pydantic/pydantic/pull/6851)
* Allow customizing core schema generation by making `GenerateSchema` public by @adriangb in [#6737](https://github.com/pydantic/pydantic/pull/6737)

## v2.0.3 (2023-07-05)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.0.3)

* Mention PyObject (v1) moving to ImportString (v2) in migration doc by @slafs in [#6456](https://github.com/pydantic/pydantic/pull/6456)
* Fix release-tweet CI by @Kludex in [#6461](https://github.com/pydantic/pydantic/pull/6461)
* Revise the section on required / optional / nullable fields. by @ybressler in [#6468](https://github.com/pydantic/pydantic/pull/6468)
* Warn if a type hint is not in fact a type by @adriangb in [#6479](https://github.com/pydantic/pydantic/pull/6479)
* Replace TransformSchema with GetPydanticSchema by @dmontagu in [#6484](https://github.com/pydantic/pydantic/pull/6484)
* Fix the un-hashability of various annotation types, for use in caching generic containers by @dmontagu in [#6480](https://github.com/pydantic/pydantic/pull/6480)
* PYD-164: Rework custom types docs by @adriangb in [#6490](https://github.com/pydantic/pydantic/pull/6490)
* Fix ci by @adriangb in [#6507](https://github.com/pydantic/pydantic/pull/6507)
* Fix forward ref in generic by @adriangb in [#6511](https://github.com/pydantic/pydantic/pull/6511)
* Fix generation of serialization JSON schemas for core_schema.ChainSchema by @dmontagu in [#6515](https://github.com/pydantic/pydantic/pull/6515)
* Document the change in `Field.alias` behavior in Pydantic V2 by @hramezani in [#6508](https://github.com/pydantic/pydantic/pull/6508)
* Give better error message attempting to compute the json schema of a model with undefined fields by @dmontagu in [#6519](https://github.com/pydantic/pydantic/pull/6519)
* Document `alias_priority` by @tpdorsey in [#6520](https://github.com/pydantic/pydantic/pull/6520)
* Add redirect for types documentation by @tpdorsey in [#6513](https://github.com/pydantic/pydantic/pull/6513)
* Allow updating docs without release by @samuelcolvin in [#6551](https://github.com/pydantic/pydantic/pull/6551)
* Ensure docs tests always run in the right folder by @dmontagu in [#6487](https://github.com/pydantic/pydantic/pull/6487)
* Defer evaluation of return type hints for serializer functions by @dmontagu in [#6516](https://github.com/pydantic/pydantic/pull/6516)
* Disable E501 from Ruff and rely on just Black by @adriangb in [#6552](https://github.com/pydantic/pydantic/pull/6552)
* Update JSON Schema documentation for V2 by @tpdorsey in [#6492](https://github.com/pydantic/pydantic/pull/6492)
* Add documentation of cyclic reference handling by @dmontagu in [#6493](https://github.com/pydantic/pydantic/pull/6493)
* Remove the need for change files by @samuelcolvin in [#6556](https://github.com/pydantic/pydantic/pull/6556)
* add "north star" benchmark by @davidhewitt in [#6547](https://github.com/pydantic/pydantic/pull/6547)
* Update Dataclasses docs by @tpdorsey in [#6470](https://github.com/pydantic/pydantic/pull/6470)
* ♻️ Use different error message on v1 redirects by @Kludex in [#6595](https://github.com/pydantic/pydantic/pull/6595)
* ⬆ Upgrade `pydantic-core` to v2.2.0 by @lig in [#6589](https://github.com/pydantic/pydantic/pull/6589)
* Fix serialization for IPvAny by @dmontagu in [#6572](https://github.com/pydantic/pydantic/pull/6572)
* Improve CI by using PDM instead of pip to install typing-extensions by @adriangb in [#6602](https://github.com/pydantic/pydantic/pull/6602)
* Add `enum` error type docs  by @lig in [#6603](https://github.com/pydantic/pydantic/pull/6603)
* 🐛 Fix `max_length` for unicode strings by @lig in [#6559](https://github.com/pydantic/pydantic/pull/6559)
* Add documentation for accessing features via `pydantic.v1` by @tpdorsey in [#6604](https://github.com/pydantic/pydantic/pull/6604)
* Include extra when iterating over a model by @adriangb in [#6562](https://github.com/pydantic/pydantic/pull/6562)
* Fix typing of model_validator by @adriangb in [#6514](https://github.com/pydantic/pydantic/pull/6514)
* Touch up Decimal validator by @adriangb in [#6327](https://github.com/pydantic/pydantic/pull/6327)
* Fix various docstrings using fixed pytest-examples by @dmontagu in [#6607](https://github.com/pydantic/pydantic/pull/6607)
* Handle function validators in a discriminated union by @dmontagu in [#6570](https://github.com/pydantic/pydantic/pull/6570)
* Review json_schema.md by @tpdorsey in [#6608](https://github.com/pydantic/pydantic/pull/6608)
* Make validate_call work on basemodel methods by @dmontagu in [#6569](https://github.com/pydantic/pydantic/pull/6569)
* add test for big int json serde by @davidhewitt in [#6614](https://github.com/pydantic/pydantic/pull/6614)
* Fix pydantic dataclass problem with dataclasses.field default_factory by @hramezani in [#6616](https://github.com/pydantic/pydantic/pull/6616)
* Fixed mypy type inference for TypeAdapter by @zakstucke in [#6617](https://github.com/pydantic/pydantic/pull/6617)
* Make it work to use None as a generic parameter by @dmontagu in [#6609](https://github.com/pydantic/pydantic/pull/6609)
* Make it work to use `$ref` as an alias by @dmontagu in [#6568](https://github.com/pydantic/pydantic/pull/6568)
* add note to migration guide about changes to `AnyUrl` etc by @davidhewitt in [#6618](https://github.com/pydantic/pydantic/pull/6618)
* 🐛 Support defining `json_schema_extra` on `RootModel` using `Field` by @lig in [#6622](https://github.com/pydantic/pydantic/pull/6622)
* Update pre-commit to prevent commits to main branch on accident by @dmontagu in [#6636](https://github.com/pydantic/pydantic/pull/6636)
* Fix PDM CI for python 3.7 on MacOS/windows by @dmontagu in [#6627](https://github.com/pydantic/pydantic/pull/6627)
* Produce more accurate signatures for pydantic dataclasses by @dmontagu in [#6633](https://github.com/pydantic/pydantic/pull/6633)
* Updates to Url types for Pydantic V2 by @tpdorsey in [#6638](https://github.com/pydantic/pydantic/pull/6638)
* Fix list markdown in `transform` docstring by @StefanBRas in [#6649](https://github.com/pydantic/pydantic/pull/6649)
* simplify slots_dataclass construction to appease mypy by @davidhewitt in [#6639](https://github.com/pydantic/pydantic/pull/6639)
* Update TypedDict schema generation docstring by @adriangb in [#6651](https://github.com/pydantic/pydantic/pull/6651)
* Detect and lint-error for prints by @dmontagu in [#6655](https://github.com/pydantic/pydantic/pull/6655)
* Add xfailing test for pydantic-core PR 766 by @dmontagu in [#6641](https://github.com/pydantic/pydantic/pull/6641)
* Ignore unrecognized fields from dataclasses metadata by @dmontagu in [#6634](https://github.com/pydantic/pydantic/pull/6634)
* Make non-existent class getattr a mypy error by @dmontagu in [#6658](https://github.com/pydantic/pydantic/pull/6658)
* Update pydantic-core to 2.3.0 by @hramezani in [#6648](https://github.com/pydantic/pydantic/pull/6648)
* Use OrderedDict from typing_extensions by @dmontagu in [#6664](https://github.com/pydantic/pydantic/pull/6664)
* Fix typehint for JSON schema extra callable by @dmontagu in [#6659](https://github.com/pydantic/pydantic/pull/6659)

## v2.0.2 (2023-07-05)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.0.2)

* Fix bug where round-trip pickling/unpickling a `RootModel` would change the value of `__dict__`, [#6457](https://github.com/pydantic/pydantic/pull/6457) by @dmontagu
* Allow single-item discriminated unions, [#6405](https://github.com/pydantic/pydantic/pull/6405) by @dmontagu
* Fix issue with union parsing of enums, [#6440](https://github.com/pydantic/pydantic/pull/6440) by @dmontagu
* Docs: Fixed `constr` documentation, renamed old `regex` to new `pattern`, [#6452](https://github.com/pydantic/pydantic/pull/6452) by @miili
* Change `GenerateJsonSchema.generate_definitions` signature, [#6436](https://github.com/pydantic/pydantic/pull/6436) by @dmontagu

See the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0.2)

## v2.0.1 (2023-07-04)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.0.1)

First patch release of Pydantic V2

* Extra fields added via `setattr` (i.e. `m.some_extra_field = 'extra_value'`)
  are added to `.model_extra` if `model_config` `extra='allowed'`. Fixed [#6333](https://github.com/pydantic/pydantic/pull/6333), [#6365](https://github.com/pydantic/pydantic/pull/6365) by @aaraney
* Automatically unpack JSON schema '$ref' for custom types, [#6343](https://github.com/pydantic/pydantic/pull/6343) by @adriangb
* Fix tagged unions multiple processing in submodels, [#6340](https://github.com/pydantic/pydantic/pull/6340) by @suharnikov

See the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0.1)

## v2.0 (2023-06-30)

[GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.0)

Pydantic V2 is here! :tada:

See [this post](https://docs.pydantic.dev/2.0/blog/pydantic-v2-final/) for more details.

## v2.0b3 (2023-06-16)

Third beta pre-release of Pydantic V2

See the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0b3)

## v2.0b2 (2023-06-03)

Add `from_attributes` runtime flag to `TypeAdapter.validate_python` and `BaseModel.model_validate`.

See the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0b2)

## v2.0b1 (2023-06-01)

First beta pre-release of Pydantic V2

See the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0b1)

## v2.0a4 (2023-05-05)

Fourth pre-release of Pydantic V2

See the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0a4)

## v2.0a3 (2023-04-20)

Third pre-release of Pydantic V2

See the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0a3)

## v2.0a2 (2023-04-12)

Second pre-release of Pydantic V2

See the full changelog [here](https://github.com/pydantic/pydantic/releases/tag/v2.0a2)

## v2.0a1 (2023-04-03)

First pre-release of Pydantic V2!

See [this post](https://docs.pydantic.dev/blog/pydantic-v2-alpha/) for more details.

## v1.10.24 (2025-09-25)

* Add user warning when using Python 3.14 by @Viicos in https://github.com/pydantic/pydantic/pull/12263
  Pydantic V1 will *not* work with Python 3.14 and greater. A warning is now raised as no actual
  error show up when using it, but the core behavior will silently get broken at runtime.
* Fix mypy plugin issue for mypy v1.18 by @cdce8p in https://github.com/pydantic/pydantic/pull/12254
  This fixes another mypy issue that was discovered after the previous v1.10.23 release.

## v1.10.23 (2025-09-13)

* Fix mypy plugin for mypy 1.18 by @cdce8p in https://github.com/pydantic/pydantic/pull/12207

## v1.10.22 (2025-04-17)

* Fix compatibility with `typing-extensions` by @Viicos in https://github.com/pydantic/pydantic/pull/11764

## v1.10.21 (2025-01-10)

* Fix compatibility with ForwardRef._evaluate and Python < 3.12.4 by @griels in https://github.com/pydantic/pydantic/pull/11232

## v1.10.20 (2025-01-07)

This release provides proper support for Python 3.13, with (Cythonized) wheels published for this version.
As a consequence, Cython was updated from `0.29.x` to `3.0.x`.

* General maintenance of CI and build ecosystem by @Viicos in https://github.com/pydantic/pydantic/pull/10847
    * Update Cython to `3.0.x`.
    * Properly address Python 3.13 deprecation warnings.
    * Migrate packaging to `pyproject.toml`, make use of PEP 517 build options.
    * Use [`build`](https://pypi.org/project/build/) instead of direct `setup.py` invocations.
    * Update various Github Actions versions.
* Replace outdated stpmex link in documentation by @jaredenorris in https://github.com/pydantic/pydantic/pull/10997

## v1.10.19 (2024-11-06)

* Add warning when v2 model is nested in v1 model by @sydney-runkle in https://github.com/pydantic/pydantic/pull/10432
* Fix deprecation warning in V1 `isinstance` check by @alicederyn in https://github.com/pydantic/pydantic/pull/10645

## v1.10.18 (2024-08-22)

* Eval type fix in V1 by @sydney-runkle in https://github.com/pydantic/pydantic/pull/9751
* Add `to_lower_camel` to `__all__` in `utils.py` by @sydney-runkle (direct commit)
* Fix `mypy` v1 plugin for mypy 1.11 release by @flaeppe in https://github.com/pydantic/pydantic/pull/10139
* Fix discriminator key used when discriminator has alias and `.schema(by_alias=False)` by @exs-dwoodward in https://github.com/pydantic/pydantic/pull/10146

## v1.10.17 (2024-06-20)

* Advertise Python 3.12 for 1.10.x! Part Deux by @vfazio in https://github.com/pydantic/pydantic/pull/9644
* Mirrored modules in `v1` namespace to fix typing and object resolution in python>3.11 by @exs-dwoodward in https://github.com/pydantic/pydantic/pull/9660
* setup: remove upper bound from python_requires by @vfazio in https://github.com/pydantic/pydantic/pull/9685

## v1.10.16 (2024-06-11)

* Specify recursive_guard as kwarg in FutureRef._evaluate by @vfazio in https://github.com/pydantic/pydantic/pull/9612
* Fix mypy v1 plugin for upcoming mypy release by @ cdce8p in https://github.com/pydantic/pydantic/pull/9586
* Import modules/objects directly from v1 namespace by @exs-dwoodward in https://github.com/pydantic/pydantic/pull/9162

## v1.10.15 (2024-04-03)

* Add pydantic.v1 namespace to Pydantic v1 by @exs-dmiketa in https://github.com/pydantic/pydantic/pull/9042
* Relax version of typing-extensions for V1 by @SonOfLilit in https://github.com/pydantic/pydantic/pull/8819
* patch fix for mypy by @sydney-runkle in https://github.com/pydantic/pydantic/pull/8765

## v1.10.14 (2024-01-19)

* Update install.md by @dmontagu in #7690
* Fix ci to only deploy docs on release by @sydney-runkle in #7740
* Ubuntu fixes for V1 by @sydney-runkle in #8540 and #8587
* Fix cached_property handling in dataclasses when copied by @rdbisme in #8407

## v1.10.13 (2023-09-27)

* Fix: Add max length check to `pydantic.validate_email`, #7673 by @hramezani
* Docs: Fix pip commands to install v1, #6930 by @chbndrhnns

## v1.10.12 (2023-07-24)

* Fixes the `maxlen` property being dropped on `deque` validation. Happened only if the deque item has been typed. Changes the `_validate_sequence_like` func, [#6581](https://github.com/pydantic/pydantic/pull/6581) by @maciekglowka

## v1.10.11 (2023-07-04)

* Importing create_model in tools.py through relative path instead of absolute path - so that it doesn't import V2 code when copied over to V2 branch, [#6361](https://github.com/pydantic/pydantic/pull/6361) by @SharathHuddar

## v1.10.10 (2023-06-30)

* Add Pydantic `Json` field support to settings management, [#6250](https://github.com/pydantic/pydantic/pull/6250) by @hramezani
* Fixed literal validator errors for unhashable values, [#6188](https://github.com/pydantic/pydantic/pull/6188) by @markus1978
* Fixed bug with generics receiving forward refs, [#6130](https://github.com/pydantic/pydantic/pull/6130) by @mark-todd
* Update install method of FastAPI for internal tests in CI, [#6117](https://github.com/pydantic/pydantic/pull/6117) by @Kludex

## v1.10.9 (2023-06-07)

* Fix trailing zeros not ignored in Decimal validation, [#5968](https://github.com/pydantic/pydantic/pull/5968) by @hramezani
* Fix mypy plugin for v1.4.0, [#5928](https://github.com/pydantic/pydantic/pull/5928) by @cdce8p
* Add future and past date hypothesis strategies, [#5850](https://github.com/pydantic/pydantic/pull/5850) by @bschoenmaeckers
* Discourage usage of Cython 3 with Pydantic 1.x, [#5845](https://github.com/pydantic/pydantic/pull/5845) by @lig

## v1.10.8 (2023-05-23)

* Fix a bug in `Literal` usage with `typing-extension==4.6.0`, [#5826](https://github.com/pydantic/pydantic/pull/5826) by @hramezani
* This solves the (closed) issue [#3849](https://github.com/pydantic/pydantic/pull/3849) where aliased fields that use discriminated union fail to validate when the data contains the non-aliased field name, [#5736](https://github.com/pydantic/pydantic/pull/5736) by @benwah
* Update email-validator dependency to >=2.0.0post2, [#5627](https://github.com/pydantic/pydantic/pull/5627) by @adriangb
* update `AnyClassMethod` for changes in [python/typeshed#9771](https://github.com/python/typeshed/issues/9771), [#5505](https://github.com/pydantic/pydantic/pull/5505) by @ITProKyle

## v1.10.7 (2023-03-22)

* Fix creating schema from model using `ConstrainedStr` with `regex` as dict key, [#5223](https://github.com/pydantic/pydantic/pull/5223) by @matejetz
* Address bug in mypy plugin caused by explicit_package_bases=True, [#5191](https://github.com/pydantic/pydantic/pull/5191) by @dmontagu
* Add implicit defaults in the mypy plugin for Field with no default argument, [#5190](https://github.com/pydantic/pydantic/pull/5190) by @dmontagu
* Fix schema generated for Enum values used as Literals in discriminated unions, [#5188](https://github.com/pydantic/pydantic/pull/5188) by @javibookline
* Fix mypy failures caused by the pydantic mypy plugin when users define `from_orm` in their own classes, [#5187](https://github.com/pydantic/pydantic/pull/5187) by @dmontagu
* Fix `InitVar` usage with pydantic dataclasses, mypy version `1.1.1` and the custom mypy plugin, [#5162](https://github.com/pydantic/pydantic/pull/5162) by @cdce8p

## v1.10.6 (2023-03-08)

* Implement logic to support creating validators from non standard callables by using defaults to identify them and unwrapping `functools.partial` and `functools.partialmethod` when checking the signature, [#5126](https://github.com/pydantic/pydantic/pull/5126) by @JensHeinrich
* Fix mypy plugin for v1.1.1, and fix `dataclass_transform` decorator for pydantic dataclasses, [#5111](https://github.com/pydantic/pydantic/pull/5111) by @cdce8p
* Raise `ValidationError`, not `ConfigError`, when a discriminator value is unhashable, [#4773](https://github.com/pydantic/pydantic/pull/4773) by @kurtmckee

## v1.10.5 (2023-02-15)

* Fix broken parametrized bases handling with `GenericModel`s with complex sets of models, [#5052](https://github.com/pydantic/pydantic/pull/5052) by @MarkusSintonen
* Invalidate mypy cache if plugin config changes, [#5007](https://github.com/pydantic/pydantic/pull/5007) by @cdce8p
* Fix `RecursionError` when deep-copying dataclass types wrapped by pydantic, [#4949](https://github.com/pydantic/pydantic/pull/4949) by @mbillingr
* Fix `X | Y` union syntax breaking `GenericModel`, [#4146](https://github.com/pydantic/pydantic/pull/4146) by @thenx
* Switch coverage badge to show coverage for this branch/release, [#5060](https://github.com/pydantic/pydantic/pull/5060) by @samuelcolvin

## v1.10.4 (2022-12-30)

* Change dependency to `typing-extensions>=4.2.0`, [#4885](https://github.com/pydantic/pydantic/pull/4885) by @samuelcolvin

## v1.10.3 (2022-12-29)

**NOTE: v1.10.3 was ["yanked"](https://pypi.org/help/#yanked) from PyPI due to [#4885](https://github.com/pydantic/pydantic/pull/4885) which is fixed in v1.10.4**

* fix parsing of custom root models, [#4883](https://github.com/pydantic/pydantic/pull/4883) by @gou177
* fix: use dataclass proxy for frozen or empty dataclasses, [#4878](https://github.com/pydantic/pydantic/pull/4878) by @PrettyWood
* Fix `schema` and `schema_json` on models where a model instance is a one of default values, [#4781](https://github.com/pydantic/pydantic/pull/4781) by @Bobronium
* Add Jina AI to sponsors on docs index page, [#4767](https://github.com/pydantic/pydantic/pull/4767) by @samuelcolvin
* fix: support assignment on `DataclassProxy`, [#4695](https://github.com/pydantic/pydantic/pull/4695) by @PrettyWood
* Add `postgresql+psycopg` as allowed scheme for `PostgreDsn` to make it usable with SQLAlchemy 2, [#4689](https://github.com/pydantic/pydantic/pull/4689) by @morian
* Allow dict schemas to have both `patternProperties` and `additionalProperties`, [#4641](https://github.com/pydantic/pydantic/pull/4641) by @jparise
* Fixes error passing None for optional lists with `unique_items`, [#4568](https://github.com/pydantic/pydantic/pull/4568) by @mfulgo
* Fix `GenericModel` with `Callable` param raising a `TypeError`, [#4551](https://github.com/pydantic/pydantic/pull/4551) by @mfulgo
* Fix field regex with `StrictStr` type annotation, [#4538](https://github.com/pydantic/pydantic/pull/4538) by @sisp
* Correct `dataclass_transform` keyword argument name from `field_descriptors` to `field_specifiers`, [#4500](https://github.com/pydantic/pydantic/pull/4500) by @samuelcolvin
* fix: avoid multiple calls of `__post_init__` when dataclasses are inherited, [#4487](https://github.com/pydantic/pydantic/pull/4487) by @PrettyWood
* Reduce the size of binary wheels, [#2276](https://github.com/pydantic/pydantic/pull/2276) by @samuelcolvin

## v1.10.2 (2022-09-05)

* **Revert Change:** Revert percent encoding of URL parts which was originally added in [#4224](https://github.com/pydantic/pydantic/pull/4224), [#4470](https://github.com/pydantic/pydantic/pull/4470) by @samuelcolvin
* Prevent long (length > `4_300`) strings/bytes as input to int fields, see
  [python/cpython#95778](https://github.com/python/cpython/issues/95778) and
  [CVE-2020-10735](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-10735), [#1477](https://github.com/pydantic/pydantic/pull/1477) by @samuelcolvin
* fix: dataclass wrapper was not always called, [#4477](https://github.com/pydantic/pydantic/pull/4477) by @PrettyWood
* Use `tomllib` on Python 3.11 when parsing `mypy` configuration, [#4476](https://github.com/pydantic/pydantic/pull/4476) by @hauntsaninja
* Basic fix of `GenericModel` cache to detect order of arguments in `Union` models, [#4474](https://github.com/pydantic/pydantic/pull/4474) by @sveinugu
* Fix mypy plugin when using bare types like `list` and `dict` as `default_factory`, [#4457](https://github.com/pydantic/pydantic/pull/4457) by @samuelcolvin

## v1.10.1 (2022-08-31)

* Add `__hash__` method to `pydantic.color.Color` class, [#4454](https://github.com/pydantic/pydantic/pull/4454) by @czaki

## v1.10.0 (2022-08-30)

* Refactor the whole *pydantic* `dataclass` decorator to really act like its standard lib equivalent.
  It hence keeps `__eq__`, `__hash__`, ... and makes comparison with its non-validated version possible.
  It also fixes usage of `frozen` dataclasses in fields and usage of `default_factory` in nested dataclasses.
  The support of `Config.extra` has been added.
  Finally, config customization directly via a `dict` is now possible, [#2557](https://github.com/pydantic/pydantic/pull/2557) by @PrettyWood
  <br/><br/>
  **BREAKING CHANGES:**
    * The `compiled` boolean (whether *pydantic* is compiled with cython) has been moved from `main.py` to `version.py`
    * Now that `Config.extra` is supported, `dataclass` ignores by default extra arguments (like `BaseModel`)
* Fix PEP487 `__set_name__` protocol in `BaseModel` for PrivateAttrs, [#4407](https://github.com/pydantic/pydantic/pull/4407) by @tlambert03
* Allow for custom parsing of environment variables via `parse_env_var` in `Config`, [#4406](https://github.com/pydantic/pydantic/pull/4406) by @acmiyaguchi
* Rename `master` to `main`, [#4405](https://github.com/pydantic/pydantic/pull/4405) by @hramezani
* Fix `StrictStr` does not raise `ValidationError` when `max_length` is present in `Field`, [#4388](https://github.com/pydantic/pydantic/pull/4388) by @hramezani
* Make `SecretStr` and `SecretBytes` hashable, [#4387](https://github.com/pydantic/pydantic/pull/4387) by @chbndrhnns
* Fix `StrictBytes` does not raise `ValidationError` when `max_length` is present in `Field`, [#4380](https://github.com/pydantic/pydantic/pull/4380) by @JeanArhancet
* Add support for bare `type`, [#4375](https://github.com/pydantic/pydantic/pull/4375) by @hramezani
* Support Python 3.11, including binaries for 3.11 in PyPI, [#4374](https://github.com/pydantic/pydantic/pull/4374) by @samuelcolvin
* Add support for `re.Pattern`, [#4366](https://github.com/pydantic/pydantic/pull/4366) by @hramezani
* Fix `__post_init_post_parse__` is incorrectly passed keyword arguments when no `__post_init__` is defined, [#4361](https://github.com/pydantic/pydantic/pull/4361) by @hramezani
* Fix implicitly importing `ForwardRef` and `Callable` from `pydantic.typing` instead of `typing` and also expose `MappingIntStrAny`, [#4358](https://github.com/pydantic/pydantic/pull/4358) by @aminalaee
* remove `Any` types from the `dataclass` decorator so it can be used with the `disallow_any_expr` mypy option, [#4356](https://github.com/pydantic/pydantic/pull/4356) by @DetachHead
* moved repo to `pydantic/pydantic`, [#4348](https://github.com/pydantic/pydantic/pull/4348) by @yezz123
* fix "extra fields not permitted" error when dataclass with `Extra.forbid` is validated multiple times, [#4343](https://github.com/pydantic/pydantic/pull/4343) by @detachhead
* Add Python 3.9 and 3.10 examples to docs, [#4339](https://github.com/pydantic/pydantic/pull/4339) by @Bobronium
* Discriminated union models now use `oneOf` instead of `anyOf` when generating OpenAPI schema definitions, [#4335](https://github.com/pydantic/pydantic/pull/4335) by @MaxwellPayne
* Allow type checkers to infer inner type of `Json` type. `Json[list[str]]` will be now inferred as `list[str]`,
  `Json[Any]` should be used instead of plain `Json`.
  Runtime behaviour is not changed, [#4332](https://github.com/pydantic/pydantic/pull/4332) by @Bobronium
* Allow empty string aliases by using a `alias is not None` check, rather than `bool(alias)`, [#4253](https://github.com/pydantic/pydantic/pull/4253) by @sergeytsaplin
* Update `ForwardRef`s in `Field.outer_type_`, [#4249](https://github.com/pydantic/pydantic/pull/4249) by @JacobHayes
* The use of `__dataclass_transform__` has been replaced by `typing_extensions.dataclass_transform`, which is the preferred way to mark pydantic models as a dataclass under [PEP 681](https://peps.python.org/pep-0681/), [#4241](https://github.com/pydantic/pydantic/pull/4241) by @multimeric
* Use parent model's `Config` when validating nested `NamedTuple` fields, [#4219](https://github.com/pydantic/pydantic/pull/4219) by @synek
* Update `BaseModel.construct` to work with aliased Fields, [#4192](https://github.com/pydantic/pydantic/pull/4192) by @kylebamos
* Catch certain raised errors in `smart_deepcopy` and revert to `deepcopy` if so, [#4184](https://github.com/pydantic/pydantic/pull/4184) by @coneybeare
* Add `Config.anystr_upper` and `to_upper` kwarg to constr and conbytes, [#4165](https://github.com/pydantic/pydantic/pull/4165) by @satheler
* Fix JSON schema for `set` and `frozenset` when they include default values, [#4155](https://github.com/pydantic/pydantic/pull/4155) by @aminalaee
* Teach the mypy plugin that methods decorated by `@validator` are classmethods, [#4102](https://github.com/pydantic/pydantic/pull/4102) by @DMRobertson
* Improve mypy plugin's ability to detect required fields, [#4086](https://github.com/pydantic/pydantic/pull/4086) by @richardxia
* Support fields of type `Type[]` in schema, [#4051](https://github.com/pydantic/pydantic/pull/4051) by @aminalaee
* Add `default` value in JSON Schema when `const=True`, [#4031](https://github.com/pydantic/pydantic/pull/4031) by @aminalaee
* Adds reserved word check to signature generation logic, [#4011](https://github.com/pydantic/pydantic/pull/4011) by @strue36
* Fix Json strategy failure for the complex nested field, [#4005](https://github.com/pydantic/pydantic/pull/4005) by @sergiosim
* Add JSON-compatible float constraint `allow_inf_nan`, [#3994](https://github.com/pydantic/pydantic/pull/3994) by @tiangolo
* Remove undefined behaviour when `env_prefix` had characters in common with `env_nested_delimiter`, [#3975](https://github.com/pydantic/pydantic/pull/3975) by @arsenron
* Support generics model with `create_model`, [#3945](https://github.com/pydantic/pydantic/pull/3945) by @hot123s
* allow submodels to overwrite extra field info, [#3934](https://github.com/pydantic/pydantic/pull/3934) by @PrettyWood
* Document and test structural pattern matching ([PEP 636](https://peps.python.org/pep-0636/)) on `BaseModel`, [#3920](https://github.com/pydantic/pydantic/pull/3920) by @irgolic
* Fix incorrect deserialization of python timedelta object to ISO 8601 for negative time deltas.
  Minus was serialized in incorrect place ("P-1DT23H59M59.888735S" instead of correct "-P1DT23H59M59.888735S"), [#3899](https://github.com/pydantic/pydantic/pull/3899) by @07pepa
* Fix validation of discriminated union fields with an alias when passing a model instance, [#3846](https://github.com/pydantic/pydantic/pull/3846) by @chornsby
* Add a CockroachDsn type to validate CockroachDB connection strings. The type
  supports the following schemes: `cockroachdb`, `cockroachdb+psycopg2` and `cockroachdb+asyncpg`, [#3839](https://github.com/pydantic/pydantic/pull/3839) by @blubber
* Fix MyPy plugin to not override pre-existing `__init__` method in models, [#3824](https://github.com/pydantic/pydantic/pull/3824) by @patrick91
* Fix mypy version checking, [#3783](https://github.com/pydantic/pydantic/pull/3783) by @KotlinIsland
* support overwriting dunder attributes of `BaseModel` instances, [#3777](https://github.com/pydantic/pydantic/pull/3777) by @PrettyWood
* Added `ConstrainedDate` and `condate`, [#3740](https://github.com/pydantic/pydantic/pull/3740) by @hottwaj
* Support `kw_only` in dataclasses, [#3670](https://github.com/pydantic/pydantic/pull/3670) by @detachhead
* Add comparison method for `Color` class, [#3646](https://github.com/pydantic/pydantic/pull/3646) by @aminalaee
* Drop support for python3.6, associated cleanup, [#3605](https://github.com/pydantic/pydantic/pull/3605) by @samuelcolvin
* created new function `to_lower_camel()` for "non pascal case" camel case, [#3463](https://github.com/pydantic/pydantic/pull/3463) by @schlerp
* Add checks to `default` and `default_factory` arguments in Mypy plugin, [#3430](https://github.com/pydantic/pydantic/pull/3430) by @klaa97
* fix mangling of `inspect.signature` for `BaseModel`, [#3413](https://github.com/pydantic/pydantic/pull/3413) by @fix-inspect-signature
* Adds the `SecretField` abstract class so that all the current and future secret fields like `SecretStr` and `SecretBytes` will derive from it, [#3409](https://github.com/pydantic/pydantic/pull/3409) by @expobrain
* Support multi hosts validation in `PostgresDsn`, [#3337](https://github.com/pydantic/pydantic/pull/3337) by @rglsk
* Fix parsing of very small numeric timedelta values, [#3315](https://github.com/pydantic/pydantic/pull/3315) by @samuelcolvin
* Update `SecretsSettingsSource` to respect `config.case_sensitive`, [#3273](https://github.com/pydantic/pydantic/pull/3273) by @JeanArhancet
* Add MongoDB network data source name (DSN) schema, [#3229](https://github.com/pydantic/pydantic/pull/3229) by @snosratiershad
* Add support for multiple dotenv files, [#3222](https://github.com/pydantic/pydantic/pull/3222) by @rekyungmin
* Raise an explicit `ConfigError` when multiple fields are incorrectly set for a single validator, [#3215](https://github.com/pydantic/pydantic/pull/3215) by @SunsetOrange
* Allow ellipsis on `Field`s inside `Annotated` for `TypedDicts` required, [#3133](https://github.com/pydantic/pydantic/pull/3133) by @ezegomez
* Catch overflow errors in `int_validator`, [#3112](https://github.com/pydantic/pydantic/pull/3112) by @ojii
* Adds a `__rich_repr__` method to `Representation` class which enables pretty printing with [Rich](https://github.com/willmcgugan/rich), [#3099](https://github.com/pydantic/pydantic/pull/3099) by @willmcgugan
* Add percent encoding in `AnyUrl` and descendent types, [#3061](https://github.com/pydantic/pydantic/pull/3061) by @FaresAhmedb
* `validate_arguments` decorator now supports `alias`, [#3019](https://github.com/pydantic/pydantic/pull/3019) by @MAD-py
* Avoid `__dict__` and `__weakref__` attributes in `AnyUrl` and IP address fields, [#2890](https://github.com/pydantic/pydantic/pull/2890) by @nuno-andre
* Add ability to use `Final` in a field type annotation, [#2766](https://github.com/pydantic/pydantic/pull/2766) by @uriyyo
* Update requirement to `typing_extensions>=4.1.0` to guarantee `dataclass_transform` is available, [#4424](https://github.com/pydantic/pydantic/pull/4424) by @commonism
* Add Explosion and AWS to main sponsors, [#4413](https://github.com/pydantic/pydantic/pull/4413) by @samuelcolvin
* Update documentation for `copy_on_model_validation` to reflect recent changes, [#4369](https://github.com/pydantic/pydantic/pull/4369) by @samuelcolvin
* Runtime warning if `__slots__` is passed to `create_model`, `__slots__` is then ignored, [#4432](https://github.com/pydantic/pydantic/pull/4432) by @samuelcolvin
* Add type hints to `BaseSettings.Config` to avoid mypy errors, also correct mypy version compatibility notice in docs, [#4450](https://github.com/pydantic/pydantic/pull/4450) by @samuelcolvin

## v1.10.0b1 (2022-08-24)

Pre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v1.10.0b1) for details.

## v1.10.0a2 (2022-08-24)

Pre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v1.10.0a2) for details.

## v1.10.0a1 (2022-08-22)

Pre-release, see [the GitHub release](https://github.com/pydantic/pydantic/releases/tag/v1.10.0a1) for details.

## v1.9.2 (2022-08-11)

**Revert Breaking Change**: *v1.9.1* introduced a breaking change where model fields were
deep copied by default, this release reverts the default behaviour to match *v1.9.0* and before,
while also allow deep-copy behaviour via `copy_on_model_validation = 'deep'`. See [#4092](https://github.com/pydantic/pydantic/pull/4092) for more information.

* Allow for shallow copies of model fields, `Config.copy_on_model_validation` is now a str which must be
  `'none'`, `'deep'`, or `'shallow'` corresponding to not copying, deep copy & shallow copy; default `'shallow'`,
  [#4093](https://github.com/pydantic/pydantic/pull/4093) by @timkpaine

## v1.9.1 (2022-05-19)

Thank you to pydantic's sponsors:
@tiangolo, @stellargraph, @JonasKs, @grillazz, @Mazyod, @kevinalh, @chdsbd, @povilasb, @povilasb, @jina-ai,
@mainframeindustries, @robusta-dev, @SendCloud, @rszamszur, @jodal, @hardbyte, @corleyma, @daddycocoaman,
@Rehket, @jokull, @reillysiemens, @westonsteimel, @primer-io, @koxudaxi, @browniebroke, @stradivari96,
@adriangb, @kamalgill, @jqueguiner, @dev-zero, @datarootsio, @RedCarpetUp
for their kind support.

* Limit the size of `generics._generic_types_cache` and `generics._assigned_parameters`
  to avoid unlimited increase in memory usage, [#4083](https://github.com/pydantic/pydantic/pull/4083) by @samuelcolvin
* Add Jupyverse and FPS as Jupyter projects using pydantic, [#4082](https://github.com/pydantic/pydantic/pull/4082) by @davidbrochart
* Speedup `__isinstancecheck__` on pydantic models when the type is not a model, may also avoid memory "leaks", [#4081](https://github.com/pydantic/pydantic/pull/4081) by @samuelcolvin
* Fix in-place modification of `FieldInfo` that caused problems with PEP 593 type aliases, [#4067](https://github.com/pydantic/pydantic/pull/4067) by @adriangb
* Add support for autocomplete in VS Code via `__dataclass_transform__` when using `pydantic.dataclasses.dataclass`, [#4006](https://github.com/pydantic/pydantic/pull/4006) by @giuliano-oliveira
* Remove benchmarks from codebase and docs, [#3973](https://github.com/pydantic/pydantic/pull/3973) by @samuelcolvin
* Typing checking with pyright in CI, improve docs on vscode/pylance/pyright, [#3972](https://github.com/pydantic/pydantic/pull/3972) by @samuelcolvin
* Fix nested Python dataclass schema regression, [#3819](https://github.com/pydantic/pydantic/pull/3819) by @himbeles
* Update documentation about lazy evaluation of sources for Settings, [#3806](https://github.com/pydantic/pydantic/pull/3806) by @garyd203
* Prevent subclasses of bytes being converted to bytes, [#3706](https://github.com/pydantic/pydantic/pull/3706) by @samuelcolvin
* Fixed "error checking inheritance of" when using PEP585 and PEP604 type hints, [#3681](https://github.com/pydantic/pydantic/pull/3681) by @aleksul
* Allow self referencing `ClassVar`s in models, [#3679](https://github.com/pydantic/pydantic/pull/3679) by @samuelcolvin
* **Breaking Change, see [#4106](https://github.com/pydantic/pydantic/pull/4106)**: Fix issue with self-referencing dataclass, [#3675](https://github.com/pydantic/pydantic/pull/3675) by @uriyyo
* Include non-standard port numbers in rendered URLs, [#3652](https://github.com/pydantic/pydantic/pull/3652) by @dolfinus
* `Config.copy_on_model_validation` does a deep copy and not a shallow one, [#3641](https://github.com/pydantic/pydantic/pull/3641) by @PrettyWood
* fix: clarify that discriminated unions do not support singletons, [#3636](https://github.com/pydantic/pydantic/pull/3636) by @tommilligan
* Add `read_text(encoding='utf-8')` for `setup.py`, [#3625](https://github.com/pydantic/pydantic/pull/3625) by @hswong3i
* Fix JSON Schema generation for Discriminated Unions within lists, [#3608](https://github.com/pydantic/pydantic/pull/3608) by @samuelcolvin

## v1.9.0 (2021-12-31)

Thank you to pydantic's sponsors:
@sthagen, @timdrijvers, @toinbis, @koxudaxi, @ginomempin, @primer-io, @and-semakin, @westonsteimel, @reillysiemens,
@es3n1n, @jokull, @JonasKs, @Rehket, @corleyma, @daddycocoaman, @hardbyte, @datarootsio, @jodal, @aminalaee, @rafsaf,
@jqueguiner, @chdsbd, @kevinalh, @Mazyod, @grillazz, @JonasKs, @simw, @leynier, @xfenix
for their kind support.

### Highlights

* add Python 3.10 support, [#2885](https://github.com/pydantic/pydantic/pull/2885) by @PrettyWood
* [Discriminated unions](https://docs.pydantic.dev/usage/types/#discriminated-unions-aka-tagged-unions), [#619](https://github.com/pydantic/pydantic/pull/619) by @PrettyWood
* [`Config.smart_union` for better union logic](https://docs.pydantic.dev/usage/model_config/#smart-union), [#2092](https://github.com/pydantic/pydantic/pull/2092) by @PrettyWood
* Binaries for Macos M1 CPUs, [#3498](https://github.com/pydantic/pydantic/pull/3498) by @samuelcolvin
* Complex types can be set via [nested environment variables](https://docs.pydantic.dev/usage/settings/#parsing-environment-variable-values), e.g. `foo___bar`, [#3159](https://github.com/pydantic/pydantic/pull/3159) by @Air-Mark
* add a dark mode to *pydantic* documentation, [#2913](https://github.com/pydantic/pydantic/pull/2913) by @gbdlin
* Add support for autocomplete in VS Code via `__dataclass_transform__`, [#2721](https://github.com/pydantic/pydantic/pull/2721) by @tiangolo
* Add "exclude" as a field parameter so that it can be configured using model config, [#660](https://github.com/pydantic/pydantic/pull/660) by @daviskirk

### v1.9.0 (2021-12-31) Changes

* Apply `update_forward_refs` to `Config.json_encodes` prevent name clashes in types defined via strings, [#3583](https://github.com/pydantic/pydantic/pull/3583) by @samuelcolvin
* Extend pydantic's mypy plugin to support mypy versions `0.910`, `0.920`, `0.921` & `0.930`, [#3573](https://github.com/pydantic/pydantic/pull/3573) & [#3594](https://github.com/pydantic/pydantic/pull/3594) by @PrettyWood, @christianbundy, @samuelcolvin

### v1.9.0a2 (2021-12-24) Changes

* support generic models with discriminated union, [#3551](https://github.com/pydantic/pydantic/pull/3551) by @PrettyWood
* keep old behaviour of `json()` by default, [#3542](https://github.com/pydantic/pydantic/pull/3542) by @PrettyWood
* Removed typing-only `__root__` attribute from `BaseModel`, [#3540](https://github.com/pydantic/pydantic/pull/3540) by @layday
* Build Python 3.10 wheels, [#3539](https://github.com/pydantic/pydantic/pull/3539) by @mbachry
* Fix display of `extra` fields with model `__repr__`, [#3234](https://github.com/pydantic/pydantic/pull/3234) by @cocolman
* models copied via `Config.copy_on_model_validation` always have all fields, [#3201](https://github.com/pydantic/pydantic/pull/3201) by @PrettyWood
* nested ORM from nested dictionaries, [#3182](https://github.com/pydantic/pydantic/pull/3182) by @PrettyWood
* fix link to discriminated union section by @PrettyWood

### v1.9.0a1 (2021-12-18) Changes

* Add support for `Decimal`-specific validation configurations in `Field()`, additionally to using `condecimal()`,
  to allow better support from editors and tooling, [#3507](https://github.com/pydantic/pydantic/pull/3507) by @tiangolo
* Add `arm64` binaries suitable for MacOS with an M1 CPU to PyPI, [#3498](https://github.com/pydantic/pydantic/pull/3498) by @samuelcolvin
* Fix issue where `None` was considered invalid when using a `Union` type containing `Any` or `object`, [#3444](https://github.com/pydantic/pydantic/pull/3444) by @tharradine
* When generating field schema, pass optional `field` argument (of type
  `pydantic.fields.ModelField`) to `__modify_schema__()` if present, [#3434](https://github.com/pydantic/pydantic/pull/3434) by @jasujm
* Fix issue when pydantic fail to parse `typing.ClassVar` string type annotation, [#3401](https://github.com/pydantic/pydantic/pull/3401) by @uriyyo
* Mention Python >= 3.9.2 as an alternative to `typing_extensions.TypedDict`, [#3374](https://github.com/pydantic/pydantic/pull/3374) by @BvB93
* Changed the validator method name in the [Custom Errors example](https://docs.pydantic.dev/usage/models/#custom-errors)
  to more accurately describe what the validator is doing; changed from `name_must_contain_space` to `value_must_equal_bar`, [#3327](https://github.com/pydantic/pydantic/pull/3327) by @michaelrios28
* Add `AmqpDsn` class, [#3254](https://github.com/pydantic/pydantic/pull/3254) by @kludex
* Always use `Enum` value as default in generated JSON schema, [#3190](https://github.com/pydantic/pydantic/pull/3190) by @joaommartins
* Add support for Mypy 0.920, [#3175](https://github.com/pydantic/pydantic/pull/3175) by @christianbundy
* `validate_arguments` now supports `extra` customization (used to always be `Extra.forbid`), [#3161](https://github.com/pydantic/pydantic/pull/3161) by @PrettyWood
* Complex types can be set by nested environment variables, [#3159](https://github.com/pydantic/pydantic/pull/3159) by @Air-Mark
* Fix mypy plugin to collect fields based on `pydantic.utils.is_valid_field` so that it ignores untyped private variables, [#3146](https://github.com/pydantic/pydantic/pull/3146) by @hi-ogawa
* fix `validate_arguments` issue with `Config.validate_all`, [#3135](https://github.com/pydantic/pydantic/pull/3135) by @PrettyWood
* avoid dict coercion when using dict subclasses as field type, [#3122](https://github.com/pydantic/pydantic/pull/3122) by @PrettyWood
* add support for `object` type, [#3062](https://github.com/pydantic/pydantic/pull/3062) by @PrettyWood
* Updates pydantic dataclasses to keep `_special` properties on parent classes, [#3043](https://github.com/pydantic/pydantic/pull/3043) by @zulrang
* Add a `TypedDict` class for error objects, [#3038](https://github.com/pydantic/pydantic/pull/3038) by @matthewhughes934
* Fix support for using a subclass of an annotation as a default, [#3018](https://github.com/pydantic/pydantic/pull/3018) by @JacobHayes
* make `create_model_from_typeddict` mypy compliant, [#3008](https://github.com/pydantic/pydantic/pull/3008) by @PrettyWood
* Make multiple inheritance work when using `PrivateAttr`, [#2989](https://github.com/pydantic/pydantic/pull/2989) by @hmvp
* Parse environment variables as JSON, if they have a `Union` type with a complex subfield, [#2936](https://github.com/pydantic/pydantic/pull/2936) by @cbartz
* Prevent `StrictStr` permitting `Enum` values where the enum inherits from `str`, [#2929](https://github.com/pydantic/pydantic/pull/2929) by @samuelcolvin
* Make `SecretsSettingsSource` parse values being assigned to fields of complex types when sourced from a secrets file,
  just as when sourced from environment variables, [#2917](https://github.com/pydantic/pydantic/pull/2917) by @davidmreed
* add a dark mode to *pydantic* documentation, [#2913](https://github.com/pydantic/pydantic/pull/2913) by @gbdlin
* Make `pydantic-mypy` plugin compatible with `pyproject.toml` configuration, consistent with `mypy` changes.
  See the [doc](https://docs.pydantic.dev/mypy_plugin/#configuring-the-plugin) for more information, [#2908](https://github.com/pydantic/pydantic/pull/2908) by @jrwalk
* add Python 3.10 support, [#2885](https://github.com/pydantic/pydantic/pull/2885) by @PrettyWood
* Correctly parse generic models with `Json[T]`, [#2860](https://github.com/pydantic/pydantic/pull/2860) by @geekingfrog
* Update contrib docs re: Python version to use for building docs, [#2856](https://github.com/pydantic/pydantic/pull/2856) by @paxcodes
* Clarify documentation about *pydantic*'s support for custom validation and strict type checking,
  despite *pydantic* being primarily a parsing library, [#2855](https://github.com/pydantic/pydantic/pull/2855) by @paxcodes
* Fix schema generation for `Deque` fields, [#2810](https://github.com/pydantic/pydantic/pull/2810) by @sergejkozin
* fix an edge case when mixing constraints and `Literal`, [#2794](https://github.com/pydantic/pydantic/pull/2794) by @PrettyWood
* Fix postponed annotation resolution for `NamedTuple` and `TypedDict` when they're used directly as the type of fields
  within Pydantic models, [#2760](https://github.com/pydantic/pydantic/pull/2760) by @jameysharp
* Fix bug when `mypy` plugin fails on `construct` method call for `BaseSettings` derived classes, [#2753](https://github.com/pydantic/pydantic/pull/2753) by @uriyyo
* Add function overloading for a `pydantic.create_model` function, [#2748](https://github.com/pydantic/pydantic/pull/2748) by @uriyyo
* Fix mypy plugin issue with self field declaration, [#2743](https://github.com/pydantic/pydantic/pull/2743) by @uriyyo
* The colon at the end of the line "The fields which were supplied when user was initialised:" suggests that the code following it is related.
  Changed it to a period, [#2733](https://github.com/pydantic/pydantic/pull/2733) by @krisaoe
* Renamed variable `schema` to `schema_` to avoid shadowing of global variable name, [#2724](https://github.com/pydantic/pydantic/pull/2724) by @shahriyarr
* Add support for autocomplete in VS Code via `__dataclass_transform__`, [#2721](https://github.com/pydantic/pydantic/pull/2721) by @tiangolo
* add missing type annotations in `BaseConfig` and handle `max_length = 0`, [#2719](https://github.com/pydantic/pydantic/pull/2719) by @PrettyWood
* Change `orm_mode` checking to allow recursive ORM mode parsing with dicts, [#2718](https://github.com/pydantic/pydantic/pull/2718) by @nuno-andre
* Add episode 313 of the *Talk Python To Me* podcast, where Michael Kennedy and Samuel Colvin discuss Pydantic, to the docs, [#2712](https://github.com/pydantic/pydantic/pull/2712) by @RatulMaharaj
* fix JSON schema generation when a field is of type `NamedTuple` and has a default value, [#2707](https://github.com/pydantic/pydantic/pull/2707) by @PrettyWood
* `Enum` fields now properly support extra kwargs in schema generation, [#2697](https://github.com/pydantic/pydantic/pull/2697) by @sammchardy
* **Breaking Change, see [#3780](https://github.com/pydantic/pydantic/pull/3780)**: Make serialization of referenced pydantic models possible, [#2650](https://github.com/pydantic/pydantic/pull/2650) by @PrettyWood
* Add `uniqueItems` option to `ConstrainedList`, [#2618](https://github.com/pydantic/pydantic/pull/2618) by @nuno-andre
* Try to evaluate forward refs automatically at model creation, [#2588](https://github.com/pydantic/pydantic/pull/2588) by @uriyyo
* Switch docs preview and coverage display to use [smokeshow](https://smokeshow.helpmanual.io/), [#2580](https://github.com/pydantic/pydantic/pull/2580) by @samuelcolvin
* Add `__version__` attribute to pydantic module, [#2572](https://github.com/pydantic/pydantic/pull/2572) by @paxcodes
* Add `postgresql+asyncpg`, `postgresql+pg8000`, `postgresql+psycopg2`, `postgresql+psycopg2cffi`, `postgresql+py-postgresql`
  and `postgresql+pygresql` schemes for `PostgresDsn`, [#2567](https://github.com/pydantic/pydantic/pull/2567) by @postgres-asyncpg
* Enable the Hypothesis plugin to generate a constrained decimal when the `decimal_places` argument is specified, [#2524](https://github.com/pydantic/pydantic/pull/2524) by @cwe5590
* Allow `collections.abc.Callable` to be used as type in Python 3.9, [#2519](https://github.com/pydantic/pydantic/pull/2519) by @daviskirk
* Documentation update how to custom compile pydantic when using pip install, small change in `setup.py`
  to allow for custom CFLAGS when compiling, [#2517](https://github.com/pydantic/pydantic/pull/2517) by @peterroelants
* remove side effect of `default_factory` to run it only once even if `Config.validate_all` is set, [#2515](https://github.com/pydantic/pydantic/pull/2515) by @PrettyWood
* Add lookahead to ip regexes for `AnyUrl` hosts. This allows urls with DNS labels
  looking like IPs to validate as they are perfectly valid host names, [#2512](https://github.com/pydantic/pydantic/pull/2512) by @sbv-csis
* Set `minItems` and `maxItems` in generated JSON schema for fixed-length tuples, [#2497](https://github.com/pydantic/pydantic/pull/2497) by @PrettyWood
* Add `strict` argument to `conbytes`, [#2489](https://github.com/pydantic/pydantic/pull/2489) by @koxudaxi
* Support user defined generic field types in generic models, [#2465](https://github.com/pydantic/pydantic/pull/2465) by @daviskirk
* Add an example and a short explanation of subclassing `GetterDict` to docs, [#2463](https://github.com/pydantic/pydantic/pull/2463) by @nuno-andre
* add `KafkaDsn` type, `HttpUrl` now has default port 80 for http and 443 for https, [#2447](https://github.com/pydantic/pydantic/pull/2447) by @MihanixA
* Add `PastDate` and `FutureDate` types, [#2425](https://github.com/pydantic/pydantic/pull/2425) by @Kludex
* Support generating schema for `Generic` fields with subtypes, [#2375](https://github.com/pydantic/pydantic/pull/2375) by @maximberg
* fix(encoder): serialize `NameEmail` to str, [#2341](https://github.com/pydantic/pydantic/pull/2341) by @alecgerona
* add `Config.smart_union` to prevent coercion in `Union` if possible, see
 [the doc](https://docs.pydantic.dev/usage/model_config/#smart-union) for more information, [#2092](https://github.com/pydantic/pydantic/pull/2092) by @PrettyWood
* Add ability to use `typing.Counter` as a model field type, [#2060](https://github.com/pydantic/pydantic/pull/2060) by @uriyyo
* Add parameterised subclasses to `__bases__` when constructing new parameterised classes, so that `A <: B => A[int] <: B[int]`, [#2007](https://github.com/pydantic/pydantic/pull/2007) by @diabolo-dan
* Create `FileUrl` type that allows URLs that conform to [RFC 8089](https://tools.ietf.org/html/rfc8089#section-2).
  Add `host_required` parameter, which is `True` by default (`AnyUrl` and subclasses), `False` in `RedisDsn`, `FileUrl`, [#1983](https://github.com/pydantic/pydantic/pull/1983) by @vgerak
* add `confrozenset()`, analogous to `conset()` and `conlist()`, [#1897](https://github.com/pydantic/pydantic/pull/1897) by @PrettyWood
* stop calling parent class `root_validator` if overridden, [#1895](https://github.com/pydantic/pydantic/pull/1895) by @PrettyWood
* Add `repr` (defaults to `True`) parameter to `Field`, to hide it from the default representation of the `BaseModel`, [#1831](https://github.com/pydantic/pydantic/pull/1831) by @fnep
* Accept empty query/fragment URL parts, [#1807](https://github.com/pydantic/pydantic/pull/1807) by @xavier

## v1.8.2 (2021-05-11)

!!! warning
    A security vulnerability, level "moderate" is fixed in v1.8.2. Please upgrade **ASAP**.
    See security advisory [CVE-2021-29510](https://github.com/pydantic/pydantic/security/advisories/GHSA-5jqp-qgf6-3pvh)

* **Security fix:** Fix `date` and `datetime` parsing so passing either `'infinity'` or `float('inf')`
  (or their negative values) does not cause an infinite loop,
  see security advisory [CVE-2021-29510](https://github.com/pydantic/pydantic/security/advisories/GHSA-5jqp-qgf6-3pvh)
* fix schema generation with Enum by generating a valid name, [#2575](https://github.com/pydantic/pydantic/pull/2575) by @PrettyWood
* fix JSON schema generation with a `Literal` of an enum member, [#2536](https://github.com/pydantic/pydantic/pull/2536) by @PrettyWood
* Fix bug with configurations declarations that are passed as
  keyword arguments during class creation, [#2532](https://github.com/pydantic/pydantic/pull/2532) by @uriyyo
* Allow passing `json_encoders` in class kwargs, [#2521](https://github.com/pydantic/pydantic/pull/2521) by @layday
* support arbitrary types with custom `__eq__`, [#2483](https://github.com/pydantic/pydantic/pull/2483) by @PrettyWood
* support `Annotated` in `validate_arguments` and in generic models with Python 3.9, [#2483](https://github.com/pydantic/pydantic/pull/2483) by @PrettyWood

## v1.8.1 (2021-03-03)

Bug fixes for regressions and new features from `v1.8`

* allow elements of `Config.field` to update elements of a `Field`, [#2461](https://github.com/pydantic/pydantic/pull/2461) by @samuelcolvin
* fix validation with a `BaseModel` field and a custom root type, [#2449](https://github.com/pydantic/pydantic/pull/2449) by @PrettyWood
* expose `Pattern` encoder to `fastapi`, [#2444](https://github.com/pydantic/pydantic/pull/2444) by @PrettyWood
* enable the Hypothesis plugin to generate a constrained float when the `multiple_of` argument is specified, [#2442](https://github.com/pydantic/pydantic/pull/2442) by @tobi-lipede-oodle
* Avoid `RecursionError` when using some types like `Enum` or `Literal` with generic models, [#2436](https://github.com/pydantic/pydantic/pull/2436) by @PrettyWood
* do not overwrite declared `__hash__` in subclasses of a model, [#2422](https://github.com/pydantic/pydantic/pull/2422) by @PrettyWood
* fix `mypy` complaints on `Path` and `UUID` related custom types, [#2418](https://github.com/pydantic/pydantic/pull/2418) by @PrettyWood
* Support properly variable length tuples of compound types, [#2416](https://github.com/pydantic/pydantic/pull/2416) by @PrettyWood

## v1.8 (2021-02-26)

Thank you to pydantic's sponsors:
@jorgecarleitao, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @koxudaxi, @timdrijvers, @mkeen, @meadsteve,
@ginomempin, @primer-io, @and-semakin, @tomthorogood, @AjitZK, @westonsteimel, @Mazyod, @christippett, @CarlosDomingues,
@Kludex, @r-m-n
for their kind support.

### Highlights

* [Hypothesis plugin](https://docs.pydantic.dev/hypothesis_plugin/) for testing, [#2097](https://github.com/pydantic/pydantic/pull/2097) by @Zac-HD
* support for [`NamedTuple` and `TypedDict`](https://docs.pydantic.dev/usage/types/#annotated-types), [#2216](https://github.com/pydantic/pydantic/pull/2216) by @PrettyWood
* Support [`Annotated` hints on model fields](https://docs.pydantic.dev/usage/schema/#typingannotated-fields), [#2147](https://github.com/pydantic/pydantic/pull/2147) by @JacobHayes
* [`frozen` parameter on `Config`](https://docs.pydantic.dev/usage/model_config/) to allow models to be hashed, [#1880](https://github.com/pydantic/pydantic/pull/1880) by @rhuille

### Changes

* **Breaking Change**, remove old deprecation aliases from v1, [#2415](https://github.com/pydantic/pydantic/pull/2415) by @samuelcolvin:
    * remove notes on migrating to v1 in docs
    * remove `Schema` which was replaced by `Field`
    * remove `Config.case_insensitive` which was replaced by `Config.case_sensitive` (default `False`)
    * remove `Config.allow_population_by_alias` which was replaced by `Config.allow_population_by_field_name`
    * remove `model.fields` which was replaced by `model.__fields__`
    * remove `model.to_string()` which was replaced by `str(model)`
    * remove `model.__values__` which was replaced by `model.__dict__`
* **Breaking Change:** always validate only first sublevel items with `each_item`.
  There were indeed some edge cases with some compound types where the validated items were the last sublevel ones, [#1933](https://github.com/pydantic/pydantic/pull/1933) by @PrettyWood
* Update docs extensions to fix local syntax highlighting, [#2400](https://github.com/pydantic/pydantic/pull/2400) by @daviskirk
* fix: allow `utils.lenient_issubclass` to handle `typing.GenericAlias` objects like `list[str]` in Python >= 3.9, [#2399](https://github.com/pydantic/pydantic/pull/2399) by @daviskirk
* Improve field declaration for *pydantic* `dataclass` by allowing the usage of *pydantic* `Field` or `'metadata'` kwarg of `dataclasses.field`, [#2384](https://github.com/pydantic/pydantic/pull/2384) by @PrettyWood
* Making `typing-extensions` a required dependency, [#2368](https://github.com/pydantic/pydantic/pull/2368) by @samuelcolvin
* Make `resolve_annotations` more lenient, allowing for missing modules, [#2363](https://github.com/pydantic/pydantic/pull/2363) by @samuelcolvin
* Allow configuring models through class kwargs, [#2356](https://github.com/pydantic/pydantic/pull/2356) by @Bobronium
* Prevent `Mapping` subclasses from always being coerced to `dict`, [#2325](https://github.com/pydantic/pydantic/pull/2325) by @ofek
* fix: allow `None` for type `Optional[conset / conlist]`, [#2320](https://github.com/pydantic/pydantic/pull/2320) by @PrettyWood
* Support empty tuple type, [#2318](https://github.com/pydantic/pydantic/pull/2318) by @PrettyWood
* fix: `python_requires` metadata to require >=3.6.1, [#2306](https://github.com/pydantic/pydantic/pull/2306) by @hukkinj1
* Properly encode `Decimal` with, or without any decimal places, [#2293](https://github.com/pydantic/pydantic/pull/2293) by @hultner
* fix: update `__fields_set__` in `BaseModel.copy(update=…)`, [#2290](https://github.com/pydantic/pydantic/pull/2290) by @PrettyWood
* fix: keep order of fields with `BaseModel.construct()`, [#2281](https://github.com/pydantic/pydantic/pull/2281) by @PrettyWood
* Support generating schema for Generic fields, [#2262](https://github.com/pydantic/pydantic/pull/2262) by @maximberg
* Fix `validate_decorator` so `**kwargs` doesn't exclude values when the keyword
  has the same name as the `*args` or `**kwargs` names, [#2251](https://github.com/pydantic/pydantic/pull/2251) by @cybojenix
* Prevent overriding positional arguments with keyword arguments in
  `validate_arguments`, as per behaviour with native functions, [#2249](https://github.com/pydantic/pydantic/pull/2249) by @cybojenix
* add documentation for `con*` type functions, [#2242](https://github.com/pydantic/pydantic/pull/2242) by @tayoogunbiyi
* Support custom root type (aka `__root__`) when using `parse_obj()` with nested models, [#2238](https://github.com/pydantic/pydantic/pull/2238) by @PrettyWood
* Support custom root type (aka `__root__`) with `from_orm()`, [#2237](https://github.com/pydantic/pydantic/pull/2237) by @PrettyWood
* ensure cythonized functions are left untouched when creating models, based on [#1944](https://github.com/pydantic/pydantic/pull/1944) by @kollmats, [#2228](https://github.com/pydantic/pydantic/pull/2228) by @samuelcolvin
* Resolve forward refs for stdlib dataclasses converted into *pydantic* ones, [#2220](https://github.com/pydantic/pydantic/pull/2220) by @PrettyWood
* Add support for `NamedTuple` and `TypedDict` types.
  Those two types are now handled and validated when used inside `BaseModel` or *pydantic* `dataclass`.
  Two utils are also added `create_model_from_namedtuple` and `create_model_from_typeddict`, [#2216](https://github.com/pydantic/pydantic/pull/2216) by @PrettyWood
* Do not ignore annotated fields when type is `Union[Type[...], ...]`, [#2213](https://github.com/pydantic/pydantic/pull/2213) by @PrettyWood
* Raise a user-friendly `TypeError` when a `root_validator` does not return a `dict` (e.g. `None`), [#2209](https://github.com/pydantic/pydantic/pull/2209) by @masalim2
* Add a `FrozenSet[str]` type annotation to the `allowed_schemes` argument on the `strict_url` field type, [#2198](https://github.com/pydantic/pydantic/pull/2198) by @Midnighter
* add `allow_mutation` constraint to `Field`, [#2195](https://github.com/pydantic/pydantic/pull/2195) by @sblack-usu
* Allow `Field` with a `default_factory` to be used as an argument to a function
  decorated with `validate_arguments`, [#2176](https://github.com/pydantic/pydantic/pull/2176) by @thomascobb
* Allow non-existent secrets directory by only issuing a warning, [#2175](https://github.com/pydantic/pydantic/pull/2175) by @davidolrik
* fix URL regex to parse fragment without query string, [#2168](https://github.com/pydantic/pydantic/pull/2168) by @andrewmwhite
* fix: ensure to always return one of the values in `Literal` field type, [#2166](https://github.com/pydantic/pydantic/pull/2166) by @PrettyWood
* Support `typing.Annotated` hints on model fields. A `Field` may now be set in the type hint with `Annotated[..., Field(...)`; all other annotations are ignored but still visible with `get_type_hints(..., include_extras=True)`, [#2147](https://github.com/pydantic/pydantic/pull/2147) by @JacobHayes
* Added `StrictBytes` type as well as `strict=False` option to `ConstrainedBytes`, [#2136](https://github.com/pydantic/pydantic/pull/2136) by @rlizzo
* added `Config.anystr_lower` and `to_lower` kwarg to `constr` and `conbytes`, [#2134](https://github.com/pydantic/pydantic/pull/2134) by @tayoogunbiyi
* Support plain `typing.Tuple` type, [#2132](https://github.com/pydantic/pydantic/pull/2132) by @PrettyWood
* Add a bound method `validate` to functions decorated with `validate_arguments`
  to validate parameters without actually calling the function, [#2127](https://github.com/pydantic/pydantic/pull/2127) by @PrettyWood
* Add the ability to customize settings sources (add / disable / change priority order), [#2107](https://github.com/pydantic/pydantic/pull/2107) by @kozlek
* Fix mypy complaints about most custom *pydantic* types, [#2098](https://github.com/pydantic/pydantic/pull/2098) by @PrettyWood
* Add a [Hypothesis](https://hypothesis.readthedocs.io/) plugin for easier [property-based testing](https://increment.com/testing/in-praise-of-property-based-testing/) with Pydantic's custom types - [usage details here](https://docs.pydantic.dev/hypothesis_plugin/), [#2097](https://github.com/pydantic/pydantic/pull/2097) by @Zac-HD
* add validator for `None`, `NoneType` or `Literal[None]`, [#2095](https://github.com/pydantic/pydantic/pull/2095) by @PrettyWood
* Handle properly fields of type `Callable` with a default value, [#2094](https://github.com/pydantic/pydantic/pull/2094) by @PrettyWood
* Updated `create_model` return type annotation to return type which inherits from `__base__` argument, [#2071](https://github.com/pydantic/pydantic/pull/2071) by @uriyyo
* Add merged `json_encoders` inheritance, [#2064](https://github.com/pydantic/pydantic/pull/2064) by @art049
* allow overwriting `ClassVar`s in sub-models without having to re-annotate them, [#2061](https://github.com/pydantic/pydantic/pull/2061) by @layday
* add default encoder for `Pattern` type, [#2045](https://github.com/pydantic/pydantic/pull/2045) by @PrettyWood
* Add `NonNegativeInt`, `NonPositiveInt`, `NonNegativeFloat`, `NonPositiveFloat`, [#1975](https://github.com/pydantic/pydantic/pull/1975) by @mdavis-xyz
* Use % for percentage in string format of colors, [#1960](https://github.com/pydantic/pydantic/pull/1960) by @EdwardBetts
* Fixed issue causing `KeyError` to be raised when building schema from multiple `BaseModel` with the same names declared in separate classes, [#1912](https://github.com/pydantic/pydantic/pull/1912) by @JSextonn
* Add `rediss` (Redis over SSL) protocol to `RedisDsn`
  Allow URLs without `user` part (e.g., `rediss://:pass@localhost`), [#1911](https://github.com/pydantic/pydantic/pull/1911) by @TrDex
* Add a new `frozen` boolean parameter to `Config` (default: `False`).
  Setting `frozen=True` does everything that `allow_mutation=False` does, and also generates a `__hash__()` method for the model. This makes instances of the model potentially hashable if all the attributes are hashable, [#1880](https://github.com/pydantic/pydantic/pull/1880) by @rhuille
* fix schema generation with multiple Enums having the same name, [#1857](https://github.com/pydantic/pydantic/pull/1857) by @PrettyWood
* Added support for 13/19 digits VISA credit cards in `PaymentCardNumber` type, [#1416](https://github.com/pydantic/pydantic/pull/1416) by @AlexanderSov
* fix: prevent `RecursionError` while using recursive `GenericModel`s, [#1370](https://github.com/pydantic/pydantic/pull/1370) by @xppt
* use `enum` for `typing.Literal` in JSON schema, [#1350](https://github.com/pydantic/pydantic/pull/1350) by @PrettyWood
* Fix: some recursive models did not require `update_forward_refs` and silently behaved incorrectly, [#1201](https://github.com/pydantic/pydantic/pull/1201) by @PrettyWood
* Fix bug where generic models with fields where the typevar is nested in another type `a: List[T]` are considered to be concrete. This allows these models to be subclassed and composed as expected, [#947](https://github.com/pydantic/pydantic/pull/947) by @daviskirk
* Add `Config.copy_on_model_validation` flag. When set to `False`, *pydantic* will keep models used as fields
  untouched on validation instead of reconstructing (copying) them, [#265](https://github.com/pydantic/pydantic/pull/265) by @PrettyWood

## v1.7.4 (2021-05-11)

* **Security fix:** Fix `date` and `datetime` parsing so passing either `'infinity'` or `float('inf')`
  (or their negative values) does not cause an infinite loop,
  See security advisory [CVE-2021-29510](https://github.com/pydantic/pydantic/security/advisories/GHSA-5jqp-qgf6-3pvh)

## v1.7.3 (2020-11-30)

Thank you to pydantic's sponsors:
@timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api,
@mkeen, @meadsteve for their kind support.

* fix: set right default value for required (optional) fields, [#2142](https://github.com/pydantic/pydantic/pull/2142) by @PrettyWood
* fix: support `underscore_attrs_are_private` with generic models, [#2138](https://github.com/pydantic/pydantic/pull/2138) by @PrettyWood
* fix: update all modified field values in `root_validator` when `validate_assignment` is on, [#2116](https://github.com/pydantic/pydantic/pull/2116) by @PrettyWood
* Allow pickling of `pydantic.dataclasses.dataclass` dynamically created from a built-in `dataclasses.dataclass`, [#2111](https://github.com/pydantic/pydantic/pull/2111) by @aimestereo
* Fix a regression where Enum fields would not propagate keyword arguments to the schema, [#2109](https://github.com/pydantic/pydantic/pull/2109) by @bm424
* Ignore `__doc__` as private attribute when `Config.underscore_attrs_are_private` is set, [#2090](https://github.com/pydantic/pydantic/pull/2090) by @PrettyWood

## v1.7.2 (2020-11-01)

* fix slow `GenericModel` concrete model creation, allow `GenericModel` concrete name reusing in module, [#2078](https://github.com/pydantic/pydantic/pull/2078) by @Bobronium
* keep the order of the fields when `validate_assignment` is set, [#2073](https://github.com/pydantic/pydantic/pull/2073) by @PrettyWood
* forward all the params of the stdlib `dataclass` when converted into *pydantic* `dataclass`, [#2065](https://github.com/pydantic/pydantic/pull/2065) by @PrettyWood

## v1.7.1 (2020-10-28)

Thank you to pydantic's sponsors:
@timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api, @mkeen
for their kind support.

* fix annotation of `validate_arguments` when passing configuration as argument, [#2055](https://github.com/pydantic/pydantic/pull/2055) by @layday
* Fix mypy assignment error when using `PrivateAttr`, [#2048](https://github.com/pydantic/pydantic/pull/2048) by @aphedges
* fix `underscore_attrs_are_private` causing `TypeError` when overriding `__init__`, [#2047](https://github.com/pydantic/pydantic/pull/2047) by @samuelcolvin
* Fixed regression introduced in v1.7 involving exception handling in field validators when `validate_assignment=True`, [#2044](https://github.com/pydantic/pydantic/pull/2044) by @johnsabath
* fix: *pydantic* `dataclass` can inherit from stdlib `dataclass`
  and `Config.arbitrary_types_allowed` is supported, [#2042](https://github.com/pydantic/pydantic/pull/2042) by @PrettyWood

## v1.7 (2020-10-26)

Thank you to pydantic's sponsors:
@timdrijvers, @BCarley, @chdsbd, @tiangolo, @matin, @linusg, @kevinalh, @jorgecarleitao, @koxudaxi, @primer-api
for their kind support.

### Highlights

* Python 3.9 support, thanks @PrettyWood
* [Private model attributes](https://docs.pydantic.dev/usage/models/#private-model-attributes), thanks @Bobronium
* ["secrets files" support in `BaseSettings`](https://docs.pydantic.dev/usage/settings/#secret-support), thanks @mdgilene
* [convert stdlib dataclasses to pydantic dataclasses and use stdlib dataclasses in models](https://docs.pydantic.dev/usage/dataclasses/#stdlib-dataclasses-and-pydantic-dataclasses), thanks @PrettyWood

### Changes

* **Breaking Change:** remove `__field_defaults__`, add `default_factory` support with `BaseModel.construct`.
  Use `.get_default()` method on fields in `__fields__` attribute instead, [#1732](https://github.com/pydantic/pydantic/pull/1732) by @PrettyWood
* Rearrange CI to run linting as a separate job, split install recipes for different tasks, [#2020](https://github.com/pydantic/pydantic/pull/2020) by @samuelcolvin
* Allows subclasses of generic models to make some, or all, of the superclass's type parameters concrete, while
  also defining new type parameters in the subclass, [#2005](https://github.com/pydantic/pydantic/pull/2005) by @choogeboom
* Call validator with the correct `values` parameter type in `BaseModel.__setattr__`,
  when `validate_assignment = True` in model config, [#1999](https://github.com/pydantic/pydantic/pull/1999) by @me-ransh
* Force `fields.Undefined` to be a singleton object, fixing inherited generic model schemas, [#1981](https://github.com/pydantic/pydantic/pull/1981) by @daviskirk
* Include tests in source distributions, [#1976](https://github.com/pydantic/pydantic/pull/1976) by @sbraz
* Add ability to use `min_length/max_length` constraints with secret types, [#1974](https://github.com/pydantic/pydantic/pull/1974) by @uriyyo
* Also check `root_validators` when `validate_assignment` is on, [#1971](https://github.com/pydantic/pydantic/pull/1971) by @PrettyWood
* Fix const validators not running when custom validators are present, [#1957](https://github.com/pydantic/pydantic/pull/1957) by @hmvp
* add `deque` to field types, [#1935](https://github.com/pydantic/pydantic/pull/1935) by @wozniakty
* add basic support for Python 3.9, [#1832](https://github.com/pydantic/pydantic/pull/1832) by @PrettyWood
* Fix typo in the anchor of exporting_models.md#modelcopy and incorrect description, [#1821](https://github.com/pydantic/pydantic/pull/1821) by @KimMachineGun
* Added ability for `BaseSettings` to read "secret files", [#1820](https://github.com/pydantic/pydantic/pull/1820) by @mdgilene
* add `parse_raw_as` utility function, [#1812](https://github.com/pydantic/pydantic/pull/1812) by @PrettyWood
* Support home directory relative paths for `dotenv` files (e.g. `~/.env`), [#1803](https://github.com/pydantic/pydantic/pull/1803) by @PrettyWood
* Clarify documentation for `parse_file` to show that the argument
  should be a file *path* not a file-like object, [#1794](https://github.com/pydantic/pydantic/pull/1794) by @mdavis-xyz
* Fix false positive from mypy plugin when a class nested within a `BaseModel` is named `Model`, [#1770](https://github.com/pydantic/pydantic/pull/1770) by @selimb
* add basic support of Pattern type in schema generation, [#1767](https://github.com/pydantic/pydantic/pull/1767) by @PrettyWood
* Support custom title, description and default in schema of enums, [#1748](https://github.com/pydantic/pydantic/pull/1748) by @PrettyWood
* Properly represent `Literal` Enums when `use_enum_values` is True, [#1747](https://github.com/pydantic/pydantic/pull/1747) by @noelevans
* Allows timezone information to be added to strings to be formatted as time objects. Permitted formats are `Z` for UTC
  or an offset for absolute positive or negative time shifts. Or the timezone data can be omitted, [#1744](https://github.com/pydantic/pydantic/pull/1744) by @noelevans
* Add stub `__init__` with Python 3.6 signature for `ForwardRef`, [#1738](https://github.com/pydantic/pydantic/pull/1738) by @sirtelemak
* Fix behaviour with forward refs and optional fields in nested models, [#1736](https://github.com/pydantic/pydantic/pull/1736) by @PrettyWood
* add `Enum` and `IntEnum` as valid types for fields, [#1735](https://github.com/pydantic/pydantic/pull/1735) by @PrettyWood
* Change default value of `__module__` argument of `create_model` from `None` to `'pydantic.main'`.
  Set reference of created concrete model to it's module to allow pickling (not applied to models created in
  functions), [#1686](https://github.com/pydantic/pydantic/pull/1686) by @Bobronium
* Add private attributes support, [#1679](https://github.com/pydantic/pydantic/pull/1679) by @Bobronium
* add `config` to `@validate_arguments`, [#1663](https://github.com/pydantic/pydantic/pull/1663) by @samuelcolvin
* Allow descendant Settings models to override env variable names for the fields defined in parent Settings models with
  `env` in their `Config`. Previously only `env_prefix` configuration option was applicable, [#1561](https://github.com/pydantic/pydantic/pull/1561) by @ojomio
* Support `ref_template` when creating schema `$ref`s, [#1479](https://github.com/pydantic/pydantic/pull/1479) by @kilo59
* Add a `__call__` stub to `PyObject` so that mypy will know that it is callable, [#1352](https://github.com/pydantic/pydantic/pull/1352) by @brianmaissy
* `pydantic.dataclasses.dataclass` decorator now supports built-in `dataclasses.dataclass`.
  It is hence possible to convert an existing `dataclass` easily to add Pydantic validation.
  Moreover nested dataclasses are also supported, [#744](https://github.com/pydantic/pydantic/pull/744) by @PrettyWood

## v1.6.2 (2021-05-11)

* **Security fix:** Fix `date` and `datetime` parsing so passing either `'infinity'` or `float('inf')`
  (or their negative values) does not cause an infinite loop,
  See security advisory [CVE-2021-29510](https://github.com/pydantic/pydantic/security/advisories/GHSA-5jqp-qgf6-3pvh)

## v1.6.1 (2020-07-15)

* fix validation and parsing of nested models with `default_factory`, [#1710](https://github.com/pydantic/pydantic/pull/1710) by @PrettyWood

## v1.6 (2020-07-11)

Thank you to pydantic's sponsors: @matin, @tiangolo, @chdsbd, @jorgecarleitao, and 1 anonymous sponsor for their kind support.

* Modify validators for `conlist` and `conset` to not have `always=True`, [#1682](https://github.com/pydantic/pydantic/pull/1682) by @samuelcolvin
* add port check to `AnyUrl` (can't exceed 65536) ports are 16 unsigned bits: `0 <= port <= 2**16-1` src: [rfc793 header format](https://tools.ietf.org/html/rfc793#section-3.1), [#1654](https://github.com/pydantic/pydantic/pull/1654) by @flapili
* Document default `regex` anchoring semantics, [#1648](https://github.com/pydantic/pydantic/pull/1648) by @yurikhan
* Use `chain.from_iterable` in class_validators.py. This is a faster and more idiomatic way of using `itertools.chain`.
  Instead of computing all the items in the iterable and storing them in memory, they are computed one-by-one and never
  stored as a huge list. This can save on both runtime and memory space, [#1642](https://github.com/pydantic/pydantic/pull/1642) by @cool-RR
* Add `conset()`, analogous to `conlist()`, [#1623](https://github.com/pydantic/pydantic/pull/1623) by @patrickkwang
* make Pydantic errors (un)pickable, [#1616](https://github.com/pydantic/pydantic/pull/1616) by @PrettyWood
* Allow custom encoding for `dotenv` files, [#1615](https://github.com/pydantic/pydantic/pull/1615) by @PrettyWood
* Ensure `SchemaExtraCallable` is always defined to get type hints on BaseConfig, [#1614](https://github.com/pydantic/pydantic/pull/1614) by @PrettyWood
* Update datetime parser to support negative timestamps, [#1600](https://github.com/pydantic/pydantic/pull/1600) by @mlbiche
* Update mypy, remove `AnyType` alias for `Type[Any]`, [#1598](https://github.com/pydantic/pydantic/pull/1598) by @samuelcolvin
* Adjust handling of root validators so that errors are aggregated from *all* failing root validators, instead of reporting on only the first root validator to fail, [#1586](https://github.com/pydantic/pydantic/pull/1586) by @beezee
* Make `__modify_schema__` on Enums apply to the enum schema rather than fields that use the enum, [#1581](https://github.com/pydantic/pydantic/pull/1581) by @therefromhere
* Fix behavior of `__all__` key when used in conjunction with index keys in advanced include/exclude of fields that are sequences, [#1579](https://github.com/pydantic/pydantic/pull/1579) by @xspirus
* Subclass validators do not run when referencing a `List` field defined in a parent class when `each_item=True`. Added an example to the docs illustrating this, [#1566](https://github.com/pydantic/pydantic/pull/1566) by @samueldeklund
* change `schema.field_class_to_schema` to support `frozenset` in schema, [#1557](https://github.com/pydantic/pydantic/pull/1557) by @wangpeibao
* Call `__modify_schema__` only for the field schema, [#1552](https://github.com/pydantic/pydantic/pull/1552) by @PrettyWood
* Move the assignment of `field.validate_always` in `fields.py` so the `always` parameter of validators work on inheritance, [#1545](https://github.com/pydantic/pydantic/pull/1545) by @dcHHH
* Added support for UUID instantiation through 16 byte strings such as `b'\x12\x34\x56\x78' * 4`. This was done to support `BINARY(16)` columns in sqlalchemy, [#1541](https://github.com/pydantic/pydantic/pull/1541) by @shawnwall
* Add a test assertion that `default_factory` can return a singleton, [#1523](https://github.com/pydantic/pydantic/pull/1523) by @therefromhere
* Add `NameEmail.__eq__` so duplicate `NameEmail` instances are evaluated as equal, [#1514](https://github.com/pydantic/pydantic/pull/1514) by @stephen-bunn
* Add datamodel-code-generator link in pydantic document site, [#1500](https://github.com/pydantic/pydantic/pull/1500) by @koxudaxi
* Added a "Discussion of Pydantic" section to the documentation, with a link to "Pydantic Introduction" video by Alexander Hultnér, [#1499](https://github.com/pydantic/pydantic/pull/1499) by @hultner
* Avoid some side effects of `default_factory` by calling it only once
  if possible and by not setting a default value in the schema, [#1491](https://github.com/pydantic/pydantic/pull/1491) by @PrettyWood
* Added docs about dumping dataclasses to JSON, [#1487](https://github.com/pydantic/pydantic/pull/1487) by @mikegrima
* Make `BaseModel.__signature__` class-only, so getting `__signature__` from model instance will raise `AttributeError`, [#1466](https://github.com/pydantic/pydantic/pull/1466) by @Bobronium
* include `'format': 'password'` in the schema for secret types, [#1424](https://github.com/pydantic/pydantic/pull/1424) by @atheuz
* Modify schema constraints on `ConstrainedFloat` so that `exclusiveMinimum` and
  minimum are not included in the schema if they are equal to `-math.inf` and
  `exclusiveMaximum` and `maximum` are not included if they are equal to `math.inf`, [#1417](https://github.com/pydantic/pydantic/pull/1417) by @vdwees
* Squash internal `__root__` dicts in `.dict()` (and, by extension, in `.json()`), [#1414](https://github.com/pydantic/pydantic/pull/1414) by @patrickkwang
* Move `const` validator to post-validators so it validates the parsed value, [#1410](https://github.com/pydantic/pydantic/pull/1410) by @selimb
* Fix model validation to handle nested literals, e.g. `Literal['foo', Literal['bar']]`, [#1364](https://github.com/pydantic/pydantic/pull/1364) by @DBCerigo
* Remove `user_required = True` from `RedisDsn`, neither user nor password are required, [#1275](https://github.com/pydantic/pydantic/pull/1275) by @samuelcolvin
* Remove extra `allOf` from schema for fields with `Union` and custom `Field`, [#1209](https://github.com/pydantic/pydantic/pull/1209) by @mostaphaRoudsari
* Updates OpenAPI schema generation to output all enums as separate models.
  Instead of inlining the enum values in the model schema, models now use a `$ref`
  property to point to the enum definition, [#1173](https://github.com/pydantic/pydantic/pull/1173) by @calvinwyoung

## v1.5.1 (2020-04-23)

* Signature generation with `extra: allow` never uses a field name, [#1418](https://github.com/pydantic/pydantic/pull/1418) by @prettywood
* Avoid mutating `Field` default value, [#1412](https://github.com/pydantic/pydantic/pull/1412) by @prettywood

## v1.5 (2020-04-18)

* Make includes/excludes arguments for `.dict()`, `._iter()`, ..., immutable, [#1404](https://github.com/pydantic/pydantic/pull/1404) by @AlexECX
* Always use a field's real name with includes/excludes in `model._iter()`, regardless of `by_alias`, [#1397](https://github.com/pydantic/pydantic/pull/1397) by @AlexECX
* Update constr regex example to include start and end lines, [#1396](https://github.com/pydantic/pydantic/pull/1396) by @lmcnearney
* Confirm that shallow `model.copy()` does make a shallow copy of attributes, [#1383](https://github.com/pydantic/pydantic/pull/1383) by @samuelcolvin
* Renaming `model_name` argument of `main.create_model()` to `__model_name` to allow using `model_name` as a field name, [#1367](https://github.com/pydantic/pydantic/pull/1367) by @kittipatv
* Replace raising of exception to silent passing  for non-Var attributes in mypy plugin, [#1345](https://github.com/pydantic/pydantic/pull/1345) by @b0g3r
* Remove `typing_extensions` dependency for Python 3.8, [#1342](https://github.com/pydantic/pydantic/pull/1342) by @prettywood
* Make `SecretStr` and `SecretBytes` initialization idempotent, [#1330](https://github.com/pydantic/pydantic/pull/1330) by @atheuz
* document making secret types dumpable using the json method, [#1328](https://github.com/pydantic/pydantic/pull/1328) by @atheuz
* Move all testing and build to github actions, add windows and macos binaries,
  thank you @StephenBrown2 for much help, [#1326](https://github.com/pydantic/pydantic/pull/1326) by @samuelcolvin
* fix card number length check in `PaymentCardNumber`, `PaymentCardBrand` now inherits from `str`, [#1317](https://github.com/pydantic/pydantic/pull/1317) by @samuelcolvin
* Have `BaseModel` inherit from `Representation` to make mypy happy when overriding `__str__`, [#1310](https://github.com/pydantic/pydantic/pull/1310) by @FuegoFro
* Allow `None` as input to all optional list fields, [#1307](https://github.com/pydantic/pydantic/pull/1307) by @prettywood
* Add `datetime` field to `default_factory` example, [#1301](https://github.com/pydantic/pydantic/pull/1301) by @StephenBrown2
* Allow subclasses of known types to be encoded with superclass encoder, [#1291](https://github.com/pydantic/pydantic/pull/1291) by @StephenBrown2
* Exclude exported fields from all elements of a list/tuple of submodels/dicts with `'__all__'`, [#1286](https://github.com/pydantic/pydantic/pull/1286) by @masalim2
* Add pydantic.color.Color objects as available input for Color fields, [#1258](https://github.com/pydantic/pydantic/pull/1258) by @leosussan
* In examples, type nullable fields as `Optional`, so that these are valid mypy annotations, [#1248](https://github.com/pydantic/pydantic/pull/1248) by @kokes
* Make `pattern_validator()` accept pre-compiled `Pattern` objects. Fix `str_validator()` return type to `str`, [#1237](https://github.com/pydantic/pydantic/pull/1237) by @adamgreg
* Document how to manage Generics and inheritance, [#1229](https://github.com/pydantic/pydantic/pull/1229) by @esadruhn
* `update_forward_refs()` method of BaseModel now copies `__dict__` of class module instead of modifying it, [#1228](https://github.com/pydantic/pydantic/pull/1228) by @paul-ilyin
* Support instance methods and class methods with `@validate_arguments`, [#1222](https://github.com/pydantic/pydantic/pull/1222) by @samuelcolvin
* Add `default_factory` argument to `Field` to create a dynamic default value by passing a zero-argument callable, [#1210](https://github.com/pydantic/pydantic/pull/1210) by @prettywood
* add support for `NewType` of `List`, `Optional`, etc, [#1207](https://github.com/pydantic/pydantic/pull/1207) by @Kazy
* fix mypy signature for `root_validator`, [#1192](https://github.com/pydantic/pydantic/pull/1192) by @samuelcolvin
* Fixed parsing of nested 'custom root type' models, [#1190](https://github.com/pydantic/pydantic/pull/1190) by @Shados
* Add `validate_arguments` function decorator which checks the arguments to a function matches type annotations, [#1179](https://github.com/pydantic/pydantic/pull/1179) by @samuelcolvin
* Add `__signature__` to models, [#1034](https://github.com/pydantic/pydantic/pull/1034) by @Bobronium
* Refactor `._iter()` method, 10x speed boost for `dict(model)`, [#1017](https://github.com/pydantic/pydantic/pull/1017) by @Bobronium

## v1.4 (2020-01-24)

* **Breaking Change:** alias precedence logic changed so aliases on a field always take priority over
  an alias from `alias_generator` to avoid buggy/unexpected behaviour,
  see [here](https://docs.pydantic.dev/usage/model_config/#alias-precedence) for details, [#1178](https://github.com/pydantic/pydantic/pull/1178) by @samuelcolvin
* Add support for unicode and punycode in TLDs, [#1182](https://github.com/pydantic/pydantic/pull/1182) by @jamescurtin
* Fix `cls` argument in validators during assignment, [#1172](https://github.com/pydantic/pydantic/pull/1172) by @samuelcolvin
* completing Luhn algorithm for `PaymentCardNumber`, [#1166](https://github.com/pydantic/pydantic/pull/1166) by @cuencandres
* add support for generics that implement `__get_validators__` like a custom data type, [#1159](https://github.com/pydantic/pydantic/pull/1159) by @tiangolo
* add support for infinite generators with `Iterable`, [#1152](https://github.com/pydantic/pydantic/pull/1152) by @tiangolo
* fix `url_regex` to accept schemas with `+`, `-` and `.` after the first character, [#1142](https://github.com/pydantic/pydantic/pull/1142) by @samuelcolvin
* move `version_info()` to `version.py`, suggest its use in issues, [#1138](https://github.com/pydantic/pydantic/pull/1138) by @samuelcolvin
* Improve pydantic import time by roughly 50% by deferring some module loading and regex compilation, [#1127](https://github.com/pydantic/pydantic/pull/1127) by @samuelcolvin
* Fix `EmailStr` and `NameEmail` to accept instances of themselves in cython, [#1126](https://github.com/pydantic/pydantic/pull/1126) by @koxudaxi
* Pass model class to the `Config.schema_extra` callable, [#1125](https://github.com/pydantic/pydantic/pull/1125) by @therefromhere
* Fix regex for username and password in URLs, [#1115](https://github.com/pydantic/pydantic/pull/1115) by @samuelcolvin
* Add support for nested generic models, [#1104](https://github.com/pydantic/pydantic/pull/1104) by @dmontagu
* add `__all__` to `__init__.py` to prevent "implicit reexport" errors from mypy, [#1072](https://github.com/pydantic/pydantic/pull/1072) by @samuelcolvin
* Add support for using "dotenv" files with `BaseSettings`, [#1011](https://github.com/pydantic/pydantic/pull/1011) by @acnebs

## v1.3 (2019-12-21)

* Change `schema` and `schema_model` to handle dataclasses by using their `__pydantic_model__` feature, [#792](https://github.com/pydantic/pydantic/pull/792) by @aviramha
* Added option for `root_validator` to be skipped if values validation fails using keyword `skip_on_failure=True`, [#1049](https://github.com/pydantic/pydantic/pull/1049) by @aviramha
* Allow `Config.schema_extra` to be a callable so that the generated schema can be post-processed, [#1054](https://github.com/pydantic/pydantic/pull/1054) by @selimb
* Update mypy to version 0.750, [#1057](https://github.com/pydantic/pydantic/pull/1057) by @dmontagu
* Trick Cython into allowing str subclassing, [#1061](https://github.com/pydantic/pydantic/pull/1061) by @skewty
* Prevent type attributes being added to schema unless the attribute `__schema_attributes__` is `True`, [#1064](https://github.com/pydantic/pydantic/pull/1064) by @samuelcolvin
* Change `BaseModel.parse_file` to use `Config.json_loads`, [#1067](https://github.com/pydantic/pydantic/pull/1067) by @kierandarcy
* Fix for optional `Json` fields, [#1073](https://github.com/pydantic/pydantic/pull/1073) by @volker48
* Change the default number of threads used when compiling with cython to one,
  allow override via the `CYTHON_NTHREADS` environment variable, [#1074](https://github.com/pydantic/pydantic/pull/1074) by @samuelcolvin
* Run FastAPI tests during Pydantic's CI tests, [#1075](https://github.com/pydantic/pydantic/pull/1075) by @tiangolo
* My mypy strictness constraints, and associated tweaks to type annotations, [#1077](https://github.com/pydantic/pydantic/pull/1077) by @samuelcolvin
* Add `__eq__` to SecretStr and SecretBytes to allow "value equals", [#1079](https://github.com/pydantic/pydantic/pull/1079) by @sbv-trueenergy
* Fix schema generation for nested None case, [#1088](https://github.com/pydantic/pydantic/pull/1088) by @lutostag
* Consistent checks for sequence like objects, [#1090](https://github.com/pydantic/pydantic/pull/1090) by @samuelcolvin
* Fix `Config` inheritance on `BaseSettings` when used with `env_prefix`, [#1091](https://github.com/pydantic/pydantic/pull/1091) by @samuelcolvin
* Fix for `__modify_schema__` when it conflicted with `field_class_to_schema*`, [#1102](https://github.com/pydantic/pydantic/pull/1102) by @samuelcolvin
* docs: Fix explanation of case sensitive environment variable names when populating `BaseSettings` subclass attributes, [#1105](https://github.com/pydantic/pydantic/pull/1105) by @tribals
* Rename django-rest-framework benchmark in documentation, [#1119](https://github.com/pydantic/pydantic/pull/1119) by @frankie567

## v1.2 (2019-11-28)

* **Possible Breaking Change:** Add support for required `Optional` with `name: Optional[AnyType] = Field(...)`
  and refactor `ModelField` creation to preserve `required` parameter value, [#1031](https://github.com/pydantic/pydantic/pull/1031) by @tiangolo;
  see [here](https://docs.pydantic.dev/usage/models/#required-optional-fields) for details
* Add benchmarks for `cattrs`, [#513](https://github.com/pydantic/pydantic/pull/513) by @sebastianmika
* Add `exclude_none` option to `dict()` and friends, [#587](https://github.com/pydantic/pydantic/pull/587) by @niknetniko
* Add benchmarks for `valideer`, [#670](https://github.com/pydantic/pydantic/pull/670) by @gsakkis
* Add `parse_obj_as` and `parse_file_as` functions for ad-hoc parsing of data into arbitrary pydantic-compatible types, [#934](https://github.com/pydantic/pydantic/pull/934) by @dmontagu
* Add `allow_reuse` argument to validators, thus allowing validator reuse, [#940](https://github.com/pydantic/pydantic/pull/940) by @dmontagu
* Add support for mapping types for custom root models, [#958](https://github.com/pydantic/pydantic/pull/958) by @dmontagu
* Mypy plugin support for dataclasses, [#966](https://github.com/pydantic/pydantic/pull/966) by @koxudaxi
* Add support for dataclasses default factory, [#968](https://github.com/pydantic/pydantic/pull/968) by @ahirner
* Add a `ByteSize` type for converting byte string (`1GB`) to plain bytes, [#977](https://github.com/pydantic/pydantic/pull/977) by @dgasmith
* Fix mypy complaint about `@root_validator(pre=True)`, [#984](https://github.com/pydantic/pydantic/pull/984) by @samuelcolvin
* Add manylinux binaries for Python 3.8 to pypi, also support manylinux2010, [#994](https://github.com/pydantic/pydantic/pull/994) by @samuelcolvin
* Adds ByteSize conversion to another unit, [#995](https://github.com/pydantic/pydantic/pull/995) by @dgasmith
* Fix `__str__` and `__repr__` inheritance for models, [#1022](https://github.com/pydantic/pydantic/pull/1022) by @samuelcolvin
* add testimonials section to docs, [#1025](https://github.com/pydantic/pydantic/pull/1025) by @sullivancolin
* Add support for `typing.Literal` for Python 3.8, [#1026](https://github.com/pydantic/pydantic/pull/1026) by @dmontagu

## v1.1.1 (2019-11-20)

* Fix bug where use of complex fields on sub-models could cause fields to be incorrectly configured, [#1015](https://github.com/pydantic/pydantic/pull/1015) by @samuelcolvin

## v1.1 (2019-11-07)

* Add a mypy plugin for type checking `BaseModel.__init__` and more, [#722](https://github.com/pydantic/pydantic/pull/722) by @dmontagu
* Change return type typehint for `GenericModel.__class_getitem__` to prevent PyCharm warnings, [#936](https://github.com/pydantic/pydantic/pull/936) by @dmontagu
* Fix usage of `Any` to allow `None`, also support `TypeVar` thus allowing use of un-parameterised collection types
  e.g. `Dict` and `List`, [#962](https://github.com/pydantic/pydantic/pull/962) by @samuelcolvin
* Set `FieldInfo` on subfields to fix schema generation for complex nested types, [#965](https://github.com/pydantic/pydantic/pull/965) by @samuelcolvin

## v1.0 (2019-10-23)

* **Breaking Change:** deprecate the `Model.fields` property, use `Model.__fields__` instead, [#883](https://github.com/pydantic/pydantic/pull/883) by @samuelcolvin
* **Breaking Change:** Change the precedence of aliases so child model aliases override parent aliases,
  including using `alias_generator`, [#904](https://github.com/pydantic/pydantic/pull/904) by @samuelcolvin
* **Breaking change:** Rename `skip_defaults` to `exclude_unset`, and add ability to exclude actual defaults, [#915](https://github.com/pydantic/pydantic/pull/915) by @dmontagu
* Add `**kwargs` to `pydantic.main.ModelMetaclass.__new__` so `__init_subclass__` can take custom parameters on extended
  `BaseModel` classes, [#867](https://github.com/pydantic/pydantic/pull/867) by @retnikt
* Fix field of a type that has a default value, [#880](https://github.com/pydantic/pydantic/pull/880) by @koxudaxi
* Use `FutureWarning` instead of `DeprecationWarning` when `alias` instead of `env` is used for settings models, [#881](https://github.com/pydantic/pydantic/pull/881) by @samuelcolvin
* Fix issue with `BaseSettings` inheritance and `alias` getting set to `None`, [#882](https://github.com/pydantic/pydantic/pull/882) by @samuelcolvin
* Modify `__repr__` and `__str__` methods to be consistent across all public classes, add `__pretty__` to support
  python-devtools, [#884](https://github.com/pydantic/pydantic/pull/884) by @samuelcolvin
* deprecation warning for `case_insensitive` on `BaseSettings` config, [#885](https://github.com/pydantic/pydantic/pull/885) by @samuelcolvin
* For `BaseSettings` merge environment variables and in-code values recursively, as long as they create a valid object
  when merged together, to allow splitting init arguments, [#888](https://github.com/pydantic/pydantic/pull/888) by @idmitrievsky
* change secret types example, [#890](https://github.com/pydantic/pydantic/pull/890) by @ashears
* Change the signature of `Model.construct()` to be more user-friendly, document `construct()` usage, [#898](https://github.com/pydantic/pydantic/pull/898) by @samuelcolvin
* Add example for the `construct()` method, [#907](https://github.com/pydantic/pydantic/pull/907) by @ashears
* Improve use of `Field` constraints on complex types, raise an error if constraints are not enforceable,
  also support tuples with an ellipsis `Tuple[X, ...]`, `Sequence` and `FrozenSet` in schema, [#909](https://github.com/pydantic/pydantic/pull/909) by @samuelcolvin
* update docs for bool missing valid value, [#911](https://github.com/pydantic/pydantic/pull/911) by @trim21
* Better `str`/`repr` logic for `ModelField`, [#912](https://github.com/pydantic/pydantic/pull/912) by @samuelcolvin
* Fix `ConstrainedList`, update schema generation to reflect `min_items` and `max_items` `Field()` arguments, [#917](https://github.com/pydantic/pydantic/pull/917) by @samuelcolvin
* Allow abstracts sets (eg. dict keys) in the `include` and `exclude` arguments of `dict()`, [#921](https://github.com/pydantic/pydantic/pull/921) by @samuelcolvin
* Fix JSON serialization errors on `ValidationError.json()` by using `pydantic_encoder`, [#922](https://github.com/pydantic/pydantic/pull/922) by @samuelcolvin
* Clarify usage of `remove_untouched`, improve error message for types with no validators, [#926](https://github.com/pydantic/pydantic/pull/926) by @retnikt

## v1.0b2 (2019-10-07)

* Mark `StrictBool` typecheck as `bool` to allow for default values without mypy errors, [#690](https://github.com/pydantic/pydantic/pull/690) by @dmontagu
* Transfer the documentation build from sphinx to mkdocs, re-write much of the documentation, [#856](https://github.com/pydantic/pydantic/pull/856) by @samuelcolvin
* Add support for custom naming schemes for `GenericModel` subclasses, [#859](https://github.com/pydantic/pydantic/pull/859) by @dmontagu
* Add `if TYPE_CHECKING:` to the excluded lines for test coverage, [#874](https://github.com/pydantic/pydantic/pull/874) by @dmontagu
* Rename `allow_population_by_alias` to `allow_population_by_field_name`, remove unnecessary warning about it, [#875](https://github.com/pydantic/pydantic/pull/875) by @samuelcolvin

## v1.0b1 (2019-10-01)

* **Breaking Change:** rename `Schema` to `Field`, make it a function to placate mypy, [#577](https://github.com/pydantic/pydantic/pull/577) by @samuelcolvin
* **Breaking Change:** modify parsing behavior for `bool`, [#617](https://github.com/pydantic/pydantic/pull/617) by @dmontagu
* **Breaking Change:** `get_validators` is no longer recognised, use `__get_validators__`.
  `Config.ignore_extra` and `Config.allow_extra` are no longer recognised, use `Config.extra`, [#720](https://github.com/pydantic/pydantic/pull/720) by @samuelcolvin
* **Breaking Change:** modify default config settings for `BaseSettings`; `case_insensitive` renamed to `case_sensitive`,
  default changed to `case_sensitive = False`, `env_prefix` default changed to `''` - e.g. no prefix, [#721](https://github.com/pydantic/pydantic/pull/721) by @dmontagu
* **Breaking change:** Implement `root_validator` and rename root errors from `__obj__` to `__root__`, [#729](https://github.com/pydantic/pydantic/pull/729) by @samuelcolvin
* **Breaking Change:** alter the behaviour of `dict(model)` so that sub-models are nolonger
  converted to dictionaries, [#733](https://github.com/pydantic/pydantic/pull/733) by @samuelcolvin
* **Breaking change:** Added `initvars` support to `post_init_post_parse`, [#748](https://github.com/pydantic/pydantic/pull/748) by @Raphael-C-Almeida
* **Breaking Change:** Make `BaseModel.json()` only serialize the `__root__` key for models with custom root, [#752](https://github.com/pydantic/pydantic/pull/752) by @dmontagu
* **Breaking Change:** complete rewrite of `URL` parsing logic, [#755](https://github.com/pydantic/pydantic/pull/755) by @samuelcolvin
* **Breaking Change:** preserve superclass annotations for field-determination when not provided in subclass, [#757](https://github.com/pydantic/pydantic/pull/757) by @dmontagu
* **Breaking Change:** `BaseSettings` now uses the special `env` settings to define which environment variables to
  read, not aliases, [#847](https://github.com/pydantic/pydantic/pull/847) by @samuelcolvin
* add support for `assert` statements inside validators, [#653](https://github.com/pydantic/pydantic/pull/653) by @abdusco
* Update documentation to specify the use of `pydantic.dataclasses.dataclass` and subclassing `pydantic.BaseModel`, [#710](https://github.com/pydantic/pydantic/pull/710) by @maddosaurus
* Allow custom JSON decoding and encoding via `json_loads` and `json_dumps` `Config` properties, [#714](https://github.com/pydantic/pydantic/pull/714) by @samuelcolvin
* make all annotated fields occur in the order declared, [#715](https://github.com/pydantic/pydantic/pull/715) by @dmontagu
* use pytest to test `mypy` integration, [#735](https://github.com/pydantic/pydantic/pull/735) by @dmontagu
* add `__repr__` method to `ErrorWrapper`, [#738](https://github.com/pydantic/pydantic/pull/738) by @samuelcolvin
* Added support for `FrozenSet` members in dataclasses, and a better error when attempting to use types from the `typing` module that are not supported by Pydantic, [#745](https://github.com/pydantic/pydantic/pull/745) by @djpetti
* add documentation for Pycharm Plugin, [#750](https://github.com/pydantic/pydantic/pull/750) by @koxudaxi
* fix broken examples in the docs, [#753](https://github.com/pydantic/pydantic/pull/753) by @dmontagu
* moving typing related objects into `pydantic.typing`, [#761](https://github.com/pydantic/pydantic/pull/761) by @samuelcolvin
* Minor performance improvements to `ErrorWrapper`, `ValidationError` and datetime parsing, [#763](https://github.com/pydantic/pydantic/pull/763) by @samuelcolvin
* Improvements to `datetime`/`date`/`time`/`timedelta` types: more descriptive errors,
  change errors to `value_error` not `type_error`, support bytes, [#766](https://github.com/pydantic/pydantic/pull/766) by @samuelcolvin
* fix error messages for `Literal` types with multiple allowed values, [#770](https://github.com/pydantic/pydantic/pull/770) by @dmontagu
* Improved auto-generated `title` field in JSON schema by converting underscore to space, [#772](https://github.com/pydantic/pydantic/pull/772) by @skewty
* support `mypy --no-implicit-reexport` for dataclasses, also respect `--no-implicit-reexport` in pydantic itself, [#783](https://github.com/pydantic/pydantic/pull/783) by @samuelcolvin
* add the `PaymentCardNumber` type, [#790](https://github.com/pydantic/pydantic/pull/790) by @matin
* Fix const validations for lists, [#794](https://github.com/pydantic/pydantic/pull/794) by @hmvp
* Set `additionalProperties` to false in schema for models with extra fields disallowed, [#796](https://github.com/pydantic/pydantic/pull/796) by @Code0x58
* `EmailStr` validation method now returns local part case-sensitive per RFC 5321, [#798](https://github.com/pydantic/pydantic/pull/798) by @henriklindgren
* Added ability to validate strictness to `ConstrainedFloat`, `ConstrainedInt` and `ConstrainedStr` and added
  `StrictFloat` and `StrictInt` classes, [#799](https://github.com/pydantic/pydantic/pull/799) by @DerRidda
* Improve handling of `None` and `Optional`, replace `whole` with `each_item` (inverse meaning, default `False`)
  on validators, [#803](https://github.com/pydantic/pydantic/pull/803) by @samuelcolvin
* add support for `Type[T]` type hints, [#807](https://github.com/pydantic/pydantic/pull/807) by @timonbimon
* Performance improvements from removing `change_exceptions`, change how pydantic error are constructed, [#819](https://github.com/pydantic/pydantic/pull/819) by @samuelcolvin
* Fix the error message arising when a `BaseModel`-type model field causes a `ValidationError` during parsing, [#820](https://github.com/pydantic/pydantic/pull/820) by @dmontagu
* allow `getter_dict` on `Config`, modify `GetterDict` to be more like a `Mapping` object and thus easier to work with, [#821](https://github.com/pydantic/pydantic/pull/821) by @samuelcolvin
* Only check `TypeVar` param on base `GenericModel` class, [#842](https://github.com/pydantic/pydantic/pull/842) by @zpencerq
* rename `Model._schema_cache` -> `Model.__schema_cache__`, `Model._json_encoder` -> `Model.__json_encoder__`,
  `Model._custom_root_type` -> `Model.__custom_root_type__`, [#851](https://github.com/pydantic/pydantic/pull/851) by @samuelcolvin

## v0.32.2 (2019-08-17)

(Docs are available [here](https://5d584fcca7c9b70007d1c997--pydantic-docs.netlify.com))

* fix `__post_init__` usage with dataclass inheritance, fix [#739](https://github.com/pydantic/pydantic/pull/739) by @samuelcolvin
* fix required fields validation on GenericModels classes, [#742](https://github.com/pydantic/pydantic/pull/742) by @amitbl
* fix defining custom `Schema` on `GenericModel` fields, [#754](https://github.com/pydantic/pydantic/pull/754) by @amitbl

## v0.32.1 (2019-08-08)

* do not validate extra fields when `validate_assignment` is on, [#724](https://github.com/pydantic/pydantic/pull/724) by @YaraslauZhylko

## v0.32 (2019-08-06)

* add model name to `ValidationError` error message, [#676](https://github.com/pydantic/pydantic/pull/676) by @dmontagu
* **breaking change**: remove `__getattr__` and rename `__values__` to `__dict__` on `BaseModel`,
  deprecation warning on use `__values__` attr, attributes access speed increased up to 14 times, [#712](https://github.com/pydantic/pydantic/pull/712) by @Bobronium
* support `ForwardRef` (without self-referencing annotations) in Python 3.6, [#706](https://github.com/pydantic/pydantic/pull/706) by @koxudaxi
* implement `schema_extra` in `Config` sub-class, [#663](https://github.com/pydantic/pydantic/pull/663) by @tiangolo

## v0.31.1 (2019-07-31)

* fix json generation for `EnumError`, [#697](https://github.com/pydantic/pydantic/pull/697) by @dmontagu
* update numerous dependencies

## v0.31 (2019-07-24)

* better support for floating point `multiple_of` values, [#652](https://github.com/pydantic/pydantic/pull/652) by @justindujardin
* fix schema generation for `NewType` and `Literal`, [#649](https://github.com/pydantic/pydantic/pull/649) by @dmontagu
* fix `alias_generator` and field config conflict, [#645](https://github.com/pydantic/pydantic/pull/645) by @gmetzker and [#658](https://github.com/pydantic/pydantic/pull/658) by @Bobronium
* more detailed message for `EnumError`, [#673](https://github.com/pydantic/pydantic/pull/673) by @dmontagu
* add advanced exclude support for `dict`, `json` and `copy`, [#648](https://github.com/pydantic/pydantic/pull/648) by @Bobronium
* fix bug in `GenericModel` for models with concrete parameterized fields, [#672](https://github.com/pydantic/pydantic/pull/672) by @dmontagu
* add documentation for `Literal` type, [#651](https://github.com/pydantic/pydantic/pull/651) by @dmontagu
* add `Config.keep_untouched` for custom descriptors support, [#679](https://github.com/pydantic/pydantic/pull/679) by @Bobronium
* use `inspect.cleandoc` internally to get model description, [#657](https://github.com/pydantic/pydantic/pull/657) by @tiangolo
* add `Color` to schema generation, by @euri10
* add documentation for Literal type, [#651](https://github.com/pydantic/pydantic/pull/651) by @dmontagu

## v0.30.1 (2019-07-15)

* fix so nested classes which inherit and change `__init__` are correctly processed while still allowing `self` as a
  parameter, [#644](https://github.com/pydantic/pydantic/pull/644) by @lnaden and @dgasmith

## v0.30 (2019-07-07)

* enforce single quotes in code, [#612](https://github.com/pydantic/pydantic/pull/612) by @samuelcolvin
* fix infinite recursion with dataclass inheritance and `__post_init__`, [#606](https://github.com/pydantic/pydantic/pull/606) by @Hanaasagi
* fix default values for `GenericModel`, [#610](https://github.com/pydantic/pydantic/pull/610) by @dmontagu
* clarify that self-referencing models require Python 3.7+, [#616](https://github.com/pydantic/pydantic/pull/616) by @vlcinsky
* fix truncate for types, [#611](https://github.com/pydantic/pydantic/pull/611) by @dmontagu
* add `alias_generator` support, [#622](https://github.com/pydantic/pydantic/pull/622) by @Bobronium
* fix unparameterized generic type schema generation, [#625](https://github.com/pydantic/pydantic/pull/625) by @dmontagu
* fix schema generation with multiple/circular references to the same model, [#621](https://github.com/pydantic/pydantic/pull/621) by @tiangolo and @wongpat
* support custom root types, [#628](https://github.com/pydantic/pydantic/pull/628) by @koxudaxi
* support `self` as a field name in `parse_obj`, [#632](https://github.com/pydantic/pydantic/pull/632) by @samuelcolvin

## v0.29 (2019-06-19)

* support dataclasses.InitVar, [#592](https://github.com/pydantic/pydantic/pull/592) by @pfrederiks
* Updated documentation to elucidate the usage of `Union` when defining multiple types under an attribute's
  annotation and showcase how the type-order can affect marshalling of provided values, [#594](https://github.com/pydantic/pydantic/pull/594) by @somada141
* add `conlist` type, [#583](https://github.com/pydantic/pydantic/pull/583) by @hmvp
* add support for generics, [#595](https://github.com/pydantic/pydantic/pull/595) by @dmontagu

## v0.28 (2019-06-06)

* fix support for JSON Schema generation when using models with circular references in Python 3.7, [#572](https://github.com/pydantic/pydantic/pull/572) by @tiangolo
* support `__post_init_post_parse__` on dataclasses, [#567](https://github.com/pydantic/pydantic/pull/567) by @sevaho
* allow dumping dataclasses to JSON, [#575](https://github.com/pydantic/pydantic/pull/575) by @samuelcolvin and @DanielOberg
* ORM mode, [#562](https://github.com/pydantic/pydantic/pull/562) by @samuelcolvin
* fix `pydantic.compiled` on ipython, [#573](https://github.com/pydantic/pydantic/pull/573) by @dmontagu and @samuelcolvin
* add `StrictBool` type, [#579](https://github.com/pydantic/pydantic/pull/579) by @cazgp

## v0.27 (2019-05-30)

* **breaking change**  `_pydantic_post_init` to execute dataclass' original `__post_init__` before
  validation, [#560](https://github.com/pydantic/pydantic/pull/560) by @HeavenVolkoff
* fix handling of generic types without specified parameters, [#550](https://github.com/pydantic/pydantic/pull/550) by @dmontagu
* **breaking change** (maybe): this is the first release compiled with **cython**, see the docs and please
  submit an issue if you run into problems

## v0.27.0a1 (2019-05-26)

* fix JSON Schema for `list`, `tuple`, and `set`, [#540](https://github.com/pydantic/pydantic/pull/540) by @tiangolo
* compiling with cython, `manylinux` binaries, some other performance improvements, [#548](https://github.com/pydantic/pydantic/pull/548) by @samuelcolvin

## v0.26 (2019-05-22)

* fix to schema generation for `IPvAnyAddress`, `IPvAnyInterface`, `IPvAnyNetwork` [#498](https://github.com/pydantic/pydantic/pull/498) by @pilosus
* fix variable length tuples support, [#495](https://github.com/pydantic/pydantic/pull/495) by @pilosus
* fix return type hint for `create_model`, [#526](https://github.com/pydantic/pydantic/pull/526) by @dmontagu
* **Breaking Change:** fix `.dict(skip_keys=True)` skipping values set via alias (this involves changing
  `validate_model()` to always returns `Tuple[Dict[str, Any], Set[str], Optional[ValidationError]]`), [#517](https://github.com/pydantic/pydantic/pull/517) by @sommd
* fix to schema generation for `IPv4Address`, `IPv6Address`, `IPv4Interface`,
  `IPv6Interface`, `IPv4Network`, `IPv6Network` [#532](https://github.com/pydantic/pydantic/pull/532) by @euri10
* add `Color` type, [#504](https://github.com/pydantic/pydantic/pull/504) by @pilosus and @samuelcolvin

## v0.25 (2019-05-05)

* Improve documentation on self-referencing models and annotations, [#487](https://github.com/pydantic/pydantic/pull/487) by @theenglishway
* fix `.dict()` with extra keys, [#490](https://github.com/pydantic/pydantic/pull/490) by @JaewonKim
* support `const` keyword in `Schema`, [#434](https://github.com/pydantic/pydantic/pull/434) by @Sean1708

## v0.24 (2019-04-23)

* fix handling `ForwardRef` in sub-types, like `Union`, [#464](https://github.com/pydantic/pydantic/pull/464) by @tiangolo
* fix secret serialization, [#465](https://github.com/pydantic/pydantic/pull/465) by @atheuz
* Support custom validators for dataclasses, [#454](https://github.com/pydantic/pydantic/pull/454) by @primal100
* fix `parse_obj` to cope with dict-like objects, [#472](https://github.com/pydantic/pydantic/pull/472) by @samuelcolvin
* fix to schema generation in nested dataclass-based models, [#474](https://github.com/pydantic/pydantic/pull/474) by @NoAnyLove
* fix `json` for `Path`, `FilePath`, and `DirectoryPath` objects, [#473](https://github.com/pydantic/pydantic/pull/473) by @mikegoodspeed

## v0.23 (2019-04-04)

* improve documentation for contributing section, [#441](https://github.com/pydantic/pydantic/pull/441) by @pilosus
* improve README.rst to include essential information about the package, [#446](https://github.com/pydantic/pydantic/pull/446) by @pilosus
* `IntEnum` support, [#444](https://github.com/pydantic/pydantic/pull/444) by @potykion
* fix PyObject callable value, [#409](https://github.com/pydantic/pydantic/pull/409) by @pilosus
* fix `black` deprecation warnings after update, [#451](https://github.com/pydantic/pydantic/pull/451) by @pilosus
* fix `ForwardRef` collection bug, [#450](https://github.com/pydantic/pydantic/pull/450) by @tigerwings
* Support specialized `ClassVars`, [#455](https://github.com/pydantic/pydantic/pull/455) by @tyrylu
* fix JSON serialization for `ipaddress` types, [#333](https://github.com/pydantic/pydantic/pull/333) by @pilosus
* add `SecretStr` and `SecretBytes` types, [#452](https://github.com/pydantic/pydantic/pull/452) by @atheuz

## v0.22 (2019-03-29)

* add `IPv{4,6,Any}Network` and `IPv{4,6,Any}Interface` types from `ipaddress` stdlib, [#333](https://github.com/pydantic/pydantic/pull/333) by @pilosus
* add docs for `datetime` types, [#386](https://github.com/pydantic/pydantic/pull/386) by @pilosus
* fix to schema generation in dataclass-based models, [#408](https://github.com/pydantic/pydantic/pull/408) by @pilosus
* fix path in nested models, [#437](https://github.com/pydantic/pydantic/pull/437) by @kataev
* add `Sequence` support, [#304](https://github.com/pydantic/pydantic/pull/304) by @pilosus

## v0.21.0 (2019-03-15)

* fix typo in `NoneIsNotAllowedError` message, [#414](https://github.com/pydantic/pydantic/pull/414) by @YaraslauZhylko
* add `IPvAnyAddress`, `IPv4Address` and `IPv6Address` types, [#333](https://github.com/pydantic/pydantic/pull/333) by @pilosus

## v0.20.1 (2019-02-26)

* fix type hints of `parse_obj` and similar methods, [#405](https://github.com/pydantic/pydantic/pull/405) by @erosennin
* fix submodel validation, [#403](https://github.com/pydantic/pydantic/pull/403) by @samuelcolvin
* correct type hints for `ValidationError.json`, [#406](https://github.com/pydantic/pydantic/pull/406) by @layday

## v0.20.0 (2019-02-18)

* fix tests for Python 3.8, [#396](https://github.com/pydantic/pydantic/pull/396) by @samuelcolvin
* Adds fields to the `dir` method for autocompletion in interactive sessions, [#398](https://github.com/pydantic/pydantic/pull/398) by @dgasmith
* support `ForwardRef` (and therefore `from __future__ import annotations`) with dataclasses, [#397](https://github.com/pydantic/pydantic/pull/397) by @samuelcolvin

## v0.20.0a1 (2019-02-13)

* **breaking change** (maybe): more sophisticated argument parsing for validators, any subset of
  `values`, `config` and `field` is now permitted, eg. `(cls, value, field)`,
  however the variadic key word argument ("`**kwargs`") **must** be called `kwargs`, [#388](https://github.com/pydantic/pydantic/pull/388) by @samuelcolvin
* **breaking change**: Adds `skip_defaults` argument to `BaseModel.dict()` to allow skipping of fields that
  were not explicitly set, signature of `Model.construct()` changed, [#389](https://github.com/pydantic/pydantic/pull/389) by @dgasmith
* add `py.typed` marker file for PEP-561 support, [#391](https://github.com/pydantic/pydantic/pull/391) by @je-l
* Fix `extra` behaviour for multiple inheritance/mix-ins, [#394](https://github.com/pydantic/pydantic/pull/394) by @YaraslauZhylko

## v0.19.0 (2019-02-04)

* Support `Callable` type hint, fix [#279](https://github.com/pydantic/pydantic/pull/279) by @proofit404
* Fix schema for fields with `validator` decorator, fix [#375](https://github.com/pydantic/pydantic/pull/375) by @tiangolo
* Add `multiple_of` constraint to `ConstrainedDecimal`, `ConstrainedFloat`, `ConstrainedInt`
  and their related types `condecimal`, `confloat`, and `conint` [#371](https://github.com/pydantic/pydantic/pull/371), thanks @StephenBrown2
* Deprecated `ignore_extra` and `allow_extra` Config fields in favor of `extra`, [#352](https://github.com/pydantic/pydantic/pull/352) by @liiight
* Add type annotations to all functions, test fully with mypy, [#373](https://github.com/pydantic/pydantic/pull/373) by @samuelcolvin
* fix for 'missing' error with `validate_all` or `validate_always`, [#381](https://github.com/pydantic/pydantic/pull/381) by @samuelcolvin
* Change the second/millisecond watershed for date/datetime parsing to `2e10`, [#385](https://github.com/pydantic/pydantic/pull/385) by @samuelcolvin

## v0.18.2 (2019-01-22)

* Fix to schema generation with `Optional` fields, fix [#361](https://github.com/pydantic/pydantic/pull/361) by @samuelcolvin

## v0.18.1 (2019-01-17)

* add `ConstrainedBytes` and `conbytes` types, [#315](https://github.com/pydantic/pydantic/pull/315) @Gr1N
* adding `MANIFEST.in` to include license in package `.tar.gz`, [#358](https://github.com/pydantic/pydantic/pull/358) by @samuelcolvin

## v0.18.0 (2019-01-13)

* **breaking change**: don't call validators on keys of dictionaries, [#254](https://github.com/pydantic/pydantic/pull/254) by @samuelcolvin
* Fix validators with `always=True` when the default is `None` or the type is optional, also prevent
  `whole` validators being called for sub-fields, fix [#132](https://github.com/pydantic/pydantic/pull/132) by @samuelcolvin
* improve documentation for settings priority and allow it to be easily changed, [#343](https://github.com/pydantic/pydantic/pull/343) by @samuelcolvin
* fix `ignore_extra=False` and `allow_population_by_alias=True`, fix [#257](https://github.com/pydantic/pydantic/pull/257) by @samuelcolvin
* **breaking change**: Set `BaseConfig` attributes `min_anystr_length` and `max_anystr_length` to
  `None` by default, fix [#349](https://github.com/pydantic/pydantic/pull/349) in [#350](https://github.com/pydantic/pydantic/pull/350) by @tiangolo
* add support for postponed annotations, [#348](https://github.com/pydantic/pydantic/pull/348) by @samuelcolvin

## v0.17.0 (2018-12-27)

* fix schema for `timedelta` as number, [#325](https://github.com/pydantic/pydantic/pull/325) by @tiangolo
* prevent validators being called repeatedly after inheritance, [#327](https://github.com/pydantic/pydantic/pull/327) by @samuelcolvin
* prevent duplicate validator check in ipython, fix [#312](https://github.com/pydantic/pydantic/pull/312) by @samuelcolvin
* add "Using Pydantic" section to docs, [#323](https://github.com/pydantic/pydantic/pull/323) by @tiangolo & [#326](https://github.com/pydantic/pydantic/pull/326) by @samuelcolvin
* fix schema generation for fields annotated as `: dict`, `: list`,
  `: tuple` and `: set`, [#330](https://github.com/pydantic/pydantic/pull/330) & [#335](https://github.com/pydantic/pydantic/pull/335) by @nkonin
* add support for constrained strings as dict keys in schema, [#332](https://github.com/pydantic/pydantic/pull/332) by @tiangolo
* support for passing Config class in dataclasses decorator, [#276](https://github.com/pydantic/pydantic/pull/276) by @jarekkar
  (**breaking change**: this supersedes the `validate_assignment` argument with `config`)
* support for nested dataclasses, [#334](https://github.com/pydantic/pydantic/pull/334) by @samuelcolvin
* better errors when getting an `ImportError` with `PyObject`, [#309](https://github.com/pydantic/pydantic/pull/309) by @samuelcolvin
* rename `get_validators` to `__get_validators__`, deprecation warning on use of old name, [#338](https://github.com/pydantic/pydantic/pull/338) by @samuelcolvin
* support `ClassVar` by excluding such attributes from fields, [#184](https://github.com/pydantic/pydantic/pull/184) by @samuelcolvin

## v0.16.1 (2018-12-10)

* fix `create_model` to correctly use the passed `__config__`, [#320](https://github.com/pydantic/pydantic/pull/320) by @hugoduncan

## v0.16.0 (2018-12-03)

* **breaking change**: refactor schema generation to be compatible with JSON Schema and OpenAPI specs, [#308](https://github.com/pydantic/pydantic/pull/308) by @tiangolo
* add `schema` to `schema` module to generate top-level schemas from base models, [#308](https://github.com/pydantic/pydantic/pull/308) by @tiangolo
* add additional fields to `Schema` class to declare validation for `str` and numeric values, [#311](https://github.com/pydantic/pydantic/pull/311) by @tiangolo
* rename `_schema` to `schema` on fields, [#318](https://github.com/pydantic/pydantic/pull/318) by @samuelcolvin
* add `case_insensitive` option to `BaseSettings` `Config`, [#277](https://github.com/pydantic/pydantic/pull/277) by @jasonkuhrt

## v0.15.0 (2018-11-18)

* move codebase to use black, [#287](https://github.com/pydantic/pydantic/pull/287) by @samuelcolvin
* fix alias use in settings, [#286](https://github.com/pydantic/pydantic/pull/286) by @jasonkuhrt and @samuelcolvin
* fix datetime parsing in `parse_date`, [#298](https://github.com/pydantic/pydantic/pull/298) by @samuelcolvin
* allow dataclass inheritance, fix [#293](https://github.com/pydantic/pydantic/pull/293) by @samuelcolvin
* fix `PyObject = None`, fix [#305](https://github.com/pydantic/pydantic/pull/305) by @samuelcolvin
* allow `Pattern` type, fix [#303](https://github.com/pydantic/pydantic/pull/303) by @samuelcolvin

## v0.14.0 (2018-10-02)

* dataclasses decorator, [#269](https://github.com/pydantic/pydantic/pull/269) by @Gaunt and @samuelcolvin

## v0.13.1 (2018-09-21)

* fix issue where int_validator doesn't cast a `bool` to an `int` [#264](https://github.com/pydantic/pydantic/pull/264) by @nphyatt
* add deep copy support for `BaseModel.copy()` [#249](https://github.com/pydantic/pydantic/pull/249), @gangefors

## v0.13.0 (2018-08-25)

* raise an exception if a field's name shadows an existing `BaseModel` attribute [#242](https://github.com/pydantic/pydantic/pull/242)
* add `UrlStr` and `urlstr` types [#236](https://github.com/pydantic/pydantic/pull/236)
* timedelta json encoding ISO8601 and total seconds, custom json encoders [#247](https://github.com/pydantic/pydantic/pull/247), by @cfkanesan and @samuelcolvin
* allow `timedelta` objects as values for properties of type `timedelta` (matches `datetime` etc. behavior) [#247](https://github.com/pydantic/pydantic/pull/247)

## v0.12.1 (2018-07-31)

* fix schema generation for fields defined using `typing.Any` [#237](https://github.com/pydantic/pydantic/pull/237)

## v0.12.0 (2018-07-31)

* add `by_alias` argument in `.dict()` and `.json()` model methods [#205](https://github.com/pydantic/pydantic/pull/205)
* add Json type support [#214](https://github.com/pydantic/pydantic/pull/214)
* support tuples [#227](https://github.com/pydantic/pydantic/pull/227)
* major improvements and changes to schema [#213](https://github.com/pydantic/pydantic/pull/213)

## v0.11.2 (2018-07-05)

* add `NewType` support [#115](https://github.com/pydantic/pydantic/pull/115)
* fix `list`, `set` & `tuple` validation [#225](https://github.com/pydantic/pydantic/pull/225)
* separate out `validate_model` method, allow errors to be returned along with valid values [#221](https://github.com/pydantic/pydantic/pull/221)

## v0.11.1 (2018-07-02)

* support Python 3.7 [#216](https://github.com/pydantic/pydantic/pull/216), thanks @layday
* Allow arbitrary types in model [#209](https://github.com/pydantic/pydantic/pull/209), thanks @oldPadavan

## v0.11.0 (2018-06-28)

* make `list`, `tuple` and `set` types stricter [#86](https://github.com/pydantic/pydantic/pull/86)
* **breaking change**: remove msgpack parsing [#201](https://github.com/pydantic/pydantic/pull/201)
* add `FilePath` and `DirectoryPath` types [#10](https://github.com/pydantic/pydantic/pull/10)
* model schema generation [#190](https://github.com/pydantic/pydantic/pull/190)
* JSON serialization of models and schemas [#133](https://github.com/pydantic/pydantic/pull/133)

## v0.10.0 (2018-06-11)

* add `Config.allow_population_by_alias` [#160](https://github.com/pydantic/pydantic/pull/160), thanks @bendemaree
* **breaking change**: new errors format [#179](https://github.com/pydantic/pydantic/pull/179), thanks @Gr1N
* **breaking change**: removed `Config.min_number_size` and `Config.max_number_size` [#183](https://github.com/pydantic/pydantic/pull/183), thanks @Gr1N
* **breaking change**: correct behaviour of `lt` and `gt` arguments to `conint` etc. [#188](https://github.com/pydantic/pydantic/pull/188)
  for the old behaviour use `le` and `ge` [#194](https://github.com/pydantic/pydantic/pull/194), thanks @jaheba
* added error context and ability to redefine error message templates using `Config.error_msg_templates` [#183](https://github.com/pydantic/pydantic/pull/183),
  thanks @Gr1N
* fix typo in validator exception [#150](https://github.com/pydantic/pydantic/pull/150)
* copy defaults to model values, so different models don't share objects [#154](https://github.com/pydantic/pydantic/pull/154)

## v0.9.1 (2018-05-10)

* allow custom `get_field_config` on config classes [#159](https://github.com/pydantic/pydantic/pull/159)
* add `UUID1`, `UUID3`, `UUID4` and `UUID5` types [#167](https://github.com/pydantic/pydantic/pull/167), thanks @Gr1N
* modify some inconsistent docstrings and annotations [#173](https://github.com/pydantic/pydantic/pull/173), thanks @YannLuo
* fix type annotations for exotic types [#171](https://github.com/pydantic/pydantic/pull/171), thanks @Gr1N
* Reuse type validators in exotic types [#171](https://github.com/pydantic/pydantic/pull/171)
* scheduled monthly requirements updates [#168](https://github.com/pydantic/pydantic/pull/168)
* add `Decimal`, `ConstrainedDecimal` and `condecimal` types [#170](https://github.com/pydantic/pydantic/pull/170), thanks @Gr1N

## v0.9.0 (2018-04-28)

* tweak email-validator import error message [#145](https://github.com/pydantic/pydantic/pull/145)
* fix parse error of `parse_date()` and `parse_datetime()` when input is 0 [#144](https://github.com/pydantic/pydantic/pull/144), thanks @YannLuo
* add `Config.anystr_strip_whitespace` and `strip_whitespace` kwarg to `constr`,
  by default values is `False` [#163](https://github.com/pydantic/pydantic/pull/163), thanks @Gr1N
* add `ConstrainedFloat`, `confloat`, `PositiveFloat` and `NegativeFloat` types [#166](https://github.com/pydantic/pydantic/pull/166), thanks @Gr1N

## v0.8.0 (2018-03-25)

* fix type annotation for `inherit_config` [#139](https://github.com/pydantic/pydantic/pull/139)
* **breaking change**: check for invalid field names in validators [#140](https://github.com/pydantic/pydantic/pull/140)
* validate attributes of parent models [#141](https://github.com/pydantic/pydantic/pull/141)
* **breaking change**: email validation now uses
  [email-validator](https://github.com/JoshData/python-email-validator) [#142](https://github.com/pydantic/pydantic/pull/142)

## v0.7.1 (2018-02-07)

* fix bug with `create_model` modifying the base class

## v0.7.0 (2018-02-06)

* added compatibility with abstract base classes (ABCs) [#123](https://github.com/pydantic/pydantic/pull/123)
* add `create_model` method [#113](https://github.com/pydantic/pydantic/pull/113) [#125](https://github.com/pydantic/pydantic/pull/125)
* **breaking change**: rename `.config` to `.__config__` on a model
* **breaking change**: remove deprecated `.values()` on a model, use `.dict()` instead
* remove use of `OrderedDict` and use simple dict [#126](https://github.com/pydantic/pydantic/pull/126)
* add `Config.use_enum_values` [#127](https://github.com/pydantic/pydantic/pull/127)
* add wildcard validators of the form `@validate('*')` [#128](https://github.com/pydantic/pydantic/pull/128)

## v0.6.4 (2018-02-01)

* allow Python date and times objects [#122](https://github.com/pydantic/pydantic/pull/122)

## v0.6.3 (2017-11-26)

* fix direct install without `README.rst` present

## v0.6.2 (2017-11-13)

* errors for invalid validator use
* safer check for complex models in `Settings`

## v0.6.1 (2017-11-08)

* prevent duplicate validators, [#101](https://github.com/pydantic/pydantic/pull/101)
* add `always` kwarg to validators, [#102](https://github.com/pydantic/pydantic/pull/102)

## v0.6.0 (2017-11-07)

* assignment validation [#94](https://github.com/pydantic/pydantic/pull/94), thanks petroswork!
* JSON in environment variables for complex types, [#96](https://github.com/pydantic/pydantic/pull/96)
* add `validator` decorators for complex validation, [#97](https://github.com/pydantic/pydantic/pull/97)
* depreciate `values(...)` and replace with `.dict(...)`, [#99](https://github.com/pydantic/pydantic/pull/99)

## v0.5.0 (2017-10-23)

* add `UUID` validation [#89](https://github.com/pydantic/pydantic/pull/89)
* remove `index` and `track` from error object (json) if they're null [#90](https://github.com/pydantic/pydantic/pull/90)
* improve the error text when a list is provided rather than a dict [#90](https://github.com/pydantic/pydantic/pull/90)
* add benchmarks table to docs [#91](https://github.com/pydantic/pydantic/pull/91)

## v0.4.0 (2017-07-08)

* show length in string validation error
* fix aliases in config during inheritance [#55](https://github.com/pydantic/pydantic/pull/55)
* simplify error display
* use unicode ellipsis in `truncate`
* add `parse_obj`, `parse_raw` and `parse_file` helper functions [#58](https://github.com/pydantic/pydantic/pull/58)
* switch annotation only fields to come first in fields list not last

## v0.3.0 (2017-06-21)

* immutable models via `config.allow_mutation = False`, associated cleanup and performance improvement [#44](https://github.com/pydantic/pydantic/pull/44)
* immutable helper methods `construct()` and `copy()` [#53](https://github.com/pydantic/pydantic/pull/53)
* allow pickling of models [#53](https://github.com/pydantic/pydantic/pull/53)
* `setattr` is removed as `__setattr__` is now intelligent [#44](https://github.com/pydantic/pydantic/pull/44)
* `raise_exception` removed, Models now always raise exceptions [#44](https://github.com/pydantic/pydantic/pull/44)
* instance method validators removed
* django-restful-framework benchmarks added [#47](https://github.com/pydantic/pydantic/pull/47)
* fix inheritance bug [#49](https://github.com/pydantic/pydantic/pull/49)
* make str type stricter so list, dict etc are not coerced to strings. [#52](https://github.com/pydantic/pydantic/pull/52)
* add `StrictStr` which only always strings as input [#52](https://github.com/pydantic/pydantic/pull/52)

## v0.2.1 (2017-06-07)

* pypi and travis together messed up the deploy of `v0.2` this should fix it

## v0.2.0 (2017-06-07)

* **breaking change**: `values()` on a model is now a method not a property,
  takes `include` and `exclude` arguments
* allow annotation only fields to support mypy
* add pretty `to_string(pretty=True)` method for models

## v0.1.0 (2017-06-03)

* add docs
* add history


## Links discovered
- [GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.5)
- [#12522](https://github.com/pydantic/pydantic/pull/12522)
- [GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.4)
- [`AnyUrl` and Dsn types](https://docs.pydantic.dev/latest/api/networks/)
- [#12427](https://github.com/pydantic/pydantic/pull/12427)
- [#12430](https://github.com/pydantic/pydantic/pull/12430)
- [pydantic-core#1833](https://github.com/pydantic/pydantic-core/pull/1833)
- [pydantic-core#1868](https://github.com/pydantic/pydantic-core/pull/1868)
- [pydantic-core#1853](https://github.com/pydantic/pydantic-core/pull/1853)
- [`collections.defaultdict`](https://docs.python.org/3/library/collections.html#collections.defaultdict)
- [pydantic-core#1879](https://github.com/pydantic/pydantic-core/pull/1879)
- [pydantic-core#1864](https://github.com/pydantic/pydantic-core/pull/1864)
- [GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.3)
- [*after* model validator](https://docs.pydantic.dev/latest/concepts/validators/#model-validators)
- [#12414](https://github.com/pydantic/pydantic/pull/12414)
- [`FieldInfo.asdict()`](https://docs.pydantic.dev/latest/api/fields/#pydantic.fields.FieldInfo.asdict)
- [#12411](https://github.com/pydantic/pydantic/pull/12411)
- [added example](https://docs.pydantic.dev/latest/examples/dynamic_models/)
- [blog post](https://pydantic.dev/articles/pydantic-v2-12-release#changes)
- [GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.2)
- [pydantic-core#1843](https://github.com/pydantic/pydantic-core/pull/1843)
- [#12398](https://github.com/pydantic/pydantic/pull/12398)
- [GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.1)
- [#12355](https://github.com/pydantic/pydantic/pull/12355)
- [#12370](https://github.com/pydantic/pydantic/pull/12370)
- [#12367](https://github.com/pydantic/pydantic/pull/12367)
- [#12366](https://github.com/pydantic/pydantic/pull/12366)
- [pydantic-core#1826](https://github.com/pydantic/pydantic-core/pull/1826)
- [pydantic-core#1829](https://github.com/pydantic/pydantic-core/pull/1829)
- [pydantic-core#1836](https://github.com/pydantic/pydantic-core/pull/1836)
- [GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.0)
- [versioning policy](https://docs.pydantic.dev/2.12/version-policy/#pydantic-v2)
- [#12338](https://github.com/pydantic/pydantic/pull/12338)
- [#12233](https://github.com/pydantic/pydantic/pull/12233)
- [#12334](https://github.com/pydantic/pydantic/pull/12334)
- [#12336](https://github.com/pydantic/pydantic/pull/12336)
- [#12147](https://github.com/pydantic/pydantic/pull/12147)
- [#12001](https://github.com/pydantic/pydantic/pull/12001)
- [#12289](https://github.com/pydantic/pydantic/pull/12289)
- [#12324](https://github.com/pydantic/pydantic/pull/12324)
- [#12279](https://github.com/pydantic/pydantic/pull/12279)
- [#12339](https://github.com/pydantic/pydantic/pull/12339)
- [#12340](https://github.com/pydantic/pydantic/pull/12340)
- [#12341](https://github.com/pydantic/pydantic/pull/12341)
- [#12342](https://github.com/pydantic/pydantic/pull/12342)
- [#12327](https://github.com/pydantic/pydantic/pull/12327)
- [GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.0b1)
- [#12314](https://github.com/pydantic/pydantic/pull/12314)
- [#12141](https://github.com/pydantic/pydantic/pull/12141)
- [#11942](https://github.com/pydantic/pydantic/pull/11942)
- [#12068](https://github.com/pydantic/pydantic/pull/12068)
- [#12179](https://github.com/pydantic/pydantic/pull/12179)
- [pydantic-core#1799](https://github.com/pydantic/pydantic-core/pull/1799)
- [pydantic-core#1789](https://github.com/pydantic/pydantic-core/pull/1789)
- [#12196](https://github.com/pydantic/pydantic/pull/12196)
- [#12265](https://github.com/pydantic/pydantic/pull/12265)
- [#11669](https://github.com/pydantic/pydantic/pull/11669)
- [#12106](https://github.com/pydantic/pydantic/pull/12106)
- [#12133](https://github.com/pydantic/pydantic/pull/12133)
- [#12173](https://github.com/pydantic/pydantic/pull/12173)
- [#12209](https://github.com/pydantic/pydantic/pull/12209)
- [#11892](https://github.com/pydantic/pydantic/pull/11892)
- [#12219](https://github.com/pydantic/pydantic/pull/12219)
- [#12290](https://github.com/pydantic/pydantic/pull/12290)
- [GitHub release](https://github.com/pydantic/pydantic/releases/tag/v2.12.0a1)
- [#11762](https://github.com/pydantic/pydantic/pull/11762)
- [#11991](https://github.com/pydantic/pydantic/pull/11991)
- [#11987](https://github.com/pydantic/pydantic/pull/11987)
- [#12077](https://github.com/pydantic/pydantic/pull/12077)
- [#11883](https://github.com/pydantic/pydantic/pull/11883)
- [#11714](https://github.com/pydantic/pydantic/pull/11714)
- [#11733](https://github.com/pydantic/pydantic/pull/11733)
- [#11829](https://github.com/pydantic/pydantic/pull/11829)
- [#11832](https://github.com/pydantic/pydantic/pull/11832)
- [#11957](https://github.com/pydantic/pydantic/pull/11957)
- [#11898](https://github.com/pydantic/pydantic/pull/11898)
- [#12008](https://github.com/pydantic/pydantic/pull/12008)
- [#12028](https://github.com/pydantic/pydantic/pull/12028)
- [#11721](https://github.com/pydantic/pydantic/pull/11721)
- [#11755](https://github.com/pydantic/pydantic/pull/11755)
- [#11772](https://github.com/pydantic/pydantic/pull/11772)
- [#11735](https://github.com/pydantic/pydantic/pull/11735)
- [#11759](https://github.com/pydantic/pydantic/pull/11759)
- [#11761](https://github.com/pydantic/pydantic/pull/11761)
- [#11775](https://github.com/pydantic/pydantic/pull/11775)
- [#11803](https://github.com/pydantic/pydantic/pull/11803)
- [#11769](https://github.com/pydantic/pydantic/pull/11769)
- [#11801](https://github.com/pydantic/pydantic/pull/11801)
- [#11822](https://github.com/pydantic/pydantic/pull/11822)
- [#11855](https://github.com/pydantic/pydantic/pull/11855)
- [#11890](https://github.com/pydantic/pydantic/pull/11890)
- [#11949](https://github.com/pydantic/pydantic/pull/11949)
- [#11946](https://github.com/pydantic/pydantic/pull/11946)
- [#11914](https://github.com/pydantic/pydantic/pull/11914)
- [#11941](https://github.com/pydantic/pydantic/pull/11941)
- [#12002](https://github.com/pydantic/pydantic/pull/12002)
- [#11988](https://github.com/pydantic/pydantic/pull/11988)
- [#12051](https://github.com/pydantic/pydantic/pull/12051)
- [#11694](https://github.com/pydantic/pydantic/pull/11694)
- [#11725](https://github.com/pydantic/pydantic/pull/11725)

--- README.md ---
# Pydantic Validation

[![CI](https://img.shields.io/github/actions/workflow/status/pydantic/pydantic/ci.yml?branch=main&logo=github&label=CI)](https://github.com/pydantic/pydantic/actions?query=event%3Apush+branch%3Amain+workflow%3ACI)
[![Coverage](https://coverage-badge.samuelcolvin.workers.dev/pydantic/pydantic.svg)](https://coverage-badge.samuelcolvin.workers.dev/redirect/pydantic/pydantic)
[![pypi](https://img.shields.io/pypi/v/pydantic.svg)](https://pypi.python.org/pypi/pydantic)
[![CondaForge](https://img.shields.io/conda/v/conda-forge/pydantic.svg)](https://anaconda.org/conda-forge/pydantic)
[![downloads](https://static.pepy.tech/badge/pydantic/month)](https://pepy.tech/project/pydantic)
[![versions](https://img.shields.io/pypi/pyversions/pydantic.svg)](https://github.com/pydantic/pydantic)
[![license](https://img.shields.io/github/license/pydantic/pydantic.svg)](https://github.com/pydantic/pydantic/blob/main/LICENSE)
[![Pydantic v2](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json)](https://docs.pydantic.dev/latest/contributing/#badges)
[![llms.txt](https://img.shields.io/badge/llms.txt-green)](https://docs.pydantic.dev/latest/llms.txt)

Data validation using Python type hints.

Fast and extensible, Pydantic plays nicely with your linters/IDE/brain.
Define how data should be in pure, canonical Python 3.9+; validate it with Pydantic.

## Pydantic Logfire :fire:

We've recently launched Pydantic Logfire to help you monitor your applications.
[Learn more](https://pydantic.dev/articles/logfire-announcement)

## Pydantic V1.10 vs. V2

Pydantic V2 is a ground-up rewrite that offers many new features, performance improvements, and some breaking changes compared to Pydantic V1.

If you're using Pydantic V1 you may want to look at the
[pydantic V1.10 Documentation](https://docs.pydantic.dev/) or,
[`1.10.X-fixes` git branch](https://github.com/pydantic/pydantic/tree/1.10.X-fixes). Pydantic V2 also ships with the latest version of Pydantic V1 built in so that you can incrementally upgrade your code base and projects: `from pydantic import v1 as pydantic_v1`.

## Help

See [documentation](https://docs.pydantic.dev/) for more details.

## Installation

Install using `pip install -U pydantic` or `conda install pydantic -c conda-forge`.
For more installation options to make Pydantic even faster,
see the [Install](https://docs.pydantic.dev/install/) section in the documentation.

## A Simple Example

```python
from datetime import datetime
from typing import Optional
from pydantic import BaseModel

class User(BaseModel):
    id: int
    name: str = 'John Doe'
    signup_ts: Optional[datetime] = None
    friends: list[int] = []

external_data = {'id': '123', 'signup_ts': '2017-06-01 12:22', 'friends': [1, '2', b'3']}
user = User(**external_data)
print(user)
#> User id=123 name='John Doe' signup_ts=datetime.datetime(2017, 6, 1, 12, 22) friends=[1, 2, 3]
print(user.id)
#> 123
```

## Contributing

For guidance on setting up a development environment and how to make a
contribution to Pydantic, see
[Contributing to Pydantic](https://docs.pydantic.dev/contributing/).

## Reporting a Security Vulnerability

See our [security policy](https://github.com/pydantic/pydantic/security/policy).


## Links discovered
- [![CI](https://img.shields.io/github/actions/workflow/status/pydantic/pydantic/ci.yml?branch=main&logo=github&label=CI)
- [![Coverage](https://coverage-badge.samuelcolvin.workers.dev/pydantic/pydantic.svg)
- [![pypi](https://img.shields.io/pypi/v/pydantic.svg)
- [![CondaForge](https://img.shields.io/conda/v/conda-forge/pydantic.svg)
- [![downloads](https://static.pepy.tech/badge/pydantic/month)
- [![versions](https://img.shields.io/pypi/pyversions/pydantic.svg)
- [![license](https://img.shields.io/github/license/pydantic/pydantic.svg)
- [![Pydantic v2](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/pydantic/pydantic/main/docs/badge/v2.json)
- [![llms.txt](https://img.shields.io/badge/llms.txt-green)
- [Learn more](https://pydantic.dev/articles/logfire-announcement)
- [pydantic V1.10 Documentation](https://docs.pydantic.dev/)
- [`1.10.X-fixes` git branch](https://github.com/pydantic/pydantic/tree/1.10.X-fixes)
- [documentation](https://docs.pydantic.dev/)
- [Install](https://docs.pydantic.dev/install/)
- [Contributing to Pydantic](https://docs.pydantic.dev/contributing/)
- [security policy](https://github.com/pydantic/pydantic/security/policy)

--- .github/PULL_REQUEST_TEMPLATE.md ---
<!-- Thank you for your contribution! -->
<!-- Unless your change is trivial, please create an issue to discuss the change before creating a PR -->

## Change Summary

<!-- Please give a short summary of the changes. -->

## Related issue number

<!-- WARNING: please use "fix #123" style references so the issue is closed when this PR is merged. -->

## Checklist

* [ ] The pull request title is a good summary of the changes - it will be used in the changelog
* [ ] Unit tests for the changes exist
* [ ] Tests pass on CI
* [ ] Documentation reflects the changes where applicable
* [ ] My PR is ready to review, **please add a comment including the phrase "please review" to assign reviewers**


--- .github/actions/people/people.py ---
"""Use the github API to get lists of people who have contributed in various ways to Pydantic.

This logic is inspired by that of @tiangolo's
[FastAPI people script](https://github.com/tiangolo/fastapi/blob/master/.github/actions/people/app/main.py).
"""

# ruff: noqa: D101
# ruff: noqa: D103

import logging
import subprocess
import sys
from collections import Counter
from collections.abc import Container
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Any

import requests
import yaml
from github import Github
from pydantic_settings import BaseSettings

from pydantic import BaseModel, SecretStr

github_graphql_url = 'https://api.github.com/graphql'

discussions_query = """
query Q($after: String) {
  repository(name: "pydantic", owner: "pydantic") {
    discussions(first: 100, after: $after) {
      edges {
        cursor
        node {
          number
          author {
            login
            avatarUrl
            url
          }
          title
          createdAt
          comments(first: 100) {
            nodes {
              createdAt
              author {
                login
                avatarUrl
                url
              }
              isAnswer
              replies(first: 10) {
                nodes {
                  createdAt
                  author {
                    login
                    avatarUrl
                    url
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}
"""

issues_query = """
query Q($after: String) {
  repository(name: "pydantic", owner: "samuelcolvin") {
    issues(first: 100, after: $after) {
      edges {
        cursor
        node {
          number
          author {
            login
            avatarUrl
            url
          }
          title
          createdAt
          state
          comments(first: 100) {
            nodes {
              createdAt
              author {
                login
                avatarUrl
                url
              }
            }
          }
        }
      }
    }
  }
}
"""

prs_query = """
query Q($after: String) {
  repository(name: "pydantic", owner: "samuelcolvin") {
    pullRequests(first: 100, after: $after) {
      edges {
        cursor
        node {
          number
          labels(first: 100) {
            nodes {
              name
            }
          }
          author {
            login
            avatarUrl
            url
          }
          title
          createdAt
          state
          comments(first: 100) {
            nodes {
              createdAt
              author {
                login
                avatarUrl
                url
              }
            }
          }
          reviews(first:100) {
            nodes {
              author {
                login
                avatarUrl
                url
              }
              state
            }
          }
        }
      }
    }
  }
}
"""


class Author(BaseModel):
    """Represents a GitHub user with their basic information."""

    login: str
    avatarUrl: str
    url: str


# Issues and Discussions


class CommentsNode(BaseModel):
    """Represents a comment node with creation time and author information."""

    createdAt: datetime
    author: Author | None = None


class Replies(BaseModel):
    """Container for reply nodes in a discussion."""

    nodes: list[CommentsNode]


class DiscussionsCommentsNode(CommentsNode):
    """Extends CommentsNode to include replies in discussions."""

    replies: Replies


class Comments(BaseModel):
    """Container for comment nodes."""

    nodes: list[CommentsNode]


class DiscussionsComments(BaseModel):
    """Container for discussion comment nodes."""

    nodes: list[DiscussionsCommentsNode]


class IssuesNode(BaseModel):
    """Represents a GitHub issue with its metadata and comments."""

    number: int
    author: Author | None = None
    title: str
    createdAt: datetime
    state: str
    comments: Comments


class DiscussionsNode(BaseModel):
    """Represents a GitHub discussion with its metadata and comments."""

    number: int
    author: Author | None = None
    title: str
    createdAt: datetime
    comments: DiscussionsComments


class IssuesEdge(BaseModel):
    """Represents an edge in the GitHub GraphQL issues query."""

    cursor: str
    node: IssuesNode


class DiscussionsEdge(BaseModel):
    """Represents an edge in the GitHub GraphQL discussions query."""

    cursor: str
    node: DiscussionsNode


class Issues(BaseModel):
    """Container for issue edges."""

    edges: list[IssuesEdge]


class Discussions(BaseModel):
    """Container for discussion edges."""

    edges: list[DiscussionsEdge]


class IssuesRepository(BaseModel):
    """Represents a repository's issues in the GitHub GraphQL response."""

    issues: Issues


class DiscussionsRepository(BaseModel):
    """Represents a repository's discussions in the GitHub GraphQL response."""

    discussions: Discussions


class IssuesResponseData(BaseModel):
    """Top-level container for issues response data."""

    repository: IssuesRepository


class DiscussionsResponseData(BaseModel):
    """Top-level container for discussions response data."""

    repository: DiscussionsRepository


class IssuesResponse(BaseModel):
    """Complete response structure for issues query."""

    data: IssuesResponseData


class DiscussionsResponse(BaseModel):
    """Complete response structure for discussions query."""

    data: DiscussionsResponseData


# PRs


class LabelNode(BaseModel):
    """Represents a GitHub label."""

    name: str


class Labels(BaseModel):
    """Container for label nodes."""

    nodes: list[LabelNode]


class ReviewNode(BaseModel):
    """Represents a pull request review with author and state."""

    author: Author | None = None
    state: str


class Reviews(BaseModel):
    """Container for review nodes."""

    nodes: list[ReviewNode]


class PullRequestNode(BaseModel):
    """Represents a GitHub pull request with its metadata and interactions."""

    number: int
    labels: Labels
    author: Author | None = None
    title: str
    createdAt: datetime
    state: str
    comments: Comments
    reviews: Reviews


class PullRequestEdge(BaseModel):
    """Represents an edge in the GitHub GraphQL pull requests query."""

    cursor: str
    node: PullRequestNode


class PullRequests(BaseModel):
    """Container for pull request edges."""

    edges: list[PullRequestEdge]


class PRsRepository(BaseModel):
    """Represents a repository's pull requests in the GitHub GraphQL response."""

    pullRequests: PullRequests


class PRsResponseData(BaseModel):
    """Top-level container for pull requests response data."""

    repository: PRsRepository


class PRsResponse(BaseModel):
    """Complete response structure for pull requests query."""

    data: PRsResponseData


class Settings(BaseSettings):
    """Configuration settings for the GitHub API interaction."""

    input_token: SecretStr
    github_repository: str = 'pydantic/pydantic'
    request_timeout: int = 30


def get_graphql_response(
    *,
    settings: Settings,
    query: str,
    after: str | None = None,
) -> dict[str, Any]:
    """Make a GraphQL request to GitHub API.

    Args:
        settings: Configuration settings including API token
        query: GraphQL query string
        after: Cursor for pagination, if any

    Returns:
        Response data from GitHub API in JSON format

    Raises:
        RuntimeError: If the API request fails or returns errors
    """
    headers = {'Authorization': f'token {settings.input_token.get_secret_value()}'}
    variables = {'after': after}
    response = requests.post(
        github_graphql_url,
        headers=headers,
        timeout=settings.request_timeout,
        json={'query': query, 'variables': variables, 'operationName': 'Q'},
    )
    if response.status_code != 200:
        logging.error(f'Response was not 200, after: {after}')
        logging.error(response.text)
        raise RuntimeError(response.text)
    data = response.json()
    if 'errors' in data:
        logging.error(f'Errors in response, after: {after}')
        logging.error(data['errors'])
        logging.error(response.text)
        raise RuntimeError(response.text)
    return data


def get_graphql_issue_edges(*, settings: Settings, after: str | None = None) -> list[IssuesEdge]:
    """Fetch issue edges from GitHub GraphQL API.

    Args:
        settings: Configuration settings
        after: Cursor for pagination, if any

    Returns:
        List of issue edges from the GraphQL response
    """
    data = get_graphql_response(settings=settings, query=issues_query, after=after)
    graphql_response = IssuesResponse.model_validate(data)
    return graphql_response.data.repository.issues.edges


def get_graphql_question_discussion_edges(
    *,
    settings: Settings,
    after: str | None = None,
) -> list[DiscussionsEdge]:
    """Fetch discussion edges from GitHub GraphQL API.

    Args:
        settings: Configuration settings
        after: Cursor for pagination, if any

    Returns:
        List of discussion edges from the GraphQL response
    """
    data = get_graphql_response(
        settings=settings,
        query=discussions_query,
        after=after,
    )
    graphql_response = DiscussionsResponse.model_validate(data)
    return graphql_response.data.repository.discussions.edges


def get_graphql_pr_edges(*, settings: Settings, after: str | None = None) -> list[PullRequestEdge]:
    """Fetch pull request edges from GitHub GraphQL API.

    Args:
        settings: Configuration settings
        after: Cursor for pagination, if any

    Returns:
        List of pull request edges from the GraphQL response
    """
    data = get_graphql_response(settings=settings, query=prs_query, after=after)
    graphql_response = PRsResponse.model_validate(data)
    return graphql_response.data.repository.pullRequests.edges


def get_issues_experts(settings: Settings) -> tuple[Counter, Counter, dict[str, Author]]:
    """Analyze issues to identify expert contributors.

    Args:
        settings: Configuration settings

    Returns:
        A tuple containing:
            - Counter of all commentors
            - Counter of commentors from the last month
            - Dictionary mapping usernames to Author objects
    """
    issue_nodes: list[IssuesNode] = []
    issue_edges = get_graphql_issue_edges(settings=settings)

    while issue_edges:
        issue_nodes.extend(edge.node for edge in issue_edges)
        last_edge = issue_edges[-1]
        issue_edges = get_graphql_issue_edges(settings=settings, after=last_edge.cursor)

    commentors = Counter()
    last_month_commentors = Counter()
    authors: dict[str, Author] = {}

    now = datetime.now(tz=timezone.utc)
    one_month_ago = now - timedelta(days=30)

    for issue in issue_nodes:
        issue_author_name = None
        if issue.author:
            authors[issue.author.login] = issue.author
            issue_author_name = issue.author.login
        issue_commentors = set()
        for comment in issue.comments.nodes:
            if comment.author:
                authors[comment.author.login] = comment.author
                if comment.author.login != issue_author_name:
                    issue_commentors.add(comment.author.login)
        for author_name in issue_commentors:
            commentors[author_name] += 1
            if issue.createdAt > one_month_ago:
                last_month_commentors[author_name] += 1

    return commentors, last_month_commentors, authors


def get_discussions_experts(settings: Settings) -> tuple[Counter, Counter, dict[str, Author]]:
    """Analyze discussions to identify expert contributors.

    Args:
        settings: Configuration settings

    Returns:
        A tuple containing:
            - Counter of all commentors
            - Counter of commentors from the last month
            - Dictionary mapping usernames to Author objects
    """
    discussion_nodes: list[DiscussionsNode] = []
    discussion_edges = get_graphql_question_discussion_edges(settings=settings)

    while discussion_edges:
        discussion_nodes.extend(discussion_edge.node for discussion_edge in discussion_edges)
        last_edge = discussion_edges[-1]
        discussion_edges = get_graphql_question_discussion_edges(settings=settings, after=last_edge.cursor)

    commentors = Counter()
    last_month_commentors = Counter()
    authors: dict[str, Author] = {}

    now = datetime.now(tz=timezone.utc)
    one_month_ago = now - timedelta(days=30)

    for discussion in discussion_nodes:
        discussion_author_name = None
        if discussion.author:
            authors[discussion.author.login] = discussion.author
            discussion_author_name = discussion.author.login
        discussion_commentors = set()
        for comment in discussion.comments.nodes:
            if comment.author:
                authors[comment.author.login] = comment.author
                if comment.author.login != discussion_author_name:
                    discussion_commentors.add(comment.author.login)
            for reply in comment.replies.nodes:
                if reply.author:
                    authors[reply.author.login] = reply.author
                    if reply.author.login != discussion_author_name:
                        discussion_commentors.add(reply.author.login)
        for author_name in discussion_commentors:
            commentors[author_name] += 1
            if discussion.createdAt > one_month_ago:
                last_month_commentors[author_name] += 1
    return commentors, last_month_commentors, authors


def get_experts(settings: Settings) -> tuple[Counter, Counter, dict[str, Author]]:
    """Get combined expert contributors from discussions.

    Args:
        settings: Configuration settings

    Returns:
        A tuple containing:
            - Counter of all commentors
            - Counter of commentors from the last month
            - Dictionary mapping usernames to Author objects
    """
    # Migrated to only use GitHub Discussions
    # (
    #     issues_commentors,
    #     issues_last_month_commentors,
    #     issues_authors,
    # ) = get_issues_experts(settings=settings)
    (
        discussions_commentors,
        discussions_last_month_commentors,
        discussions_authors,
    ) = get_discussions_experts(settings=settings)
    # commentors = issues_commentors + discussions_commentors
    commentors = discussions_commentors
    # last_month_commentors = (
    #     issues_last_month_commentors + discussions_last_month_commentors
    # )
    last_month_commentors = discussions_last_month_commentors
    # authors = {**issues_authors, **discussions_authors}
    authors = {**discussions_authors}
    return commentors, last_month_commentors, authors


def get_contributors(settings: Settings) -> tuple[Counter, Counter, Counter, dict[str, Author]]:
    """Analyze pull requests to identify contributors, commentors, and reviewers.

    Args:
        settings: Configuration settings

    Returns:
        A tuple containing:
            - Counter of contributors (merged PRs)
            - Counter of commentors
            - Counter of reviewers
            - Dictionary mapping usernames to Author objects
    """
    pr_nodes: list[PullRequestNode] = []
    pr_edges = get_graphql_pr_edges(settings=settings)

    while pr_edges:
        pr_nodes.extend(edge.node for edge in pr_edges)
        last_edge = pr_edges[-1]
        pr_edges = get_graphql_pr_edges(settings=settings, after=last_edge.cursor)

    contributors = Counter()
    commentors = Counter()
    reviewers = Counter()
    authors: dict[str, Author] = {}

    for pr in pr_nodes:
        author_name = None
        if pr.author:
            authors[pr.author.login] = pr.author
            author_name = pr.author.login
        pr_commentors: set[str] = set()
        pr_reviewers: set[str] = set()
        for comment in pr.comments.nodes:
            if comment.author:
                authors[comment.author.login] = comment.author
                if comment.author.login == author_name:
                    continue
                pr_commentors.add(comment.author.login)
        for author_name in pr_commentors:
            commentors[author_name] += 1
        for review in pr.reviews.nodes:
            if review.author:
                authors[review.author.login] = review.author
                pr_reviewers.add(review.author.login)
        for reviewer in pr_reviewers:
            reviewers[reviewer] += 1
        if pr.state == 'MERGED' and pr.author:
            contributors[pr.author.login] += 1
    return contributors, commentors, reviewers, authors


def get_top_users(
    *,
    counter: Counter,
    min_count: int,
    authors: dict[str, Author],
    skip_users: Container[str],
) -> list[dict[str, Any]]:
    """Get top users based on their contribution counts.

    Args:
        counter: Counter with user contribution counts
        min_count: Minimum count to be included in results
        authors: Dictionary mapping usernames to Author objects
        skip_users: Container of usernames to exclude from results

    Returns:
        List of dictionaries containing:
            - login: Username
            - count: Number of contributions
            - avatarUrl: URL to user's avatar
            - url: URL to user's GitHub profile
    """
    users: list[dict[str, Any]] = []
    for commentor, count in counter.most_common(50):
        if commentor in skip_users:
            continue
        if count >= min_count:
            author = authors[commentor]
            users.append(
                {
                    'login': commentor,
                    'count': count,
                    'avatarUrl': author.avatarUrl,
                    'url': author.url,
                }
            )
    return users


if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    settings = Settings()
    logging.info(f'Using config: {settings.model_dump_json()}')
    g = Github(settings.input_token.get_secret_value())
    repo = g.get_repo(settings.github_repository)
    question_commentors, question_last_month_commentors, question_authors = get_experts(settings=settings)
    contributors, pr_commentors, reviewers, pr_authors = get_contributors(settings=settings)
    authors = {**question_authors, **pr_authors}
    maintainers_logins = {
        'samuelcolvin',
        'adriangb',
        'dmontagu',
        'hramezani',
        'Kludex',
        'davidhewitt',
        'alexmojaki',
        'Viicos',
    }
    bot_names = {'codecov', 'github-actions', 'pre-commit-ci', 'dependabot'}
    maintainers = []
    for login in maintainers_logins:
        user = authors[login]
        maintainers.append(
            {
                'login': login,
                'answers': question_commentors[login],
                'prs': contributors[login],
                'avatarUrl': user.avatarUrl,
                'url': user.url,
            }
        )

    min_count_expert = 10
    min_count_last_month = 3
    min_count_contributor = 4
    min_count_reviewer = 4
    skip_users = maintainers_logins | bot_names
    experts = get_top_users(
        counter=question_commentors,
        min_count=min_count_expert,
        authors=authors,
        skip_users=skip_users,
    )
    last_month_active = get_top_users(
        counter=question_last_month_commentors,
        min_count=min_count_last_month,
        authors=authors,
        skip_users=skip_users,
    )
    top_contributors = get_top_users(
        counter=contributors,
        min_count=min_count_contributor,
        authors=authors,
        skip_users=skip_users,
    )
    top_reviewers = get_top_users(
        counter=reviewers,
        min_count=min_count_reviewer,
        authors=authors,
        skip_users=skip_users,
    )

    extra_experts = [
        {
            'login': 'ybressler',
            'count': None,
            'avatarUrl': 'https://avatars.githubusercontent.com/u/40807730?v=4',
            'url': 'https://github.com/ybressler',
        },
    ]
    expert_logins = {e['login'] for e in experts}
    experts.extend([expert for expert in extra_experts if expert['login'] not in expert_logins])

    people = {
        'maintainers': maintainers,
        'experts': experts,
        'last_month_active': last_month_active,
        'top_contributors': top_contributors,
        'top_reviewers': top_reviewers,
    }
    people_path = Path('./docs/plugins/people.yml')
    people_old_content = people_path.read_text(encoding='utf-8')
    new_people_content = yaml.dump(people, sort_keys=False, width=200, allow_unicode=True)
    if people_old_content == new_people_content:
        logging.info("The Pydantic People data hasn't changed, finishing.")
        sys.exit(0)
    people_path.write_text(new_people_content, encoding='utf-8')

    logging.info('Setting up GitHub Actions git user')
    subprocess.run(['git', 'config', 'user.name', 'github-actions'], check=True)
    subprocess.run(['git', 'config', 'user.email', 'github-actions@github.com'], check=True)

    branch_name = 'pydantic-people-update'
    logging.info(f'Creating a new branch {branch_name}')
    subprocess.run(['git', 'checkout', '-b', branch_name], check=True)
    logging.info('Adding updated file')
    subprocess.run(['git', 'add', str(people_path)], check=True)
    logging.info('Committing updated file')
    message = '👥 Update Pydantic People'
    result = subprocess.run(['git', 'commit', '-m', message], check=True)
    logging.info('Pushing branch')
    subprocess.run(['git', 'push', 'origin', branch_name], check=True)
    logging.info('Creating PR')
    pr = repo.create_pull(title=message, body=message, base='main', head=branch_name)
    logging.info(f'Created PR: {pr.number}')
    logging.info('Finished')


## Links discovered
- [FastAPI people script](https://github.com/tiangolo/fastapi/blob/master/.github/actions/people/app/main.py)

--- pydantic/alias_generators.py ---
"""Alias generators for converting between different capitalization conventions."""

import re

__all__ = ('to_pascal', 'to_camel', 'to_snake')

# TODO: in V3, change the argument names to be more descriptive
# Generally, don't only convert from snake_case, or name the functions
# more specifically like snake_to_camel.


def to_pascal(snake: str) -> str:
    """Convert a snake_case string to PascalCase.

    Args:
        snake: The string to convert.

    Returns:
        The PascalCase string.
    """
    camel = snake.title()
    return re.sub('([0-9A-Za-z])_(?=[0-9A-Z])', lambda m: m.group(1), camel)


def to_camel(snake: str) -> str:
    """Convert a snake_case string to camelCase.

    Args:
        snake: The string to convert.

    Returns:
        The converted camelCase string.
    """
    # If the string is already in camelCase and does not contain a digit followed
    # by a lowercase letter, return it as it is
    if re.match('^[a-z]+[A-Za-z0-9]*$', snake) and not re.search(r'\d[a-z]', snake):
        return snake

    camel = to_pascal(snake)
    return re.sub('(^_*[A-Z])', lambda m: m.group(1).lower(), camel)


def to_snake(camel: str) -> str:
    """Convert a PascalCase, camelCase, or kebab-case string to snake_case.

    Args:
        camel: The string to convert.

    Returns:
        The converted string in snake_case.
    """
    # Handle the sequence of uppercase letters followed by a lowercase letter
    snake = re.sub(r'([A-Z]+)([A-Z][a-z])', lambda m: f'{m.group(1)}_{m.group(2)}', camel)
    # Insert an underscore between a lowercase letter and an uppercase letter
    snake = re.sub(r'([a-z])([A-Z])', lambda m: f'{m.group(1)}_{m.group(2)}', snake)
    # Insert an underscore between a digit and an uppercase letter
    snake = re.sub(r'([0-9])([A-Z])', lambda m: f'{m.group(1)}_{m.group(2)}', snake)
    # Insert an underscore between a lowercase letter and a digit
    snake = re.sub(r'([a-z])([0-9])', lambda m: f'{m.group(1)}_{m.group(2)}', snake)
    # Replace hyphens with underscores to handle kebab-case
    snake = snake.replace('-', '_')
    return snake.lower()


--- pydantic/aliases.py ---
"""Support for alias configurations."""

from __future__ import annotations

import dataclasses
from typing import Any, Callable, Literal

from pydantic_core import PydanticUndefined

from ._internal import _internal_dataclass

__all__ = ('AliasGenerator', 'AliasPath', 'AliasChoices')


@dataclasses.dataclass(**_internal_dataclass.slots_true)
class AliasPath:
    """!!! abstract "Usage Documentation"
        [`AliasPath` and `AliasChoices`](../concepts/alias.md#aliaspath-and-aliaschoices)

    A data class used by `validation_alias` as a convenience to create aliases.

    Attributes:
        path: A list of string or integer aliases.
    """

    path: list[int | str]

    def __init__(self, first_arg: str, *args: str | int) -> None:
        self.path = [first_arg] + list(args)

    def convert_to_aliases(self) -> list[str | int]:
        """Converts arguments to a list of string or integer aliases.

        Returns:
            The list of aliases.
        """
        return self.path

    def search_dict_for_path(self, d: dict) -> Any:
        """Searches a dictionary for the path specified by the alias.

        Returns:
            The value at the specified path, or `PydanticUndefined` if the path is not found.
        """
        v = d
        for k in self.path:
            if isinstance(v, str):
                # disallow indexing into a str, like for AliasPath('x', 0) and x='abc'
                return PydanticUndefined
            try:
                v = v[k]
            except (KeyError, IndexError, TypeError):
                return PydanticUndefined
        return v


@dataclasses.dataclass(**_internal_dataclass.slots_true)
class AliasChoices:
    """!!! abstract "Usage Documentation"
        [`AliasPath` and `AliasChoices`](../concepts/alias.md#aliaspath-and-aliaschoices)

    A data class used by `validation_alias` as a convenience to create aliases.

    Attributes:
        choices: A list containing a string or `AliasPath`.
    """

    choices: list[str | AliasPath]

    def __init__(self, first_choice: str | AliasPath, *choices: str | AliasPath) -> None:
        self.choices = [first_choice] + list(choices)

    def convert_to_aliases(self) -> list[list[str | int]]:
        """Converts arguments to a list of lists containing string or integer aliases.

        Returns:
            The list of aliases.
        """
        aliases: list[list[str | int]] = []
        for c in self.choices:
            if isinstance(c, AliasPath):
                aliases.append(c.convert_to_aliases())
            else:
                aliases.append([c])
        return aliases


@dataclasses.dataclass(**_internal_dataclass.slots_true)
class AliasGenerator:
    """!!! abstract "Usage Documentation"
        [Using an `AliasGenerator`](../concepts/alias.md#using-an-aliasgenerator)

    A data class used by `alias_generator` as a convenience to create various aliases.

    Attributes:
        alias: A callable that takes a field name and returns an alias for it.
        validation_alias: A callable that takes a field name and returns a validation alias for it.
        serialization_alias: A callable that takes a field name and returns a serialization alias for it.
    """

    alias: Callable[[str], str] | None = None
    validation_alias: Callable[[str], str | AliasPath | AliasChoices] | None = None
    serialization_alias: Callable[[str], str] | None = None

    def _generate_alias(
        self,
        alias_kind: Literal['alias', 'validation_alias', 'serialization_alias'],
        allowed_types: tuple[type[str] | type[AliasPath] | type[AliasChoices], ...],
        field_name: str,
    ) -> str | AliasPath | AliasChoices | None:
        """Generate an alias of the specified kind. Returns None if the alias generator is None.

        Raises:
            TypeError: If the alias generator produces an invalid type.
        """
        alias = None
        if alias_generator := getattr(self, alias_kind):
            alias = alias_generator(field_name)
            if alias and not isinstance(alias, allowed_types):
                raise TypeError(
                    f'Invalid `{alias_kind}` type. `{alias_kind}` generator must produce one of `{allowed_types}`'
                )
        return alias

    def generate_aliases(self, field_name: str) -> tuple[str | None, str | AliasPath | AliasChoices | None, str | None]:
        """Generate `alias`, `validation_alias`, and `serialization_alias` for a field.

        Returns:
            A tuple of three aliases - validation, alias, and serialization.
        """
        alias = self._generate_alias('alias', (str,), field_name)
        validation_alias = self._generate_alias('validation_alias', (str, AliasChoices, AliasPath), field_name)
        serialization_alias = self._generate_alias('serialization_alias', (str,), field_name)

        return alias, validation_alias, serialization_alias  # type: ignore


## Links discovered
- [`AliasPath` and `AliasChoices`](https://github.com/pydantic/pydantic/blob/main/concepts/alias.md#aliaspath-and-aliaschoices)
- [Using an `AliasGenerator`](https://github.com/pydantic/pydantic/blob/main/concepts/alias.md#using-an-aliasgenerator)

--- pydantic/annotated_handlers.py ---
"""Type annotations to use with `__get_pydantic_core_schema__` and `__get_pydantic_json_schema__`."""

from __future__ import annotations as _annotations

from typing import TYPE_CHECKING, Any, Union

from pydantic_core import core_schema

if TYPE_CHECKING:
    from ._internal._namespace_utils import NamespacesTuple
    from .json_schema import JsonSchemaMode, JsonSchemaValue

    CoreSchemaOrField = Union[
        core_schema.CoreSchema,
        core_schema.ModelField,
        core_schema.DataclassField,
        core_schema.TypedDictField,
        core_schema.ComputedField,
    ]

__all__ = 'GetJsonSchemaHandler', 'GetCoreSchemaHandler'


class GetJsonSchemaHandler:
    """Handler to call into the next JSON schema generation function.

    Attributes:
        mode: Json schema mode, can be `validation` or `serialization`.
    """

    mode: JsonSchemaMode

    def __call__(self, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:
        """Call the inner handler and get the JsonSchemaValue it returns.
        This will call the next JSON schema modifying function up until it calls
        into `pydantic.json_schema.GenerateJsonSchema`, which will raise a
        `pydantic.errors.PydanticInvalidForJsonSchema` error if it cannot generate
        a JSON schema.

        Args:
            core_schema: A `pydantic_core.core_schema.CoreSchema`.

        Returns:
            JsonSchemaValue: The JSON schema generated by the inner JSON schema modify
            functions.
        """
        raise NotImplementedError

    def resolve_ref_schema(self, maybe_ref_json_schema: JsonSchemaValue, /) -> JsonSchemaValue:
        """Get the real schema for a `{"$ref": ...}` schema.
        If the schema given is not a `$ref` schema, it will be returned as is.
        This means you don't have to check before calling this function.

        Args:
            maybe_ref_json_schema: A JsonSchemaValue which may be a `$ref` schema.

        Raises:
            LookupError: If the ref is not found.

        Returns:
            JsonSchemaValue: A JsonSchemaValue that has no `$ref`.
        """
        raise NotImplementedError


class GetCoreSchemaHandler:
    """Handler to call into the next CoreSchema schema generation function."""

    def __call__(self, source_type: Any, /) -> core_schema.CoreSchema:
        """Call the inner handler and get the CoreSchema it returns.
        This will call the next CoreSchema modifying function up until it calls
        into Pydantic's internal schema generation machinery, which will raise a
        `pydantic.errors.PydanticSchemaGenerationError` error if it cannot generate
        a CoreSchema for the given source type.

        Args:
            source_type: The input type.

        Returns:
            CoreSchema: The `pydantic-core` CoreSchema generated.
        """
        raise NotImplementedError

    def generate_schema(self, source_type: Any, /) -> core_schema.CoreSchema:
        """Generate a schema unrelated to the current context.
        Use this function if e.g. you are handling schema generation for a sequence
        and want to generate a schema for its items.
        Otherwise, you may end up doing something like applying a `min_length` constraint
        that was intended for the sequence itself to its items!

        Args:
            source_type: The input type.

        Returns:
            CoreSchema: The `pydantic-core` CoreSchema generated.
        """
        raise NotImplementedError

    def resolve_ref_schema(self, maybe_ref_schema: core_schema.CoreSchema, /) -> core_schema.CoreSchema:
        """Get the real schema for a `definition-ref` schema.
        If the schema given is not a `definition-ref` schema, it will be returned as is.
        This means you don't have to check before calling this function.

        Args:
            maybe_ref_schema: A `CoreSchema`, `ref`-based or not.

        Raises:
            LookupError: If the `ref` is not found.

        Returns:
            A concrete `CoreSchema`.
        """
        raise NotImplementedError

    @property
    def field_name(self) -> str | None:
        """Get the name of the closest field to this validator."""
        raise NotImplementedError

    def _get_types_namespace(self) -> NamespacesTuple:
        """Internal method used during type resolution for serializer annotations."""
        raise NotImplementedError


--- pydantic/color.py ---
"""Color definitions are used as per the CSS3
[CSS Color Module Level 3](http://www.w3.org/TR/css3-color/#svg-color) specification.

A few colors have multiple names referring to the sames colors, eg. `grey` and `gray` or `aqua` and `cyan`.

In these cases the _last_ color when sorted alphabetically takes preferences,
eg. `Color((0, 255, 255)).as_named() == 'cyan'` because "cyan" comes after "aqua".

Warning: Deprecated
    The `Color` class is deprecated, use `pydantic_extra_types` instead.
    See [`pydantic-extra-types.Color`](../usage/types/extra_types/color_types.md)
    for more information.
"""

import math
import re
from colorsys import hls_to_rgb, rgb_to_hls
from typing import Any, Callable, Optional, Union, cast

from pydantic_core import CoreSchema, PydanticCustomError, core_schema
from typing_extensions import deprecated

from ._internal import _repr
from ._internal._schema_generation_shared import GetJsonSchemaHandler as _GetJsonSchemaHandler
from .json_schema import JsonSchemaValue
from .warnings import PydanticDeprecatedSince20

ColorTuple = Union[tuple[int, int, int], tuple[int, int, int, float]]
ColorType = Union[ColorTuple, str]
HslColorTuple = Union[tuple[float, float, float], tuple[float, float, float, float]]


class RGBA:
    """Internal use only as a representation of a color."""

    __slots__ = 'r', 'g', 'b', 'alpha', '_tuple'

    def __init__(self, r: float, g: float, b: float, alpha: Optional[float]):
        self.r = r
        self.g = g
        self.b = b
        self.alpha = alpha

        self._tuple: tuple[float, float, float, Optional[float]] = (r, g, b, alpha)

    def __getitem__(self, item: Any) -> Any:
        return self._tuple[item]


# these are not compiled here to avoid import slowdown, they'll be compiled the first time they're used, then cached
_r_255 = r'(\d{1,3}(?:\.\d+)?)'
_r_comma = r'\s*,\s*'
_r_alpha = r'(\d(?:\.\d+)?|\.\d+|\d{1,2}%)'
_r_h = r'(-?\d+(?:\.\d+)?|-?\.\d+)(deg|rad|turn)?'
_r_sl = r'(\d{1,3}(?:\.\d+)?)%'
r_hex_short = r'\s*(?:#|0x)?([0-9a-f])([0-9a-f])([0-9a-f])([0-9a-f])?\s*'
r_hex_long = r'\s*(?:#|0x)?([0-9a-f]{2})([0-9a-f]{2})([0-9a-f]{2})([0-9a-f]{2})?\s*'
# CSS3 RGB examples: rgb(0, 0, 0), rgba(0, 0, 0, 0.5), rgba(0, 0, 0, 50%)
r_rgb = rf'\s*rgba?\(\s*{_r_255}{_r_comma}{_r_255}{_r_comma}{_r_255}(?:{_r_comma}{_r_alpha})?\s*\)\s*'
# CSS3 HSL examples: hsl(270, 60%, 50%), hsla(270, 60%, 50%, 0.5), hsla(270, 60%, 50%, 50%)
r_hsl = rf'\s*hsla?\(\s*{_r_h}{_r_comma}{_r_sl}{_r_comma}{_r_sl}(?:{_r_comma}{_r_alpha})?\s*\)\s*'
# CSS4 RGB examples: rgb(0 0 0), rgb(0 0 0 / 0.5), rgb(0 0 0 / 50%), rgba(0 0 0 / 50%)
r_rgb_v4_style = rf'\s*rgba?\(\s*{_r_255}\s+{_r_255}\s+{_r_255}(?:\s*/\s*{_r_alpha})?\s*\)\s*'
# CSS4 HSL examples: hsl(270 60% 50%), hsl(270 60% 50% / 0.5), hsl(270 60% 50% / 50%), hsla(270 60% 50% / 50%)
r_hsl_v4_style = rf'\s*hsla?\(\s*{_r_h}\s+{_r_sl}\s+{_r_sl}(?:\s*/\s*{_r_alpha})?\s*\)\s*'

# colors where the two hex characters are the same, if all colors match this the short version of hex colors can be used
repeat_colors = {int(c * 2, 16) for c in '0123456789abcdef'}
rads = 2 * math.pi


@deprecated(
    'The `Color` class is deprecated, use `pydantic_extra_types` instead. '
    'See https://docs.pydantic.dev/latest/api/pydantic_extra_types_color/.',
    category=PydanticDeprecatedSince20,
)
class Color(_repr.Representation):
    """Represents a color."""

    __slots__ = '_original', '_rgba'

    def __init__(self, value: ColorType) -> None:
        self._rgba: RGBA
        self._original: ColorType
        if isinstance(value, (tuple, list)):
            self._rgba = parse_tuple(value)
        elif isinstance(value, str):
            self._rgba = parse_str(value)
        elif isinstance(value, Color):
            self._rgba = value._rgba
            value = value._original
        else:
            raise PydanticCustomError(
                'color_error', 'value is not a valid color: value must be a tuple, list or string'
            )

        # if we've got here value must be a valid color
        self._original = value

    @classmethod
    def __get_pydantic_json_schema__(
        cls, core_schema: core_schema.CoreSchema, handler: _GetJsonSchemaHandler
    ) -> JsonSchemaValue:
        field_schema = {}
        field_schema.update(type='string', format='color')
        return field_schema

    def original(self) -> ColorType:
        """Original value passed to `Color`."""
        return self._original

    def as_named(self, *, fallback: bool = False) -> str:
        """Returns the name of the color if it can be found in `COLORS_BY_VALUE` dictionary,
        otherwise returns the hexadecimal representation of the color or raises `ValueError`.

        Args:
            fallback: If True, falls back to returning the hexadecimal representation of
                the color instead of raising a ValueError when no named color is found.

        Returns:
            The name of the color, or the hexadecimal representation of the color.

        Raises:
            ValueError: When no named color is found and fallback is `False`.
        """
        if self._rgba.alpha is None:
            rgb = cast(tuple[int, int, int], self.as_rgb_tuple())
            try:
                return COLORS_BY_VALUE[rgb]
            except KeyError as e:
                if fallback:
                    return self.as_hex()
                else:
                    raise ValueError('no named color found, use fallback=True, as_hex() or as_rgb()') from e
        else:
            return self.as_hex()

    def as_hex(self) -> str:
        """Returns the hexadecimal representation of the color.

        Hex string representing the color can be 3, 4, 6, or 8 characters depending on whether the string
        a "short" representation of the color is possible and whether there's an alpha channel.

        Returns:
            The hexadecimal representation of the color.
        """
        values = [float_to_255(c) for c in self._rgba[:3]]
        if self._rgba.alpha is not None:
            values.append(float_to_255(self._rgba.alpha))

        as_hex = ''.join(f'{v:02x}' for v in values)
        if all(c in repeat_colors for c in values):
            as_hex = ''.join(as_hex[c] for c in range(0, len(as_hex), 2))
        return '#' + as_hex

    def as_rgb(self) -> str:
        """Color as an `rgb(<r>, <g>, <b>)` or `rgba(<r>, <g>, <b>, <a>)` string."""
        if self._rgba.alpha is None:
            return f'rgb({float_to_255(self._rgba.r)}, {float_to_255(self._rgba.g)}, {float_to_255(self._rgba.b)})'
        else:
            return (
                f'rgba({float_to_255(self._rgba.r)}, {float_to_255(self._rgba.g)}, {float_to_255(self._rgba.b)}, '
                f'{round(self._alpha_float(), 2)})'
            )

    def as_rgb_tuple(self, *, alpha: Optional[bool] = None) -> ColorTuple:
        """Returns the color as an RGB or RGBA tuple.

        Args:
            alpha: Whether to include the alpha channel. There are three options for this input:

                - `None` (default): Include alpha only if it's set. (e.g. not `None`)
                - `True`: Always include alpha.
                - `False`: Always omit alpha.

        Returns:
            A tuple that contains the values of the red, green, and blue channels in the range 0 to 255.
                If alpha is included, it is in the range 0 to 1.
        """
        r, g, b = (float_to_255(c) for c in self._rgba[:3])
        if alpha is None:
            if self._rgba.alpha is None:
                return r, g, b
            else:
                return r, g, b, self._alpha_float()
        elif alpha:
            return r, g, b, self._alpha_float()
        else:
            # alpha is False
            return r, g, b

    def as_hsl(self) -> str:
        """Color as an `hsl(<h>, <s>, <l>)` or `hsl(<h>, <s>, <l>, <a>)` string."""
        if self._rgba.alpha is None:
            h, s, li = self.as_hsl_tuple(alpha=False)  # type: ignore
            return f'hsl({h * 360:0.0f}, {s:0.0%}, {li:0.0%})'
        else:
            h, s, li, a = self.as_hsl_tuple(alpha=True)  # type: ignore
            return f'hsl({h * 360:0.0f}, {s:0.0%}, {li:0.0%}, {round(a, 2)})'

    def as_hsl_tuple(self, *, alpha: Optional[bool] = None) -> HslColorTuple:
        """Returns the color as an HSL or HSLA tuple.

        Args:
            alpha: Whether to include the alpha channel.

                - `None` (default): Include the alpha channel only if it's set (e.g. not `None`).
                - `True`: Always include alpha.
                - `False`: Always omit alpha.

        Returns:
            The color as a tuple of hue, saturation, lightness, and alpha (if included).
                All elements are in the range 0 to 1.

        Note:
            This is HSL as used in HTML and most other places, not HLS as used in Python's `colorsys`.
        """
        h, l, s = rgb_to_hls(self._rgba.r, self._rgba.g, self._rgba.b)  # noqa: E741
        if alpha is None:
            if self._rgba.alpha is None:
                return h, s, l
            else:
                return h, s, l, self._alpha_float()
        if alpha:
            return h, s, l, self._alpha_float()
        else:
            # alpha is False
            return h, s, l

    def _alpha_float(self) -> float:
        return 1 if self._rgba.alpha is None else self._rgba.alpha

    @classmethod
    def __get_pydantic_core_schema__(
        cls, source: type[Any], handler: Callable[[Any], CoreSchema]
    ) -> core_schema.CoreSchema:
        return core_schema.with_info_plain_validator_function(
            cls._validate, serialization=core_schema.to_string_ser_schema()
        )

    @classmethod
    def _validate(cls, __input_value: Any, _: Any) -> 'Color':
        return cls(__input_value)

    def __str__(self) -> str:
        return self.as_named(fallback=True)

    def __repr_args__(self) -> '_repr.ReprArgs':
        return [(None, self.as_named(fallback=True))] + [('rgb', self.as_rgb_tuple())]

    def __eq__(self, other: Any) -> bool:
        return isinstance(other, Color) and self.as_rgb_tuple() == other.as_rgb_tuple()

    def __hash__(self) -> int:
        return hash(self.as_rgb_tuple())


def parse_tuple(value: tuple[Any, ...]) -> RGBA:
    """Parse a tuple or list to get RGBA values.

    Args:
        value: A tuple or list.

    Returns:
        An `RGBA` tuple parsed from the input tuple.

    Raises:
        PydanticCustomError: If tuple is not valid.
    """
    if len(value) == 3:
        r, g, b = (parse_color_value(v) for v in value)
        return RGBA(r, g, b, None)
    elif len(value) == 4:
        r, g, b = (parse_color_value(v) for v in value[:3])
        return RGBA(r, g, b, parse_float_alpha(value[3]))
    else:
        raise PydanticCustomError('color_error', 'value is not a valid color: tuples must have length 3 or 4')


def parse_str(value: str) -> RGBA:
    """Parse a string representing a color to an RGBA tuple.

    Possible formats for the input string include:

    * named color, see `COLORS_BY_NAME`
    * hex short eg. `<prefix>fff` (prefix can be `#`, `0x` or nothing)
    * hex long eg. `<prefix>ffffff` (prefix can be `#`, `0x` or nothing)
    * `rgb(<r>, <g>, <b>)`
    * `rgba(<r>, <g>, <b>, <a>)`

    Args:
        value: A string representing a color.

    Returns:
        An `RGBA` tuple parsed from the input string.

    Raises:
        ValueError: If the input string cannot be parsed to an RGBA tuple.
    """
    value_lower = value.lower()
    try:
        r, g, b = COLORS_BY_NAME[value_lower]
    except KeyError:
        pass
    else:
        return ints_to_rgba(r, g, b, None)

    m = re.fullmatch(r_hex_short, value_lower)
    if m:
        *rgb, a = m.groups()
        r, g, b = (int(v * 2, 16) for v in rgb)
        if a:
            alpha: Optional[float] = int(a * 2, 16) / 255
        else:
            alpha = None
        return ints_to_rgba(r, g, b, alpha)

    m = re.fullmatch(r_hex_long, value_lower)
    if m:
        *rgb, a = m.groups()
        r, g, b = (int(v, 16) for v in rgb)
        if a:
            alpha = int(a, 16) / 255
        else:
            alpha = None
        return ints_to_rgba(r, g, b, alpha)

    m = re.fullmatch(r_rgb, value_lower) or re.fullmatch(r_rgb_v4_style, value_lower)
    if m:
        return ints_to_rgba(*m.groups())  # type: ignore

    m = re.fullmatch(r_hsl, value_lower) or re.fullmatch(r_hsl_v4_style, value_lower)
    if m:
        return parse_hsl(*m.groups())  # type: ignore

    raise PydanticCustomError('color_error', 'value is not a valid color: string not recognised as a valid color')


def ints_to_rgba(r: Union[int, str], g: Union[int, str], b: Union[int, str], alpha: Optional[float] = None) -> RGBA:
    """Converts integer or string values for RGB color and an optional alpha value to an `RGBA` object.

    Args:
        r: An integer or string representing the red color value.
        g: An integer or string representing the green color value.
        b: An integer or string representing the blue color value.
        alpha: A float representing the alpha value. Defaults to None.

    Returns:
        An instance of the `RGBA` class with the corresponding color and alpha values.
    """
    return RGBA(parse_color_value(r), parse_color_value(g), parse_color_value(b), parse_float_alpha(alpha))


def parse_color_value(value: Union[int, str], max_val: int = 255) -> float:
    """Parse the color value provided and return a number between 0 and 1.

    Args:
        value: An integer or string color value.
        max_val: Maximum range value. Defaults to 255.

    Raises:
        PydanticCustomError: If the value is not a valid color.

    Returns:
        A number between 0 and 1.
    """
    try:
        color = float(value)
    except ValueError:
        raise PydanticCustomError('color_error', 'value is not a valid color: color values must be a valid number')
    if 0 <= color <= max_val:
        return color / max_val
    else:
        raise PydanticCustomError(
            'color_error',
            'value is not a valid color: color values must be in the range 0 to {max_val}',
            {'max_val': max_val},
        )


def parse_float_alpha(value: Union[None, str, float, int]) -> Optional[float]:
    """Parse an alpha value checking it's a valid float in the range 0 to 1.

    Args:
        value: The input value to parse.

    Returns:
        The parsed value as a float, or `None` if the value was None or equal 1.

    Raises:
        PydanticCustomError: If the input value cannot be successfully parsed as a float in the expected range.
    """
    if value is None:
        return None
    try:
        if isinstance(value, str) and value.endswith('%'):
            alpha = float(value[:-1]) / 100
        else:
            alpha = float(value)
    except ValueError:
        raise PydanticCustomError('color_error', 'value is not a valid color: alpha values must be a valid float')

    if math.isclose(alpha, 1):
        return None
    elif 0 <= alpha <= 1:
        return alpha
    else:
        raise PydanticCustomError('color_error', 'value is not a valid color: alpha values must be in the range 0 to 1')


def parse_hsl(h: str, h_units: str, sat: str, light: str, alpha: Optional[float] = None) -> RGBA:
    """Parse raw hue, saturation, lightness, and alpha values and convert to RGBA.

    Args:
        h: The hue value.
        h_units: The unit for hue value.
        sat: The saturation value.
        light: The lightness value.
        alpha: Alpha value.

    Returns:
        An instance of `RGBA`.
    """
    s_value, l_value = parse_color_value(sat, 100), parse_color_value(light, 100)

    h_value = float(h)
    if h_units in {None, 'deg'}:
        h_value = h_value % 360 / 360
    elif h_units == 'rad':
        h_value = h_value % rads / rads
    else:
        # turns
        h_value = h_value % 1

    r, g, b = hls_to_rgb(h_value, l_value, s_value)
    return RGBA(r, g, b, parse_float_alpha(alpha))


def float_to_255(c: float) -> int:
    """Converts a float value between 0 and 1 (inclusive) to an integer between 0 and 255 (inclusive).

    Args:
        c: The float value to be converted. Must be between 0 and 1 (inclusive).

    Returns:
        The integer equivalent of the given float value rounded to the nearest whole number.

    Raises:
        ValueError: If the given float value is outside the acceptable range of 0 to 1 (inclusive).
    """
    return int(round(c * 255))


COLORS_BY_NAME = {
    'aliceblue': (240, 248, 255),
    'antiquewhite': (250, 235, 215),
    'aqua': (0, 255, 255),
    'aquamarine': (127, 255, 212),
    'azure': (240, 255, 255),
    'beige': (245, 245, 220),
    'bisque': (255, 228, 196),
    'black': (0, 0, 0),
    'blanchedalmond': (255, 235, 205),
    'blue': (0, 0, 255),
    'blueviolet': (138, 43, 226),
    'brown': (165, 42, 42),
    'burlywood': (222, 184, 135),
    'cadetblue': (95, 158, 160),
    'chartreuse': (127, 255, 0),
    'chocolate': (210, 105, 30),
    'coral': (255, 127, 80),
    'cornflowerblue': (100, 149, 237),
    'cornsilk': (255, 248, 220),
    'crimson': (220, 20, 60),
    'cyan': (0, 255, 255),
    'darkblue': (0, 0, 139),
    'darkcyan': (0, 139, 139),
    'darkgoldenrod': (184, 134, 11),
    'darkgray': (169, 169, 169),
    'darkgreen': (0, 100, 0),
    'darkgrey': (169, 169, 169),
    'darkkhaki': (189, 183, 107),
    'darkmagenta': (139, 0, 139),
    'darkolivegreen': (85, 107, 47),
    'darkorange': (255, 140, 0),
    'darkorchid': (153, 50, 204),
    'darkred': (139, 0, 0),
    'darksalmon': (233, 150, 122),
    'darkseagreen': (143, 188, 143),
    'darkslateblue': (72, 61, 139),
    'darkslategray': (47, 79, 79),
    'darkslategrey': (47, 79, 79),
    'darkturquoise': (0, 206, 209),
    'darkviolet': (148, 0, 211),
    'deeppink': (255, 20, 147),
    'deepskyblue': (0, 191, 255),
    'dimgray': (105, 105, 105),
    'dimgrey': (105, 105, 105),
    'dodgerblue': (30, 144, 255),
    'firebrick': (178, 34, 34),
    'floralwhite': (255, 250, 240),
    'forestgreen': (34, 139, 34),
    'fuchsia': (255, 0, 255),
    'gainsboro': (220, 220, 220),
    'ghostwhite': (248, 248, 255),
    'gold': (255, 215, 0),
    'goldenrod': (218, 165, 32),
    'gray': (128, 128, 128),
    'green': (0, 128, 0),
    'greenyellow': (173, 255, 47),
    'grey': (128, 128, 128),
    'honeydew': (240, 255, 240),
    'hotpink': (255, 105, 180),
    'indianred': (205, 92, 92),
    'indigo': (75, 0, 130),
    'ivory': (255, 255, 240),
    'khaki': (240, 230, 140),
    'lavender': (230, 230, 250),
    'lavenderblush': (255, 240, 245),
    'lawngreen': (124, 252, 0),
    'lemonchiffon': (255, 250, 205),
    'lightblue': (173, 216, 230),
    'lightcoral': (240, 128, 128),
    'lightcyan': (224, 255, 255),
    'lightgoldenrodyellow': (250, 250, 210),
    'lightgray': (211, 211, 211),
    'lightgreen': (144, 238, 144),
    'lightgrey': (211, 211, 211),
    'lightpink': (255, 182, 193),
    'lightsalmon': (255, 160, 122),
    'lightseagreen': (32, 178, 170),
    'lightskyblue': (135, 206, 250),
    'lightslategray': (119, 136, 153),
    'lightslategrey': (119, 136, 153),
    'lightsteelblue': (176, 196, 222),
    'lightyellow': (255, 255, 224),
    'lime': (0, 255, 0),
    'limegreen': (50, 205, 50),
    'linen': (250, 240, 230),
    'magenta': (255, 0, 255),
    'maroon': (128, 0, 0),
    'mediumaquamarine': (102, 205, 170),
    'mediumblue': (0, 0, 205),
    'mediumorchid': (186, 85, 211),
    'mediumpurple': (147, 112, 219),
    'mediumseagreen': (60, 179, 113),
    'mediumslateblue': (123, 104, 238),
    'mediumspringgreen': (0, 250, 154),
    'mediumturquoise': (72, 209, 204),
    'mediumvioletred': (199, 21, 133),
    'midnightblue': (25, 25, 112),
    'mintcream': (245, 255, 250),
    'mistyrose': (255, 228, 225),
    'moccasin': (255, 228, 181),
    'navajowhite': (255, 222, 173),
    'navy': (0, 0, 128),
    'oldlace': (253, 245, 230),
    'olive': (128, 128, 0),
    'olivedrab': (107, 142, 35),
    'orange': (255, 165, 0),
    'orangered': (255, 69, 0),
    'orchid': (218, 112, 214),
    'palegoldenrod': (238, 232, 170),
    'palegreen': (152, 251, 152),
    'paleturquoise': (175, 238, 238),
    'palevioletred': (219, 112, 147),
    'papayawhip': (255, 239, 213),
    'peachpuff': (255, 218, 185),
    'peru': (205, 133, 63),
    'pink': (255, 192, 203),
    'plum': (221, 160, 221),
    'powderblue': (176, 224, 230),
    'purple': (128, 0, 128),
    'red': (255, 0, 0),
    'rosybrown': (188, 143, 143),
    'royalblue': (65, 105, 225),
    'saddlebrown': (139, 69, 19),
    'salmon': (250, 128, 114),
    'sandybrown': (244, 164, 96),
    'seagreen': (46, 139, 87),
    'seashell': (255, 245, 238),
    'sienna': (160, 82, 45),
    'silver': (192, 192, 192),
    'skyblue': (135, 206, 235),
    'slateblue': (106, 90, 205),
    'slategray': (112, 128, 144),
    'slategrey': (112, 128, 144),
    'snow': (255, 250, 250),
    'springgreen': (0, 255, 127),
    'steelblue': (70, 130, 180),
    'tan': (210, 180, 140),
    'teal': (0, 128, 128),
    'thistle': (216, 191, 216),
    'tomato': (255, 99, 71),
    'turquoise': (64, 224, 208),
    'violet': (238, 130, 238),
    'wheat': (245, 222, 179),
    'white': (255, 255, 255),
    'whitesmoke': (245, 245, 245),
    'yellow': (255, 255, 0),
    'yellowgreen': (154, 205, 50),
}

COLORS_BY_VALUE = {v: k for k, v in COLORS_BY_NAME.items()}


## Links discovered
- [CSS Color Module Level 3](http://www.w3.org/TR/css3-color/#svg-color)
- [`pydantic-extra-types.Color`](https://github.com/pydantic/pydantic/blob/main/usage/types/extra_types/color_types.md)

--- pydantic/config.py ---
"""Configuration for Pydantic models."""

from __future__ import annotations as _annotations

import warnings
from re import Pattern
from typing import TYPE_CHECKING, Any, Callable, Literal, TypeVar, Union, cast, overload

from typing_extensions import TypeAlias, TypedDict, Unpack, deprecated

from ._migration import getattr_migration
from .aliases import AliasGenerator
from .errors import PydanticUserError
from .warnings import PydanticDeprecatedSince211

if TYPE_CHECKING:
    from ._internal._generate_schema import GenerateSchema as _GenerateSchema
    from .fields import ComputedFieldInfo, FieldInfo

__all__ = ('ConfigDict', 'with_config')


JsonValue: TypeAlias = Union[int, float, str, bool, None, list['JsonValue'], 'JsonDict']
JsonDict: TypeAlias = dict[str, JsonValue]

JsonEncoder = Callable[[Any], Any]

JsonSchemaExtraCallable: TypeAlias = Union[
    Callable[[JsonDict], None],
    Callable[[JsonDict, type[Any]], None],
]

ExtraValues = Literal['allow', 'ignore', 'forbid']


class ConfigDict(TypedDict, total=False):
    """A TypedDict for configuring Pydantic behaviour."""

    title: str | None
    """The title for the generated JSON schema, defaults to the model's name"""

    model_title_generator: Callable[[type], str] | None
    """A callable that takes a model class and returns the title for it. Defaults to `None`."""

    field_title_generator: Callable[[str, FieldInfo | ComputedFieldInfo], str] | None
    """A callable that takes a field's name and info and returns title for it. Defaults to `None`."""

    str_to_lower: bool
    """Whether to convert all characters to lowercase for str types. Defaults to `False`."""

    str_to_upper: bool
    """Whether to convert all characters to uppercase for str types. Defaults to `False`."""

    str_strip_whitespace: bool
    """Whether to strip leading and trailing whitespace for str types."""

    str_min_length: int
    """The minimum length for str types. Defaults to `None`."""

    str_max_length: int | None
    """The maximum length for str types. Defaults to `None`."""

    extra: ExtraValues | None
    '''
    Whether to ignore, allow, or forbid extra data during model initialization. Defaults to `'ignore'`.

    Three configuration values are available:

    - `'ignore'`: Providing extra data is ignored (the default):
      ```python
      from pydantic import BaseModel, ConfigDict

      class User(BaseModel):
          model_config = ConfigDict(extra='ignore')  # (1)!

          name: str

      user = User(name='John Doe', age=20)  # (2)!
      print(user)
      #> name='John Doe'
      ```

        1. This is the default behaviour.
        2. The `age` argument is ignored.

    - `'forbid'`: Providing extra data is not permitted, and a [`ValidationError`][pydantic_core.ValidationError]
      will be raised if this is the case:
      ```python
      from pydantic import BaseModel, ConfigDict, ValidationError


      class Model(BaseModel):
          x: int

          model_config = ConfigDict(extra='forbid')


      try:
          Model(x=1, y='a')
      except ValidationError as exc:
          print(exc)
          """
          1 validation error for Model
          y
            Extra inputs are not permitted [type=extra_forbidden, input_value='a', input_type=str]
          """
      ```

    - `'allow'`: Providing extra data is allowed and stored in the `__pydantic_extra__` dictionary attribute:
      ```python
      from pydantic import BaseModel, ConfigDict


      class Model(BaseModel):
          x: int

          model_config = ConfigDict(extra='allow')


      m = Model(x=1, y='a')
      assert m.__pydantic_extra__ == {'y': 'a'}
      ```
      By default, no validation will be applied to these extra items, but you can set a type for the values by overriding
      the type annotation for `__pydantic_extra__`:
      ```python
      from pydantic import BaseModel, ConfigDict, Field, ValidationError


      class Model(BaseModel):
          __pydantic_extra__: dict[str, int] = Field(init=False)  # (1)!

          x: int

          model_config = ConfigDict(extra='allow')


      try:
          Model(x=1, y='a')
      except ValidationError as exc:
          print(exc)
          """
          1 validation error for Model
          y
            Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='a', input_type=str]
          """

      m = Model(x=1, y='2')
      assert m.x == 1
      assert m.y == 2
      assert m.model_dump() == {'x': 1, 'y': 2}
      assert m.__pydantic_extra__ == {'y': 2}
      ```

        1. The `= Field(init=False)` does not have any effect at runtime, but prevents the `__pydantic_extra__` field from
           being included as a parameter to the model's `__init__` method by type checkers.

    As well as specifying an `extra` configuration value on the model, you can also provide it as an argument to the validation methods.
    This will override any `extra` configuration value set on the model:
    ```python
    from pydantic import BaseModel, ConfigDict, ValidationError

    class Model(BaseModel):
        x: int
        model_config = ConfigDict(extra="allow")

    try:
        # Override model config and forbid extra fields just this time
        Model.model_validate({"x": 1, "y": 2}, extra="forbid")
    except ValidationError as exc:
        print(exc)
        """
        1 validation error for Model
        y
          Extra inputs are not permitted [type=extra_forbidden, input_value=2, input_type=int]
        """
    ```
    '''

    frozen: bool
    """
    Whether models are faux-immutable, i.e. whether `__setattr__` is allowed, and also generates
    a `__hash__()` method for the model. This makes instances of the model potentially hashable if all the
    attributes are hashable. Defaults to `False`.

    Note:
        On V1, the inverse of this setting was called `allow_mutation`, and was `True` by default.
    """

    populate_by_name: bool
    """
    Whether an aliased field may be populated by its name as given by the model
    attribute, as well as the alias. Defaults to `False`.

    !!! warning
        `populate_by_name` usage is not recommended in v2.11+ and will be deprecated in v3.
        Instead, you should use the [`validate_by_name`][pydantic.config.ConfigDict.validate_by_name] configuration setting.

        When `validate_by_name=True` and `validate_by_alias=True`, this is strictly equivalent to the
        previous behavior of `populate_by_name=True`.

        In v2.11, we also introduced a [`validate_by_alias`][pydantic.config.ConfigDict.validate_by_alias] setting that introduces more fine grained
        control for validation behavior.

        Here's how you might go about using the new settings to achieve the same behavior:

        ```python
        from pydantic import BaseModel, ConfigDict, Field

        class Model(BaseModel):
            model_config = ConfigDict(validate_by_name=True, validate_by_alias=True)

            my_field: str = Field(alias='my_alias')  # (1)!

        m = Model(my_alias='foo')  # (2)!
        print(m)
        #> my_field='foo'

        m = Model(my_field='foo')  # (3)!
        print(m)
        #> my_field='foo'
        ```

        1. The field `'my_field'` has an alias `'my_alias'`.
        2. The model is populated by the alias `'my_alias'`.
        3. The model is populated by the attribute name `'my_field'`.
    """

    use_enum_values: bool
    """
    Whether to populate models with the `value` property of enums, rather than the raw enum.
    This may be useful if you want to serialize `model.model_dump()` later. Defaults to `False`.

    !!! note
        If you have an `Optional[Enum]` value that you set a default for, you need to use `validate_default=True`
        for said Field to ensure that the `use_enum_values` flag takes effect on the default, as extracting an
        enum's value occurs during validation, not serialization.

    ```python
    from enum import Enum
    from typing import Optional

    from pydantic import BaseModel, ConfigDict, Field

    class SomeEnum(Enum):
        FOO = 'foo'
        BAR = 'bar'
        BAZ = 'baz'

    class SomeModel(BaseModel):
        model_config = ConfigDict(use_enum_values=True)

        some_enum: SomeEnum
        another_enum: Optional[SomeEnum] = Field(
            default=SomeEnum.FOO, validate_default=True
        )

    model1 = SomeModel(some_enum=SomeEnum.BAR)
    print(model1.model_dump())
    #> {'some_enum': 'bar', 'another_enum': 'foo'}

    model2 = SomeModel(some_enum=SomeEnum.BAR, another_enum=SomeEnum.BAZ)
    print(model2.model_dump())
    #> {'some_enum': 'bar', 'another_enum': 'baz'}
    ```
    """

    validate_assignment: bool
    """
    Whether to validate the data when the model is changed. Defaults to `False`.

    The default behavior of Pydantic is to validate the data when the model is created.

    In case the user changes the data after the model is created, the model is _not_ revalidated.

    ```python
    from pydantic import BaseModel

    class User(BaseModel):
        name: str

    user = User(name='John Doe')  # (1)!
    print(user)
    #> name='John Doe'
    user.name = 123  # (1)!
    print(user)
    #> name=123
    ```

    1. The validation happens only when the model is created.
    2. The validation does not happen when the data is changed.

    In case you want to revalidate the model when the data is changed, you can use `validate_assignment=True`:

    ```python
    from pydantic import BaseModel, ValidationError

    class User(BaseModel, validate_assignment=True):  # (1)!
        name: str

    user = User(name='John Doe')  # (2)!
    print(user)
    #> name='John Doe'
    try:
        user.name = 123  # (3)!
    except ValidationError as e:
        print(e)
        '''
        1 validation error for User
        name
          Input should be a valid string [type=string_type, input_value=123, input_type=int]
        '''
    ```

    1. You can either use class keyword arguments, or `model_config` to set `validate_assignment=True`.
    2. The validation happens when the model is created.
    3. The validation _also_ happens when the data is changed.
    """

    arbitrary_types_allowed: bool
    """
    Whether arbitrary types are allowed for field types. Defaults to `False`.

    ```python
    from pydantic import BaseModel, ConfigDict, ValidationError

    # This is not a pydantic model, it's an arbitrary class
    class Pet:
        def __init__(self, name: str):
            self.name = name

    class Model(BaseModel):
        model_config = ConfigDict(arbitrary_types_allowed=True)

        pet: Pet
        owner: str

    pet = Pet(name='Hedwig')
    # A simple check of instance type is used to validate the data
    model = Model(owner='Harry', pet=pet)
    print(model)
    #> pet=<__main__.Pet object at 0x0123456789ab> owner='Harry'
    print(model.pet)
    #> <__main__.Pet object at 0x0123456789ab>
    print(model.pet.name)
    #> Hedwig
    print(type(model.pet))
    #> <class '__main__.Pet'>
    try:
        # If the value is not an instance of the type, it's invalid
        Model(owner='Harry', pet='Hedwig')
    except ValidationError as e:
        print(e)
        '''
        1 validation error for Model
        pet
          Input should be an instance of Pet [type=is_instance_of, input_value='Hedwig', input_type=str]
        '''

    # Nothing in the instance of the arbitrary type is checked
    # Here name probably should have been a str, but it's not validated
    pet2 = Pet(name=42)
    model2 = Model(owner='Harry', pet=pet2)
    print(model2)
    #> pet=<__main__.Pet object at 0x0123456789ab> owner='Harry'
    print(model2.pet)
    #> <__main__.Pet object at 0x0123456789ab>
    print(model2.pet.name)
    #> 42
    print(type(model2.pet))
    #> <class '__main__.Pet'>
    ```
    """

    from_attributes: bool
    """
    Whether to build models and look up discriminators of tagged unions using python object attributes.
    """

    loc_by_alias: bool
    """Whether to use the actual key provided in the data (e.g. alias) for error `loc`s rather than the field's name. Defaults to `True`."""

    alias_generator: Callable[[str], str] | AliasGenerator | None
    """
    A callable that takes a field name and returns an alias for it
    or an instance of [`AliasGenerator`][pydantic.aliases.AliasGenerator]. Defaults to `None`.

    When using a callable, the alias generator is used for both validation and serialization.
    If you want to use different alias generators for validation and serialization, you can use
    [`AliasGenerator`][pydantic.aliases.AliasGenerator] instead.

    If data source field names do not match your code style (e.g. CamelCase fields),
    you can automatically generate aliases using `alias_generator`. Here's an example with
    a basic callable:

    ```python
    from pydantic import BaseModel, ConfigDict
    from pydantic.alias_generators import to_pascal

    class Voice(BaseModel):
        model_config = ConfigDict(alias_generator=to_pascal)

        name: str
        language_code: str

    voice = Voice(Name='Filiz', LanguageCode='tr-TR')
    print(voice.language_code)
    #> tr-TR
    print(voice.model_dump(by_alias=True))
    #> {'Name': 'Filiz', 'LanguageCode': 'tr-TR'}
    ```

    If you want to use different alias generators for validation and serialization, you can use
    [`AliasGenerator`][pydantic.aliases.AliasGenerator].

    ```python
    from pydantic import AliasGenerator, BaseModel, ConfigDict
    from pydantic.alias_generators import to_camel, to_pascal

    class Athlete(BaseModel):
        first_name: str
        last_name: str
        sport: str

        model_config = ConfigDict(
            alias_generator=AliasGenerator(
                validation_alias=to_camel,
                serialization_alias=to_pascal,
            )
        )

    athlete = Athlete(firstName='John', lastName='Doe', sport='track')
    print(athlete.model_dump(by_alias=True))
    #> {'FirstName': 'John', 'LastName': 'Doe', 'Sport': 'track'}
    ```

    Note:
        Pydantic offers three built-in alias generators: [`to_pascal`][pydantic.alias_generators.to_pascal],
        [`to_camel`][pydantic.alias_generators.to_camel], and [`to_snake`][pydantic.alias_generators.to_snake].
    """

    ignored_types: tuple[type, ...]
    """A tuple of types that may occur as values of class attributes without annotations. This is
    typically used for custom descriptors (classes that behave like `property`). If an attribute is set on a
    class without an annotation and has a type that is not in this tuple (or otherwise recognized by
    _pydantic_), an error will be raised. Defaults to `()`.
    """

    allow_inf_nan: bool
    """Whether to allow infinity (`+inf` an `-inf`) and NaN values to float and decimal fields. Defaults to `True`."""

    json_schema_extra: JsonDict | JsonSchemaExtraCallable | None
    """A dict or callable to provide extra JSON schema properties. Defaults to `None`."""

    json_encoders: dict[type[object], JsonEncoder] | None
    """
    A `dict` of custom JSON encoders for specific types. Defaults to `None`.

    /// version-deprecated | v2
    This configuration option is a carryover from v1. We originally planned to remove it in v2 but didn't have a 1:1 replacement
    so we are keeping it for now. It is still deprecated and will likely be removed in the future.
    ///
    """

    # new in V2
    strict: bool
    """
    Whether strict validation is applied to all fields on the model.

    By default, Pydantic attempts to coerce values to the correct type, when possible.

    There are situations in which you may want to disable this behavior, and instead raise an error if a value's type
    does not match the field's type annotation.

    To configure strict mode for all fields on a model, you can set `strict=True` on the model.

    ```python
    from pydantic import BaseModel, ConfigDict

    class Model(BaseModel):
        model_config = ConfigDict(strict=True)

        name: str
        age: int
    ```

    See [Strict Mode](../concepts/strict_mode.md) for more details.

    See the [Conversion Table](../concepts/conversion_table.md) for more details on how Pydantic converts data in both
    strict and lax modes.

    /// version-added | v2
    ///
    """
    # whether instances of models and dataclasses (including subclass instances) should re-validate, default 'never'
    revalidate_instances: Literal['always', 'never', 'subclass-instances']
    """
    When and how to revalidate models and dataclasses during validation. Can be one of:

    - `'never'`: will *not* revalidate models and dataclasses during validation
    - `'always'`: will revalidate models and dataclasses during validation
    - `'subclass-instances'`: will revalidate models and dataclasses during validation if the instance is a
        subclass of the model or dataclass

    The default is `'never'` (no revalidation).

    This configuration only affects *the current model* it is applied on, and does *not* propagate to the models
    referenced in fields.

    ```python
    from pydantic import BaseModel

    class User(BaseModel, revalidate_instances='never'):  # (1)!
        name: str

    class Transaction(BaseModel):
        user: User

    my_user = User(name='John')
    t = Transaction(user=my_user)

    my_user.name = 1  # (2)!
    t = Transaction(user=my_user)  # (3)!
    print(t)
    #> user=User(name=1)
    ```

    1. This is the default behavior.
    2. The assignment is *not* validated, unless you set [`validate_assignment`][pydantic.ConfigDict.validate_assignment] in the configuration.
    3. Since `revalidate_instances` is set to `'never'`, the user instance is not revalidated.

    Here is an example demonstrating the behavior of `'subclass-instances'`:

    ```python
    from pydantic import BaseModel

    class User(BaseModel, revalidate_instances='subclass-instances'):
        name: str

    class SubUser(User):
        age: int

    class Transaction(BaseModel):
        user: User

    my_user = User(name='John')
    my_user.name = 1  # (1)!
    t = Transaction(user=my_user)  # (2)!
    print(t)
    #> user=User(name=1)

    my_sub_user = SubUser(name='John', age=20)
    t = Transaction(user=my_sub_user)
    print(t)  # (3)!
    #> user=User(name='John')
    ```

    1. The assignment is *not* validated, unless you set [`validate_assignment`][pydantic.ConfigDict.validate_assignment] in the configuration.
    2. Because `my_user` is a "direct" instance of `User`, it is *not* being revalidated. It would have been the case if
      `revalidate_instances` was set to `'always'`.
    3. Because `my_sub_user` is an instance of a `User` subclass, it is being revalidated. In this case, Pydantic coerces `my_sub_user` to the defined
       `User` class defined on `Transaction`. If one of its fields had an invalid value, a validation error would have been raised.

    /// version-added | v2
    ///
    """

    ser_json_timedelta: Literal['iso8601', 'float']
    """
    The format of JSON serialized timedeltas. Accepts the string values of `'iso8601'` and
    `'float'`. Defaults to `'iso8601'`.

    - `'iso8601'` will serialize timedeltas to [ISO 8601 text format](https://en.wikipedia.org/wiki/ISO_8601#Durations).
    - `'float'` will serialize timedeltas to the total number of seconds.

    /// version-changed | v2.12
    It is now recommended to use the [`ser_json_temporal`][pydantic.config.ConfigDict.ser_json_temporal]
    setting. `ser_json_timedelta` will be deprecated in v3.
    ///
    """

    ser_json_temporal: Literal['iso8601', 'seconds', 'milliseconds']
    """
    The format of JSON serialized temporal types from the [`datetime`][] module. This includes:

    - [`datetime.datetime`][]
    - [`datetime.date`][]
    - [`datetime.time`][]
    - [`datetime.timedelta`][]

    Can be one of:

    - `'iso8601'` will serialize date-like types to [ISO 8601 text format](https://en.wikipedia.org/wiki/ISO_8601#Durations).
    - `'milliseconds'` will serialize date-like types to a floating point number of milliseconds since the epoch.
    - `'seconds'` will serialize date-like types to a floating point number of seconds since the epoch.

    Defaults to `'iso8601'`.

    /// version-added | v2.12
    This setting replaces [`ser_json_timedelta`][pydantic.config.ConfigDict.ser_json_timedelta],
    which will be deprecated in v3. `ser_json_temporal` adds more configurability for the other temporal types.
    ///
    """

    val_temporal_unit: Literal['seconds', 'milliseconds', 'infer']
    """
    The unit to assume for validating numeric input for datetime-like types ([`datetime.datetime`][] and [`datetime.date`][]). Can be one of:

    - `'seconds'` will validate date or time numeric inputs as seconds since the [epoch].
    - `'milliseconds'` will validate date or time numeric inputs as milliseconds since the [epoch].
    - `'infer'` will infer the unit from the string numeric input on unix time as:

        * seconds since the [epoch] if $-2^{10} <= v <= 2^{10}$
        * milliseconds since the [epoch] (if $v < -2^{10}$ or $v > 2^{10}$).

    Defaults to `'infer'`.

    /// version-added | v2.12
    ///

    [epoch]: https://en.wikipedia.org/wiki/Unix_time
    """

    ser_json_bytes: Literal['utf8', 'base64', 'hex']
    """
    The encoding of JSON serialized bytes. Defaults to `'utf8'`.
    Set equal to `val_json_bytes` to get back an equal value after serialization round trip.

    - `'utf8'` will serialize bytes to UTF-8 strings.
    - `'base64'` will serialize bytes to URL safe base64 strings.
    - `'hex'` will serialize bytes to hexadecimal strings.
    """

    val_json_bytes: Literal['utf8', 'base64', 'hex']
    """
    /// version-added | v2.9
    ///

    The encoding of JSON serialized bytes to decode. Defaults to `'utf8'`.
    Set equal to `ser_json_bytes` to get back an equal value after serialization round trip.

    - `'utf8'` will deserialize UTF-8 strings to bytes.
    - `'base64'` will deserialize URL safe base64 strings to bytes.
    - `'hex'` will deserialize hexadecimal strings to bytes.
    """

    ser_json_inf_nan: Literal['null', 'constants', 'strings']
    """
    The encoding of JSON serialized infinity and NaN float values. Defaults to `'null'`.

    - `'null'` will serialize infinity and NaN values as `null`.
    - `'constants'` will serialize infinity and NaN values as `Infinity` and `NaN`.
    - `'strings'` will serialize infinity as string `"Infinity"` and NaN as string `"NaN"`.
    """

    # whether to validate default values during validation, default False
    validate_default: bool
    """Whether to validate default values during validation. Defaults to `False`."""

    validate_return: bool
    """Whether to validate the return value from call validators. Defaults to `False`."""

    protected_namespaces: tuple[str | Pattern[str], ...]
    """
    A tuple of strings and/or regex patterns that prevent models from having fields with names that conflict with its existing members/methods.

    Strings are matched on a prefix basis. For instance, with `'dog'`, having a field named `'dog_name'` will be disallowed.

    Regex patterns are matched on the entire field name. For instance, with the pattern `'^dog$'`, having a field named `'dog'` will be disallowed,
    but `'dog_name'` will be accepted.

    Defaults to `('model_validate', 'model_dump')`. This default is used to prevent collisions with the existing (and possibly future)
    [validation](../concepts/models.md#validating-data) and [serialization](../concepts/serialization.md#serializing-data) methods.

    ```python
    import warnings

    from pydantic import BaseModel

    warnings.filterwarnings('error')  # Raise warnings as errors

    try:

        class Model(BaseModel):
            model_dump_something: str

    except UserWarning as e:
        print(e)
        '''
        Field 'model_dump_something' in 'Model' conflicts with protected namespace 'model_dump'.

        You may be able to solve this by setting the 'protected_namespaces' configuration to ('model_validate',).
        '''
    ```

    You can customize this behavior using the `protected_namespaces` setting:

    ```python {test="skip"}
    import re
    import warnings

    from pydantic import BaseModel, ConfigDict

    with warnings.catch_warnings(record=True) as caught_warnings:
        warnings.simplefilter('always')  # Catch all warnings

        class Model(BaseModel):
            safe_field: str
            also_protect_field: str
            protect_this: str

            model_config = ConfigDict(
                protected_namespaces=(
                    'protect_me_',
                    'also_protect_',
                    re.compile('^protect_this$'),
                )
            )

    for warning in caught_warnings:
        print(f'{warning.message}')
        '''
        Field 'also_protect_field' in 'Model' conflicts with protected namespace 'also_protect_'.
        You may be able to solve this by setting the 'protected_namespaces' configuration to ('protect_me_', re.compile('^protect_this$'))`.

        Field 'protect_this' in 'Model' conflicts with protected namespace 're.compile('^protect_this$')'.
        You may be able to solve this by setting the 'protected_namespaces' configuration to ('protect_me_', 'also_protect_')`.
        '''
    ```

    While Pydantic will only emit a warning when an item is in a protected namespace but does not actually have a collision,
    an error _is_ raised if there is an actual collision with an existing attribute:

    ```python
    from pydantic import BaseModel, ConfigDict

    try:

        class Model(BaseModel):
            model_validate: str

            model_config = ConfigDict(protected_namespaces=('model_',))

    except ValueError as e:
        print(e)
        '''
        Field 'model_validate' conflicts with member <bound method BaseModel.model_validate of <class 'pydantic.main.BaseModel'>> of protected namespace 'model_'.
        '''
    ```

    /// version-changed | v2.10
    The default protected namespaces was changed from `('model_',)` to `('model_validate', 'model_dump')`, to allow
    for fields like `model_id`, `model_name` to be used.
    ///
    """

    hide_input_in_errors: bool
    """
    Whether to hide inputs when printing errors. Defaults to `False`.

    Pydantic shows the input value and type when it raises `ValidationError` during the validation.

    ```python
    from pydantic import BaseModel, ValidationError

    class Model(BaseModel):
        a: str

    try:
        Model(a=123)
    except ValidationError as e:
        print(e)
        '''
        1 validation error for Model
        a
          Input should be a valid string [type=string_type, input_value=123, input_type=int]
        '''
    ```

    You can hide the input value and type by setting the `hide_input_in_errors` config to `True`.

    ```python
    from pydantic import BaseModel, ConfigDict, ValidationError

    class Model(BaseModel):
        a: str
        model_config = ConfigDict(hide_input_in_errors=True)

    try:
        Model(a=123)
    except ValidationError as e:
        print(e)
        '''
        1 validation error for Model
        a
          Input should be a valid string [type=string_type]
        '''
    ```
    """

    defer_build: bool
    """
    Whether to defer model validator and serializer construction until the first model validation. Defaults to False.

    This can be useful to avoid the overhead of building models which are only
    used nested within other models, or when you want to manually define type namespace via
    [`Model.model_rebuild(_types_namespace=...)`][pydantic.BaseModel.model_rebuild].

    /// version-changed | v2.10
    The setting also applies to [Pydantic dataclasses](../concepts/dataclasses.md) and [type adapters](../concepts/type_adapter.md).
    ///
    """

    plugin_settings: dict[str, object] | None
    """A `dict` of settings for plugins. Defaults to `None`."""

    schema_generator: type[_GenerateSchema] | None
    """
    The `GenerateSchema` class to use during core schema generation.

    /// version-deprecated | v2.10
    The `GenerateSchema` class is private and highly subject to change.
    ///
    """

    json_schema_serialization_defaults_required: bool
    """
    Whether fields with default values should be marked as required in the serialization schema. Defaults to `False`.

    This ensures that the serialization schema will reflect the fact a field with a default will always be present
    when serializing the model, even though it is not required for validation.

    However, there are scenarios where this may be undesirable — in particular, if you want to share the schema
    between validation and serialization, and don't mind fields with defaults being marked as not required during
    serialization. See [#7209](https://github.com/pydantic/pydantic/issues/7209) for more details.

    ```python
    from pydantic import BaseModel, ConfigDict

    class Model(BaseModel):
        a: str = 'a'

        model_config = ConfigDict(json_schema_serialization_defaults_required=True)

    print(Model.model_json_schema(mode='validation'))
    '''
    {
        'properties': {'a': {'default': 'a', 'title': 'A', 'type': 'string'}},
        'title': 'Model',
        'type': 'object',
    }
    '''
    print(Model.model_json_schema(mode='serialization'))
    '''
    {
        'properties': {'a': {'default': 'a', 'title': 'A', 'type': 'string'}},
        'required': ['a'],
        'title': 'Model',
        'type': 'object',
    }
    '''
    ```

    /// version-added | v2.4
    ///
    """

    json_schema_mode_override: Literal['validation', 'serialization', None]
    """
    If not `None`, the specified mode will be used to generate the JSON schema regardless of what `mode` was passed to
    the function call. Defaults to `None`.

    This provides a way to force the JSON schema generation to reflect a specific mode, e.g., to always use the
    validation schema.

    It can be useful when using frameworks (such as FastAPI) that may generate different schemas for validation
    and serialization that must both be referenced from the same schema; when this happens, we automatically append
    `-Input` to the definition reference for the validation schema and `-Output` to the definition reference for the
    serialization schema. By specifying a `json_schema_mode_override` though, this prevents the conflict between
    the validation and serialization schemas (since both will use the specified schema), and so prevents the suffixes
    from being added to the definition references.

    ```python
    from pydantic import BaseModel, ConfigDict, Json

    class Model(BaseModel):
        a: Json[int]  # requires a string to validate, but will dump an int

    print(Model.model_json_schema(mode='serialization'))
    '''
    {
        'properties': {'a': {'title': 'A', 'type': 'integer'}},
        'required': ['a'],
        'title': 'Model',
        'type': 'object',
    }
    '''

    class ForceInputModel(Model):
        # the following ensures that even with mode='serialization', we
        # will get the schema that would be generated for validation.
        model_config = ConfigDict(json_schema_mode_override='validation')

    print(ForceInputModel.model_json_schema(mode='serialization'))
    '''
    {
        'properties': {
            'a': {
                'contentMediaType': 'application/json',
                'contentSchema': {'type': 'integer'},
                'title': 'A',
                'type': 'string',
            }
        },
        'required': ['a'],
        'title': 'ForceInputModel',
        'type': 'object',
    }
    '''
    ```

    /// version-added | v2.4
    ///
    """

    coerce_numbers_to_str: bool
    """
    If `True`, enables automatic coercion of any `Number` type to `str` in "lax" (non-strict) mode. Defaults to `False`.

    Pydantic doesn't allow number types (`int`, `float`, `Decimal`) to be coerced as type `str` by default.

    ```python
    from decimal import Decimal

    from pydantic import BaseModel, ConfigDict, ValidationError

    class Model(BaseModel):
        value: str

    try:
        print(Model(value=42))
    except ValidationError as e:
        print(e)
        '''
        1 validation error for Model
        value
          Input should be a valid string [type=string_type, input_value=42, input_type=int]
        '''

    class Model(BaseModel):
        model_config = ConfigDict(coerce_numbers_to_str=True)

        value: str

    repr(Model(value=42).value)
    #> "42"
    repr(Model(value=42.13).value)
    #> "42.13"
    repr(Model(value=Decimal('42.13')).value)
    #> "42.13"
    ```
    """

    regex_engine: Literal['rust-regex', 'python-re']
    """
    The regex engine to be used for pattern validation.
    Defaults to `'rust-regex'`.

    - `'rust-regex'` uses the [`regex`](https://docs.rs/regex) Rust crate,
      which is non-backtracking and therefore more DDoS resistant, but does not support all regex features.
    - `'python-re'` use the [`re`][] module, which supports all regex features, but may be slower.

    !!! note
        If you use a compiled regex pattern, the `'python-re'` engine will be used regardless of this setting.
        This is so that flags such as [`re.IGNORECASE`][] are respected.

    ```python
    from pydantic import BaseModel, ConfigDict, Field, ValidationError

    class Model(BaseModel):
        model_config = ConfigDict(regex_engine='python-re')

        value: str = Field(pattern=r'^abc(?=def)')

    print(Model(value='abcdef').value)
    #> abcdef

    try:
        print(Model(value='abxyzcdef'))
    except ValidationError as e:
        print(e)
        '''
        1 validation error for Model
        value
          String should match pattern '^abc(?=def)' [type=string_pattern_mismatch, input_value='abxyzcdef', input_type=str]
        '''
    ```

    /// version-added | v2.5
    ///
    """

    validation_error_cause: bool
    """
    If `True`, Python exceptions that were part of a validation failure will be shown as an exception group as a cause. Can be useful for debugging. Defaults to `False`.

    Note:
        Python 3.10 and older don't support exception groups natively. <=3.10, backport must be installed: `pip install exceptiongroup`.

    Note:
        The structure of validation errors are likely to change in future Pydantic versions. Pydantic offers no guarantees about their structure. Should be used for visual traceback debugging only.

    /// version-added | v2.5
    ///
    """

    use_attribute_docstrings: bool
    '''
    Whether docstrings of attributes (bare string literals immediately following the attribute declaration)
    should be used for field descriptions. Defaults to `False`.

    ```python
    from pydantic import BaseModel, ConfigDict, Field


    class Model(BaseModel):
        model_config = ConfigDict(use_attribute_docstrings=True)

        x: str
        """
        Example of an attribute docstring
        """

        y: int = Field(description="Description in Field")
        """
        Description in Field overrides attribute docstring
        """


    print(Model.model_fields["x"].description)
    # > Example of an attribute docstring
    print(Model.model_fields["y"].description)
    # > Description in Field
    ```
    This requires the source code of the class to be available at runtime (and so won't work in the interactive interpreter shell).

    !!! warning "Usage with `TypedDict` and stdlib dataclasses"
        Due to current limitations, attribute docstrings detection may not work as expected when using
        [`TypedDict`][typing.TypedDict] and stdlib dataclasses, in particular when:

        - inheritance is being used.
        - multiple classes have the same name in the same source file (unless Python 3.13 or greater is used).

    /// version-added | v2.7
    ///
    '''

    cache_strings: bool | Literal['all', 'keys', 'none']
    """
    Whether to cache strings to avoid constructing new Python objects. Defaults to True.

    Enabling this setting should significantly improve validation performance while increasing memory usage slightly.

    - `True` or `'all'` (the default): cache all strings
    - `'keys'`: cache only dictionary keys
    - `False` or `'none'`: no caching

    !!! note
        `True` or `'all'` is required to cache strings during general validation because
        validators don't know if they're in a key or a value.

    !!! tip
        If repeated strings are rare, it's recommended to use `'keys'` or `'none'` to reduce memory usage,
        as the performance difference is minimal if repeated strings are rare.

    /// version-added | v2.7
    ///
    """

    validate_by_alias: bool
    """
    Whether an aliased field may be populated by its alias. Defaults to `True`.

    Here's an example of disabling validation by alias:

    ```py
    from pydantic import BaseModel, ConfigDict, Field

    class Model(BaseModel):
        model_config = ConfigDict(validate_by_name=True, validate_by_alias=False)

        my_field: str = Field(validation_alias='my_alias')  # (1)!

    m = Model(my_field='foo')  # (2)!
    print(m)
    #> my_field='foo'
    ```

    1. The field `'my_field'` has an alias `'my_alias'`.
    2. The model can only be populated by the attribute name `'my_field'`.

    !!! warning
        You cannot set both `validate_by_alias` and `validate_by_name` to `False`.
        This would make it impossible to populate an attribute.

        See [usage errors](../errors/usage_errors.md#validate-by-alias-and-name-false) for an example.

        If you set `validate_by_alias` to `False`, under the hood, Pydantic dynamically sets
        `validate_by_name` to `True` to ensure that validation can still occur.

    /// version-added | v2.11
    This setting was introduced in conjunction with [`validate_by_name`][pydantic.ConfigDict.validate_by_name]
    to empower users with more fine grained validation control.
    ///
    """

    validate_by_name: bool
    """
    Whether an aliased field may be populated by its name as given by the model
    attribute. Defaults to `False`.

    ```python
    from pydantic import BaseModel, ConfigDict, Field

    class Model(BaseModel):
        model_config = ConfigDict(validate_by_name=True, validate_by_alias=True)

        my_field: str = Field(validation_alias='my_alias')  # (1)!

    m = Model(my_alias='foo')  # (2)!
    print(m)
    #> my_field='foo'

    m = Model(my_field='foo')  # (3)!
    print(m)
    #> my_field='foo'
    ```

    1. The field `'my_field'` has an alias `'my_alias'`.
    2. The model is populated by the alias `'my_alias'`.
    3. The model is populated by the attribute name `'my_field'`.

    !!! warning
        You cannot set both `validate_by_alias` and `validate_by_name` to `False`.
        This would make it impossible to populate an attribute.

        See [usage errors](../errors/usage_errors.md#validate-by-alias-and-name-false) for an example.

    /// version-added | v2.11
    This setting was introduced in conjunction with [`validate_by_alias`][pydantic.ConfigDict.validate_by_alias]
    to empower users with more fine grained validation control. It is an alternative to [`populate_by_name`][pydantic.ConfigDict.populate_by_name],
    that enables validation by name **and** by alias.
    ///
    """

    serialize_by_alias: bool
    """
    Whether an aliased field should be serialized by its alias. Defaults to `False`.

    Note: In v2.11, `serialize_by_alias` was introduced to address the
    [popular request](https://github.com/pydantic/pydantic/issues/8379)
    for consistency with alias behavior for validation and serialization settings.
    In v3, the default value is expected to change to `True` for consistency with the validation default.

    ```python
    from pydantic import BaseModel, ConfigDict, Field

    class Model(BaseModel):
        model_config = ConfigDict(serialize_by_alias=True)

        my_field: str = Field(serialization_alias='my_alias')  # (1)!

    m = Model(my_field='foo')
    print(m.model_dump())  # (2)!
    #> {'my_alias': 'foo'}
    ```

    1. The field `'my_field'` has an alias `'my_alias'`.
    2. The model is serialized using the alias `'my_alias'` for the `'my_field'` attribute.


    /// version-added | v2.11
    This setting was introduced to address the [popular request](https://github.com/pydantic/pydantic/issues/8379)
    for consistency with alias behavior for validation and serialization.

    In v3, the default value is expected to change to `True` for consistency with the validation default.
    ///
    """

    url_preserve_empty_path: bool
    """
    Whether to preserve empty URL paths when validating values for a URL type. Defaults to `False`.

    ```python
    from pydantic import AnyUrl, BaseModel, ConfigDict

    class Model(BaseModel):
        model_config = ConfigDict(url_preserve_empty_path=True)

        url: AnyUrl

    m = Model(url='http://example.com')
    print(m.url)
    #> http://example.com
    ```

    /// version-added | v2.12
    ///
    """


_TypeT = TypeVar('_TypeT', bound=type)


@overload
@deprecated('Passing `config` as a keyword argument is deprecated. Pass `config` as a positional argument instead.')
def with_config(*, config: ConfigDict) -> Callable[[_TypeT], _TypeT]: ...


@overload
def with_config(config: ConfigDict, /) -> Callable[[_TypeT], _TypeT]: ...


@overload
def with_config(**config: Unpack[ConfigDict]) -> Callable[[_TypeT], _TypeT]: ...


def with_config(config: ConfigDict | None = None, /, **kwargs: Any) -> Callable[[_TypeT], _TypeT]:
    """!!! abstract "Usage Documentation"
        [Configuration with other types](../concepts/config.md#configuration-on-other-supported-types)

    A convenience decorator to set a [Pydantic configuration](config.md) on a `TypedDict` or a `dataclass` from the standard library.

    Although the configuration can be set using the `__pydantic_config__` attribute, it does not play well with type checkers,
    especially with `TypedDict`.

    !!! example "Usage"

        ```python
        from typing_extensions import TypedDict

        from pydantic import ConfigDict, TypeAdapter, with_config

        @with_config(ConfigDict(str_to_lower=True))
        class TD(TypedDict):
            x: str

        ta = TypeAdapter(TD)

        print(ta.validate_python({'x': 'ABC'}))
        #> {'x': 'abc'}
        ```

    /// deprecated-removed | v2.11 v3
    Passing `config` as a keyword argument.
    ///

    /// version-changed | v2.11
    Keyword arguments can be provided directly instead of a config dictionary.
    ///
    """
    if config is not None and kwargs:
        raise ValueError('Cannot specify both `config` and keyword arguments')

    if len(kwargs) == 1 and (kwargs_conf := kwargs.get('config')) is not None:
        warnings.warn(
            'Passing `config` as a keyword argument is deprecated. Pass `config` as a positional argument instead',
            category=PydanticDeprecatedSince211,
            stacklevel=2,
        )
        final_config = cast(ConfigDict, kwargs_conf)
    else:
        final_config = config if config is not None else cast(ConfigDict, kwargs)

    def inner(class_: _TypeT, /) -> _TypeT:
        # Ideally, we would check for `class_` to either be a `TypedDict` or a stdlib dataclass.
        # However, the `@with_config` decorator can be applied *after* `@dataclass`. To avoid
        # common mistakes, we at least check for `class_` to not be a Pydantic model.
        from ._internal._utils import is_model_class

        if is_model_class(class_):
            raise PydanticUserError(
                f'Cannot use `with_config` on {class_.__name__} as it is a Pydantic model',
                code='with-config-on-model',
            )
        class_.__pydantic_config__ = final_config
        return class_

    return inner


__getattr__ = getattr_migration(__name__)


## Links discovered
- [Strict Mode](https://github.com/pydantic/pydantic/blob/main/concepts/strict_mode.md)
- [Conversion Table](https://github.com/pydantic/pydantic/blob/main/concepts/conversion_table.md)
- [ISO 8601 text format](https://en.wikipedia.org/wiki/ISO_8601#Durations)
- [validation](https://github.com/pydantic/pydantic/blob/main/concepts/models.md#validating-data)
- [serialization](https://github.com/pydantic/pydantic/blob/main/concepts/serialization.md#serializing-data)
- [Pydantic dataclasses](https://github.com/pydantic/pydantic/blob/main/concepts/dataclasses.md)
- [type adapters](https://github.com/pydantic/pydantic/blob/main/concepts/type_adapter.md)
- [#7209](https://github.com/pydantic/pydantic/issues/7209)
- [`regex`](https://docs.rs/regex)
- [usage errors](https://github.com/pydantic/pydantic/blob/main/errors/usage_errors.md#validate-by-alias-and-name-false)
- [popular request](https://github.com/pydantic/pydantic/issues/8379)
- [Configuration with other types](https://github.com/pydantic/pydantic/blob/main/concepts/config.md#configuration-on-other-supported-types)
- [Pydantic configuration](https://github.com/pydantic/pydantic/blob/main/pydantic/config.md)

--- pydantic/datetime_parse.py ---
"""The `datetime_parse` module is a backport module from V1."""

from ._migration import getattr_migration

__getattr__ = getattr_migration(__name__)


--- pydantic/decorator.py ---
"""The `decorator` module is a backport module from V1."""

from ._migration import getattr_migration

__getattr__ = getattr_migration(__name__)


--- pydantic/env_settings.py ---
"""The `env_settings` module is a backport module from V1."""

from ._migration import getattr_migration

__getattr__ = getattr_migration(__name__)


--- pydantic/error_wrappers.py ---
"""The `error_wrappers` module is a backport module from V1."""

from ._migration import getattr_migration

__getattr__ = getattr_migration(__name__)


--- pydantic/errors.py ---
"""Pydantic-specific errors."""

from __future__ import annotations as _annotations

import re
from typing import Any, ClassVar, Literal

from typing_extensions import Self
from typing_inspection.introspection import Qualifier

from pydantic._internal import _repr

from ._migration import getattr_migration
from .version import version_short

__all__ = (
    'PydanticUserError',
    'PydanticUndefinedAnnotation',
    'PydanticImportError',
    'PydanticSchemaGenerationError',
    'PydanticInvalidForJsonSchema',
    'PydanticForbiddenQualifier',
    'PydanticErrorCodes',
)

# We use this URL to allow for future flexibility about how we host the docs, while allowing for Pydantic
# code in the while with "old" URLs to still work.
# 'u' refers to "user errors" - e.g. errors caused by developers using pydantic, as opposed to validation errors.
DEV_ERROR_DOCS_URL = f'https://errors.pydantic.dev/{version_short()}/u/'
PydanticErrorCodes = Literal[
    'class-not-fully-defined',
    'custom-json-schema',
    'decorator-invalid-fields',
    'decorator-missing-arguments',
    'decorator-missing-field',
    'discriminator-no-field',
    'discriminator-alias-type',
    'discriminator-needs-literal',
    'discriminator-alias',
    'discriminator-validator',
    'callable-discriminator-no-tag',
    'typed-dict-version',
    'model-field-overridden',
    'model-field-missing-annotation',
    'config-both',
    'removed-kwargs',
    'circular-reference-schema',
    'invalid-for-json-schema',
    'json-schema-already-used',
    'base-model-instantiated',
    'undefined-annotation',
    'schema-for-unknown-type',
    'import-error',
    'create-model-field-definitions',
    'validator-instance-method',
    'validator-input-type',
    'root-validator-pre-skip',
    'model-serializer-instance-method',
    'validator-field-config-info',
    'validator-v1-signature',
    'validator-signature',
    'field-serializer-signature',
    'model-serializer-signature',
    'multiple-field-serializers',
    'invalid-annotated-type',
    'type-adapter-config-unused',
    'root-model-extra',
    'unevaluable-type-annotation',
    'dataclass-init-false-extra-allow',
    'clashing-init-and-init-var',
    'model-config-invalid-field-name',
    'with-config-on-model',
    'dataclass-on-model',
    'validate-call-type',
    'unpack-typed-dict',
    'overlapping-unpack-typed-dict',
    'invalid-self-type',
    'validate-by-alias-and-name-false',
]


class PydanticErrorMixin:
    """A mixin class for common functionality shared by all Pydantic-specific errors.

    Attributes:
        message: A message describing the error.
        code: An optional error code from PydanticErrorCodes enum.
    """

    def __init__(self, message: str, *, code: PydanticErrorCodes | None) -> None:
        self.message = message
        self.code = code

    def __str__(self) -> str:
        if self.code is None:
            return self.message
        else:
            return f'{self.message}\n\nFor further information visit {DEV_ERROR_DOCS_URL}{self.code}'


class PydanticUserError(PydanticErrorMixin, RuntimeError):
    """An error raised due to incorrect use of Pydantic."""


class PydanticUndefinedAnnotation(PydanticErrorMixin, NameError):
    """A subclass of `NameError` raised when handling undefined annotations during `CoreSchema` generation.

    Attributes:
        name: Name of the error.
        message: Description of the error.
    """

    def __init__(self, name: str, message: str) -> None:
        self.name = name
        super().__init__(message=message, code='undefined-annotation')

    @classmethod
    def from_name_error(cls, name_error: NameError) -> Self:
        """Convert a `NameError` to a `PydanticUndefinedAnnotation` error.

        Args:
            name_error: `NameError` to be converted.

        Returns:
            Converted `PydanticUndefinedAnnotation` error.
        """
        try:
            name = name_error.name  # type: ignore  # python > 3.10
        except AttributeError:
            name = re.search(r".*'(.+?)'", str(name_error)).group(1)  # type: ignore[union-attr]
        return cls(name=name, message=str(name_error))


class PydanticImportError(PydanticErrorMixin, ImportError):
    """An error raised when an import fails due to module changes between V1 and V2.

    Attributes:
        message: Description of the error.
    """

    def __init__(self, message: str) -> None:
        super().__init__(message, code='import-error')


class PydanticSchemaGenerationError(PydanticUserError):
    """An error raised during failures to generate a `CoreSchema` for some type.

    Attributes:
        message: Description of the error.
    """

    def __init__(self, message: str) -> None:
        super().__init__(message, code='schema-for-unknown-type')


class PydanticInvalidForJsonSchema(PydanticUserError):
    """An error raised during failures to generate a JSON schema for some `CoreSchema`.

    Attributes:
        message: Description of the error.
    """

    def __init__(self, message: str) -> None:
        super().__init__(message, code='invalid-for-json-schema')


class PydanticForbiddenQualifier(PydanticUserError):
    """An error raised if a forbidden type qualifier is found in a type annotation."""

    _qualifier_repr_map: ClassVar[dict[Qualifier, str]] = {
        'required': 'typing.Required',
        'not_required': 'typing.NotRequired',
        'read_only': 'typing.ReadOnly',
        'class_var': 'typing.ClassVar',
        'init_var': 'dataclasses.InitVar',
        'final': 'typing.Final',
    }

    def __init__(self, qualifier: Qualifier, annotation: Any) -> None:
        super().__init__(
            message=(
                f'The annotation {_repr.display_as_type(annotation)!r} contains the {self._qualifier_repr_map[qualifier]!r} '
                f'type qualifier, which is invalid in the context it is defined.'
            ),
            code=None,
        )


__getattr__ = getattr_migration(__name__)


--- pydantic-core/README.md ---
# pydantic-core

[![CI](https://github.com/pydantic/pydantic-core/workflows/ci/badge.svg?event=push)](https://github.com/pydantic/pydantic-core/actions?query=event%3Apush+branch%3Amain+workflow%3Aci)
[![Coverage](https://codecov.io/gh/pydantic/pydantic-core/branch/main/graph/badge.svg)](https://codecov.io/gh/pydantic/pydantic-core)
[![pypi](https://img.shields.io/pypi/v/pydantic-core.svg)](https://pypi.python.org/pypi/pydantic-core)
[![versions](https://img.shields.io/pypi/pyversions/pydantic-core.svg)](https://github.com/pydantic/pydantic-core)
[![license](https://img.shields.io/github/license/pydantic/pydantic-core.svg)](https://github.com/pydantic/pydantic-core/blob/main/LICENSE)

This package provides the core functionality for [pydantic](https://docs.pydantic.dev) validation and serialization.

Pydantic-core is currently around 17x faster than pydantic V1.
See [`tests/benchmarks/`](./tests/benchmarks/) for details.

## Example of direct usage

*NOTE: You should not need to use pydantic-core directly; instead, use pydantic, which in turn uses pydantic-core.*

```py
from pydantic_core import SchemaValidator, ValidationError


v = SchemaValidator(
    {
        'type': 'typed-dict',
        'fields': {
            'name': {
                'type': 'typed-dict-field',
                'schema': {
                    'type': 'str',
                },
            },
            'age': {
                'type': 'typed-dict-field',
                'schema': {
                    'type': 'int',
                    'ge': 18,
                },
            },
            'is_developer': {
                'type': 'typed-dict-field',
                'schema': {
                    'type': 'default',
                    'schema': {'type': 'bool'},
                    'default': True,
                },
            },
        },
    }
)

r1 = v.validate_python({'name': 'Samuel', 'age': 35})
assert r1 == {'name': 'Samuel', 'age': 35, 'is_developer': True}

# pydantic-core can also validate JSON directly
r2 = v.validate_json('{"name": "Samuel", "age": 35}')
assert r1 == r2

try:
    v.validate_python({'name': 'Samuel', 'age': 11})
except ValidationError as e:
    print(e)
    """
    1 validation error for model
    age
      Input should be greater than or equal to 18
      [type=greater_than_equal, context={ge: 18}, input_value=11, input_type=int]
    """
```

## Getting Started

### Prerequisites

You'll need:

1. **[Rust](https://rustup.rs/)** - Rust stable (or nightly for coverage)
2. **[uv](https://docs.astral.sh/uv/getting-started/installation/)** - Fast Python package manager (will install Python 3.9+ automatically)
3. **[git](https://git-scm.com/)** - For version control
4. **[make](https://www.gnu.org/software/make/)** - For running development commands (or use `nmake` on Windows)

### Quick Start

```bash
# Clone the repository (or from your fork)
git clone git@github.com:pydantic/pydantic-core.git
cd pydantic-core

# Install all dependencies using uv, setup pre-commit hooks, and build the development version
make install
```

Verify your installation by running:

```bash
make
```

This runs a full development cycle: formatting, building, linting, and testing

### Development Commands

Run `make help` to see all available commands, or use these common ones:

```bash
make build-dev    # to build the package during development
make build-prod   # to perform an optimised build for benchmarking
make test         # to run the tests
make testcov      # to run the tests and generate a coverage report
make lint         # to run the linter
make format       # to format python and rust code
make all          # to run to run build-dev + format + lint + test
```

### Useful Resources

* [`python/pydantic_core/_pydantic_core.pyi`](./python/pydantic_core/_pydantic_core.pyi) - Python API types
* [`python/pydantic_core/core_schema.py`](./python/pydantic_core/core_schema.py) - Core schema definitions
* [`tests/`](./tests) - Comprehensive usage examples

## Profiling

It's possible to profile the code using the [`flamegraph` utility from `flamegraph-rs`](https://github.com/flamegraph-rs/flamegraph). (Tested on Linux.) You can install this with `cargo install flamegraph`.

Run `make build-profiling` to install a release build with debugging symbols included (needed for profiling).

Once that is built, you can profile pytest benchmarks with (e.g.):

```bash
flamegraph -- pytest tests/benchmarks/test_micro_benchmarks.py -k test_list_of_ints_core_py --benchmark-enable
```

The `flamegraph` command will produce an interactive SVG at `flamegraph.svg`.

## Releasing

TBC (needs to be integrated into `pydantic` repository release process).


## Links discovered
- [![CI](https://github.com/pydantic/pydantic-core/workflows/ci/badge.svg?event=push)
- [![Coverage](https://codecov.io/gh/pydantic/pydantic-core/branch/main/graph/badge.svg)
- [![pypi](https://img.shields.io/pypi/v/pydantic-core.svg)
- [![versions](https://img.shields.io/pypi/pyversions/pydantic-core.svg)
- [![license](https://img.shields.io/github/license/pydantic/pydantic-core.svg)
- [pydantic](https://docs.pydantic.dev)
- [`tests/benchmarks/`](https://github.com/pydantic/pydantic/blob/main/pydantic-core/tests/benchmarks.md)
- [Rust](https://rustup.rs/)
- [uv](https://docs.astral.sh/uv/getting-started/installation/)
- [git](https://git-scm.com/)
- [make](https://www.gnu.org/software/make/)
- [`python/pydantic_core/_pydantic_core.pyi`](https://github.com/pydantic/pydantic/blob/main/pydantic-core/python/pydantic_core/_pydantic_core.pyi)
- [`python/pydantic_core/core_schema.py`](https://github.com/pydantic/pydantic/blob/main/pydantic-core/python/pydantic_core/core_schema.py)
- [`tests/`](https://github.com/pydantic/pydantic/blob/main/pydantic-core/tests.md)
- [`flamegraph` utility from `flamegraph-rs`](https://github.com/flamegraph-rs/flamegraph)

--- pydantic-core/wasm-preview/README.md ---
# Demonstration of pydantic-core unit tests running in the browser

[Run tests in your browser at this web link](https://githubproxy.samuelcolvin.workers.dev/pydantic/pydantic-core/blob/main/wasm-preview/index.html).

To test with a specific version of pydantic-core, add a query parameter `?pydantic_core_version=...` to the URL, e.g. `?pydantic_core_version=v2.4.0`, defaults to latest release.

This doesn't work for version of pydantic-core before v0.23.0 as before that we built 3.10 binaries, and pyodide now rust 3.11.

If the output appears to stop prematurely, try looking in the developer console for more details.

For pydantic-core versions prior to `2.2.0`, tests will freeze at  at 10-15% of the way through on Chrome due to a suspected V8 bug, see [pyodide/pyodide#3792](https://github.com/pyodide/pyodide/issues/3792) for more information.


## Links discovered
- [Run tests in your browser at this web link](https://githubproxy.samuelcolvin.workers.dev/pydantic/pydantic-core/blob/main/wasm-preview/index.html)
- [pyodide/pyodide#3792](https://github.com/pyodide/pyodide/issues/3792)

--- pydantic-core/wasm-preview/index.html ---
<!DOCTYPE html>
<!-- NOTE: to view this page go to: https://githubproxy.samuelcolvin.workers.dev/pydantic/pydantic-core/blob/main/wasm-preview/index.html -->
<html lang="en">
  <head>
    <title>pydantic-core unit tests</title>
    <style>
      html,
      body {
        height: 100%;
        background: rgb(30, 31, 46);
        color: white;
        font-family: monospace;
        overflow: hidden;
      }
      main {
        max-width: 800px;
        height: 100%;
        margin: 10px auto;
      }
      section {
        margin-top: 20px;
        padding: 10px 15px;
        height: calc(100% - 160px);
        overflow-y: scroll;
        overflow-x: hidden;
        border: 1px solid #aaa;
        border-radius: 5px;
      }
      pre {
        margin: 0;
        padding: 0;
        white-space: pre-wrap;
      }
      a {
        color: #58a6ff;
        text-decoration: none;
      }
    </style>
  </head>
  <body>
    <main>
      <h1><a href="https://github.com/pydantic/pydantic-core/tree/main/wasm-preview">pydantic-core</a> unit tests</h1>
      <aside>
        pydantic-core is compiled to webassembly and run in the browser using
        <a href="https://pyodide.org/en/stable/">pyodide</a>.
      </aside>
      <section>
        <pre id="output">loading...</pre>
      </section>
    </main>

    <script src="https://githubproxy.samuelcolvin.workers.dev/samuelcolvin/824b7fe45b0cb36ffdfd7db7a3d4ce87/raw/ansi-to-html.browser.js"></script>
    <script>
      const output_el = document.getElementById('output');
      const decoder = new TextDecoder();
      const Convert = require('ansi-to-html');
      const ansi_converter = new Convert();
      let terminal_output = '';

      output_el.innerText = 'Starting worker...';
      const query_args = new URLSearchParams(location.search);
      query_args.set('ts', Date.now());
      const worker = new Worker(`./worker.js?${query_args.toString()}`);
      worker.onmessage = ({data}) => {
        if (typeof data == 'string') {
          terminal_output += data;
        } else {
          for (let chunk of data) {
            let arr = new Uint8Array(chunk);
            let extra = decoder.decode(arr);
            terminal_output += extra;
          }
        }
        output_el.innerHTML = ansi_converter.toHtml(terminal_output);
        // scrolls to the bottom of the div
        output_el.scrollIntoView(false);
      };
      worker.postMessage(null);
    </script>
  </body>
</html>


## Links discovered
- [pydantic-core](https://github.com/pydantic/pydantic-core/tree/main/wasm-preview)
- [pyodide](https://pyodide.org/en/stable/)

--- pydantic-core/.github/check_version.py ---
#!/usr/bin/env python3
"""
Check the version in Cargo.toml matches the version from `GITHUB_REF` environment variable.
"""

import os
import re
import sys
from pathlib import Path


def main() -> int:
    cargo_path = Path('Cargo.toml')
    if not cargo_path.is_file():
        print(f'✖ path "{cargo_path}" does not exist')
        return 1

    version_ref = os.getenv('GITHUB_REF')
    if version_ref:
        version = re.sub('^refs/tags/v*', '', version_ref.lower())
    else:
        print('✖ "GITHUB_REF" env variables not found')
        return 1

    # convert from python pre-release version to rust pre-release version
    # this is the reverse of what's done in lib.rs::_rust_notify
    version = version.replace('a', '-alpha').replace('b', '-beta')

    version_regex = re.compile(r"""^version ?= ?(["'])(.+)\1""", re.M)
    cargo_content = cargo_path.read_text()
    match = version_regex.search(cargo_content)
    if not match:
        print(f'✖ {version_regex!r} not found in {cargo_path}')
        return 1

    cargo_version = match.group(2)
    if cargo_version == version:
        print(f'✓ GITHUB_REF version matches {cargo_path} version "{cargo_version}"')
        return 0
    else:
        print(f'✖ GITHUB_REF version "{version}" does not match {cargo_path} version "{cargo_version}"')
        return 1


if __name__ == '__main__':
    sys.exit(main())


--- pydantic-core/tests/conftest.py ---
from __future__ import annotations as _annotations

import functools
import gc
import importlib.util
import json
import os
import re
import sys
from dataclasses import dataclass
from pathlib import Path
from time import sleep, time
from typing import Any, Callable, Literal

import hypothesis
import pytest

from pydantic_core import ArgsKwargs, CoreSchema, SchemaValidator, ValidationError
from pydantic_core.core_schema import CoreConfig, ExtraBehavior

__all__ = 'Err', 'PyAndJson', 'assert_gc', 'is_free_threaded', 'plain_repr', 'infinite_generator'

hypothesis.settings.register_profile('fast', max_examples=2)
hypothesis.settings.register_profile('slow', max_examples=1_000)
hypothesis.settings.load_profile(os.getenv('HYPOTHESIS_PROFILE', 'fast'))

try:
    is_free_threaded = not sys._is_gil_enabled()
except AttributeError:
    is_free_threaded = False


def plain_repr(obj):
    r = repr(obj)
    r = re.sub(r',\s*([)}])', r'\1', r)
    r = re.sub(r'\s+', '', r)
    return r


@dataclass
class Err:
    message: str
    errors: Any | None = None

    def __repr__(self):
        if self.errors:
            return f'Err({self.message!r}, errors={self.errors!r})'
        else:
            return f'Err({self.message!r})'


def json_default(obj):
    if isinstance(obj, ArgsKwargs):
        raise pytest.skip('JSON skipping ArgsKwargs')
    else:
        raise TypeError(f'Object of type {type(obj).__name__} is not JSON serializable')


class PyAndJsonValidator:
    def __init__(
        self,
        schema: CoreSchema,
        config: CoreConfig | None = None,
        *,
        validator_type: Literal['json', 'python'] | None = None,
    ):
        self.validator = SchemaValidator(schema, config)
        self.validator_type = validator_type

    def validate_python(self, py_input, strict: bool | None = None, context: Any = None):
        return self.validator.validate_python(py_input, strict=strict, context=context)

    def validate_json(self, json_str: str, strict: bool | None = None, context: Any = None):
        return self.validator.validate_json(json_str, strict=strict, context=context)

    def validate_test(
        self, py_input, strict: bool | None = None, context: Any = None, extra: ExtraBehavior | None = None
    ):
        if self.validator_type == 'json':
            return self.validator.validate_json(
                json.dumps(py_input, default=json_default),
                strict=strict,
                extra=extra,
                context=context,
            )
        else:
            assert self.validator_type == 'python', self.validator_type
            return self.validator.validate_python(py_input, strict=strict, context=context, extra=extra)

    def isinstance_test(self, py_input, strict: bool | None = None, context: Any = None):
        if self.validator_type == 'json':
            try:
                self.validator.validate_json(json.dumps(py_input), strict=strict, context=context)
                return True
            except ValidationError:
                return False
        else:
            assert self.validator_type == 'python', self.validator_type
            return self.validator.isinstance_python(py_input, strict=strict, context=context)


PyAndJson = type[PyAndJsonValidator]


@pytest.fixture(params=['python', 'json'])
def py_and_json(request) -> PyAndJson:
    class ChosenPyAndJsonValidator(PyAndJsonValidator):
        __init__ = functools.partialmethod(PyAndJsonValidator.__init__, validator_type=request.param)

    return ChosenPyAndJsonValidator


class StrictModeType:
    def __init__(self, schema: bool, extra: bool):
        assert schema or extra
        self.schema = schema
        self.validator_args = {'strict': True} if extra else {}


@pytest.fixture(
    params=[
        StrictModeType(schema=True, extra=False),
        StrictModeType(schema=False, extra=True),
        StrictModeType(schema=True, extra=True),
    ],
    ids=['strict-schema', 'strict-extra', 'strict-both'],
)
def strict_mode_type(request) -> StrictModeType:
    return request.param


@pytest.fixture
def tmp_work_path(tmp_path: Path):
    """
    Create a temporary working directory.
    """
    previous_cwd = Path.cwd()
    os.chdir(tmp_path)

    yield tmp_path

    os.chdir(previous_cwd)


@pytest.fixture
def import_execute(request, tmp_work_path: Path):
    def _import_execute(source: str, *, custom_module_name: str | None = None):
        module_name = custom_module_name or request.node.name

        module_path = tmp_work_path / f'{module_name}.py'
        module_path.write_text(source)
        spec = importlib.util.spec_from_file_location('__main__', str(module_path))
        module = importlib.util.module_from_spec(spec)
        try:
            spec.loader.exec_module(module)
        except KeyboardInterrupt:
            print('KeyboardInterrupt')
        else:
            return module

    return _import_execute


@pytest.fixture
def pydantic_version():
    try:
        import pydantic

        # include major and minor version only
        return '.'.join(pydantic.__version__.split('.')[:2])
    except ImportError:
        return 'latest'


def infinite_generator():
    i = 0
    while True:
        yield i
        i += 1


def assert_gc(test: Callable[[], bool], timeout: float = 10) -> None:
    """Helper to retry garbage collection until the test passes or timeout is
    reached.

    This is useful on free-threading where the GC collect call finishes before
    all cleanup is done.
    """
    start = now = time()
    while now - start < timeout:
        if test():
            return
        gc.collect()
        sleep(0.1)
        now = time()
    raise AssertionError('Timeout waiting for GC')


--- pydantic-core/tests/emscripten_runner.js ---
const {opendir} = require('node:fs/promises');
const {loadPyodide} = require('pyodide');
const path = require('path');

async function find_wheel(dist_dir) {
  const dir = await opendir(dist_dir);
  for await (const dirent of dir) {
    if (dirent.name.endsWith('.whl')) {
      return path.join(dist_dir, dirent.name);
    }
  }
}

function make_tty_ops(stream) {
  return {
    // get_char has 3 particular return values:
    // a.) the next character represented as an integer
    // b.) undefined to signal that no data is currently available
    // c.) null to signal an EOF
    get_char(tty) {
      if (!tty.input.length) {
        let result = null;
        const BUFSIZE = 256;
        const buf = Buffer.alloc(BUFSIZE);
        const bytesRead = fs.readSync(process.stdin.fd, buf, 0, BUFSIZE, -1);
        if (bytesRead === 0) {
          return null;
        }
        result = buf.slice(0, bytesRead);
        tty.input = Array.from(result);
      }
      return tty.input.shift();
    },
    put_char(tty, val) {
      try {
        if (val !== null) {
          tty.output.push(val);
        }
        if (val === null || val === 10) {
          process.stdout.write(Buffer.from(tty.output));
          tty.output = [];
        }
      } catch (e) {
        console.warn(e);
      }
    },
    fsync(tty) {
      if (!tty.output || tty.output.length === 0) {
        return;
      }
      stream.write(Buffer.from(tty.output));
      tty.output = [];
    },
  };
}

function setupStreams(FS, TTY) {
  let mytty = FS.makedev(FS.createDevice.major++, 0);
  let myttyerr = FS.makedev(FS.createDevice.major++, 0);
  TTY.register(mytty, make_tty_ops(process.stdout));
  TTY.register(myttyerr, make_tty_ops(process.stderr));
  FS.mkdev('/dev/mytty', mytty);
  FS.mkdev('/dev/myttyerr', myttyerr);
  FS.unlink('/dev/stdin');
  FS.unlink('/dev/stdout');
  FS.unlink('/dev/stderr');
  FS.symlink('/dev/mytty', '/dev/stdin');
  FS.symlink('/dev/mytty', '/dev/stdout');
  FS.symlink('/dev/myttyerr', '/dev/stderr');
  FS.closeStream(0);
  FS.closeStream(1);
  FS.closeStream(2);
  FS.open('/dev/stdin', 0);
  FS.open('/dev/stdout', 1);
  FS.open('/dev/stderr', 1);
}

async function main() {
  const root_dir = path.resolve(__dirname, '..');
  const wheel_path = await find_wheel(path.join(root_dir, 'dist'));
  let errcode = 1;
  try {
    const pyodide = await loadPyodide();
    const FS = pyodide.FS;
    setupStreams(FS, pyodide._module.TTY);
    FS.mkdir('/test_dir');
    FS.mount(FS.filesystems.NODEFS, {root: path.join(root_dir, 'tests')}, '/test_dir');
    FS.chdir('/test_dir');
    await pyodide.loadPackage(['micropip', 'pytest', 'pygments']);
    // language=python
    errcode = await pyodide.runPythonAsync(`
import micropip
import importlib

# ugly hack to get tests to work on arm64 (my m1 mac)
# see https://github.com/pyodide/pyodide/issues/2840
# import sys; sys.setrecursionlimit(200)

await micropip.install([
    'dirty-equals',
    # inline-snapshot 0.21 requires pytest 8.3.4, pyodide 0.26 ships with 8.1.1
    'inline-snapshot < 0.21',
    'hypothesis',
    'pytest-speed',
    'pytest-mock',
    'tzdata',
    'file:${wheel_path}',
    'typing-extensions>=4.14.1',
    'typing-inspection',
])
importlib.invalidate_caches()

print('installed packages:', micropip.list())

import pytest
pytest.main()
`);
  } catch (e) {
    console.error(e);
    process.exit(1);
  }
  process.exit(errcode);
}

main();


--- pydantic-core/tests/__init__.py ---


--- pydantic-core/.github/PULL_REQUEST_TEMPLATE.md ---
<!-- Thank you for your contribution! -->

## Change Summary

<!-- Please give a short summary of the changes. -->

## Related issue number

<!-- Are there any issues opened that will be resolved by merging this change? -->
<!-- WARNING: please use "fix #123" style references so the issue is closed when this PR is merged. -->

## Checklist

* [ ] Unit tests for the changes exist
* [ ] Documentation reflects the changes where applicable
* [ ] Pydantic tests pass with this `pydantic-core` (except for expected changes)
* [ ] My PR is ready to review, **please add a comment including the phrase "please review" to assign reviewers**


--- pydantic-core/wasm-preview/run_tests.py ---
import base64
import importlib
import re
import sys
import traceback
from io import BytesIO
from pathlib import Path
from zipfile import ZipFile

import micropip
import pyodide
import pytest

# this seems to be required for me on M1 Mac
sys.setrecursionlimit(200)


async def main(tests_zip: str, tag_name: str):
    print(f'Using pyodide version: {pyodide.__version__}')
    print(f'Extracting test files (size: {len(tests_zip):,})...')
    # File saved on the GH release
    pydantic_core_wheel = (
        'https://githubproxy.samuelcolvin.workers.dev/pydantic/pydantic-core/releases/'
        f'download/{tag_name}/pydantic_core-{tag_name.lstrip("v")}-cp312-cp312-emscripten_3_1_58_wasm32.whl'
    )
    zip_file = ZipFile(BytesIO(base64.b64decode(tests_zip)))
    count = 0
    for name in zip_file.namelist():
        if name.endswith('.py'):
            path, subs = re.subn(r'^pydantic-core-.+?/tests/', 'tests/', name)
            if subs:
                count += 1
                path = Path(path)
                path.parent.mkdir(parents=True, exist_ok=True)
                with zip_file.open(name, 'r') as f:
                    path.write_bytes(f.read())

    print(f'Mounted {count} test files, installing dependencies...')

    await micropip.install(
        [
            'dirty-equals',
            'hypothesis',
            'pytest-speed',
            'pytest-mock',
            'tzdata',
            'inline-snapshot<0.21',
            'typing-extensions>=4.14.1',
            'typing-inspection',
            pydantic_core_wheel,
        ]
    )
    importlib.invalidate_caches()

    # print('installed packages:')
    # print(micropip.list())
    print('Running tests...')
    pytest.main()


try:
    await main(tests_zip, pydantic_core_version)  # noqa: F821,F704
except Exception:
    traceback.print_exc()
    raise


--- pydantic-core/src/self_schema.py ---
# this file is auto-generated by generate_self_schema.py, DO NOT edit manually
self_schema = {'type': 'definitions', 'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'definitions': [{'type': 'tagged-union', 'choices': {'invalid': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['invalid']}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'any': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['any']}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'none': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none']}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'bool': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['bool']}, 'required': True}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'int': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['int']}, 'required': True}, 'multiple_of': {'schema': {'type': 'int'}, 'required': False}, 'le': {'schema': {'type': 'int'}, 'required': False}, 'ge': {'schema': {'type': 'int'}, 'required': False}, 'lt': {'schema': {'type': 'int'}, 'required': False}, 'gt': {'schema': {'type': 'int'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'float': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['float']}, 'required': True}, 'allow_inf_nan': {'schema': {'type': 'bool'}, 'required': False}, 'multiple_of': {'schema': {'type': 'float'}, 'required': False}, 'le': {'schema': {'type': 'float'}, 'required': False}, 'ge': {'schema': {'type': 'float'}, 'required': False}, 'lt': {'schema': {'type': 'float'}, 'required': False}, 'gt': {'schema': {'type': 'float'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'decimal': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['decimal']}, 'required': True}, 'allow_inf_nan': {'schema': {'type': 'bool'}, 'required': False}, 'multiple_of': {'schema': {'type': 'decimal'}, 'required': False}, 'le': {'schema': {'type': 'decimal'}, 'required': False}, 'ge': {'schema': {'type': 'decimal'}, 'required': False}, 'lt': {'schema': {'type': 'decimal'}, 'required': False}, 'gt': {'schema': {'type': 'decimal'}, 'required': False}, 'max_digits': {'schema': {'type': 'int'}, 'required': False}, 'decimal_places': {'schema': {'type': 'int'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'str': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['str']}, 'required': True}, 'pattern': {'schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'any'}]}, 'required': False}, 'max_length': {'schema': {'type': 'int'}, 'required': False}, 'min_length': {'schema': {'type': 'int'}, 'required': False}, 'strip_whitespace': {'schema': {'type': 'bool'}, 'required': False}, 'to_lower': {'schema': {'type': 'bool'}, 'required': False}, 'to_upper': {'schema': {'type': 'bool'}, 'required': False}, 'regex_engine': {'schema': {'type': 'literal', 'expected': ['rust-regex', 'python-re']}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'coerce_numbers_to_str': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'bytes': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['bytes']}, 'required': True}, 'max_length': {'schema': {'type': 'int'}, 'required': False}, 'min_length': {'schema': {'type': 'int'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'date': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['date']}, 'required': True}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'le': {'schema': {'type': 'date'}, 'required': False}, 'ge': {'schema': {'type': 'date'}, 'required': False}, 'lt': {'schema': {'type': 'date'}, 'required': False}, 'gt': {'schema': {'type': 'date'}, 'required': False}, 'now_op': {'schema': {'type': 'literal', 'expected': ['past', 'future']}, 'required': False}, 'now_utc_offset': {'schema': {'type': 'int', 'gt': -86400, 'lt': 86400}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'time': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['time']}, 'required': True}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'le': {'schema': {'type': 'time'}, 'required': False}, 'ge': {'schema': {'type': 'time'}, 'required': False}, 'lt': {'schema': {'type': 'time'}, 'required': False}, 'gt': {'schema': {'type': 'time'}, 'required': False}, 'tz_constraint': {'schema': {'type': 'union', 'choices': [{'type': 'literal', 'expected': ['aware', 'naive']}, {'type': 'int'}]}, 'required': False}, 'microseconds_precision': {'schema': {'type': 'literal', 'expected': ['truncate', 'error']}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'datetime': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['datetime']}, 'required': True}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'le': {'schema': {'type': 'datetime'}, 'required': False}, 'ge': {'schema': {'type': 'datetime'}, 'required': False}, 'lt': {'schema': {'type': 'datetime'}, 'required': False}, 'gt': {'schema': {'type': 'datetime'}, 'required': False}, 'now_op': {'schema': {'type': 'literal', 'expected': ['past', 'future']}, 'required': False}, 'tz_constraint': {'schema': {'type': 'union', 'choices': [{'type': 'literal', 'expected': ['aware', 'naive']}, {'type': 'int'}]}, 'required': False}, 'now_utc_offset': {'schema': {'type': 'int', 'gt': -86400, 'lt': 86400}, 'required': False}, 'microseconds_precision': {'schema': {'type': 'literal', 'expected': ['truncate', 'error']}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'timedelta': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['timedelta']}, 'required': True}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'le': {'schema': {'type': 'timedelta'}, 'required': False}, 'ge': {'schema': {'type': 'timedelta'}, 'required': False}, 'lt': {'schema': {'type': 'timedelta'}, 'required': False}, 'gt': {'schema': {'type': 'timedelta'}, 'required': False}, 'microseconds_precision': {'schema': {'type': 'literal', 'expected': ['truncate', 'error']}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'literal': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['literal']}, 'required': True}, 'expected': {'schema': {'type': 'list', 'items_schema': {'type': 'any'}}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'enum': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['enum']}, 'required': True}, 'cls': {'schema': {'type': 'any'}, 'required': True}, 'members': {'schema': {'type': 'list', 'items_schema': {'type': 'any'}}, 'required': True}, 'sub_type': {'schema': {'type': 'literal', 'expected': ['str', 'int', 'float']}, 'required': False}, 'missing': {'schema': {'type': 'callable'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'is-instance': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['is-instance']}, 'required': True}, 'cls': {'schema': {'type': 'any'}, 'required': True}, 'cls_repr': {'schema': {'type': 'str'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'is-subclass': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['is-subclass']}, 'required': True}, 'cls': {'schema': {'type': 'any'}, 'required': True}, 'cls_repr': {'schema': {'type': 'str'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'callable': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['callable']}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'list': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['list']}, 'required': True}, 'items_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'min_length': {'schema': {'type': 'int'}, 'required': False}, 'max_length': {'schema': {'type': 'int'}, 'required': False}, 'fail_fast': {'schema': {'type': 'bool'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'tagged-union', 'discriminator': 'type', 'choices': {'include-exclude-sequence': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['include-exclude-sequence']}, 'required': True}, 'include': {'schema': {'type': 'set', 'items_schema': {'type': 'int'}}, 'required': False}, 'exclude': {'schema': {'type': 'set', 'items_schema': {'type': 'int'}}, 'required': False}}, 'extra_behavior': 'forbid'}, 'none': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'int': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bool': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'float': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'str': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bytes': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bytearray': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'list': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'tuple': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'set': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'frozenset': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'generator': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'dict': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'datetime': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'date': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'time': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'timedelta': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'multi-host-url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'json': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'uuid': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'any': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'function-plain': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-plain']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}]}, 'required': True}, 'is_field_serializer': {'schema': {'type': 'bool'}, 'required': False}, 'info_arg': {'schema': {'type': 'bool'}, 'required': False}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'function-wrap': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-wrap']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}]}, 'required': True}, 'is_field_serializer': {'schema': {'type': 'bool'}, 'required': False}, 'info_arg': {'schema': {'type': 'bool'}, 'required': False}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'format': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['format']}, 'required': True}, 'formatting_string': {'schema': {'type': 'str'}, 'required': True}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'to-string': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['to-string']}, 'required': True}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'model': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['model']}, 'required': True}, 'cls': {'schema': {'type': 'any'}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}}, 'extra_behavior': 'forbid'}}}, 'required': False}}, 'extra_behavior': 'forbid'}, 'tuple': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['tuple']}, 'required': True}, 'items_schema': {'schema': {'type': 'list', 'items_schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}}, 'required': True}, 'variadic_item_index': {'schema': {'type': 'int'}, 'required': False}, 'min_length': {'schema': {'type': 'int'}, 'required': False}, 'max_length': {'schema': {'type': 'int'}, 'required': False}, 'fail_fast': {'schema': {'type': 'bool'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'tagged-union', 'discriminator': 'type', 'choices': {'include-exclude-sequence': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['include-exclude-sequence']}, 'required': True}, 'include': {'schema': {'type': 'set', 'items_schema': {'type': 'int'}}, 'required': False}, 'exclude': {'schema': {'type': 'set', 'items_schema': {'type': 'int'}}, 'required': False}}, 'extra_behavior': 'forbid'}, 'none': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'int': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bool': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'float': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'str': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bytes': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bytearray': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'list': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'tuple': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'set': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'frozenset': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'generator': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'dict': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'datetime': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'date': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'time': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'timedelta': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'multi-host-url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'json': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'uuid': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'any': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'function-plain': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-plain']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}]}, 'required': True}, 'is_field_serializer': {'schema': {'type': 'bool'}, 'required': False}, 'info_arg': {'schema': {'type': 'bool'}, 'required': False}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'function-wrap': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-wrap']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}]}, 'required': True}, 'is_field_serializer': {'schema': {'type': 'bool'}, 'required': False}, 'info_arg': {'schema': {'type': 'bool'}, 'required': False}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'format': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['format']}, 'required': True}, 'formatting_string': {'schema': {'type': 'str'}, 'required': True}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'to-string': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['to-string']}, 'required': True}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'model': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['model']}, 'required': True}, 'cls': {'schema': {'type': 'any'}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}}, 'extra_behavior': 'forbid'}}}, 'required': False}}, 'extra_behavior': 'forbid'}, 'set': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['set']}, 'required': True}, 'items_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'min_length': {'schema': {'type': 'int'}, 'required': False}, 'max_length': {'schema': {'type': 'int'}, 'required': False}, 'fail_fast': {'schema': {'type': 'bool'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'frozenset': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['frozenset']}, 'required': True}, 'items_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'min_length': {'schema': {'type': 'int'}, 'required': False}, 'max_length': {'schema': {'type': 'int'}, 'required': False}, 'fail_fast': {'schema': {'type': 'bool'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'generator': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['generator']}, 'required': True}, 'items_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'min_length': {'schema': {'type': 'int'}, 'required': False}, 'max_length': {'schema': {'type': 'int'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'tagged-union', 'discriminator': 'type', 'choices': {'include-exclude-sequence': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['include-exclude-sequence']}, 'required': True}, 'include': {'schema': {'type': 'set', 'items_schema': {'type': 'int'}}, 'required': False}, 'exclude': {'schema': {'type': 'set', 'items_schema': {'type': 'int'}}, 'required': False}}, 'extra_behavior': 'forbid'}, 'none': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'int': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bool': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'float': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'str': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bytes': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bytearray': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'list': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'tuple': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'set': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'frozenset': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'generator': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'dict': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'datetime': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'date': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'time': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'timedelta': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'multi-host-url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'json': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'uuid': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'any': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'function-plain': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-plain']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}]}, 'required': True}, 'is_field_serializer': {'schema': {'type': 'bool'}, 'required': False}, 'info_arg': {'schema': {'type': 'bool'}, 'required': False}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'function-wrap': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-wrap']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}]}, 'required': True}, 'is_field_serializer': {'schema': {'type': 'bool'}, 'required': False}, 'info_arg': {'schema': {'type': 'bool'}, 'required': False}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'format': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['format']}, 'required': True}, 'formatting_string': {'schema': {'type': 'str'}, 'required': True}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'to-string': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['to-string']}, 'required': True}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'model': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['model']}, 'required': True}, 'cls': {'schema': {'type': 'any'}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}}, 'extra_behavior': 'forbid'}}}, 'required': False}}, 'extra_behavior': 'forbid'}, 'dict': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['dict']}, 'required': True}, 'keys_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'values_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'min_length': {'schema': {'type': 'int'}, 'required': False}, 'max_length': {'schema': {'type': 'int'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'tagged-union', 'discriminator': 'type', 'choices': {'include-exclude-dict': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['include-exclude-dict']}, 'required': True}, 'include': {'schema': {'type': 'set', 'items_schema': {'type': 'union', 'choices': [{'type': 'int'}, {'type': 'str'}]}}, 'required': False}, 'exclude': {'schema': {'type': 'set', 'items_schema': {'type': 'union', 'choices': [{'type': 'int'}, {'type': 'str'}]}}, 'required': False}}, 'extra_behavior': 'forbid'}, 'none': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'int': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bool': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'float': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'str': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bytes': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bytearray': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'list': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'tuple': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'set': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'frozenset': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'generator': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'dict': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'datetime': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'date': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'time': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'timedelta': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'multi-host-url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'json': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'uuid': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'any': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'function-plain': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-plain']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}]}, 'required': True}, 'is_field_serializer': {'schema': {'type': 'bool'}, 'required': False}, 'info_arg': {'schema': {'type': 'bool'}, 'required': False}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'function-wrap': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-wrap']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}]}, 'required': True}, 'is_field_serializer': {'schema': {'type': 'bool'}, 'required': False}, 'info_arg': {'schema': {'type': 'bool'}, 'required': False}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'format': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['format']}, 'required': True}, 'formatting_string': {'schema': {'type': 'str'}, 'required': True}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'to-string': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['to-string']}, 'required': True}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'model': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['model']}, 'required': True}, 'cls': {'schema': {'type': 'any'}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}}, 'extra_behavior': 'forbid'}}}, 'required': False}}, 'extra_behavior': 'forbid'}, 'function-after': {'type': 'typed-dict', 'fields': {'function': {'schema': {'type': 'union', 'choices': [{'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['no-info']}, 'required': True}, 'function': {'schema': {'type': 'callable'}, 'required': True}}, 'extra_behavior': 'forbid'}, {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['with-info']}, 'required': True}, 'function': {'schema': {'type': 'callable'}, 'required': True}, 'field_name': {'schema': {'type': 'str'}, 'required': False}}, 'extra_behavior': 'forbid'}]}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}, 'type': {'schema': {'type': 'literal', 'expected': ['function-after']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'function-before': {'type': 'typed-dict', 'fields': {'function': {'schema': {'type': 'union', 'choices': [{'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['no-info']}, 'required': True}, 'function': {'schema': {'type': 'callable'}, 'required': True}}, 'extra_behavior': 'forbid'}, {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['with-info']}, 'required': True}, 'function': {'schema': {'type': 'callable'}, 'required': True}, 'field_name': {'schema': {'type': 'str'}, 'required': False}}, 'extra_behavior': 'forbid'}]}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}, 'type': {'schema': {'type': 'literal', 'expected': ['function-before']}, 'required': True}, 'json_schema_input_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'function-wrap': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-wrap']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['no-info']}, 'required': True}, 'function': {'schema': {'type': 'callable'}, 'required': True}}, 'extra_behavior': 'forbid'}, {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['with-info']}, 'required': True}, 'function': {'schema': {'type': 'callable'}, 'required': True}, 'field_name': {'schema': {'type': 'str'}, 'required': False}}, 'extra_behavior': 'forbid'}]}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'json_schema_input_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'function-plain': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-plain']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['no-info']}, 'required': True}, 'function': {'schema': {'type': 'callable'}, 'required': True}}, 'extra_behavior': 'forbid'}, {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['with-info']}, 'required': True}, 'function': {'schema': {'type': 'callable'}, 'required': True}, 'field_name': {'schema': {'type': 'str'}, 'required': False}}, 'extra_behavior': 'forbid'}]}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'json_schema_input_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'default': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['default']}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'default': {'schema': {'type': 'any'}, 'required': False}, 'default_factory': {'schema': {'type': 'union', 'choices': [{'type': 'callable'}, {'type': 'callable'}]}, 'required': False}, 'default_factory_takes_data': {'schema': {'type': 'bool'}, 'required': False}, 'on_error': {'schema': {'type': 'literal', 'expected': ['raise', 'omit', 'default']}, 'required': False}, 'validate_default': {'schema': {'type': 'bool'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'nullable': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['nullable']}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'union': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['union']}, 'required': True}, 'choices': {'schema': {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'definition-ref', 'schema_ref': 'root-schema'}, {'type': 'tuple', 'items_schema': [{'type': 'definition-ref', 'schema_ref': 'root-schema'}, {'type': 'str'}]}]}}, 'required': True}, 'auto_collapse': {'schema': {'type': 'bool'}, 'required': False}, 'custom_error_type': {'schema': {'type': 'str'}, 'required': False}, 'custom_error_message': {'schema': {'type': 'str'}, 'required': False}, 'custom_error_context': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}, {'type': 'float'}]}}, 'required': False}, 'mode': {'schema': {'type': 'literal', 'expected': ['smart', 'left_to_right']}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'tagged-union': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['tagged-union']}, 'required': True}, 'choices': {'schema': {'type': 'dict', 'keys_schema': {'type': 'any'}, 'values_schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}}, 'required': True}, 'discriminator': {'schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}, {'type': 'list', 'items_schema': {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}}, {'type': 'callable'}]}, 'required': True}, 'custom_error_type': {'schema': {'type': 'str'}, 'required': False}, 'custom_error_message': {'schema': {'type': 'str'}, 'required': False}, 'custom_error_context': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}, {'type': 'float'}]}}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'from_attributes': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'chain': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['chain']}, 'required': True}, 'steps': {'schema': {'type': 'list', 'items_schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'lax-or-strict': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['lax-or-strict']}, 'required': True}, 'lax_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'strict_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'json-or-python': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['json-or-python']}, 'required': True}, 'json_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'python_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'typed-dict': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['typed-dict']}, 'required': True}, 'fields': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['typed-dict-field']}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'required': {'schema': {'type': 'bool'}, 'required': False}, 'validation_alias': {'schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}, {'type': 'list', 'items_schema': {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}}]}, 'required': False}, 'serialization_alias': {'schema': {'type': 'str'}, 'required': False}, 'serialization_exclude': {'schema': {'type': 'bool'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}}, 'extra_behavior': 'forbid'}}, 'required': True}, 'cls': {'schema': {'type': 'any'}, 'required': False}, 'cls_name': {'schema': {'type': 'str'}, 'required': False}, 'computed_fields': {'schema': {'type': 'list', 'items_schema': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['computed-field']}, 'required': True}, 'property_name': {'schema': {'type': 'str'}, 'required': True}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'alias': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}}, 'extra_behavior': 'forbid'}}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'extras_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'extra_behavior': {'schema': {'type': 'literal', 'expected': ['allow', 'forbid', 'ignore']}, 'required': False}, 'total': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}, 'config': {'schema': {'type': 'typed-dict', 'fields': {'title': {'schema': {'type': 'str'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'extra_fields_behavior': {'schema': {'type': 'literal', 'expected': ['allow', 'forbid', 'ignore']}, 'required': False}, 'typed_dict_total': {'schema': {'type': 'bool'}, 'required': False}, 'from_attributes': {'schema': {'type': 'bool'}, 'required': False}, 'loc_by_alias': {'schema': {'type': 'bool'}, 'required': False}, 'revalidate_instances': {'schema': {'type': 'literal', 'expected': ['always', 'never', 'subclass-instances']}, 'required': False}, 'validate_default': {'schema': {'type': 'bool'}, 'required': False}, 'str_max_length': {'schema': {'type': 'int'}, 'required': False}, 'str_min_length': {'schema': {'type': 'int'}, 'required': False}, 'str_strip_whitespace': {'schema': {'type': 'bool'}, 'required': False}, 'str_to_lower': {'schema': {'type': 'bool'}, 'required': False}, 'str_to_upper': {'schema': {'type': 'bool'}, 'required': False}, 'allow_inf_nan': {'schema': {'type': 'bool'}, 'required': False}, 'ser_json_timedelta': {'schema': {'type': 'literal', 'expected': ['iso8601', 'float']}, 'required': False}, 'ser_json_bytes': {'schema': {'type': 'literal', 'expected': ['utf8', 'base64', 'hex']}, 'required': False}, 'ser_json_inf_nan': {'schema': {'type': 'literal', 'expected': ['null', 'constants', 'strings']}, 'required': False}, 'val_json_bytes': {'schema': {'type': 'literal', 'expected': ['utf8', 'base64', 'hex']}, 'required': False}, 'hide_input_in_errors': {'schema': {'type': 'bool'}, 'required': False}, 'validation_error_cause': {'schema': {'type': 'bool'}, 'required': False}, 'coerce_numbers_to_str': {'schema': {'type': 'bool'}, 'required': False}, 'regex_engine': {'schema': {'type': 'literal', 'expected': ['rust-regex', 'python-re']}, 'required': False}, 'cache_strings': {'schema': {'type': 'union', 'choices': [{'type': 'bool'}, {'type': 'literal', 'expected': ['all', 'keys', 'none']}]}, 'required': False}, 'validate_by_alias': {'schema': {'type': 'bool'}, 'required': False}, 'validate_by_name': {'schema': {'type': 'bool'}, 'required': False}, 'serialize_by_alias': {'schema': {'type': 'bool'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'model-fields': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['model-fields']}, 'required': True}, 'fields': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['model-field']}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'validation_alias': {'schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}, {'type': 'list', 'items_schema': {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}}]}, 'required': False}, 'serialization_alias': {'schema': {'type': 'str'}, 'required': False}, 'serialization_exclude': {'schema': {'type': 'bool'}, 'required': False}, 'frozen': {'schema': {'type': 'bool'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}}, 'extra_behavior': 'forbid'}}, 'required': True}, 'model_name': {'schema': {'type': 'str'}, 'required': False}, 'computed_fields': {'schema': {'type': 'list', 'items_schema': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['computed-field']}, 'required': True}, 'property_name': {'schema': {'type': 'str'}, 'required': True}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'alias': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}}, 'extra_behavior': 'forbid'}}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'extras_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'extras_keys_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'extra_behavior': {'schema': {'type': 'literal', 'expected': ['allow', 'forbid', 'ignore']}, 'required': False}, 'from_attributes': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'model': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['model']}, 'required': True}, 'cls': {'schema': {'type': 'any'}, 'required': True}, 'generic_origin': {'schema': {'type': 'any'}, 'required': False}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'custom_init': {'schema': {'type': 'bool'}, 'required': False}, 'root_model': {'schema': {'type': 'bool'}, 'required': False}, 'post_init': {'schema': {'type': 'str'}, 'required': False}, 'revalidate_instances': {'schema': {'type': 'literal', 'expected': ['always', 'never', 'subclass-instances']}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'frozen': {'schema': {'type': 'bool'}, 'required': False}, 'extra_behavior': {'schema': {'type': 'literal', 'expected': ['allow', 'forbid', 'ignore']}, 'required': False}, 'config': {'schema': {'type': 'typed-dict', 'fields': {'title': {'schema': {'type': 'str'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'extra_fields_behavior': {'schema': {'type': 'literal', 'expected': ['allow', 'forbid', 'ignore']}, 'required': False}, 'typed_dict_total': {'schema': {'type': 'bool'}, 'required': False}, 'from_attributes': {'schema': {'type': 'bool'}, 'required': False}, 'loc_by_alias': {'schema': {'type': 'bool'}, 'required': False}, 'revalidate_instances': {'schema': {'type': 'literal', 'expected': ['always', 'never', 'subclass-instances']}, 'required': False}, 'validate_default': {'schema': {'type': 'bool'}, 'required': False}, 'str_max_length': {'schema': {'type': 'int'}, 'required': False}, 'str_min_length': {'schema': {'type': 'int'}, 'required': False}, 'str_strip_whitespace': {'schema': {'type': 'bool'}, 'required': False}, 'str_to_lower': {'schema': {'type': 'bool'}, 'required': False}, 'str_to_upper': {'schema': {'type': 'bool'}, 'required': False}, 'allow_inf_nan': {'schema': {'type': 'bool'}, 'required': False}, 'ser_json_timedelta': {'schema': {'type': 'literal', 'expected': ['iso8601', 'float']}, 'required': False}, 'ser_json_bytes': {'schema': {'type': 'literal', 'expected': ['utf8', 'base64', 'hex']}, 'required': False}, 'ser_json_inf_nan': {'schema': {'type': 'literal', 'expected': ['null', 'constants', 'strings']}, 'required': False}, 'val_json_bytes': {'schema': {'type': 'literal', 'expected': ['utf8', 'base64', 'hex']}, 'required': False}, 'hide_input_in_errors': {'schema': {'type': 'bool'}, 'required': False}, 'validation_error_cause': {'schema': {'type': 'bool'}, 'required': False}, 'coerce_numbers_to_str': {'schema': {'type': 'bool'}, 'required': False}, 'regex_engine': {'schema': {'type': 'literal', 'expected': ['rust-regex', 'python-re']}, 'required': False}, 'cache_strings': {'schema': {'type': 'union', 'choices': [{'type': 'bool'}, {'type': 'literal', 'expected': ['all', 'keys', 'none']}]}, 'required': False}, 'validate_by_alias': {'schema': {'type': 'bool'}, 'required': False}, 'validate_by_name': {'schema': {'type': 'bool'}, 'required': False}, 'serialize_by_alias': {'schema': {'type': 'bool'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'dataclass-args': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['dataclass-args']}, 'required': True}, 'dataclass_name': {'schema': {'type': 'str'}, 'required': True}, 'fields': {'schema': {'type': 'list', 'items_schema': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['dataclass-field']}, 'required': True}, 'name': {'schema': {'type': 'str'}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'kw_only': {'schema': {'type': 'bool'}, 'required': False}, 'init': {'schema': {'type': 'bool'}, 'required': False}, 'init_only': {'schema': {'type': 'bool'}, 'required': False}, 'frozen': {'schema': {'type': 'bool'}, 'required': False}, 'validation_alias': {'schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}, {'type': 'list', 'items_schema': {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}}]}, 'required': False}, 'serialization_alias': {'schema': {'type': 'str'}, 'required': False}, 'serialization_exclude': {'schema': {'type': 'bool'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}}, 'extra_behavior': 'forbid'}}, 'required': True}, 'computed_fields': {'schema': {'type': 'list', 'items_schema': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['computed-field']}, 'required': True}, 'property_name': {'schema': {'type': 'str'}, 'required': True}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'alias': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}}, 'extra_behavior': 'forbid'}}, 'required': False}, 'collect_init_only': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}, 'extra_behavior': {'schema': {'type': 'literal', 'expected': ['allow', 'forbid', 'ignore']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'dataclass': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['dataclass']}, 'required': True}, 'cls': {'schema': {'type': 'any'}, 'required': True}, 'generic_origin': {'schema': {'type': 'any'}, 'required': False}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'fields': {'schema': {'type': 'list', 'items_schema': {'type': 'str'}}, 'required': True}, 'cls_name': {'schema': {'type': 'str'}, 'required': False}, 'post_init': {'schema': {'type': 'bool'}, 'required': False}, 'revalidate_instances': {'schema': {'type': 'literal', 'expected': ['always', 'never', 'subclass-instances']}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'frozen': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}, 'slots': {'schema': {'type': 'bool'}, 'required': False}, 'config': {'schema': {'type': 'typed-dict', 'fields': {'title': {'schema': {'type': 'str'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'extra_fields_behavior': {'schema': {'type': 'literal', 'expected': ['allow', 'forbid', 'ignore']}, 'required': False}, 'typed_dict_total': {'schema': {'type': 'bool'}, 'required': False}, 'from_attributes': {'schema': {'type': 'bool'}, 'required': False}, 'loc_by_alias': {'schema': {'type': 'bool'}, 'required': False}, 'revalidate_instances': {'schema': {'type': 'literal', 'expected': ['always', 'never', 'subclass-instances']}, 'required': False}, 'validate_default': {'schema': {'type': 'bool'}, 'required': False}, 'str_max_length': {'schema': {'type': 'int'}, 'required': False}, 'str_min_length': {'schema': {'type': 'int'}, 'required': False}, 'str_strip_whitespace': {'schema': {'type': 'bool'}, 'required': False}, 'str_to_lower': {'schema': {'type': 'bool'}, 'required': False}, 'str_to_upper': {'schema': {'type': 'bool'}, 'required': False}, 'allow_inf_nan': {'schema': {'type': 'bool'}, 'required': False}, 'ser_json_timedelta': {'schema': {'type': 'literal', 'expected': ['iso8601', 'float']}, 'required': False}, 'ser_json_bytes': {'schema': {'type': 'literal', 'expected': ['utf8', 'base64', 'hex']}, 'required': False}, 'ser_json_inf_nan': {'schema': {'type': 'literal', 'expected': ['null', 'constants', 'strings']}, 'required': False}, 'val_json_bytes': {'schema': {'type': 'literal', 'expected': ['utf8', 'base64', 'hex']}, 'required': False}, 'hide_input_in_errors': {'schema': {'type': 'bool'}, 'required': False}, 'validation_error_cause': {'schema': {'type': 'bool'}, 'required': False}, 'coerce_numbers_to_str': {'schema': {'type': 'bool'}, 'required': False}, 'regex_engine': {'schema': {'type': 'literal', 'expected': ['rust-regex', 'python-re']}, 'required': False}, 'cache_strings': {'schema': {'type': 'union', 'choices': [{'type': 'bool'}, {'type': 'literal', 'expected': ['all', 'keys', 'none']}]}, 'required': False}, 'validate_by_alias': {'schema': {'type': 'bool'}, 'required': False}, 'validate_by_name': {'schema': {'type': 'bool'}, 'required': False}, 'serialize_by_alias': {'schema': {'type': 'bool'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'arguments': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['arguments']}, 'required': True}, 'arguments_schema': {'schema': {'type': 'list', 'items_schema': {'type': 'typed-dict', 'fields': {'name': {'schema': {'type': 'str'}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'mode': {'schema': {'type': 'literal', 'expected': ['positional_only', 'positional_or_keyword', 'keyword_only']}, 'required': False}, 'alias': {'schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}, {'type': 'list', 'items_schema': {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}}]}, 'required': False}}, 'extra_behavior': 'forbid'}}, 'required': True}, 'validate_by_name': {'schema': {'type': 'bool'}, 'required': False}, 'validate_by_alias': {'schema': {'type': 'bool'}, 'required': False}, 'var_args_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'var_kwargs_mode': {'schema': {'type': 'literal', 'expected': ['uniform', 'unpacked-typed-dict']}, 'required': False}, 'var_kwargs_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'arguments-v3': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['arguments-v3']}, 'required': True}, 'arguments_schema': {'schema': {'type': 'list', 'items_schema': {'type': 'typed-dict', 'fields': {'name': {'schema': {'type': 'str'}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'mode': {'schema': {'type': 'literal', 'expected': ['positional_only', 'positional_or_keyword', 'keyword_only', 'var_args', 'var_kwargs_uniform', 'var_kwargs_unpacked_typed_dict']}, 'required': False}, 'alias': {'schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}, {'type': 'list', 'items_schema': {'type': 'list', 'items_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}]}}}]}, 'required': False}}, 'extra_behavior': 'forbid'}}, 'required': True}, 'validate_by_name': {'schema': {'type': 'bool'}, 'required': False}, 'validate_by_alias': {'schema': {'type': 'bool'}, 'required': False}, 'extra_behavior': {'schema': {'type': 'literal', 'expected': ['forbid', 'ignore']}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'call': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['call']}, 'required': True}, 'arguments_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'function': {'schema': {'type': 'callable'}, 'required': True}, 'function_name': {'schema': {'type': 'str'}, 'required': False}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'custom-error': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['custom-error']}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'custom_error_type': {'schema': {'type': 'str'}, 'required': True}, 'custom_error_message': {'schema': {'type': 'str'}, 'required': False}, 'custom_error_context': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'union', 'choices': [{'type': 'str'}, {'type': 'int'}, {'type': 'float'}]}}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'json': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['json']}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['url']}, 'required': True}, 'max_length': {'schema': {'type': 'int'}, 'required': False}, 'allowed_schemes': {'schema': {'type': 'list', 'items_schema': {'type': 'str'}}, 'required': False}, 'host_required': {'schema': {'type': 'bool'}, 'required': False}, 'default_host': {'schema': {'type': 'str'}, 'required': False}, 'default_port': {'schema': {'type': 'int'}, 'required': False}, 'default_path': {'schema': {'type': 'str'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'multi-host-url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['multi-host-url']}, 'required': True}, 'max_length': {'schema': {'type': 'int'}, 'required': False}, 'allowed_schemes': {'schema': {'type': 'list', 'items_schema': {'type': 'str'}}, 'required': False}, 'host_required': {'schema': {'type': 'bool'}, 'required': False}, 'default_host': {'schema': {'type': 'str'}, 'required': False}, 'default_port': {'schema': {'type': 'int'}, 'required': False}, 'default_path': {'schema': {'type': 'str'}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'definitions': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['definitions']}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}, 'definitions': {'schema': {'type': 'list', 'items_schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}}, 'required': True}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'definition-ref': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['definition-ref']}, 'required': True}, 'schema_ref': {'schema': {'type': 'str'}, 'required': True}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'uuid': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['uuid']}, 'required': True}, 'version': {'schema': {'type': 'literal', 'expected': [1, 3, 4, 5, 7]}, 'required': False}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}, 'complex': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['complex']}, 'required': True}, 'strict': {'schema': {'type': 'bool'}, 'required': False}, 'ref': {'schema': {'type': 'str'}, 'required': False}, 'metadata': {'schema': {'type': 'dict', 'keys_schema': {'type': 'str'}, 'values_schema': {'type': 'any'}}, 'required': False}, 'serialization': {'schema': {'type': 'definition-ref', 'schema_ref': 'ser-schema'}, 'required': False}}, 'extra_behavior': 'forbid'}}, 'discriminator': 'type', 'ref': 'root-schema'}, {'type': 'tagged-union', 'discriminator': 'type', 'choices': {'none': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'int': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bool': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'float': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'str': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bytes': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'bytearray': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'list': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'tuple': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'set': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'frozenset': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'generator': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'dict': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'datetime': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'date': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'time': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'timedelta': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'multi-host-url': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'json': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'uuid': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'any': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['none', 'int', 'bool', 'float', 'str', 'bytes', 'bytearray', 'list', 'tuple', 'set', 'frozenset', 'generator', 'dict', 'datetime', 'date', 'time', 'timedelta', 'url', 'multi-host-url', 'json', 'uuid', 'any']}, 'required': True}}, 'extra_behavior': 'forbid'}, 'function-plain': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-plain']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}]}, 'required': True}, 'is_field_serializer': {'schema': {'type': 'bool'}, 'required': False}, 'info_arg': {'schema': {'type': 'bool'}, 'required': False}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'function-wrap': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['function-wrap']}, 'required': True}, 'function': {'schema': {'type': 'union', 'choices': [{'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}, {'type': 'callable'}]}, 'required': True}, 'is_field_serializer': {'schema': {'type': 'bool'}, 'required': False}, 'info_arg': {'schema': {'type': 'bool'}, 'required': False}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'return_schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': False}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'format': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['format']}, 'required': True}, 'formatting_string': {'schema': {'type': 'str'}, 'required': True}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'to-string': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['to-string']}, 'required': True}, 'when_used': {'schema': {'type': 'literal', 'expected': ['always', 'unless-none', 'json', 'json-unless-none']}, 'required': False}}, 'extra_behavior': 'forbid'}, 'model': {'type': 'typed-dict', 'fields': {'type': {'schema': {'type': 'literal', 'expected': ['model']}, 'required': True}, 'cls': {'schema': {'type': 'any'}, 'required': True}, 'schema': {'schema': {'type': 'definition-ref', 'schema_ref': 'root-schema'}, 'required': True}}, 'extra_behavior': 'forbid'}}, 'ref': 'ser-schema'}]}


--- tests/mypy/README.md ---
# Mypy plugin type checking suite

> [!WARNING]
> The test suite is subject to changes. It is currently not user friendly as the output and configuration
> files are separated from the source modules, making it hard to navigate. In the future, we may switch
> to using the [`pytest-mypy-plugins`][https://github.com/TypedDjango/pytest-mypy-plugins] library, which
> provides more flexibility when it comes to merging different mypy configurations.

The `test_mypy_results` test defined in [`test_mypy.py`](./test_mypy.py) runs Mypy on the files
defined in [`modules/`](./modules/), using the configuration files from [`configs/`](./configs/).

The Mypy output is merged with the source file and saved in the [`outputs/`](./outputs/) folder.

For instance, with the following file:

```python
from pydantic import BaseModel


class Model(BaseModel):
    a: int


model = Model(a=1, b=2)
```

The output will look like:

```python
from pydantic import BaseModel


class Model(BaseModel):
    a: int


model = Model(a=1, b=2)
# MYPY: error: Unexpected keyword argument "b" for "Model"  [call-arg]
```

## Adding a new test

1. Define a new file in the [`modules/`](./modules/) folder:

    ```python
    # modules/new_test.py

    class Model(BaseModel):
        a: int


    model = Model(a=1, b=2)
    ```

2. Add the new file in the defined `cases` in [`test_mypy.py`](./test_mypy.py), together
   with a configuration file:

    ```python
    cases: list[ParameterSet | tuple[str, str]] = [
        ...,
        # One-off cases
        *[
                ('mypy-plugin.ini', 'custom_constructor.py'),
                ('mypy-plugin.ini', 'config_conditional_extra.py'),
                ...,
                ('mypy-plugin.ini', 'new_test.py'),  # <-- new test added.
            ]
    ```

3. Run `make test-mypy-update`. It should create a new output with your new file.

4. Make sure the output contains the expected Mypy error message/code.

> [!NOTE]
> You can also edit existing module files. In that case, only step 3 and 4 are relevant.


## Links discovered
- [`test_mypy.py`](https://github.com/pydantic/pydantic/blob/main/tests/mypy/test_mypy.py)
- [`modules/`](https://github.com/pydantic/pydantic/blob/main/tests/mypy/modules.md)
- [`configs/`](https://github.com/pydantic/pydantic/blob/main/tests/mypy/configs.md)
- [`outputs/`](https://github.com/pydantic/pydantic/blob/main/tests/mypy/outputs.md)

--- tests/typechecking/README.md ---
# Type checking test suite

This test suite is meant to assert the correct behavior of the type hints we use in the Pydantic code.
In CI, we run both Mypy and Pyright on these files, using the [`pyproject.toml`](./pyproject.toml)
configuration file.

Note that these tests do not relate to the Mypy plugin, which is tested under the [`mypy/`](../mypy/) folder.

## Assertions

Use [`assert_type`](https://docs.python.org/3/library/typing.html#typing.assert_type) to make assertions:

```python
from typing_extensions import assert_type

from pydantic import TypeAdapter

ta1 = TypeAdapter(int)
assert_type(ta1, TypeAdapter[int])
```

To assert on invalid cases, add a `type: ignore` (for Mypy, must go first) and/or a  `pyright: ignore` (for Pyright) comment:

```python
from pydantic import BaseModel


class Model(BaseModel):
    a: int


Model()  # type: ignore[call-arg]  # pyright: ignore[reportCallIssue]
```


## Links discovered
- [`pyproject.toml`](https://github.com/pydantic/pydantic/blob/main/tests/typechecking/pyproject.toml)
- [`mypy/`](https://github.com/pydantic/pydantic/blob/main/tests/mypy.md)
- [`assert_type`](https://docs.python.org/3/library/typing.html#typing.assert_type)

--- tests/conftest.py ---
from __future__ import annotations

import importlib.util
import inspect
import os
import re
import secrets
import subprocess
import sys
import textwrap
from dataclasses import dataclass
from pathlib import Path
from types import FunctionType, ModuleType
from typing import Any, Callable

import pytest
from _pytest.assertion.rewrite import AssertionRewritingHook
from _pytest.nodes import Item
from jsonschema import Draft202012Validator, SchemaError

from pydantic._internal._generate_schema import GenerateSchema
from pydantic.json_schema import GenerateJsonSchema


def pytest_addoption(parser: pytest.Parser):
    parser.addoption('--test-mypy', action='store_true', help='run mypy tests')
    parser.addoption('--update-mypy', action='store_true', help='update mypy tests')


def _extract_source_code_from_function(function: FunctionType):
    if function.__code__.co_argcount:
        raise RuntimeError(f'function {function.__qualname__} cannot have any arguments')

    code_lines = ''
    body_started = False
    for line in textwrap.dedent(inspect.getsource(function)).split('\n'):
        if line.startswith('def '):
            body_started = True
            continue
        elif body_started:
            code_lines += f'{line}\n'

    return textwrap.dedent(code_lines)


def _create_module_file(code: str, tmp_path: Path, name: str) -> tuple[str, str]:
    # Max path length in Windows is 260. Leaving some buffer here
    max_name_len = 240 - len(str(tmp_path))
    # Windows does not allow these characters in paths. Linux bans slashes only.
    sanitized_name = re.sub('[' + re.escape('<>:"/\\|?*') + ']', '-', name)[:max_name_len]
    name = f'{sanitized_name}_{secrets.token_hex(5)}'
    path = tmp_path / f'{name}.py'
    path.write_text(code)
    return name, str(path)


@pytest.fixture(scope='session', autouse=True)
def disable_error_urls():
    # Don't add URLs during docs tests when printing
    # Otherwise we'll get version numbers in the URLs that will update frequently
    os.environ['PYDANTIC_ERRORS_INCLUDE_URL'] = 'false'


@pytest.fixture
def create_module(
    tmp_path: Path, request: pytest.FixtureRequest
) -> Callable[[FunctionType | str, bool, str | None], ModuleType]:
    def run(
        source_code_or_function: FunctionType | str,
        rewrite_assertions: bool = True,
        module_name_prefix: str | None = None,
    ) -> ModuleType:
        """
        Create module object, execute it and return
        Can be used as a decorator of the function from the source code of which the module will be constructed

        :param source_code_or_function string or function with body as a source code for created module
        :param rewrite_assertions: whether to rewrite assertions in module or not
        :param module_name_prefix: string prefix to use in the name of the module, does not affect the name of the file.

        """
        if isinstance(source_code_or_function, FunctionType):
            source_code = _extract_source_code_from_function(source_code_or_function)
        else:
            source_code = source_code_or_function

        module_name, filename = _create_module_file(source_code, tmp_path, request.node.name)
        if module_name_prefix:
            module_name = module_name_prefix + module_name

        if rewrite_assertions:
            loader = AssertionRewritingHook(config=request.config)
            loader.mark_rewrite(module_name)
        else:
            loader = None

        spec = importlib.util.spec_from_file_location(module_name, filename, loader=loader)
        sys.modules[module_name] = module = importlib.util.module_from_spec(spec)  # pyright: ignore[reportArgumentType]
        spec.loader.exec_module(module)  # pyright: ignore[reportOptionalMemberAccess]
        return module

    return run


@pytest.fixture
def subprocess_run_code(tmp_path: Path):
    def run_code(source_code_or_function) -> str:
        if isinstance(source_code_or_function, FunctionType):
            source_code = _extract_source_code_from_function(source_code_or_function)
        else:
            source_code = source_code_or_function

        py_file = tmp_path / 'test.py'
        py_file.write_text(source_code)

        return subprocess.check_output([sys.executable, str(py_file)], cwd=tmp_path, encoding='utf8')

    return run_code


@dataclass
class Err:
    message: str
    errors: Any | None = None

    def __repr__(self):
        if self.errors:
            return f'Err({self.message!r}, errors={self.errors!r})'
        else:
            return f'Err({self.message!r})'

    def message_escaped(self):
        return re.escape(self.message)


@dataclass
class CallCounter:
    count: int = 0

    def reset(self) -> None:
        self.count = 0


@pytest.fixture
def generate_schema_calls(monkeypatch: pytest.MonkeyPatch) -> CallCounter:
    orig_generate_schema = GenerateSchema.generate_schema
    counter = CallCounter()
    depth = 0  # generate_schema can be called recursively

    def generate_schema_call_counter(*args: Any, **kwargs: Any) -> Any:
        nonlocal depth
        counter.count += 1 if depth == 0 else 0
        depth += 1
        try:
            return orig_generate_schema(*args, **kwargs)
        finally:
            depth -= 1

    monkeypatch.setattr(GenerateSchema, 'generate_schema', generate_schema_call_counter)
    return counter


@pytest.fixture(scope='function', autouse=True)
def validate_json_schemas(monkeypatch: pytest.MonkeyPatch, request: pytest.FixtureRequest) -> None:
    orig_generate = GenerateJsonSchema.generate

    def generate(*args: Any, **kwargs: Any) -> Any:
        json_schema = orig_generate(*args, **kwargs)
        if not request.node.get_closest_marker('skip_json_schema_validation'):
            try:
                Draft202012Validator.check_schema(json_schema)
            except SchemaError:
                pytest.fail(
                    'Failed to validate the JSON Schema against the Draft 2020-12 spec. '
                    'If this is expected, you can mark the test function with the `skip_json_schema_validation` '
                    'marker. Note that this validation only takes place during tests, and is not active at runtime.'
                )

        return json_schema

    monkeypatch.setattr(GenerateJsonSchema, 'generate', generate)


_thread_unsafe_fixtures = (
    'generate_schema_calls',  # Monkeypatches Pydantic code
    'benchmark',  # Fixture can't be reused
    'tmp_path',  # Duplicate paths
    'tmpdir',  # Duplicate dirs
    'copy_method',  # Uses `pytest.warns()`
    'reset_plugins',  # Monkeypatching
)


# Note: it is important to add the marker in the `pytest_itemcollected` hook.
# `pytest-run-parallel` also implements this hook (and ours is running before),
# and this wouldn't work if we were to add the "thread_unsafe" marker in say
# `pytest_collection_modifyitems` (which is the last collection hook to be run).
def pytest_itemcollected(item: Item) -> None:
    """Mark tests as thread unsafe if they make use of fixtures that doesn't play well across threads."""
    fixtures: tuple[str, ...] = getattr(item, 'fixturenames', ())
    if any(fixture in fixtures for fixture in _thread_unsafe_fixtures):
        item.add_marker('thread_unsafe')


--- tests/__init__.py ---


--- tests/test_abc.py ---
import abc
import sys

import pytest

from pydantic import BaseModel


def test_model_subclassing_abstract_base_classes():
    class Model(BaseModel, abc.ABC):
        some_field: str


@pytest.mark.skipif(sys.version_info < (3, 12), reason='error value different on older versions')
def test_model_subclassing_abstract_base_classes_without_implementation_raises_exception():
    class Model(BaseModel, abc.ABC):
        some_field: str

        @abc.abstractmethod
        def my_abstract_method(self):
            pass

        @classmethod
        @abc.abstractmethod
        def my_abstract_classmethod(cls):
            pass

        @staticmethod
        @abc.abstractmethod
        def my_abstract_staticmethod():
            pass

        @property
        @abc.abstractmethod
        def my_abstract_property(self):
            pass

        @my_abstract_property.setter
        @abc.abstractmethod
        def my_abstract_property(self, val):
            pass

    with pytest.raises(TypeError) as excinfo:
        Model(some_field='some_value')
    assert str(excinfo.value) == (
        "Can't instantiate abstract class Model without an implementation for abstract methods "
        "'my_abstract_classmethod', 'my_abstract_method', 'my_abstract_property', 'my_abstract_staticmethod'"
    )


def test_register_warning_on_abstract_base_classes_subclassing_model() -> None:
    class Model(BaseModel, abc.ABC):
        some_field: str

    with pytest.warns(UserWarning):

        @Model.register
        class RegisteredModel:
            pass


--- tests/test_aliases.py ---
from contextlib import AbstractContextManager
from contextlib import nullcontext as does_not_raise
from inspect import signature
from typing import Any, Optional, Union

import pytest
from dirty_equals import IsStr
from pydantic_core import PydanticUndefined

from pydantic import (
    AliasChoices,
    AliasGenerator,
    AliasPath,
    BaseModel,
    ConfigDict,
    Field,
    PydanticUserError,
    ValidationError,
    computed_field,
)


def test_alias_generator():
    def to_camel(string: str):
        return ''.join(x.capitalize() for x in string.split('_'))

    class MyModel(BaseModel):
        model_config = ConfigDict(alias_generator=to_camel)
        a: list[str] = None
        foo_bar: str

    data = {'A': ['foo', 'bar'], 'FooBar': 'foobar'}
    v = MyModel(**data)
    assert v.a == ['foo', 'bar']
    assert v.foo_bar == 'foobar'
    assert v.model_dump(by_alias=True) == data


def test_alias_generator_defer_build() -> None:
    def to_camel(string: str):
        return ''.join(x.capitalize() for x in string.split('_'))

    class Model(BaseModel):
        model_config = ConfigDict(alias_generator=to_camel, defer_build=True)
        foo_bar: str

    assert Model.model_fields['foo_bar'].alias == 'FooBar'


def test_alias_generator_wrong_type_error():
    def return_bytes(string):
        return b'not a string'

    with pytest.raises(TypeError) as e:

        class MyModel(BaseModel):
            model_config = ConfigDict(alias_generator=return_bytes)
            bar: Any

    assert str(e.value) == IsStr(regex="alias_generator <function .*> must return str, not <class 'bytes'>")


def test_basic_alias():
    class Model(BaseModel):
        a: str = Field('foobar', alias='_a')

    assert Model().a == 'foobar'
    assert Model(_a='different').a == 'different'
    assert repr(Model.model_fields['a']) == (
        "FieldInfo(annotation=str, required=False, default='foobar', alias='_a', alias_priority=2)"
    )


def test_field_info_repr_with_aliases():
    class Model(BaseModel):
        a: str = Field('foobar', alias='_a', validation_alias='a_val', serialization_alias='a_ser')

    assert repr(Model.model_fields['a']) == (
        "FieldInfo(annotation=str, required=False, default='foobar', alias='_a', "
        "alias_priority=2, validation_alias='a_val', serialization_alias='a_ser')"
    )


def test_alias_error():
    class Model(BaseModel):
        a: int = Field(123, alias='_a')

    assert Model(_a='123').a == 123

    with pytest.raises(ValidationError) as exc_info:
        Model(_a='foo')
    assert exc_info.value.errors(include_url=False) == [
        {
            'input': 'foo',
            'loc': ('_a',),
            'msg': 'Input should be a valid integer, unable to parse string as an integer',
            'type': 'int_parsing',
        }
    ]


def test_alias_error_loc_by_alias():
    class Model(BaseModel):
        model_config = dict(loc_by_alias=False)
        a: int = Field(123, alias='_a')

    assert Model(_a='123').a == 123

    with pytest.raises(ValidationError) as exc_info:
        Model(_a='foo')
    assert exc_info.value.errors(include_url=False) == [
        {
            'input': 'foo',
            'loc': ('a',),
            'msg': 'Input should be a valid integer, unable to parse string as an integer',
            'type': 'int_parsing',
        }
    ]


def test_annotation_config():
    class Model(BaseModel):
        b: float = Field(alias='foobar')
        a: int = 10
        _c: str

    assert list(Model.model_fields.keys()) == ['b', 'a']
    assert [f.alias for f in Model.model_fields.values()] == ['foobar', None]
    assert Model(foobar='123').b == 123.0


def test_pop_by_field_name():
    class Model(BaseModel):
        model_config = ConfigDict(extra='forbid', validate_by_name=True)
        last_updated_by: Optional[str] = Field(None, alias='lastUpdatedBy')

    assert Model(lastUpdatedBy='foo').model_dump() == {'last_updated_by': 'foo'}
    assert Model(last_updated_by='foo').model_dump() == {'last_updated_by': 'foo'}
    with pytest.raises(ValidationError) as exc_info:
        Model(lastUpdatedBy='foo', last_updated_by='bar')
    assert exc_info.value.errors(include_url=False) == [
        {
            'input': 'bar',
            'loc': ('last_updated_by',),
            'msg': 'Extra inputs are not permitted',
            'type': 'extra_forbidden',
        }
    ]


def test_alias_override_behavior():
    class Parent(BaseModel):
        # Use `gt` to demonstrate that using `Field` to override an alias does not preserve other attributes
        x: int = Field(alias='x1', gt=0)

    class Child(Parent):
        x: int = Field(alias='x2')
        y: int = Field(alias='y2')

    assert Parent.model_fields['x'].alias == 'x1'
    assert Child.model_fields['x'].alias == 'x2'
    assert Child.model_fields['y'].alias == 'y2'

    Parent(x1=1)
    with pytest.raises(ValidationError) as exc_info:
        Parent(x1=-1)
    assert exc_info.value.errors(include_url=False) == [
        {'ctx': {'gt': 0}, 'input': -1, 'loc': ('x1',), 'msg': 'Input should be greater than 0', 'type': 'greater_than'}
    ]

    Child(x2=1, y2=2)

    # Check the gt=0 is not preserved from Parent
    Child(x2=-1, y2=2)

    # Check the alias from Parent cannot be used
    with pytest.raises(ValidationError) as exc_info:
        Child(x1=1, y2=2)
    assert exc_info.value.errors(include_url=False) == [
        {'input': {'x1': 1, 'y2': 2}, 'loc': ('x2',), 'msg': 'Field required', 'type': 'missing'}
    ]

    # Check the type hint from Parent _is_ preserved
    with pytest.raises(ValidationError) as exc_info:
        Child(x2='a', y2=2)
    assert exc_info.value.errors(include_url=False) == [
        {
            'input': 'a',
            'loc': ('x2',),
            'msg': 'Input should be a valid integer, unable to parse string as an integer',
            'type': 'int_parsing',
        }
    ]


def test_alias_generator_parent():
    class Parent(BaseModel):
        model_config = ConfigDict(validate_by_name=True, alias_generator=lambda f_name: f_name + '1')
        x: int

    class Child(Parent):
        model_config = ConfigDict(alias_generator=lambda f_name: f_name + '2')
        y: int

    assert Child.model_fields['y'].alias == 'y2'
    assert Child.model_fields['x'].alias == 'x2'


upper_alias_generator = [
    pytest.param(
        lambda x: x.upper(),
        id='basic_callable',
    ),
    pytest.param(
        AliasGenerator(lambda x: x.upper()),
        id='alias_generator',
    ),
]


@pytest.mark.parametrize('alias_generator', upper_alias_generator)
def test_alias_generator_on_parent(alias_generator):
    class Parent(BaseModel):
        model_config = ConfigDict(alias_generator=alias_generator)
        x: bool = Field(alias='a_b_c')
        y: str

    class Child(Parent):
        y: str
        z: str

    assert Parent.model_fields['x'].alias == 'a_b_c'
    assert Parent.model_fields['y'].alias == 'Y'
    assert Child.model_fields['x'].alias == 'a_b_c'
    assert Child.model_fields['y'].alias == 'Y'
    assert Child.model_fields['z'].alias == 'Z'


@pytest.mark.parametrize('alias_generator', upper_alias_generator)
def test_alias_generator_on_child(alias_generator):
    class Parent(BaseModel):
        x: bool = Field(alias='abc')
        y: str

    class Child(Parent):
        model_config = ConfigDict(alias_generator=alias_generator)

        y: str
        z: str

    assert [f.alias for f in Parent.model_fields.values()] == ['abc', None]
    assert [f.alias for f in Child.model_fields.values()] == ['abc', 'Y', 'Z']


@pytest.mark.parametrize('alias_generator', upper_alias_generator)
def test_alias_generator_used_by_default(alias_generator):
    class Model(BaseModel):
        model_config = ConfigDict(alias_generator=alias_generator)

        a: str
        b: str = Field(alias='b_alias')
        c: str = Field(validation_alias='c_val_alias')
        d: str = Field(serialization_alias='d_ser_alias')
        e: str = Field(alias='e_alias', validation_alias='e_val_alias')
        f: str = Field(alias='f_alias', serialization_alias='f_ser_alias')
        g: str = Field(alias='g_alias', validation_alias='g_val_alias', serialization_alias='g_ser_alias')

    assert {
        name: {k: getattr(f, k) for k in ('alias', 'validation_alias', 'serialization_alias')}
        for name, f in Model.model_fields.items()
    } == {
        # Validation/serialization aliases should be:
        # 1. The specific alias, if specified, or
        # 2. The alias, if specified, or
        # 3. The generated alias (i.e. the field name in upper case)
        'a': {
            'alias': 'A',
            'validation_alias': 'A',
            'serialization_alias': 'A',
        },
        'b': {
            'alias': 'b_alias',
            'validation_alias': 'b_alias',
            'serialization_alias': 'b_alias',
        },
        'c': {
            'alias': 'C',
            'validation_alias': 'c_val_alias',
            'serialization_alias': 'C',
        },
        'd': {
            'alias': 'D',
            'validation_alias': 'D',
            'serialization_alias': 'd_ser_alias',
        },
        'e': {
            'alias': 'e_alias',
            'validation_alias': 'e_val_alias',
            'serialization_alias': 'e_alias',
        },
        'f': {
            'alias': 'f_alias',
            'validation_alias': 'f_alias',
            'serialization_alias': 'f_ser_alias',
        },
        'g': {
            'alias': 'g_alias',
            'validation_alias': 'g_val_alias',
            'serialization_alias': 'g_ser_alias',
        },
    }


@pytest.mark.parametrize('alias_generator', upper_alias_generator)
def test_low_priority_alias(alias_generator):
    class Parent(BaseModel):
        w: bool = Field(alias='w_', validation_alias='w_val_alias', serialization_alias='w_ser_alias')
        x: bool = Field(
            alias='abc', alias_priority=1, validation_alias='x_val_alias', serialization_alias='x_ser_alias'
        )
        y: str

    class Child(Parent):
        model_config = ConfigDict(alias_generator=alias_generator)

        y: str
        z: str

    assert [f.alias for f in Parent.model_fields.values()] == ['w_', 'abc', None]
    assert [f.validation_alias for f in Parent.model_fields.values()] == ['w_val_alias', 'x_val_alias', None]
    assert [f.serialization_alias for f in Parent.model_fields.values()] == ['w_ser_alias', 'x_ser_alias', None]
    assert [f.alias for f in Child.model_fields.values()] == ['w_', 'X', 'Y', 'Z']
    assert [f.validation_alias for f in Child.model_fields.values()] == ['w_val_alias', 'X', 'Y', 'Z']
    assert [f.serialization_alias for f in Child.model_fields.values()] == ['w_ser_alias', 'X', 'Y', 'Z']


@pytest.mark.parametrize(
    'cls_params, field_params, validation_key, serialization_key',
    [
        pytest.param(
            {},
            {'alias': 'x1', 'validation_alias': 'x2'},
            'x2',
            'x1',
            id='alias-validation_alias',
        ),
        pytest.param(
            {'alias_generator': str.upper},
            {'alias': 'x'},
            'x',
            'x',
            id='alias_generator-alias',
        ),
        pytest.param(
            {'alias_generator': str.upper},
            {'alias': 'x1', 'validation_alias': 'x2'},
            'x2',
            'x1',
            id='alias_generator-alias-validation_alias',
        ),
        pytest.param(
            {'alias_generator': str.upper},
            {'alias': 'x1', 'serialization_alias': 'x2'},
            'x1',
            'x2',
            id='alias_generator-alias-serialization_alias',
        ),
        pytest.param(
            {'alias_generator': str.upper},
            {'alias': 'x1', 'validation_alias': 'x2', 'serialization_alias': 'x3'},
            'x2',
            'x3',
            id='alias_generator-alias-validation_alias-serialization_alias',
        ),
    ],
)
def test_aliases_priority(cls_params, field_params, validation_key, serialization_key):
    class Model(BaseModel, **cls_params):
        x: int = Field(**field_params)

    model = Model(**{validation_key: 1})
    assert model.x == 1
    assert model.model_dump(by_alias=True).get(serialization_key, None) is not None


def test_empty_string_alias():
    class Model(BaseModel):
        empty_string_key: int = Field(alias='')

    data = {'': 123}
    m = Model(**data)
    assert m.empty_string_key == 123
    assert m.model_dump(by_alias=True) == data


@pytest.mark.parametrize(
    'use_construct, validate_by_name_config, arg_name, expectation',
    [
        [False, True, 'bar', does_not_raise()],
        [False, True, 'bar_', does_not_raise()],
        [False, False, 'bar', does_not_raise()],
        pytest.param(
            False,
            False,
            'bar_',
            pytest.raises(ValueError),
            marks=pytest.mark.thread_unsafe(reason='`pytest.raises()` is thread unsafe'),
        ),
        [True, True, 'bar', does_not_raise()],
        [True, True, 'bar_', does_not_raise()],
        [True, False, 'bar', does_not_raise()],
        [True, False, 'bar_', does_not_raise()],
    ],
)
def test_validate_by_name_config(
    use_construct: bool,
    validate_by_name_config: bool,
    arg_name: str,
    expectation: AbstractContextManager,
):
    expected_value: int = 7

    class Foo(BaseModel):
        model_config = ConfigDict(validate_by_name=validate_by_name_config)
        bar_: int = Field(alias='bar')

    with expectation:
        if use_construct:
            f = Foo.model_construct(**{arg_name: expected_value})
        else:
            f = Foo(**{arg_name: expected_value})

        assert f.bar_ == expected_value


def test_validation_alias():
    class Model(BaseModel):
        x: str = Field(validation_alias='foo')

    data = {'foo': 'bar'}
    m = Model(**data)
    assert m.x == 'bar'

    with pytest.raises(ValidationError) as exc_info:
        Model(x='bar')
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'missing',
            'loc': ('foo',),
            'msg': 'Field required',
            'input': {'x': 'bar'},
        }
    ]


def test_validation_alias_with_alias():
    class Model(BaseModel):
        x: str = Field(alias='x_alias', validation_alias='foo')

    data = {'foo': 'bar'}
    m = Model(**data)
    assert m.x == 'bar'
    sig = signature(Model)
    assert 'x_alias' in sig.parameters

    with pytest.raises(ValidationError) as exc_info:
        Model(x='bar')
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'missing',
            'loc': ('foo',),
            'msg': 'Field required',
            'input': {'x': 'bar'},
        }
    ]


def test_validation_alias_from_str_alias():
    class Model(BaseModel):
        x: str = Field(alias='foo')

    data = {'foo': 'bar'}
    m = Model(**data)
    assert m.x == 'bar'
    sig = signature(Model)
    assert 'foo' in sig.parameters

    with pytest.raises(ValidationError) as exc_info:
        Model(x='bar')
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'missing',
            'loc': ('foo',),
            'msg': 'Field required',
            'input': {'x': 'bar'},
        }
    ]


def test_validation_alias_from_list_alias():
    class Model(BaseModel):
        x: str = Field(alias=['foo', 'bar'])

    data = {'foo': {'bar': 'test'}}
    m = Model(**data)
    assert m.x == 'test'
    sig = signature(Model)
    assert 'x' in sig.parameters

    class Model(BaseModel):
        x: str = Field(alias=['foo', 1])

    data = {'foo': ['bar0', 'bar1']}
    m = Model(**data)
    assert m.x == 'bar1'
    sig = signature(Model)
    assert 'x' in sig.parameters


def test_serialization_alias():
    class Model(BaseModel):
        x: str = Field(serialization_alias='foo')

    m = Model(x='bar')
    assert m.x == 'bar'
    assert m.model_dump() == {'x': 'bar'}
    assert m.model_dump(by_alias=True) == {'foo': 'bar'}


def test_serialization_alias_with_alias():
    class Model(BaseModel):
        x: str = Field(alias='x_alias', serialization_alias='foo')

    data = {'x_alias': 'bar'}
    m = Model(**data)
    assert m.x == 'bar'
    assert m.model_dump() == {'x': 'bar'}
    assert m.model_dump(by_alias=True) == {'foo': 'bar'}
    sig = signature(Model)
    assert 'x_alias' in sig.parameters


def test_serialization_alias_from_alias():
    class Model(BaseModel):
        x: str = Field(alias='foo')

    data = {'foo': 'bar'}
    m = Model(**data)
    assert m.x == 'bar'
    assert m.model_dump() == {'x': 'bar'}
    assert m.model_dump(by_alias=True) == {'foo': 'bar'}
    sig = signature(Model)
    assert 'foo' in sig.parameters


@pytest.mark.parametrize(
    'field,expected',
    [
        pytest.param(
            Field(alias='x_alias', validation_alias='x_val_alias', serialization_alias='x_ser_alias'),
            {
                'properties': {'x_val_alias': {'title': 'X Val Alias', 'type': 'string'}},
                'required': ['x_val_alias'],
            },
            id='single_alias',
        ),
        pytest.param(
            Field(validation_alias=AliasChoices('y_alias', 'another_alias')),
            {
                'properties': {'y_alias': {'title': 'Y Alias', 'type': 'string'}},
                'required': ['y_alias'],
            },
            id='multiple_aliases',
        ),
        pytest.param(
            Field(validation_alias=AliasChoices(AliasPath('z_alias', 'even_another_alias'), 'and_another')),
            {
                'properties': {'and_another': {'title': 'And Another', 'type': 'string'}},
                'required': ['and_another'],
            },
            id='multiple_aliases_with_path',
        ),
    ],
)
def test_aliases_json_schema(field, expected):
    class Model(BaseModel):
        x: str = field

    assert Model.model_json_schema() == {'title': 'Model', 'type': 'object', **expected}


@pytest.mark.parametrize(
    'value',
    [
        'a',
        AliasPath('a', 'b', 1),
        AliasChoices('a', 'b'),
        AliasChoices('a', AliasPath('b', 1)),
    ],
)
def test_validation_alias_path(value):
    class Model(BaseModel):
        x: str = Field(validation_alias=value)

    assert Model.model_fields['x'].validation_alias == value


def test_search_dict_for_alias_path():
    ap = AliasPath('a', 1)
    assert ap.search_dict_for_path({'a': ['hello', 'world']}) == 'world'
    assert ap.search_dict_for_path({'a': 'hello'}) is PydanticUndefined


def test_validation_alias_invalid_value_type():
    m = 'Invalid `validation_alias` type. it should be `str`, `AliasChoices`, or `AliasPath`'
    with pytest.raises(TypeError, match=m):

        class Model(BaseModel):
            x: str = Field(validation_alias=123)


def test_validation_alias_parse_data():
    class Model(BaseModel):
        x: str = Field(validation_alias=AliasChoices('a', AliasPath('b', 1), 'c'))

    assert Model.model_fields['x'].validation_alias == AliasChoices('a', AliasPath('b', 1), 'c')
    assert Model.model_validate({'a': 'hello'}).x == 'hello'
    assert Model.model_validate({'b': ['hello', 'world']}).x == 'world'
    assert Model.model_validate({'c': 'test'}).x == 'test'
    with pytest.raises(ValidationError) as exc_info:
        Model.model_validate({'b': ['hello']})
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'missing',
            'loc': ('a',),
            'msg': 'Field required',
            'input': {'b': ['hello']},
        }
    ]


def test_validation_alias_priority():
    class Model(BaseModel):
        model_config = ConfigDict(validate_by_alias=True, validate_by_name=True)
        a: str = Field(validation_alias=AliasChoices('b', AliasPath('c', 0), 'd'))

    assert Model.model_validate({'a': 'a', 'b': 'b', 'c': ['c'], 'd': 'd'}).a == 'b'
    assert Model.model_validate({'a': 'a', 'c': ['c'], 'd': 'd', 'b': 'b'}).a == 'b'
    assert Model.model_validate({'a': 'a', 'd': 'd', 'b': 'b', 'c': ['c']}).a == 'b'

    assert Model.model_validate({'a': 'a', 'c': ['c'], 'd': 'd'}).a == 'c'
    assert Model.model_validate({'a': 'a', 'd': 'd', 'c': ['c']}).a == 'c'

    assert Model.model_validate({'d': 'd', 'a': 'a'}).a == 'd'
    assert Model.model_validate({'a': 'a', 'd': 'd'}).a == 'd'

    assert Model.model_validate({'a': 'a'}).a == 'a'


def test_validation_alias_priority_json():
    class Model(BaseModel):
        model_config = ConfigDict(validate_by_alias=True, validate_by_name=True)
        a: str = Field(validation_alias=AliasChoices('b', AliasPath('c', 0), 'd'))

    assert Model.model_validate_json(b'{"a": "a", "b": "b", "c": ["c"], "d": "d"}').a == 'b'
    assert Model.model_validate_json(b'{"a": "a", "c": ["c"], "d": "d", "b": "b"}').a == 'b'
    assert Model.model_validate_json(b'{"a": "a", "d": "d", "b": "b", "c": ["c"]}').a == 'b'

    assert Model.model_validate_json(b'{"a": "a", "c": ["c"], "d": "d"}').a == 'c'
    assert Model.model_validate_json(b'{"a": "a", "d": "d", "c": ["c"]}').a == 'c'

    assert Model.model_validate_json(b'{"d": "d", "a": "a"}').a == 'd'
    assert Model.model_validate_json(b'{"a": "a", "d": "d"}').a == 'd'

    assert Model.model_validate_json(b'{"a": "a"}').a == 'a'


def test_alias_generator_class() -> None:
    class Model(BaseModel):
        a: str

        model_config = ConfigDict(
            alias_generator=AliasGenerator(
                validation_alias=lambda field_name: f'validation_{field_name}',
                serialization_alias=lambda field_name: f'serialization_{field_name}',
            )
        )

    assert Model.model_fields['a'].validation_alias == 'validation_a'
    assert Model.model_fields['a'].serialization_alias == 'serialization_a'
    assert Model.model_fields['a'].alias is None


def test_alias_generator_with_alias() -> None:
    class Model(BaseModel):
        a: str

        model_config = ConfigDict(alias_generator=AliasGenerator(alias=lambda field_name: f'{field_name}_alias'))

    assert Model.model_fields['a'].validation_alias == 'a_alias'
    assert Model.model_fields['a'].serialization_alias == 'a_alias'
    assert Model.model_fields['a'].alias == 'a_alias'


def test_alias_generator_with_positional_arg() -> None:
    class Model(BaseModel):
        a: str

        model_config = ConfigDict(alias_generator=AliasGenerator(lambda field_name: f'{field_name}_alias'))

    assert Model.model_fields['a'].validation_alias == 'a_alias'
    assert Model.model_fields['a'].serialization_alias == 'a_alias'
    assert Model.model_fields['a'].alias == 'a_alias'


@pytest.mark.parametrize('alias_generator', upper_alias_generator)
def test_alias_generator_with_computed_field(alias_generator) -> None:
    class Rectangle(BaseModel):
        model_config = ConfigDict(validate_by_name=True, alias_generator=alias_generator)

        width: int
        height: int

        @computed_field
        @property
        def area(self) -> int:
            return self.width * self.height

    r = Rectangle(width=10, height=20)
    assert r.model_dump(by_alias=True) == {'WIDTH': 10, 'HEIGHT': 20, 'AREA': 200}


def test_alias_generator_with_invalid_callables() -> None:
    for alias_kind in ('validation_alias', 'serialization_alias', 'alias'):
        with pytest.raises(
            TypeError, match=f'Invalid `{alias_kind}` type. `{alias_kind}` generator must produce one of'
        ):

            class Foo(BaseModel):
                a: str

                model_config = ConfigDict(alias_generator=AliasGenerator(**{alias_kind: lambda x: 1}))


def test_all_alias_kinds_specified() -> None:
    class Foo(BaseModel):
        a: str

        model_config = ConfigDict(
            alias_generator=AliasGenerator(
                alias=lambda field_name: f'{field_name}_alias',
                validation_alias=lambda field_name: f'{field_name}_val_alias',
                serialization_alias=lambda field_name: f'{field_name}_ser_alias',
            )
        )

    assert Foo.model_fields['a'].alias == 'a_alias'
    assert Foo.model_fields['a'].validation_alias == 'a_val_alias'
    assert Foo.model_fields['a'].serialization_alias == 'a_ser_alias'

    # the same behavior we'd expect if we defined alias, validation_alias
    # and serialization_alias on the field itself
    f = Foo(a_val_alias='a')
    assert f.a == 'a'
    assert f.model_dump(by_alias=True) == {'a_ser_alias': 'a'}
    assert f.model_dump(by_alias=False) == {'a': 'a'}


def test_alias_generator_with_computed_field_for_serialization() -> None:
    """Tests that the alias generator is used for computed fields, with serialization_alias taking precedence over alias."""

    class Rectangle(BaseModel):
        model_config = ConfigDict(
            alias_generator=AliasGenerator(
                validation_alias=lambda field_name: f'{field_name}_val_alias',
                alias=lambda field_name: f'{field_name}_alias',
                serialization_alias=lambda field_name: f'{field_name}_ser_alias',
            )
        )

        width: int
        height: int

        @computed_field
        def area(self) -> int:
            return self.width * self.height

    r = Rectangle(width_val_alias=10, height_val_alias=20)
    assert r.model_dump(by_alias=True) == {'width_ser_alias': 10, 'height_ser_alias': 20, 'area_ser_alias': 200}


empty_str_alias_generator = AliasGenerator(
    validation_alias=lambda x: '', alias=lambda x: f'{x}_alias', serialization_alias=lambda x: ''
)


def test_alias_gen_with_empty_string() -> None:
    class Model(BaseModel):
        a: str

        model_config = ConfigDict(alias_generator=empty_str_alias_generator)

    assert Model.model_fields['a'].validation_alias == ''
    assert Model.model_fields['a'].serialization_alias == ''
    assert Model.model_fields['a'].alias == 'a_alias'


def test_alias_gen_with_empty_string_and_computed_field() -> None:
    class Model(BaseModel):
        model_config = ConfigDict(alias_generator=empty_str_alias_generator)

        a: str

        @computed_field
        def b(self) -> str:
            return self.a

    assert Model.model_fields['a'].validation_alias == ''
    assert Model.model_fields['a'].serialization_alias == ''
    assert Model.model_fields['a'].alias == 'a_alias'
    assert Model.model_computed_fields['b'].alias == ''


@pytest.mark.parametrize('config_by_alias', [None, True, False])
@pytest.mark.parametrize('config_by_name', [None, True, False])
@pytest.mark.parametrize('runtime_by_alias', [None, True, False])
@pytest.mark.parametrize('runtime_by_name', [None, True, False])
def test_validation_alias_settings(
    config_by_alias: Union[bool, None],
    config_by_name: Union[bool, None],
    runtime_by_alias: Union[bool, None],
    runtime_by_name: Union[bool, None],
) -> None:
    """This test reflects the priority that applies for config vs runtime validation alias configuration.

    Runtime values take precedence over config values, when set.
    By default, `by_alias` is True and `by_name` is False.
    """

    if (config_by_alias is False and config_by_name is not True) or (
        runtime_by_alias is False and runtime_by_name is not True
    ):
        pytest.skip("Can't have both validate_by_alias and validate_by_name as effectively False")

    config_dict = {
        **({'validate_by_alias': config_by_alias} if config_by_alias is not None else {}),
        **({'validate_by_name': config_by_name} if config_by_name is not None else {}),
    }

    class Model(BaseModel):
        model_config = ConfigDict(**config_dict)

        my_field: int = Field(validation_alias='my_alias')

    alias_allowed = next(x for x in (runtime_by_alias, config_by_alias, True) if x is not None)
    name_allowed = next(x for x in (runtime_by_name, config_by_name, False) if x is not None)

    if alias_allowed:
        assert Model.model_validate({'my_alias': 1}, by_alias=runtime_by_alias, by_name=runtime_by_name).my_field == 1
    if name_allowed:
        assert Model.model_validate({'my_field': 1}, by_alias=runtime_by_alias, by_name=runtime_by_name).my_field == 1


def test_user_error_on_validation_methods() -> None:
    class Model(BaseModel):
        my_field: int = Field(alias='my_alias')

    with pytest.raises(PydanticUserError, match='At least one of `by_alias` or `by_name` must be set to True.'):
        Model.model_validate({'my_alias': 1}, by_alias=False, by_name=False)

    with pytest.raises(PydanticUserError, match='At least one of `by_alias` or `by_name` must be set to True.'):
        Model.model_validate_json("{'my_alias': 1}", by_alias=False, by_name=False)

    with pytest.raises(PydanticUserError, match='At least one of `by_alias` or `by_name` must be set to True.'):
        Model.model_validate_strings("{'my_alias': 1}", by_alias=False, by_name=False)


@pytest.mark.parametrize(
    'config,runtime,expected',
    [
        (True, True, {'my_alias': 1}),
        (True, False, {'my_field': 1}),
        (True, None, {'my_alias': 1}),
        (False, True, {'my_alias': 1}),
        (False, False, {'my_field': 1}),
        (False, None, {'my_field': 1}),
        (None, True, {'my_alias': 1}),
        (None, False, {'my_field': 1}),
        (None, None, {'my_field': 1}),
    ],
)
def test_serialization_alias_settings(
    config: Union[bool, None], runtime: Union[bool, None], expected: dict[str, int]
) -> None:
    """This test reflects the priority that applies for config vs runtime serialization alias configuration.

    Runtime value (by_alias) takes precedence over config value (serialize_by_alias).
    If neither are set, the default, False, is used.
    """

    class Model(BaseModel):
        model_config = ConfigDict(serialize_by_alias=config)

        my_field: int = Field(serialization_alias='my_alias')

    model = Model(my_field=1)
    assert model.model_dump(by_alias=runtime) == expected


--- tests/test_allow_partial.py ---
from typing import Annotated

import pytest
from annotated_types import Ge
from typing_extensions import TypedDict

from pydantic import TypeAdapter, ValidationError

from .conftest import Err


@pytest.mark.parametrize(
    'mode,value,expected',
    [
        ('python', {'a': 1, 'b': 'b', 'c': (3, '4')}, {'a': 1, 'b': 'b', 'c': (3, '4')}),
        ('python', {'a': 1, 'b': 'b', 'c': (3,)}, {'a': 1, 'b': 'b'}),
        ('python', {'a': 1, 'b': 'b'}, {'a': 1, 'b': 'b'}),
        ('json', '{"a": 1, "b": "b", "c": [3, "4"]}', {'a': 1, 'b': 'b', 'c': (3, '4')}),
        ('json', '{"a": 1, "b": "b", "c": [3, "4"]}', {'a': 1, 'b': 'b', 'c': (3, '4')}),
        ('json', '{"a": 1, "b": "b", "c": [3]}', {'a': 1, 'b': 'b'}),
        ('json', '{"a": 1, "b": "b", "c": [3', {'a': 1, 'b': 'b'}),
        ('json', '{"a": 1, "b": "b', {'a': 1}),
        ('json', '{"a": 1, "b": ', {'a': 1}),
        ('python', {'a': 1, 'c': (3,), 'b': 'b'}, Err(r'c\.1\s+Field required')),
        ('json', '{"a": 1, "c": [3], "b": "b"}', Err(r'c\.1\s+Field required')),
    ],
)
def test_typed_dict(mode, value, expected):
    class Foobar(TypedDict, total=False):
        a: int
        b: str
        c: tuple[int, str]

    ta = TypeAdapter(Foobar)
    if mode == 'python':
        if isinstance(expected, Err):
            with pytest.raises(ValidationError, match=expected.message):
                ta.validate_python(value, experimental_allow_partial=True)
        else:
            assert ta.validate_python(value, experimental_allow_partial=True) == expected
    else:
        if isinstance(expected, Err):
            with pytest.raises(ValidationError, match=expected.message):
                ta.validate_json(value, experimental_allow_partial=True)
        else:
            assert ta.validate_json(value, experimental_allow_partial=True) == expected


@pytest.mark.parametrize(
    'mode,value,expected',
    [
        ('python', [10, 20, 30], [10, 20, 30]),
        ('python', ['10', '20', '30'], [10, 20, 30]),
        ('python', [10, 20, 30], [10, 20, 30]),
        ('python', [10, 20, 3], [10, 20]),
        ('json', '[10, 20, 30]', [10, 20, 30]),
        ('json', '[10, 20, 30', [10, 20, 30]),
        ('json', '[10, 20, 3', [10, 20]),
    ],
)
def test_list(mode, value, expected):
    ta = TypeAdapter(list[Annotated[int, Ge(10)]])
    if mode == 'python':
        if isinstance(expected, Err):
            with pytest.raises(ValidationError, match=expected.message):
                ta.validate_python(value, experimental_allow_partial=True)
        else:
            assert ta.validate_python(value, experimental_allow_partial=True) == expected
    else:
        if isinstance(expected, Err):
            with pytest.raises(ValidationError, match=expected.message):
                ta.validate_json(value, experimental_allow_partial=True)
        else:
            assert ta.validate_json(value, experimental_allow_partial=True) == expected


def test_dict():
    ta = TypeAdapter(dict[str, Annotated[int, Ge(10)]])
    eap = dict(experimental_allow_partial=True)

    assert ta.validate_python({'a': 10, 'b': 20, 'c': 30}, **eap) == {'a': 10, 'b': 20, 'c': 30}
    assert ta.validate_python({'a': 10, 'b': 20, 'c': 3}, **eap) == {'a': 10, 'b': 20}
    assert ta.validate_strings({'a': '10', 'b': '20', 'c': '30'}, strict=True, **eap) == {'a': 10, 'b': 20, 'c': 30}
    assert ta.validate_strings({'a': '10', 'b': '20', 'c': '3'}, strict=True, **eap) == {'a': 10, 'b': 20}
    assert ta.validate_json('{"a": 10, "b": 20, "c": 30}', **eap) == {'a': 10, 'b': 20, 'c': 30}
    assert ta.validate_json('{"a": 10, "b": 20, "c": 3', **eap) == {'a': 10, 'b': 20}
    assert ta.validate_json('{"a": 10, "b": 20, "c": 3}', **eap) == {'a': 10, 'b': 20}


--- tests/test_annotated.py ---
import datetime as dt
import sys
from collections.abc import Iterator
from dataclasses import dataclass
from decimal import Decimal
from typing import Annotated, Any, Callable, Generic, Optional, TypeVar

import pytest
import pytz
from annotated_types import BaseMetadata, GroupedMetadata, Gt, Lt, Not, Predicate
from pydantic_core import CoreSchema, PydanticUndefined, core_schema

from pydantic import (
    BaseModel,
    BeforeValidator,
    Field,
    GetCoreSchemaHandler,
    PydanticUserError,
    TypeAdapter,
    ValidationError,
)
from pydantic.errors import PydanticSchemaGenerationError
from pydantic.fields import PrivateAttr
from pydantic.functional_validators import AfterValidator

NO_VALUE = object()


@pytest.mark.thread_unsafe(
    reason=(
        'The `FieldInfo.from_annotated_attribute()` implementation directly mutates the assigned value, '
        'if it is a `Field()`. https://github.com/pydantic/pydantic/issues/11122 tracks this issue'
    )
)
@pytest.mark.parametrize(
    'hint_fn,value,expected_repr',
    [
        (
            lambda: Annotated[int, Gt(0)],
            5,
            'FieldInfo(annotation=int, required=False, default=5, metadata=[Gt(gt=0)])',
        ),
        (
            lambda: Annotated[int, Field(gt=0)],
            5,
            'FieldInfo(annotation=int, required=False, default=5, metadata=[Gt(gt=0)])',
        ),
        (
            lambda: int,
            Field(5, gt=0),
            'FieldInfo(annotation=int, required=False, default=5, metadata=[Gt(gt=0)])',
        ),
        (
            lambda: int,
            Field(default_factory=lambda: 5, gt=0),
            'FieldInfo(annotation=int, required=False, default_factory=<lambda>, metadata=[Gt(gt=0)])',
        ),
        (
            lambda: Annotated[int, Lt(2)],
            Field(5, gt=0),
            'FieldInfo(annotation=int, required=False, default=5, metadata=[Gt(gt=0), Lt(lt=2)])',
        ),
        (
            lambda: Annotated[int, Gt(0)],
            NO_VALUE,
            'FieldInfo(annotation=int, required=True, metadata=[Gt(gt=0)])',
        ),
        (
            lambda: Annotated[int, Gt(0)],
            Field(),
            'FieldInfo(annotation=int, required=True, metadata=[Gt(gt=0)])',
        ),
        (
            lambda: int,
            Field(gt=0),
            'FieldInfo(annotation=int, required=True, metadata=[Gt(gt=0)])',
        ),
        (
            lambda: Annotated[int, Gt(0)],
            PydanticUndefined,
            'FieldInfo(annotation=int, required=True, metadata=[Gt(gt=0)])',
        ),
        (
            lambda: Annotated[int, Field(gt=0), Lt(2)],
            5,
            'FieldInfo(annotation=int, required=False, default=5, metadata=[Gt(gt=0), Lt(lt=2)])',
        ),
        (
            lambda: Annotated[int, Field(alias='foobar')],
            PydanticUndefined,
            "FieldInfo(annotation=int, required=True, alias='foobar', alias_priority=2)",
        ),
    ],
)
def test_annotated(hint_fn, value, expected_repr):
    hint = hint_fn()

    if value is NO_VALUE:

        class M(BaseModel):
            x: hint

    else:

        class M(BaseModel):
            x: hint = value

    assert repr(M.model_fields['x']) == expected_repr


@pytest.mark.parametrize('metadata', [0, 'foo'])
def test_annotated_allows_unknown(metadata):
    class M(BaseModel):
        x: Annotated[int, metadata] = 5

    field_info = M.model_fields['x']
    assert len(field_info.metadata) == 1
    assert metadata in field_info.metadata, 'Records the unknown metadata'
    assert metadata in M.__annotations__['x'].__metadata__, 'Annotated type is recorded'


@pytest.mark.thread_unsafe(reason='`pytest.raises()` is thread unsafe')
@pytest.mark.parametrize(
    ['hint_fn', 'value', 'empty_init_ctx'],
    [
        (
            lambda: int,
            PydanticUndefined,
            pytest.raises(ValueError, match=r'Field required \[type=missing,'),
        ),
        (
            lambda: Annotated[int, Field()],
            PydanticUndefined,
            pytest.raises(ValueError, match=r'Field required \[type=missing,'),
        ),
    ],
)
def test_annotated_instance_exceptions(hint_fn, value, empty_init_ctx):
    hint = hint_fn()

    class M(BaseModel):
        x: hint = value

    with empty_init_ctx:
        assert M().x == 5


def test_field_reuse():
    field = Field(description='Long description')

    class Model(BaseModel):
        one: int = field

    assert Model(one=1).model_dump() == {'one': 1}

    class AnnotatedModel(BaseModel):
        one: Annotated[int, field]

    assert AnnotatedModel(one=1).model_dump() == {'one': 1}


def test_config_field_info():
    class Foo(BaseModel):
        a: Annotated[int, Field(description='descr', json_schema_extra={'foobar': 'hello'})]

    assert Foo.model_json_schema(by_alias=True)['properties'] == {
        'a': {'title': 'A', 'description': 'descr', 'foobar': 'hello', 'type': 'integer'},
    }


@pytest.mark.skipif(sys.version_info < (3, 10), reason='repr different on older versions')
def test_annotated_alias() -> None:
    # https://github.com/pydantic/pydantic/issues/2971

    StrAlias = Annotated[str, Field(max_length=3)]
    IntAlias = Annotated[int, Field(default_factory=lambda: 2)]

    Nested = Annotated[list[StrAlias], Field(description='foo')]

    class MyModel(BaseModel):
        a: StrAlias = 'abc'
        b: StrAlias
        c: IntAlias
        d: IntAlias
        e: Nested

    fields_repr = {k: repr(v) for k, v in MyModel.model_fields.items()}
    assert fields_repr == {
        'a': "FieldInfo(annotation=str, required=False, default='abc', metadata=[MaxLen(max_length=3)])",
        'b': 'FieldInfo(annotation=str, required=True, metadata=[MaxLen(max_length=3)])',
        'c': 'FieldInfo(annotation=int, required=False, default_factory=<lambda>)',
        'd': 'FieldInfo(annotation=int, required=False, default_factory=<lambda>)',
        'e': "FieldInfo(annotation=list[Annotated[str, FieldInfo(annotation=NoneType, required=True, metadata=[MaxLen(max_length=3)])]], required=True, description='foo')",
    }
    assert MyModel(b='def', e=['xyz']).model_dump() == dict(a='abc', b='def', c=2, d=2, e=['xyz'])


def test_modify_get_schema_annotated() -> None:
    calls: list[str] = []

    class CustomType:
        @classmethod
        def __get_pydantic_core_schema__(cls, source: Any, handler: GetCoreSchemaHandler) -> core_schema.CoreSchema:
            calls.append('CustomType:before')
            with pytest.raises(PydanticSchemaGenerationError):
                handler(source)
            schema = core_schema.no_info_plain_validator_function(lambda _: CustomType())
            calls.append('CustomType:after')
            return schema

    class PydanticMetadata:
        def __get_pydantic_core_schema__(self, source: Any, handler: GetCoreSchemaHandler) -> core_schema.CoreSchema:
            calls.append('PydanticMetadata:before')
            schema = handler(source)
            calls.append('PydanticMetadata:after')
            return schema

    class GroupedMetadataMarker(GroupedMetadata):
        def __iter__(self) -> Iterator[BaseMetadata]:
            # no way to actually hook into schema building
            # so just register when our iter is called
            calls.append('GroupedMetadataMarker:iter')
            yield from []

    class _(BaseModel):
        x: Annotated[CustomType, GroupedMetadataMarker(), PydanticMetadata()]

    # insert_assert(calls)
    assert calls == [
        'GroupedMetadataMarker:iter',
        'PydanticMetadata:before',
        'CustomType:before',
        'CustomType:after',
        'PydanticMetadata:after',
    ]

    calls.clear()

    class _(BaseModel):
        x: Annotated[CustomType, PydanticMetadata(), GroupedMetadataMarker()]

    # insert_assert(calls)
    assert calls == [
        'GroupedMetadataMarker:iter',
        'PydanticMetadata:before',
        'CustomType:before',
        'CustomType:after',
        'PydanticMetadata:after',
    ]

    calls.clear()


def test_get_pydantic_core_schema_source_type() -> None:
    types: set[Any] = set()

    class PydanticMarker:
        def __get_pydantic_core_schema__(self, source: Any, handler: GetCoreSchemaHandler) -> core_schema.CoreSchema:
            types.add(source)
            return handler(source)

    class _(BaseModel):
        x: Annotated[Annotated[int, 'foo'], PydanticMarker()]

    assert types == {int}
    types.clear()

    T = TypeVar('T')

    class GenericModel(BaseModel, Generic[T]):
        y: T

    class _(BaseModel):
        x: Annotated[GenericModel[int], PydanticMarker()]

    assert types == {GenericModel[int]}
    types.clear()


def test_merge_field_infos_type_adapter() -> None:
    ta = TypeAdapter(
        Annotated[
            int, Field(gt=0), Field(lt=100), Field(gt=1), Field(description='abc'), Field(3), Field(description=None)
        ]
    )

    default = ta.get_default_value()
    assert default is not None
    assert default.value == 3

    # insert_assert(ta.validate_python(2))
    assert ta.validate_python(2) == 2

    with pytest.raises(ValidationError) as exc_info:
        ta.validate_python(1)

    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {'type': 'greater_than', 'loc': (), 'msg': 'Input should be greater than 1', 'input': 1, 'ctx': {'gt': 1}}
    ]

    # insert_assert(ta.json_schema())
    assert ta.json_schema() == {
        'default': 3,
        'description': 'abc',
        'exclusiveMaximum': 100,
        'exclusiveMinimum': 1,
        'type': 'integer',
    }


def test_merge_field_infos_model() -> None:
    class Model(BaseModel):
        x: Annotated[
            int, Field(gt=0), Field(lt=100), Field(gt=1), Field(description='abc'), Field(3), Field(description=None)
        ] = Field(5)

    # insert_assert(Model.model_json_schema())
    assert Model.model_json_schema() == {
        'properties': {
            'x': {'default': 5, 'exclusiveMaximum': 100, 'exclusiveMinimum': 1, 'title': 'X', 'type': 'integer'}
        },
        'title': 'Model',
        'type': 'object',
    }


def test_model_dump_doesnt_dump_annotated_dunder():
    class Model(BaseModel):
        one: int

    AnnotatedModel = Annotated[Model, ...]

    # In Pydantic v1, `AnnotatedModel.dict()` would have returned
    # `{'one': 1, '__orig_class__': typing.Annotated[...]}`
    assert AnnotatedModel(one=1).model_dump() == {'one': 1}


def test_merge_field_infos_ordering() -> None:
    TheType = Annotated[int, AfterValidator(lambda x: x), Field(le=2), AfterValidator(lambda x: x * 2), Field(lt=4)]

    class Model(BaseModel):
        x: TheType

    assert Model(x=1).x == 2

    with pytest.raises(ValidationError) as exc_info:
        Model(x=2)
    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {'type': 'less_than', 'loc': ('x',), 'msg': 'Input should be less than 4', 'input': 2, 'ctx': {'lt': 4}}
    ]

    with pytest.raises(ValidationError) as exc_info:
        Model(x=3)
    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'less_than_equal',
            'loc': ('x',),
            'msg': 'Input should be less than or equal to 2',
            'input': 3,
            'ctx': {'le': 2},
        }
    ]


def test_validate_float_inf_nan_python() -> None:
    ta = TypeAdapter(Annotated[float, AfterValidator(lambda x: x * 3), Field(allow_inf_nan=False)])
    assert ta.validate_python(2.0) == 6.0

    ta = TypeAdapter(Annotated[float, AfterValidator(lambda _: float('nan')), Field(allow_inf_nan=False)])

    with pytest.raises(ValidationError) as exc_info:
        ta.validate_python(1.0)

    # insert_assert(exc_info.value.errors(include_url=False))
    # TODO: input should be float('nan'), this seems like a subtle bug in pydantic-core
    assert exc_info.value.errors(include_url=False) == [
        {'type': 'finite_number', 'loc': (), 'msg': 'Input should be a finite number', 'input': 1.0}
    ]


def test_predicate_success_python() -> None:
    ta = TypeAdapter(Annotated[int, Predicate(lambda x: x > 0)])

    assert ta.validate_python(1) == 1


def test_predicate_error_python() -> None:
    ta = TypeAdapter(Annotated[int, Predicate(lambda x: x > 0)])

    with pytest.raises(ValidationError) as exc_info:
        ta.validate_python(-1)

    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'predicate_failed',
            'loc': (),
            'msg': "Predicate 'test_predicate_error_python.<locals>.<lambda>' failed",
            'input': -1,
        }
    ]


def test_not_operation_error_python() -> None:
    ta = TypeAdapter(Annotated[int, Not(lambda x: x > 5)])

    with pytest.raises(ValidationError) as exc_info:
        ta.validate_python(6)

    # insert_assert(exc_info.value.errors(include_url=False))
    assert exc_info.value.errors(include_url=False) == [
        {
            'type': 'not_operation_failed',
            'loc': (),
            'msg': "Not of 'test_not_operation_error_python.<locals>.<lambda>' failed",
            'input': 6,
        }
    ]


def test_annotated_field_info_not_lost_from_forwardref():
    from pydantic import BaseModel

    class ForwardRefAnnotatedFieldModel(BaseModel):
        foo: 'Annotated[Integer, Field(alias="bar", default=1)]' = 2
        foo2: 'Annotated[Integer, Field(alias="bar2", default=1)]' = Field(default=2, alias='baz')

    Integer = int

    ForwardRefAnnotatedFieldModel.model_rebuild()

    assert ForwardRefAnnotatedFieldModel(bar=3).foo == 3
    assert ForwardRefAnnotatedFieldModel(baz=3).foo2 == 3

    with pytest.raises(ValidationError) as exc_info:
        ForwardRefAnnotatedFieldModel(bar='bar')
    assert exc_info.value.errors(include_url=False) == [
        {
            'input': 'bar',
            'loc': ('bar',),
            'msg': 'Input should be a valid integer, unable to parse string as an integer',
            'type': 'int_parsing',
        }
    ]


def test_annotated_private_field_with_default():
    class AnnotatedPrivateFieldModel(BaseModel):
        _foo: Annotated[int, PrivateAttr(default=1)]
        _bar: Annotated[str, 'hello']
        _baz: 'Annotated[str, PrivateAttr(default=2)]'

    model = AnnotatedPrivateFieldModel()
    assert model._foo == 1
    assert model._baz == 2

    assert model.__pydantic_private__ == {'_foo': 1, '_baz': 2}

    with pytest.raises(AttributeError):
        assert model._bar

    model._bar = 'world'
    assert model._bar == 'world'
    assert model.__pydantic_private__ == {'_foo': 1, '_bar': 'world', '_baz': 2}

    with pytest.raises(AttributeError):
        assert model.bar


def test_min_length_field_info_not_lost():
    class AnnotatedFieldModel(BaseModel):
        foo: 'Annotated[String, Field(min_length=3)]' = Field(description='hello')

    String = str

    AnnotatedFieldModel.model_rebuild()

    assert AnnotatedFieldModel(foo='000').foo == '000'

    with pytest.raises(ValidationError) as exc_info:
        AnnotatedFieldModel(foo='00')

    assert exc_info.value.errors(include_url=False) == [
        {
            'loc': ('foo',),
            'input': '00',
            'ctx': {'min_length': 3},
            'msg': 'String should have at least 3 characters',
            'type': 'string_too_short',
        }
    ]


def test_tzinfo_validator_example_pattern() -> None:
    """Test that tzinfo custom validator pattern works as explained in the examples/validators docs."""

    @dataclass(frozen=True)
    class MyDatetimeValidator:
        tz_constraint: Optional[str] = None

        def tz_constraint_validator(
            self,
            value: dt.datetime,
            handler: Callable,  # (1)!
        ):
            """Validate tz_constraint and tz_info."""
            # handle naive datetimes
            if self.tz_constraint is None:
                assert value.tzinfo is None, 'tz_constraint is None, but provided value is tz-aware.'
                return handler(value)

            # validate tz_constraint and tz-aware tzinfo
            if self.tz_constraint not in pytz.all_timezones:
                raise PydanticUserError(
                    f'Invalid tz_constraint: {self.tz_constraint}', code='unevaluable-type-annotation'
                )
            result = handler(value)  # (2)!
            assert self.tz_constraint == str(result.tzinfo), (
                f'Invalid tzinfo: {str(result.tzinfo)}, expected: {self.tz_constraint}'
            )

            return result

        def __get_pydantic_core_schema__(
            self,
            source_type: Any,
            handler: GetCoreSchemaHandler,
        ) -> CoreSchema:
            return core_schema.no_info_wrap_validator_function(
                self.tz_constraint_validator,
                handler(source_type),
            )

    LA = 'America/Los_Angeles'

    # passing naive test
    ta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator()])
    ta.validate_python(dt.datetime.now())

    # failing naive test
    ta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator()])
    with pytest.raises(Exception):
        ta.validate_python(dt.datetime.now(pytz.timezone(LA)))

    # passing tz-aware test
    ta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator(LA)])
    ta.validate_python(dt.datetime.now(pytz.timezone(LA)))

    # failing bad tz
    ta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator('foo')])
    with pytest.raises(Exception):
        ta.validate_python(dt.datetime.now())

    # failing tz-aware test
    ta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator(LA)])
    with pytest.raises(Exception):
        ta.validate_python(dt.datetime.now())


def test_utcoffset_validator_example_pattern() -> None:
    """Test that utcoffset custom validator pattern works as explained in the examples/validators docs."""

    @dataclass(frozen=True)
    class MyDatetimeValidator:
        lower_bound: int
        upper_bound: int

        def validate_tz_bounds(self, value: dt.datetime, handler: Callable):
            """Validate and test bounds"""
            assert value.utcoffset() is not None, 'UTC offset must exist'
            assert self.lower_bound <= self.upper_bound, 'Invalid bounds'

            result = handler(value)

            hours_offset = value.utcoffset().total_seconds() / 3600
            assert self.lower_bound <= hours_offset <= self.upper_bound, 'Value out of bounds'

            return result

        def __get_pydantic_core_schema__(
            self,
            source_type: Any,
            handler: GetCoreSchemaHandler,
        ) -> CoreSchema:
            return core_schema.no_info_wrap_validator_function(
                self.validate_tz_bounds,
                handler(source_type),
            )

    LA = 'America/Los_Angeles'

    # test valid bound passing
    ta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator(-10, 10)])
    ta.validate_python(dt.datetime.now(pytz.timezone(LA)))

    # test valid bound failing - missing TZ
    ta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator(-12, 12)])
    with pytest.raises(Exception):
        ta.validate_python(dt.datetime.now())

    # test invalid bound
    ta = TypeAdapter(Annotated[dt.datetime, MyDatetimeValidator(0, 4)])
    with pytest.raises(Exception):
        ta.validate_python(dt.datetime.now(pytz.timezone(LA)))


def test_incompatible_metadata_error() -> None:
    ta = TypeAdapter(Annotated[list[int], Field(pattern='abc')])
    with pytest.raises(TypeError, match="Unable to apply constraint 'pattern'"):
        ta.validate_python([1, 2, 3])


def test_compatible_metadata_raises_correct_validation_error() -> None:
    """Using a no-op before validator to ensure that constraint is applied as part of a chain."""
    ta = TypeAdapter(Annotated[str, BeforeValidator(lambda x: x), Field(pattern='abc')])
    with pytest.raises(ValidationError, match="String should match pattern 'abc'"):
        ta.validate_python('def')


def test_decimal_constraints_after_annotation() -> None:
    DecimalAnnotation = Annotated[Decimal, BeforeValidator(lambda v: v), Field(max_digits=10, decimal_places=4)]

    ta = TypeAdapter(DecimalAnnotation)
    assert ta.validate_python(Decimal('123.4567')) == Decimal('123.4567')

    with pytest.raises(ValidationError) as e:
        ta.validate_python(Decimal('123.45678'))

    assert e.value.errors()[0]['type'] == 'decimal_max_places'

    with pytest.raises(ValidationError) as e:
        ta.validate_python(Decimal('12345678.901'))

    assert e.value.errors()[0]['type'] == 'decimal_max_digits'


--- tests/test_assert_in_validators.py ---
"""
PYTEST_DONT_REWRITE
"""

import difflib
import pprint

import pytest
from dirty_equals import HasRepr

from pydantic import BaseModel, ValidationError, field_validator


def _pformat_lines(obj):
    return pprint.pformat(obj).splitlines(keepends=True)


def _assert_eq(left, right):
    if left != right:
        pytest.fail('\n' + '\n'.join(difflib.ndiff(_pformat_lines(left), _pformat_lines(right))))


def test_assert_raises_validation_error():
    class Model(BaseModel):
        a: str

        @field_validator('a')
        @classmethod
        def check_a(cls, v):
            assert v == 'a', 'invalid a'
            return v

    assert Model(a='a').a == 'a'

    with pytest.raises(ValidationError) as exc_info:
        Model(a='snap')

    _assert_eq(
        [
            {
                'ctx': {'error': HasRepr(repr(AssertionError('invalid a')))},
                'input': 'snap',
                'loc': ('a',),
                'msg': 'Assertion failed, invalid a',
                'type': 'assertion_error',
            }
        ],
        exc_info.value.errors(include_url=False),
    )


--- tests/test_callable.py ---
from collections.abc import Callable as CollectionsCallable
from typing import Callable

import pytest

from pydantic import BaseModel, ValidationError

collection_callable_types = [Callable, Callable[[int], int], CollectionsCallable, CollectionsCallable[[int], int]]


@pytest.mark.parametrize('annotation', collection_callable_types)
def test_callable(annotation):
    class Model(BaseModel):
        callback: annotation

    m = Model(callback=lambda x: x)
    assert callable(m.callback)


@pytest.mark.parametrize('annotation', collection_callable_types)
def test_non_callable(annotation):
    class Model(BaseModel):
        callback: annotation

    with pytest.raises(ValidationError):
        Model(callback=1)
