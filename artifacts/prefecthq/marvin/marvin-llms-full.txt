# llms-full (private-aware)
> Built from GitHub files and website pages. Large files may be truncated.

--- docs/installation.mdx ---
---
title: Installation
description: Get started with Marvin in under a minute
icon: download
---

## Requirements

- Python 3.10 or higher
- An API key from an LLM provider (OpenAI by default)

## Install `marvin`

The easiest way to install Marvin is a package manager like `pip` or [`uv`](https://docs.astral.sh/uv/):

<CodeGroup>

```bash uv
# add marvin to your project
uv add marvin
# add marvin to your script
uv add --script some_script.py marvin
# run a python process with marvin installed ephemerally
uv run --with marvin some_script.py
```

```bash pip
pip install marvin
```
</CodeGroup>


## Configure your LLM provider

By default, Marvin uses OpenAI's models. Set your API key as an environment variable:

```bash
export OPENAI_API_KEY="your-api-key"
```

To use another provider, see the docs on [configuring LLMs](/guides/configure-llms).

## Development Installation

For development, install Marvin with development dependencies:

<CodeGroup>

```bash uv
git clone https://github.com/prefecthq/marvin.git
cd marvin
uv venv && source .venv/bin/activate
uv sync --dev
```

```bash pip
git clone https://github.com/prefecthq/marvin.git
cd marvin
python -m venv .venv && source .venv/bin/activate
pip install -e ".[dev]"
```
</CodeGroup>

## What's Next?

- Follow the [Quickstart](/quickstart) guide to build your first AI application
- Learn about [Tasks](/concepts/tasks), the building blocks of AI workflows
- Explore [Agents](/concepts/agents) to create specialized AI workers
- Read about [Threads](/concepts/threads) for managing conversation context 

## Links discovered
- [`uv`](https://docs.astral.sh/uv/)
- [configuring LLMs](https://github.com/prefecthq/marvin/blob/main/guides/configure-llms.md)
- [Quickstart](https://github.com/prefecthq/marvin/blob/main/quickstart.md)
- [Tasks](https://github.com/prefecthq/marvin/blob/main/concepts/tasks.md)
- [Agents](https://github.com/prefecthq/marvin/blob/main/concepts/agents.md)
- [Threads](https://github.com/prefecthq/marvin/blob/main/concepts/threads.md)

--- docs/quickstart.mdx ---
---
title: Quickstart
description: Build your first AI application in less than a minute
icon: rocket
---

Welcome to Marvin! This quickstart guide will walk you through the three main ways to use Marvin to create AI-powered applications.

You'll learn how to:
1. [Use quick one-liners](#quick-one-liners) with `marvin.run()`
2. [Work with specialized agents](#specialized-agents) using `agent.run()`
3. [Control tasks directly](#task-control) with `task.run()`
4. [Add advanced features](#advanced-features) like context and threads

<Warning>
This guide assumes you have already installed `marvin`. See the [installation docs](/installation) for instructions.
</Warning>

## Quick One-Liners

The fastest way to use Marvin is with `marvin.run()`:

```python
import marvin

# Run a simple task
print(marvin.run("Write a haiku about Python programming"))

# With a specific result type
numbers = marvin.run(
    "Generate five random numbers between 1 and 10",
    result_type=list[int]
)
```

<Accordion title="Output">
```text
Indented lines flow
Functions dance with elegance
Code becomes poetry

[3, 7, 2, 9, 5]
```
</Accordion>

## Specialized Agents

Create and use specialized agents for specific types of tasks:

```python
from marvin import Agent

# Create a specialized agent
writer = Agent(
    name="Technical Writer",
    instructions="Write clear, engaging content for developers"
)

# Use the agent directly
article = writer.run(
    "Write a short article about Python type hints",
    result_type=str
)

print(article)
```

<Accordion title="Output">
```text
Type Hints in Python: A Clear Path to Better Code

Python's type hints bring clarity and safety to your code without sacrificing its dynamic nature. Introduced in Python 3.5, type hints allow developers to explicitly declare variable and function types, making code more maintainable and easier to understand.

Here's a quick example:

def greet(name: str) -> str:
    return f"Hello, {name}!"

Type hints help catch errors early, improve IDE support, and make your code self-documenting. While optional, they're becoming an essential tool in modern Python development.
```
</Accordion>

## Task Control

For full control over your AI workflows, create and run tasks directly:

```python
import httpx
from marvin import Task
from pydantic import BaseModel

def check_weather(location: str) -> str:
    url = f"https://wttr.in/{location}?format=%C+%t"
    return httpx.get(url).text

# Define a structured output type
class WeatherForecast(BaseModel):
    temperature: float
    conditions: str
    precipitation_chance: float | str = "unknown"

# Create a task with specific requirements
task = Task(
    instructions="Get the weather for San Francisco",
    result_type=WeatherForecast,
    tools=[check_weather]  # Custom tools
)

# Run the task
forecast = task.run()
print(forecast)
```

<Accordion title="Output">
```text
temperature=50.0 conditions='Partly cloudy' precipitation_chance='unknown'
```
</Accordion>

## Advanced Features

All three approaches support advanced features like context, threads, and tools:

```python
import marvin
from marvin import Agent, Task

# Context improves results
data = "The patient reports mild fever and fatigue."
diagnosis = marvin.run(
    "Suggest possible conditions",
    context={"medical_notes": data}
)

# Threads maintain conversation history
with marvin.Thread() as thread:
    # Ask multiple related questions
    marvin.run("What is quantum computing?")
    marvin.run("How does that relate to classical computing?")
    marvin.run("What are its practical applications?")

# Teams of agents can collaborate
researcher = Agent("Researcher")
writer = Agent("Technical Writer")
editor = Agent("Editor")

with marvin.Thread() as thread:
    research = researcher.run("Research quantum computing")
    draft = writer.run("Write an article", context={"research": research})
    final = editor.run("Edit the article", context={"draft": draft})
```

## What's Next?

You've seen the main ways to work with Marvin. To learn more:

- Read about [Tasks](/concepts/tasks) to understand how to structure AI workflows
- Learn about [Agents](/concepts/agents) to create specialized AI workers
- Explore [Threads](/concepts/threads) for managing conversation context
- Check out [Models](/concepts/models) to work with structured data

## Links discovered
- [installation docs](https://github.com/prefecthq/marvin/blob/main/installation.md)
- [Tasks](https://github.com/prefecthq/marvin/blob/main/concepts/tasks.md)
- [Agents](https://github.com/prefecthq/marvin/blob/main/concepts/agents.md)
- [Threads](https://github.com/prefecthq/marvin/blob/main/concepts/threads.md)
- [Models](https://github.com/prefecthq/marvin/blob/main/concepts/models.md)

--- docs/README.md ---
# Marvin Documentation

This directory contains the documentation for Marvin, a Python framework for building AI applications with LLMs.

## Documentation Structure

The documentation is organized into the following sections:

### Core Concepts

- [Tasks](concepts/tasks.mdx) - The fundamental building blocks of AI workflows
- [Agents](concepts/agents.mdx) - Specialized AI workers with different roles and capabilities
- [Threads](concepts/threads.mdx) - Maintaining conversation context across multiple interactions
- [Teams](concepts/teams.mdx) - Coordinating multiple AI agents to solve complex problems
- [Tools and Context](concepts/tools-and-context.mdx) - Extending AI capabilities with custom functions and additional information
- [Memory](concepts/memory.mdx) - Enabling agents to remember information across conversations

### Functions

- [run](functions/run.mdx) - Execute a task with an LLM
- [classify](functions/classify.mdx) - Categorize content into predefined classes
- [extract](functions/extract.mdx) - Pull structured data from unstructured text
- [cast](functions/cast.mdx) - Convert content to a specified structure
- [generate](functions/generate.mdx) - Create structured data or content
- [summarize](functions/summarize.mdx) - Create concise summaries of content
- [say](functions/say.mdx) - Have conversational interactions with an LLM
- [plan](functions/plan.mdx) - Create structured plans for complex tasks
- [fn](functions/fn.mdx) - Create AI-powered functions with a decorator

### Guides

- [Installation](installation.mdx) - Install Marvin and set up your environment
- [Quickstart](quickstart.mdx) - Build your first AI application in minutes
- [Configure LLMs](guides/configure-llms.mdx) - Use different LLM providers with Marvin
- [Configuration](guides/configuration.mdx) - Configure Marvin using environment variables and settings
- [Building a Multi-step Workflow](guides/multi-step-workflow.mdx) - Create a complete AI application with multiple connected steps
- [Building a Conversational Assistant](guides/building-a-chatbot.mdx) - Create a personalized chatbot with memory
- [Migration Guide](guides/migration-guide.mdx) - Upgrade to Marvin 3.0 from previous versions

### Patterns

- [Memory](patterns/memory.mdx) - Patterns for using memory in your applications
- [Tools](patterns/tools.mdx) - Patterns for creating and using tools
- [Task Results](patterns/task-results.mdx) - Working with structured task results
- [Running Tasks](patterns/running-tasks.mdx) - Different ways to run tasks
- [Instructions](patterns/instructions.mdx) - Crafting effective instructions
- [Interactivity](patterns/interactivity.mdx) - Building interactive applications

## Contributing to Documentation

If you'd like to contribute to the documentation:

1. Make your changes or additions following the existing format and style
2. Use clear, concise language and provide practical examples
3. Submit a pull request with your changes

## Building the Documentation

The documentation uses [Mintlify](https://mintlify.com/) for rendering. The configuration is in the `mint.json` file.

## Documentation TODOs

- Add more examples and use cases
- Expand multi-modal capabilities documentation as they are implemented
- Add more integration guides with other frameworks and services 

## Links discovered
- [Tasks](https://github.com/prefecthq/marvin/blob/main/docs/concepts/tasks.mdx)
- [Agents](https://github.com/prefecthq/marvin/blob/main/docs/concepts/agents.mdx)
- [Threads](https://github.com/prefecthq/marvin/blob/main/docs/concepts/threads.mdx)
- [Teams](https://github.com/prefecthq/marvin/blob/main/docs/concepts/teams.mdx)
- [Tools and Context](https://github.com/prefecthq/marvin/blob/main/docs/concepts/tools-and-context.mdx)
- [Memory](https://github.com/prefecthq/marvin/blob/main/docs/concepts/memory.mdx)
- [run](https://github.com/prefecthq/marvin/blob/main/docs/functions/run.mdx)
- [classify](https://github.com/prefecthq/marvin/blob/main/docs/functions/classify.mdx)
- [extract](https://github.com/prefecthq/marvin/blob/main/docs/functions/extract.mdx)
- [cast](https://github.com/prefecthq/marvin/blob/main/docs/functions/cast.mdx)
- [generate](https://github.com/prefecthq/marvin/blob/main/docs/functions/generate.mdx)
- [summarize](https://github.com/prefecthq/marvin/blob/main/docs/functions/summarize.mdx)
- [say](https://github.com/prefecthq/marvin/blob/main/docs/functions/say.mdx)
- [plan](https://github.com/prefecthq/marvin/blob/main/docs/functions/plan.mdx)
- [fn](https://github.com/prefecthq/marvin/blob/main/docs/functions/fn.mdx)
- [Installation](https://github.com/prefecthq/marvin/blob/main/docs/installation.mdx)
- [Quickstart](https://github.com/prefecthq/marvin/blob/main/docs/quickstart.mdx)
- [Configure LLMs](https://github.com/prefecthq/marvin/blob/main/docs/guides/configure-llms.mdx)
- [Configuration](https://github.com/prefecthq/marvin/blob/main/docs/guides/configuration.mdx)
- [Building a Multi-step Workflow](https://github.com/prefecthq/marvin/blob/main/docs/guides/multi-step-workflow.mdx)
- [Building a Conversational Assistant](https://github.com/prefecthq/marvin/blob/main/docs/guides/building-a-chatbot.mdx)
- [Migration Guide](https://github.com/prefecthq/marvin/blob/main/docs/guides/migration-guide.mdx)
- [Memory](https://github.com/prefecthq/marvin/blob/main/docs/patterns/memory.mdx)
- [Tools](https://github.com/prefecthq/marvin/blob/main/docs/patterns/tools.mdx)
- [Task Results](https://github.com/prefecthq/marvin/blob/main/docs/patterns/task-results.mdx)
- [Running Tasks](https://github.com/prefecthq/marvin/blob/main/docs/patterns/running-tasks.mdx)
- [Instructions](https://github.com/prefecthq/marvin/blob/main/docs/patterns/instructions.mdx)
- [Interactivity](https://github.com/prefecthq/marvin/blob/main/docs/patterns/interactivity.mdx)
- [Mintlify](https://mintlify.com/)

--- docs/community.mdx ---
---
title: The Marvin Community
description: Join us!
icon: sparkles
---


![](/assets/img/quotes/sort_of_thing_you_enjoy.png)

We're thrilled you're interested in Marvin! Here, we're all about community. We're driven by a shared passion for making LLMs and agents more accessible and easier to use.

### Connect on Discord

Join us on [Discord](https://discord.gg/Kgw4HpcuYG) or [Slack](https://communityinviter.com/apps/prefect-community/prefect-community) to ask questions, share ideas, or just chat with like-minded developers. Don't be shy.

### Contributing to Marvin

We encourage all types of contributions, whether it be reporting bugs, suggesting features, or contributing code. Here's how you can contribute:

- **Issues:** Encountered a bug? Have a suggestion? Open an issue in our [GitHub repository](https://github.com/PrefectHQ/Marvin). We appreciate your input!

- **Pull Requests (PRs):** Ready to contribute code? We welcome your pull requests! Not sure how to make a PR? Check out the [GitHub guide](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests).

- **Discussions:** Have an idea but not quite ready to open an issue or PR? Create a GitHub Discussion.

- **Chat:** Join us in one of the above places to chat about ideas or behavior.


## Links discovered
- [Discord](https://discord.gg/Kgw4HpcuYG)
- [Slack](https://communityinviter.com/apps/prefect-community/prefect-community)
- [GitHub repository](https://github.com/PrefectHQ/Marvin)
- [GitHub guide](https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests)

--- docs/welcome.mdx ---
---
title: Marvin
sidebarTitle: Welcome
description: A powerful framework for building AI applications
icon: door-open
---
![](/assets/img/quotes/it_hates_me.png)

## What is Marvin?

**Marvin is a Python framework for building AI applications with LLMs.**




Marvin provides a clean, intuitive interface for working with large language models (LLMs) while handling all the complexity of state management, conversation history, and agent coordination.

## Quick Examples

<Tip>  
Using `uv`? Run the examples below by copying them to your clipboard and executing:  

<CodeGroup>  
```bash macOS  
pbpaste | uv run --with marvin -  
```  
```bash linux
xclip -selection clipboard -o | uv run --with marvin -  
```  
```bash windows
Get-Clipboard | uv run --with marvin -
```

</CodeGroup>  

</Tip>  

### Simple Tasks

The fastest way to use Marvin is with `marvin.run()`:

<CodeGroup>

```python  Run a simple task
import marvin

print(marvin.run("Write a haiku about artificial intelligence"))
```

```python Provide context for more accurate results
import httpx
import marvin

print(
    marvin.run(
        "Summarize the current astronauts in space like a 50s news anchor",
        context={"data": httpx.get("http://api.open-notify.org/astros.json", headers={"Accept": "application/json"}).json()}
    )
)
```

</CodeGroup>
### Specialized Agents

Create agents with specific skills and personalities:

```python
import marvin

# Create specialized agents
poet = marvin.Agent(
    name="Poet",
    instructions="You are an expert poet who writes in various styles."
)

scientist = marvin.Agent(
    name="Scientist",
    instructions="You are a scientist who explains complex topics clearly."
)

# Use them for specific tasks
explanation = marvin.run(
    "Explain entropy briefly",
    agents=[scientist]
)

poem = marvin.run(
    "Write a haiku about entropy",
    agents=[poet],
    context={"scientific_background": explanation}
)

print(poem)
```

### Structured Data

Get results in exactly the format you need:

```python
from typing import Annotated, Literal
import marvin
from pydantic import BaseModel, Field

class Character(BaseModel):
    name: str
    role: Literal["hero", "villain", "sidekick"]
    aura: Annotated[float, Field(ge=0, le=1)]

# Get structured results
characters = marvin.run(
    "Create three characters for a mystery story",
    result_type=list[Character]
)

for char in characters:
    print(f"{char.name} - {char.role} - {char.aura}")
```

### Persistent Memory

Give your agents memory that persists across conversations:

```python
import marvin

# Create a memory module
preferences = marvin.Memory(
    key="user_preferences",
    instructions="Remember user preferences and style"
)

# Create an agent with memory
assistant = marvin.Agent(memories=[preferences])

# The agent will remember information across conversations
marvin.run(
    "Learn about the user's writing style preferences",
    agents=[assistant],
    cli=True
)
```

## Why Marvin?

- ðŸŽ¯ **Simple Interface**: Start with one line of code, scale to complex applications
- ðŸ§  **Smart Defaults**: Sensible defaults that just work, with customization when you need it
- ðŸ”„ **State Management**: Built-in conversation history and memory management
- ðŸ“ **Structured Data**: Get results in exactly the format you need
- ðŸ¤ **Multi-Agent**: Create specialized agents that work together
- ðŸ”Œ **Extensible**: Easy to integrate with your existing Python code

## Next Steps

- [Install Marvin](/installation) - Get started in under a minute
- Try the [Quickstart](/quickstart) - Build your first AI application
- Explore [Core Concepts](/concepts) - Learn about tasks, agents, and more
- Browse [Examples](https://github.com/prefecthq/marvin/tree/main/examples) - See Marvin in action 

## Links discovered
- [Install Marvin](https://github.com/prefecthq/marvin/blob/main/installation.md)
- [Quickstart](https://github.com/prefecthq/marvin/blob/main/quickstart.md)
- [Core Concepts](https://github.com/prefecthq/marvin/blob/main/concepts.md)
- [Examples](https://github.com/prefecthq/marvin/tree/main/examples)

--- docs/concepts/agents.mdx ---
---
title: Agents
description: The intelligent workers in your AI workflows.
icon: robot
---

Agents are the intelligent, autonomous entities that power your AI workflows in Marvin. They represent AI models capable of understanding instructions, making decisions, and completing tasks.

```python
import marvin

agent = marvin.Agent(name="Marvin")
```

## What are agents?

Agents in Marvin are configurable AI entities, each with its own identity, capabilities, and even personality. They act as the "workers" in your AI workflows, responsible for executing tasks and making decisions based on their assigned instructions and available tools.

You can think of each agent as a portable LLM configuration. When you assign an agent to a task, they will work to complete it according to the instructions and tools you provide.

## Creating agents

To create an agent, use the `Agent` class:

```python
import marvin

agent = marvin.Agent(name="Marvin")
```

A more complex agent can be created by providing additional configuration. This example shows the main configuration options:

```python
import marvin

agent = marvin.Agent(
    name="Data Analyst",
    description="An AI agent specialized in data analysis",
    instructions="Perform data analysis tasks efficiently and accurately.",
    tools=[analyze_data, plot_results],
    model="openai:gpt-4o",
    memories=[knowledge_base],
)
```

## Agent properties

### Name

An agent's name is an identifier that is visible to other agents in the workflow. It is used to distinguish between agents and for logging and debugging purposes. If no name is provided, one will be randomly chosen from a list of famous AI characters.

### Description

A description is a brief summary of the agent's role or specialization. This information is visible to other agents, and helps them understand the agent's capabilities and expertise.

### Instructions

Instructions are specific instructions or guidelines for the agent to follow during task execution. These instructions are private and not shared with other agents.

### Tools

Tools are Python functions that the agent can call to perform specific actions or computations. They are defined as a list of functions when creating an agent, and can be used to enhance the agent's capabilities. The agent will have access to these tools in every task they are assigned to. If a task defines additional tools, the agent will have access to those as well.

### Model

Each agent has a model, which is the LLM that powers the agent responses. This allows you to choose the most suitable model for your needs, based on factors such as performance, latency, and cost.

Marvin supports any model that is compatible with Pydantic AI. You can specify models using a string format like "openai:gpt-4" or by providing a Model instance:

```python
import marvin
from pydantic_ai.models import OpenAIModel

# Using a string identifier
agent1 = marvin.Agent(model="openai:gpt-4")

# Using a model instance
model = OpenAIModel(name="gpt-4")
agent2 = marvin.Agent(model=model)
```

### Model Settings

You can customize the behavior of an agent's model using the `model_settings` parameter. This allows you to configure settings like temperature, top_p, etc:

```python
import marvin

agent = marvin.Agent(
    name="Creative Writer",
    model="openai:gpt-4o",
    model_settings={"temperature": 0.8}
)
```

### Memories

Agents can be configured with memories that provide additional context or knowledge. These memories persist across tasks and can be used to store and retrieve relevant information:

```python
import marvin
from marvin.memory import Memory

knowledge_base = Memory(key="documentation")

agent = marvin.Agent(
    name="Support Agent",
    memories=[knowledge_base]
)
```

## Assigning agents to tasks

Agents must be assigned to tasks in order to work on them. You can assign agents by passing them to the `agents` parameter when creating a task:

```python
import marvin

agent = marvin.Agent(name="Poet")
task = marvin.Task(
    instructions="Write a poem about AI",
    agents=[agent]
)
```

If no agent is specified, Marvin will use the default agent configured in your settings.

You can also use the agent's `say` method for simple conversational interactions:

```python
import marvin

agent = marvin.Agent(name="Assistant")
response = agent.say("What is the meaning of life?")
print(response)
```

--- docs/guides/building-a-chatbot.mdx ---
---
title: Building a Conversational Assistant
description: Create a personalized chatbot with memory and specialized knowledge
icon: message-bot
---

In this guide, we'll build a conversational assistant (chatbot) using Marvin. Our assistant will:

1. Maintain conversation context across multiple turns
2. Remember user preferences and facts
3. Respond in a consistent persona
4. Access external data when needed

This is a common use case for Marvin, and demonstrates how to combine threads, memory, agents, and tools into a cohesive application.

## Setting Up

First, ensure you have Marvin installed:

```bash
pip install marvin
```

Set up your API key (OpenAI is used by default):

```bash
export OPENAI_API_KEY="your-api-key"
```

## Creating the Assistant

Let's start by defining our assistant's persona and capabilities:

```python
import marvin
from marvin import Agent, Memory, Thread

# Create a memory for user preferences
user_memory = Memory(
    key="user_preferences",
    instructions="Remember information about the user, including their name, preferences, and any personal details they share."
)

# Create a memory for factual knowledge
knowledge_memory = Memory(
    key="assistant_knowledge",
    instructions="Store factual information about the world, products, services, or any domain-specific knowledge."
)

# Define our assistant
assistant = Agent(
    name="Helpful Assistant",
    instructions="""
    You are a friendly, helpful assistant. 
    Your tone is conversational but professional.
    Always be truthful and admit when you don't know something.
    If the user asks about preferences they've previously shared, refer to them.
    """,
    memories=[user_memory, knowledge_memory]
)
```

## Basic Conversation Loop

Now, let's implement a simple conversation loop:

```python
def chat():
    """Run a conversation with the assistant."""
    print("âœ¨ Assistant: Hello! How can I help you today? (type 'exit' to quit)")
    
    # Create a thread to maintain conversation context
    with Thread() as thread:
        while True:
            # Get user input
            user_input = input("ðŸ§‘ You: ")
            
            # Check for exit command
            if user_input.lower() in ('exit', 'quit', 'bye'):
                print("âœ¨ Assistant: Goodbye! Have a great day!")
                break
            
            # Process the input and get a response
            response = assistant.run(user_input)
            
            # Display the response
            print(f"âœ¨ Assistant: {response}")

if __name__ == "__main__":
    chat()
```

Try running this code and having a conversation. The assistant will remember information from earlier in the conversation because of the Thread context.

## Adding External Tools

Let's enhance our assistant by giving it some tools to access external information:

```python
import datetime
import requests

def get_current_time() -> str:
    """Get the current date and time."""
    now = datetime.datetime.now()
    return now.strftime("%Y-%m-%d %H:%M:%S")

def get_weather(location: str) -> str:
    """Get the current weather for a location (simulated)."""
    # In a real app, you'd use a weather API
    return f"It's currently sunny and 72Â°F in {location}."

def search_web(query: str) -> str:
    """Search the web for information (simulated)."""
    # In a real app, you'd use a search API
    return f"Here are some results for '{query}': [simulated search results]"

# Update our assistant with tools
assistant = Agent(
    name="Helpful Assistant",
    instructions="""
    You are a friendly, helpful assistant. 
    Your tone is conversational but professional.
    Always be truthful and admit when you don't know something.
    If the user asks about preferences they've previously shared, refer to them.
    Use your tools when needed to provide up-to-date information.
    """,
    memories=[user_memory, knowledge_memory],
    tools=[get_current_time, get_weather, search_web]
)
```

Now when the user asks for the time, weather, or information that might be found online, the assistant can provide that information.

## Persistent Personalization

Let's add some code to initialize the assistant with personalized knowledge about the user:

```python
import asyncio

async def initialize_assistant(name: str, preferences: dict = None):
    """Initialize the assistant with knowledge about the user."""
    # Add basic information about the user
    await user_memory.add(f"The user's name is {name}.")
    
    # Add preferences if provided
    if preferences:
        for category, pref in preferences.items():
            await user_memory.add(f"The user prefers {pref} for {category}.")
    
    print(f"Assistant initialized for user: {name}")

# Example usage
async def setup():
    await initialize_assistant(
        name="Alex",
        preferences={
            "communication style": "concise",
            "topics": "technology and science",
            "greeting": "Hi there"
        }
    )

# Run the setup
asyncio.run(setup())
```

After running this initialization, the assistant will remember the user's name and preferences across conversations, even if you restart the program (as long as the memory database persists).

## Complete Implementation

Here's the complete code for our conversational assistant:

```python
import marvin
from marvin import Agent, Memory, Thread
import asyncio
import datetime

# Create memories
user_memory = Memory(
    key="user_preferences",
    instructions="Remember information about the user, including their name, preferences, and any personal details they share."
)

knowledge_memory = Memory(
    key="assistant_knowledge",
    instructions="Store factual information about the world, products, services, or any domain-specific knowledge."
)

# Define tools
def get_current_time() -> str:
    """Get the current date and time."""
    now = datetime.datetime.now()
    return now.strftime("%Y-%m-%d %H:%M:%S")

def get_weather(location: str) -> str:
    """Get the current weather for a location (simulated)."""
    # In a real app, you'd use a weather API
    return f"It's currently sunny and 72Â°F in {location}."

def search_web(query: str) -> str:
    """Search the web for information (simulated)."""
    # In a real app, you'd use a search API
    return f"Here are some results for '{query}': [simulated search results]"

# Create the assistant
assistant = Agent(
    name="Helpful Assistant",
    instructions="""
    You are a friendly, helpful assistant. 
    Your tone is conversational but professional.
    Always be truthful and admit when you don't know something.
    If the user asks about preferences they've previously shared, refer to them.
    Use your tools when needed to provide up-to-date information.
    """,
    memories=[user_memory, knowledge_memory],
    tools=[get_current_time, get_weather, search_web]
)

async def initialize_assistant(name: str, preferences: dict = None):
    """Initialize the assistant with knowledge about the user."""
    # Add basic information about the user
    await user_memory.add(f"The user's name is {name}.")
    
    # Add preferences if provided
    if preferences:
        for category, pref in preferences.items():
            await user_memory.add(f"The user prefers {pref} for {category}.")
    
    print(f"Assistant initialized for user: {name}")

def chat():
    """Run a conversation with the assistant."""
    print("âœ¨ Assistant: Hello! How can I help you today? (type 'exit' to quit)")
    
    # Create a thread to maintain conversation context
    with Thread(id="user_conversation") as thread:
        while True:
            # Get user input
            user_input = input("ðŸ§‘ You: ")
            
            # Check for exit command
            if user_input.lower() in ('exit', 'quit', 'bye'):
                print("âœ¨ Assistant: Goodbye! Have a great day!")
                break
            
            # Process the input and get a response
            response = assistant.run(user_input)
            
            # Display the response
            print(f"âœ¨ Assistant: {response}")

async def main():
    # Initialize with user info (only needed once)
    await initialize_assistant(
        name="Alex",
        preferences={
            "communication style": "concise",
            "topics": "technology and science",
            "greeting": "Hi there"
        }
    )
    
    # Start the chat
    chat()

if __name__ == "__main__":
    asyncio.run(main())
```

## Enhancing the Assistant

Here are some ways to enhance your conversational assistant:

### Multiple Specialized Agents

For more complex assistants, you can create a team of specialized agents:

```python
researcher = Agent(name="Researcher", instructions="Research facts thoroughly")
writer = Agent(name="Writer", instructions="Write engaging, clear responses")
fact_checker = Agent(name="Fact Checker", instructions="Verify information for accuracy")

from marvin import Swarm
assistant_team = Swarm([researcher, writer, fact_checker])

# Use the team instead of a single agent
response = assistant_team.run(user_input)
```

### Adding a Web Interface

You can integrate your assistant with a web framework like FastAPI:

```python
from fastapi import FastAPI, WebSocket
from fastapi.responses import HTMLResponse
import uvicorn
import json

app = FastAPI()

# Serve a simple HTML page with a chat interface
@app.get("/")
async def get():
    html = """
    <!DOCTYPE html>
    <html>
        <head>
            <title>Marvin Chat</title>
            <style>
                #chat { margin: 0 auto; width: 600px; }
                #messages { height: 400px; overflow-y: scroll; border: 1px solid #ccc; padding: 10px; }
                #input { width: 500px; padding: 5px; }
                .user { color: blue; }
                .assistant { color: green; }
            </style>
        </head>
        <body>
            <div id="chat">
                <div id="messages"></div>
                <input id="input" type="text" placeholder="Type a message...">
                <button onclick="sendMessage()">Send</button>
            </div>
            <script>
                const ws = new WebSocket("ws://localhost:8000/ws");
                
                ws.onmessage = function(event) {
                    const messages = document.getElementById('messages');
                    const data = JSON.parse(event.data);
                    messages.innerHTML += `<div class="${data.sender}"><strong>${data.sender}:</strong> ${data.message}</div>`;
                    messages.scrollTop = messages.scrollHeight;
                };
                
                function sendMessage() {
                    const input = document.getElementById('input');
                    if (input.value) {
                        ws.send(input.value);
                        input.value = '';
                    }
                }
                
                document.getElementById('input').addEventListener('keypress', function(e) {
                    if (e.key === 'Enter') {
                        sendMessage();
                    }
                });
            </script>
        </body>
    </html>
    """
    return HTMLResponse(html)

# WebSocket endpoint for the chat
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    
    # Create a thread for this conversation
    with Thread() as thread:
        # Send a greeting
        await websocket.send_text(json.dumps({
            "sender": "assistant",
            "message": "Hello! How can I help you today?"
        }))
        
        while True:
            try:
                # Receive message from the client
                user_message = await websocket.receive_text()
                
                # Send acknowledgment that we received the message
                await websocket.send_text(json.dumps({
                    "sender": "user",
                    "message": user_message
                }))
                
                # Get response from assistant
                response = assistant.run(user_message)
                
                # Send response to the client
                await websocket.send_text(json.dumps({
                    "sender": "assistant",
                    "message": response
                }))
            except Exception as e:
                print(f"Error: {e}")
                break

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

To run this, you'd need to install FastAPI and Uvicorn:

```bash
pip install fastapi uvicorn
```

## Best Practices

When building conversational assistants with Marvin, keep these best practices in mind:

1. **Persona Consistency**: Give your assistant clear instructions about its tone and personality.

2. **Memory Management**: Use separate memory modules for different types of information (user preferences, domain knowledge, etc.)

3. **Conversation Context**: Always use a Thread to maintain context across multiple turns.

4. **Error Handling**: Add try/except blocks around AI calls to handle potential errors gracefully.

5. **User Privacy**: Be mindful of what information you store in memory, and consider adding options for users to delete their data.

6. **Feedback Loops**: Add mechanisms for users to provide feedback on the assistant's responses.

7. **Iterative Improvement**: Monitor conversations and regularly update your assistant's instructions and knowledge.

By following these guidelines, you can create a conversational assistant that provides helpful, personalized responses while maintaining a consistent persona. 

--- docs/functions/cast.mdx ---
---
title: Cast
description: Convert data between types while preserving meaning
icon: right-to-bracket
---

The `cast` function is your bridge between natural language and structured data types. It transforms `str â†’ T` while preserving meaning, making it easy to convert:
- Natural numbers ("three point five" â†’ 3.5)
- Casual responses ("sounds good" â†’ True)
- Time expressions ("next Tuesday" â†’ datetime)
- Rich descriptions ("John is 25" â†’ Person(name="John", age=25))

For complex transformations, consider creating a custom task. The `cast` function is a convenient wrapper around Marvin's task system - see [Tasks](/concepts/tasks) for more details.

## Usage

Convert natural language descriptions of numbers into their numeric representation:

```python
import marvin

# Convert text to a number
price = marvin.cast("three dollars and fifty cents", float)
print(price)
```

```python
3.5
```

## Parameters

- `data`: The input data to convert (any type)
- `target`: The target type to convert to (defaults to `str`)
- `instructions`: Optional instructions to guide the conversion
- `agent`: Optional custom agent to use
- `thread`: Optional thread for conversation context
- `context`: Optional additional context

## Async Support

The function is also available in an async version:

```python
import marvin
import asyncio

async def main():
    result = await marvin.cast_async(
        "three point five",
        float
    )
    print(result)  # 3.5

asyncio.run(main())
```

## Examples

### Converting Numbers

Convert natural language descriptions of quantities into numeric values:

```python
import marvin

price = marvin.cast("three dollars and fifty cents", float)
print(price)
```

```python
3.5
```

### Boolean Conversion

Interpret natural language expressions as boolean values:

```python
import marvin

answer = marvin.cast("that sounds great!", bool)
print(answer)
```

```python
True
```

### Structured Data

Extract structured information from natural language descriptions:

```python
import marvin
from dataclasses import dataclass

@dataclass
class Address:
    street: str
    city: str
    country: str

address = marvin.cast(
    "123 Main St in New York, USA",
    Address
)
print(f"{address.street}, {address.city}, {address.country}")
```

```python
"123 Main St", "New York", "USA"
```

### Custom Instructions

Use instructions to control how text is interpreted and formatted:

```python
from typing import Annotated
import marvin
from pydantic import Field

phone = marvin.cast(
    "call me at 800-555-0123",
    Annotated[str, Field(pattern=r"\d{1}-\d{3}-\d{3}-\d{4}")],
    instructions="extract the phone number and assume the country code is 1"
)
print(phone)
```

```python
"1-800-555-0123"
``` 

## Links discovered
- [Tasks](https://github.com/prefecthq/marvin/blob/main/concepts/tasks.md)

--- docs/functions/classify.mdx ---
---
title: Classify
description: Assign data to predefined categories
icon: tags
---

The `classify` function turns any input into clear categories. It transforms `str â†’ L` where `L` is your set of labels, making it easy to identify:
- Sentiment ("Great product!" â†’ Positive)
- Topics ("AI in healthcare" â†’ [Technology, Healthcare])
- Priority ("URGENT: System down" â†’ Critical)
- Status ("All tests passing" â†’ Success)

For complex classification needs, consider creating a custom task. The `classify` function is a convenient wrapper around Marvin's task system - see [Tasks](/concepts/tasks) for more details.

## Usage

Classify text into predefined categories:

```python
import marvin

sentiment = marvin.classify(
    "This product is amazing!",
    ["positive", "negative", "neutral"]
)
print(sentiment)
```

```python
"positive"
```

## Parameters

- `data`: The input data to classify (any type)
- `labels`: Either a sequence of labels or an Enum class
- `multi_label`: Whether to return multiple labels (defaults to `False`)
- `instructions`: Optional instructions to guide classification
- `agent`: Optional custom agent to use
- `thread`: Optional thread for conversation context
- `context`: Optional additional context

## Async Support

The function is also available in an async version:

```python
import marvin
import asyncio

async def main():
    result = await marvin.classify_async(
        "The weather is sunny and warm",
        ["sunny", "rainy", "cloudy"]
    )
    print(result)  # "sunny"

asyncio.run(main())
```

## Examples

### Basic Classification

Use simple string labels to categorize content:

```python
import marvin

priority = marvin.classify(
    "Critical system failure",
    ["low", "medium", "high", "critical"]
)
print(priority)
```

```python
"critical"
```

### Using Enums

Add type safety with Python enums:

```python
import marvin
from enum import Enum

class Priority(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

priority = marvin.classify(
    "Minor UI bug in non-critical component",
    Priority
)
print(priority)
print(priority.value)
```

```python
Priority.LOW
"low"
```

### Multi-label Classification

Identify multiple applicable categories:

```python
import marvin

genres = marvin.classify(
    "A romantic comedy about AI",
    ["comedy", "romance", "sci-fi", "drama", "action"],
    multi_label=True
)
print(genres)
```

```python
["comedy", "romance", "sci-fi"]
```

### Custom Instructions

Guide the classification with specific criteria:

```python
import marvin

sentiment = marvin.classify(
    "This product is okay",
    ["positive", "negative"],
    instructions="Classify as positive only if explicitly enthusiastic"
)
print(sentiment)
```

```python
"negative"
``` 

## Links discovered
- [Tasks](https://github.com/prefecthq/marvin/blob/main/concepts/tasks.md)

--- docs/guides/cli.mdx ---
# Marvin CLI

Marvin comes with a powerful command-line interface that helps you interact with AI capabilities right from your terminal. This guide shows you how to use the CLI for everyday tasks and advanced operations.

<Tip>
If you're new to Marvin, the CLI is often the fastest way to experiment with its capabilities!
</Tip>

## Getting Started

The CLI is bundled with Marvin, so you already have it if you've installed the package:

```bash
pip install marvin
```

To check if everything's working properly, try running:

```bash
marvin version
```

## Core Commands

### Version Check

When you need to know which version you're running or for troubleshooting:

```bash
marvin version
```

<Accordion title="Example Output">
```
Marvin version:     0.12.0
Pydantic AI version: 0.7.1
Python version:     3.10.12
Platform:          macOS-14.1.1-arm64-arm-64bit
Path:              ~/Developer/marvin
```
</Accordion>

### The Versatile `x` Command

The `x` command is your Swiss Army knife for working with AI. You can use it to extract information, cast data to different types, or generate content â€” all through the power of large language models.

<CodeGroup>
```bash Extract Data
echo "Apples cost $2.50, oranges cost $3.00, and bananas cost $1.75" | marvin x -t "list[float]"
```

```bash Cast Types
echo "42.5" | marvin x -o cast -t "int"
```

```bash Generate Content
echo "Write a haiku about coding" | marvin x -o generate -t "str"
```
</CodeGroup>

<Accordion title="Example Outputs">
```json Extract Result
[2.5, 3.0, 1.75]
```

```json Cast Result
42
```

```json Generate Result
"Fingers on keyboard\nLogic flows through silent thoughts\nCode brings dreams to life"
```
</Accordion>

#### What can you do with it?

The `x` command fits perfectly into data pipelines and shell scripts. You can:

- Extract structured data from unstructured text
- Convert between data types intelligently
- Generate content based on instructions

<Info>
The `x` command is designed to be part of Unix pipelines. It reads from stdin and outputs JSON to stdout, so you can easily chain it with tools like `jq` for further processing.
</Info>

#### Command Options

| Option | Description | Default |
|--------|-------------|---------|
| `-o, --operation` | Operation to perform (`extract`, `cast`, or `generate`) | `extract` |
| `-t, --type` | Target type (use Python syntax like `str`, `int`, `list[str]`) | `str` |
| `-i, --instructions` | Custom instructions for the operation | None |
| `-n, --n` | Number of results to generate (only for `generate`) | 1 |

#### Real-world Examples

<CodeGroup>
```bash Extract Prices
# Get a list of prices from text
echo "Our products: Widget ($19.99), Gadget ($24.50), Thingamajig ($15)" | \
marvin x -t "list[float]" | jq
```

```bash Parse Dates
# Extract and standardize dates
echo "Meeting on Jan 5th, followup on February 10" | \
marvin x -t "list[datetime]" | jq
```

```bash Name Extraction
# Extract people's names from text
echo "Report prepared by John Smith and reviewed by Jane Doe" | \
marvin x -t "list[str]" -i "Extract people's names" | jq
```
</CodeGroup>

<Accordion title="Example Outputs">
```json Price Extraction
[19.99, 24.50, 15.0]
```

```json Date Parsing
["2024-01-05T00:00:00", "2024-02-10T00:00:00"]
```

```json Name Extraction
["John Smith", "Jane Doe"]
```
</Accordion>

## Database Management

Marvin's CLI includes powerful commands for managing the database that stores your AI interactions, threads, and more.

<Warning>
Always back up your database before running migrations in production environments!
</Warning>

### Quick Commands

<CodeGroup>
```bash Check Status
# See your database status
marvin db status
```

```bash Apply Migrations
# Update your database schema
marvin db upgrade
```

```bash View History
# See migration history
marvin db history
```
</CodeGroup>

<Accordion title="Example Output">
```
DATABASE CONFIGURATION
Database URL:     sqlite:///home/user/.marvin/marvin.db
Database Type:    SQLite

MIGRATION STATUS
Current Revision: e772a112ae87
Head Revision:    e772a112ae87
Status:           Database is up to date
```
</Accordion>

For complete details on database management, check out the [Database Migrations](./database-migrations.mdx) guide.

## Developer Tools

If you're developing with Marvin or contributing to the project, you'll find these commands particularly helpful.

### Development Commands

The `dev` subcommand contains tools specifically designed for development purposes:

<CodeGroup>
```bash Create Migration
# Create an empty migration
marvin dev db revision -m "Add user settings"
```

```bash Auto Migration
# Auto-generate migration based on model changes
marvin dev db revision --autogenerate -m "Add timestamps"
```
</CodeGroup>

<Tip>
When using `--autogenerate`, always review the generated migration scripts before applying them. Automatic detection might miss complex changes or relationships.
</Tip>

## CLI Power Techniques

### Environment Variables

You can customize Marvin's behavior for a single command by setting environment variables:

```bash
MARVIN_LOG_LEVEL=DEBUG marvin db status
```

Common variables:
- `MARVIN_LOG_LEVEL`: Control logging verbosity (`DEBUG`, `INFO`, `WARNING`, etc.)
- `MARVIN_DATABASE_URL`: Override the database connection string
- `MARVIN_AI_PROVIDER`: Change the AI provider for the session

### Piping with jq

The `jq` tool pairs perfectly with Marvin's CLI for processing JSON output:

```bash
# Extract data and get just the first item
echo "orange, apple, banana" | marvin x -t "list[str]" | jq '.[0]'

# Generate multiple items and format as a comma-separated list
echo "planets" | marvin x -o generate -t "list[str]" -n 1 | jq -r '.[]' | paste -sd,
```

<Accordion title="Example Output">
```
"orange"
```

```
Mercury,Venus,Earth,Mars,Jupiter,Saturn,Uranus,Neptune
```
</Accordion>

### Scripting with Marvin

You can integrate Marvin into your shell scripts for powerful automation:

```bash
#!/bin/bash
# Example: Summarize a file with Marvin
cat long_document.txt | marvin x -o generate -t "str" -i "Summarize this text" > summary.txt
```

## Troubleshooting

<Accordion title="Common Issues">
### Command not found
Make sure Marvin is installed and your PATH includes the Python bin directory.

### Error with the x command
When using the `x` command with debug logging enabled, you might see an error. Try:
```bash
MARVIN_LOG_LEVEL=CRITICAL marvin x -t "str"
```

### Database connection issues
Check your database URL configuration with `marvin db status`.
</Accordion>

## Get Help

The CLI has built-in help for all commands. Just add `--help` to any command:

```bash
marvin --help
marvin x --help
marvin db --help
```

<Info>
Want to see a new CLI feature? Let us know in the [GitHub repository](https://github.com/prefecthq/marvin/issues)!
</Info> 

## Links discovered
- [Database Migrations](https://github.com/prefecthq/marvin/blob/main/docs/guides/database-migrations.mdx)
- [GitHub repository](https://github.com/prefecthq/marvin/issues)

--- examples/prefect_observability/README.md ---
# Prefect + OpenAI Observability

> **Note:** This is a beta feature (`marvin.beta.observability.openai`) and only
> works with OpenAI models.

This example shows how to trace Marvin agent calls back to Prefect flow and task
runs in OpenAI's observability dashboard.

## Why?

When running AI workloads in production with Prefect, you often want to answer
questions like:

- "Which flow run made this expensive GPT-4 call?"
- "How much did AI inference cost for deployment X last week?"
- "Why did this task fail? What did the AI actually return?"

This integration automatically captures Prefect runtime context (flow_run_id,
task_run_id, deployment name, etc.) and sends it to OpenAI as request metadata.
You can then filter and search in OpenAI's logs dashboard.

## Installation

```bash
uv add "marvin[prefect]"
```

Or with pip:

```bash
pip install "marvin[prefect]"
```

## Usage

The main function is `observable()`. Wrap your agent with it inside a Prefect
task to capture the current context:

```python
from prefect import flow, task
import marvin
from marvin.beta.observability.openai import observable

agent = marvin.Agent(name="analyst", model="openai:gpt-4o")

@task
async def summarize(text: str) -> str:
    return await observable(agent).run_async(f"Summarize: {text}")

@flow
async def my_pipeline(document: str):
    return await summarize(document)
```

## What gets captured

When you call `observable(agent)` inside a Prefect run:

| Metadata Key | Example Value | Description |
|--------------|---------------|-------------|
| `prefect.flow_run.id` | `abc-123-def` | UUID of the flow run |
| `prefect.flow_run.name` | `happy-tiger` | Human-readable run name |
| `prefect.flow_run.flow_name` | `my-pipeline` | Name of the flow |
| `prefect.task_run.id` | `xyz-789` | UUID of the task run |
| `prefect.task_run.name` | `summarize-0` | Human-readable task run name |
| `prefect.task_run.task_name` | `summarize` | Name of the task function |
| `prefect.deployment.id` | `dep-456` | Deployment UUID (if deployed) |
| `prefect.deployment.name` | `prod-pipeline` | Deployment name (if deployed) |

## Viewing in OpenAI

1. Run your flow
2. Go to https://platform.openai.com/logs
3. Filter by any metadata field, e.g., `prefect.flow_run.id = abc-123-def`

## Running this example

```bash
cd examples/prefect_observability
uv run example.py
```

The script will print the flow_run_id at the end - use that to find the request
in OpenAI's logs.

## Advanced: Custom metadata

If you need to add business-specific metadata:

```python
@task
async def process(customer_id: str, text: str) -> str:
    return await observable(agent, customer_id=customer_id).run_async(text)
```

All custom metadata is merged with the Prefect context.


--- examples/slackbot/README.md ---
# Marvin Slackbot

A Slack chatbot powered by AI (GPT-5 or Claude) with memories and Prefect-specific knowledge.

## Project Structure

```
â”œâ”€â”€ api.py         # FastAPI app and Slack event handlers
â”œâ”€â”€ core.py        # Database, agent, and memory management
â”œâ”€â”€ settings.py    # Configuration management
â””â”€â”€ __main__.py    # Entry point
```

## Setup

The slackbot can be run locally with minimal setup.

### Local Development

```console
# Install dependencies (from the repo root)
uv sync --extra slackbot
```

### Configuration

Create a `.env` file in your project directory:

```env
# Required Prefect Secrets (configured via UI or CLI)
# - test-slack-api-token          # Bot User OAuth Token  
# - openai-api-key                # For OpenAI models (if using GPT-5)
# - anthropic-api-key             # For Claude models
# - marvin-slackbot-github-token  # For searching GitHub issues
# - tpuf-api-key                  # TurboPuffer API key for vector storage

# Required Prefect Variables (configured via UI or CLI)
# - marvin_ai_model               # Model to use (e.g., "gpt-5", "claude-3-5-sonnet-latest")
# - marvin_bot_model              # Optional override for specific bot model
# - admin-slack-id                # Slack user ID for admin notifications

# Optional Settings (with MARVIN_SLACKBOT_ prefix)
MARVIN_SLACKBOT_TEST_MODE=true                # Enable auto-reload for development
MARVIN_SLACKBOT_HOST=0.0.0.0                  # Server host
MARVIN_SLACKBOT_PORT=4200                     # Server port
MARVIN_SLACKBOT_LOG_LEVEL=INFO                # Logging level
MARVIN_SLACKBOT_SLACK_API_TOKEN=xoxb-...      # Slack bot token (or use test-slack-api-token secret)
MARVIN_SLACKBOT_MAX_TOOL_CALLS_PER_TURN=50    # Max tool calls per agent turn (default: 50)
MARVIN_SLACKBOT_USER_MESSAGE_MAX_TOKENS=500   # Max tokens in user messages (default: 500)
MARVIN_SLACKBOT_TEMPERATURE=0.2               # Model temperature (default: 0.2, auto-set to 1.0 for GPT-5)

# Vector Store (optional, will use tpuf-api-key secret if not set)
TURBOPUFFER_API_KEY=abcd1234       # For vectorstore queries and storing user context
```

### Slack App Setup

1. Create a new Slack app at https://api.slack.com/apps
2. Add a bot user with required scopes:
   - `app_mentions:read`
   - `channels:read`
   - `chat:write`
   - `groups:read`
   - `im:read`
   - `mpim:read`
3. Set up event subscriptions:
   - URL: `https://{YOUR_DOMAIN}/chat`
   - Subscribe to bot events: `app_mention`, `team_join`

### Running Locally

1. Start ngrok in one terminal:
```console
ngrok http 4200  # Or your configured port
```

2. Start the bot in another terminal:
```console
uv run --extra slackbot -m slackbot
```

### Testing

Mention the bot in any channel it's invited to:
```
@Marvin What's new in Prefect?
```

The bot will:
- Search Prefect documentation
- Look through GitHub issues
- Remember previous interactions
- Provide context-aware responses

### Model Configuration

The bot supports both OpenAI (GPT-5) and Anthropic (Claude) models. Configure via the `marvin_ai_model` Prefect Variable:
- `gpt-5`: Latest OpenAI model (temperature automatically set to 1.0)
- `claude-3-5-sonnet-latest`: Latest Claude model (default)
- Any other supported model name from either provider

### Channel Restrictions

The bot can be configured to only respond in designated channels per workspace. Users mentioning the bot in other channels will receive a redirect message. The workspace-to-channel mapping is configured in `_internal/constants.py`:

```python
WORKSPACE_TO_CHANNEL_ID = {
    "TL09B008Y": "C04DZJC94DC",  # Prefect Community -> #ask-marvin
    "TAN3D79AL": "C046WGGKF4P",  # Prefect -> #ask-marvin-tests
    # Add more workspace mappings as needed
}
```

### Development Features

- Auto-reload in test mode
- Colored logging output
- SQLite message history
- TurboPuffer vector storage for user context
- Configurable via environment variables or .env file

### Production Deployment

For deploying to Cloud Run or similar services, refer to:
- [Dockerfile.slackbot](/examples/slackbot/Dockerfile.slackbot)
- [CI/CD Configuration](/.github/workflows/image-build-and-push-community.yaml)

## Links discovered
- [Dockerfile.slackbot](https://github.com/prefecthq/marvin/blob/main/examples/slackbot/Dockerfile.slackbot)
- [CI/CD Configuration](https://github.com/prefecthq/marvin/blob/main/.github/workflows/image-build-and-push-community.yaml)

--- examples/you_have_been_goosed/README.md ---
### Prerequisites

Before running this example, you'll need [goose](https://block.github.io/goose) installed. If you don't have it installed, you can install it with:

```bash
curl -fsSL https://github.com/block/goose/releases/download/stable/download_cli.sh | bash
```

### Run this example

```bash
goose session --with-extension 'uv run examples/you_have_been_goosed/goose_em.py'
```


## Links discovered
- [goose](https://block.github.io/goose)

--- examples/agent_mcp.py ---
import asyncio
from pathlib import Path
from typing import Annotated, TypedDict

from pydantic import Field
from pydantic_ai.mcp import MCPServerStdio
from rich import print as pprint

import marvin


class Reflection(TypedDict):
    score: Annotated[int, Field(ge=0, le=100)]
    areas_for_improvement: list[str]


# Requires Deno: `deno install -A ... jsr:@pydantic/mcp-run-python`
run_python_server = MCPServerStdio(
    command="deno",
    args=["run", "-A", "jsr:@pydantic/mcp-run-python", "stdio"],
)

# Requires uv: `uvx mcp-server-git`
git_server = MCPServerStdio(
    command="uvx",
    args=["mcp-server-git"],
)


def write_summary_of_work(description: str, file_path: str) -> str:
    """log your efforts in your own style"""
    Path(file_path).write_text(description)
    return f"Summary written to {file_path}"


linus = marvin.Agent(
    name="Linus",
    instructions="Use the available tools as needed to accomplish the user's goal.",
    mcp_servers=[run_python_server, git_server],
    tools=[write_summary_of_work],
)


async def main():
    with marvin.Thread():
        pprint("\n--- Starting Agent Run ---")
        result = await linus.run_async(
            (
                "1. Get the latest commit hash from this repo using the git_log tool\n"
                "2. Report how many characters long the commit hash is\n"
                "3. Calculate the square root of that number with python\n"
                "finish with a haiku about your experience"
            )
        )
        pprint("\n--- Final Result ---")
        pprint(result)

        pprint("\n--- Reflection ---")
        pprint(
            await linus.run_async(
                "reflect on your work and write a short `summary.txt` file",
                result_type=Reflection,
            )
        )

        if Path("summary.txt").exists():
            input("\n--- As expected, summary.txt exists - hit enter to remove it")
            Path("summary.txt").unlink()
        else:
            raise RuntimeError("agent did not write summary.txt")


if __name__ == "__main__":
    asyncio.run(main())


--- examples/custom_handler.py ---
import marvin
from marvin.engine.events import UserMessageEvent
from marvin.handlers.print_handler import MessagePanel, PrintHandler


class ShowPromptHandler(PrintHandler):
    """
    Extends the default PrintHandler with a single override that
    prints the initial user prompt before the agent response.
    """

    def on_user_message(self, event: UserMessageEvent):
        raw = getattr(event.message, "content", event.message)
        content = (
            "\n".join(map(str, raw)) if isinstance(raw, (list, tuple)) else str(raw)
        )
        if not content:
            return

        panel_id = str(event.id)
        self.panels[panel_id] = MessagePanel(
            id=panel_id,
            agent_name="User",
            timestamp=self.format_timestamp(event.timestamp),
            content=content,
        )
        self.update_display()


if __name__ == "__main__":
    # run any marvin task with our custom handler
    marvin.summarize(
        "the entire kendrick-drake beef",
        handlers=[ShowPromptHandler()],
    )


--- examples/custom_prompt.py ---
from typing import Annotated, Literal, TypedDict

from pydantic import Field

import marvin
from marvin.fns.cast import DEFAULT_PROMPT


class Tornado(TypedDict):
    enhanced_fujita_scale: Literal[1, 2, 3, 4, 5]
    fatalities: int
    description: Annotated[str, Field(description="A short story about the tornado")]


if __name__ == "__main__":
    marvin.cast(
        "Joplin EF5",
        Tornado,
        prompt=(
            DEFAULT_PROMPT
            + "\n\n You're a history nerd who compares all new things to old things."
        ),
    )


--- examples/deepseek_chat.py ---
import asyncio
import signal
import sys
from pathlib import Path
from typing import Any, ClassVar

import httpx
from prompt_toolkit import PromptSession
from prompt_toolkit.auto_suggest import AutoSuggestFromHistory
from prompt_toolkit.history import FileHistory
from pydantic import Field, SecretStr
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.deepseek import DeepSeekProvider
from pydantic_settings import BaseSettings, SettingsConfigDict

from marvin import Agent, Thread
from marvin.settings import settings as marvin_settings

running: bool = True


def handle_sigint(signum: int, frame: Any) -> None:
    global running
    running = False


signal.signal(signal.SIGINT, handle_sigint)


class Settings(BaseSettings):
    model_config: ClassVar[SettingsConfigDict] = SettingsConfigDict(
        env_file=".env", extra="ignore"
    )

    deepseek_api_key: SecretStr = Field(default=...)
    google_api_key: SecretStr = Field(default=...)
    google_cx: SecretStr = Field(default=...)
    notes_file_path: str = Field(default="notes.txt")


settings = Settings()  # type: ignore # google_cx loaded from .env file


def google_search(query: str, num: int = 3) -> str:
    """Use google to search the internet.

    Args:
        query: The query to search for.
        num: The number of results to return (preferably 3)

    Returns:
        The results of the search.
    """
    response = httpx.get(
        "https://www.googleapis.com/customsearch/v1",
        params={
            "q": query,
            "key": settings.google_api_key.get_secret_value(),
            "cx": settings.google_cx.get_secret_value(),
            "num": num,
        },
    )
    response.raise_for_status()
    return response.json()


def write_to_file(content: str, file_path: str) -> None:
    """Write content to a file.

    Args:
        content: The content to write to the file
        file_path: The path to the file to write to (will be casted to a Path)
    """
    Path(file_path).write_text(content)


async def get_user_input(session: PromptSession[str]) -> str:
    try:
        return await session.prompt_async(
            "you âž¤ ",
            auto_suggest=AutoSuggestFromHistory(),
        )
    except (KeyboardInterrupt, EOFError):
        global running
        running = False
        return ""


async def main(model: str | None = None) -> int:
    try:
        history_file = marvin_settings.home_path / ".deepseek-history.txt"
        session = PromptSession[str](history=FileHistory(str(history_file)))

        agent = Agent(
            name="deepseek assistant",
            model=OpenAIModel(
                model or "deepseek-chat",
                provider=DeepSeekProvider(
                    api_key=settings.deepseek_api_key.get_secret_value(),
                ),
            ),
            tools=[google_search, write_to_file],
            prompt=f"""You are a helpful assistant that can search the internet for information.
            You can write notes in {settings.notes_file_path}.

            Find out what the user wants to do and help them with their request.
            """,
        )

        with Thread():
            while running:
                if not (user_input := await get_user_input(session)) or not running:
                    break
                if user_input.lower() in ("exit", "quit", ":q!"):
                    break
                await agent.run_async(user_input)
    except Exception as e:
        print(f"\nError: {e}")
        return 1
    finally:
        print("Goodbye!")

    return 0


if __name__ == "__main__":
    sys.exit(asyncio.run(main(sys.argv[1] if len(sys.argv) > 1 else None)))


## Links discovered
- [str](https://github.com/prefecthq/marvin/blob/main/examples/history=FileHistory(str(history_file.md)

--- examples/english_to_schema.py ---
from typing import Annotated, Any, TypedDict

from pydantic import Field, create_model

import marvin


class FieldDefinition(TypedDict):
    type: Annotated[
        str,
        Field(
            description="a string that can be eval()'d into a Python type",
            examples=["str", "int", "list[str]", "dict[str, int]"],
        ),
    ]
    description: str
    properties: dict[str, Any]


class CreateModelInput(TypedDict):
    model_name: str
    fields: dict[str, FieldDefinition]
    description: str


create_model_input = marvin.cast(
    "a Movie with a title, release year, and a list of actors",
    target=CreateModelInput,
    instructions="suitable inputs for pydantic.create_model for the described schema",
)

Movie = create_model(
    create_model_input["model_name"],
    __config__=None,
    __doc__=create_model_input["description"],
    __module__=__name__,
    __validators__=None,
    __cls_kwargs__=None,
    **{
        k: (eval(v["type"]), Field(description=v["description"]))
        for k, v in create_model_input["fields"].items()
    },
)

print(marvin.cast("red or blue pill", target=Movie).model_dump_json(indent=2))


--- examples/hello_agent.py ---
from pathlib import Path

import marvin


def write_to_file(content: str, filename: str):
    Path(filename).write_text(content)


def read_file(filename: str) -> str:
    return Path(filename).read_text()


def delete_file(filename: str):
    Path(filename).unlink()


def confirm_with_user(content: str) -> bool:
    """require 'y' or 'yes' to confirm"""
    return input(content).lower() in ("y", "yes")


if __name__ == "__main__":
    agent = marvin.Agent(
        tools=[write_to_file, read_file, delete_file, confirm_with_user],
        prompt="use your tools to help the user with their request",
    )
    agent.run(
        (
            "write a file called 'test.txt' with content 'hello world',"
            "read the file"
            "and then delete the file if the user confirms this"
        ),
    )


--- examples/hello_cast.py ---
import asyncio
from typing import Literal

from pydantic import BaseModel, Field

import marvin


class AllergyFormatA(BaseModel):
    substance: str = Field(description="Name of the allergic substance")
    severity: str = Field(description="Severity level (mild, moderate, severe)")
    reaction: str = Field(description="Type of allergic reaction")
    dateIdentified: str = Field(description="Date allergy was identified (YYYY-MM-DD)")


class AllergyFormatB(BaseModel):
    agent: str = Field(description="Name of the allergic substance")
    riskLevel: Literal["low", "medium", "high"] = Field(description="Risk level")
    manifestations: list[str] = Field(
        description="List of observed reactions",
        alias="clinicalManifestations",
    )
    documentation_date: str = Field(
        description="Date allergy was documented (YYYY-MM-DD)",
        alias="documentationDate",
    )


async def main():
    allergy_record_a = AllergyFormatA(
        substance="penicillin",
        severity="severe",
        reaction="anaphylaxis",
        dateIdentified="2020-01-01",
    )

    allergy_record_b = await marvin.cast_async(
        allergy_record_a,
        AllergyFormatB,
        instructions="Convert Epic allergy record to Cerner format. Map 'severe' severity to 'high' risk. Format reaction as a list.",
    )
    print(f"Converted to format B: {allergy_record_b}")


if __name__ == "__main__":
    asyncio.run(main())
"""
Â» python examples/hello_cast.py
â•­â”€ Marvin â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ â ‹   Final Result                                                                                 â”‚
â”‚     Input:   {                                                                                   â”‚
â”‚                'response': {                                                                     â”‚
â”‚                  'task_id': '895be677-29f6-4642-ac99-d63171a46444',                              â”‚
â”‚                  'result': {                                                                     â”‚
â”‚                    'agent': 'penicillin',                                                        â”‚
â”‚                    'riskLevel': 'high',                                                          â”‚
â”‚                    'clinicalManifestations': [                                                   â”‚
â”‚                      'anaphylaxis'                                                               â”‚
â”‚                    ],                                                                            â”‚
â”‚                    'documentationDate': '2020-01-01'                                             â”‚
â”‚                  }                                                                               â”‚
â”‚                }                                                                                 â”‚
â”‚              }                                                                                   â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 12:23:47 AM â”€â•¯
Converted to format B: agent='penicillin' riskLevel='high' manifestations=['anaphylaxis'] documentation_date='2020-01-01'
"""


--- scripts/create_mintlify_api_ref.py ---
"""
Complete API Documentation Generator using Griffe

Extracts Python module structures and generates well-formatted Markdown documentation
for all modules, submodules, and individual Python files.
"""

import argparse
import importlib
import json
import pkgutil
import sys
from collections import defaultdict
from pathlib import Path
from typing import TYPE_CHECKING, Any, cast

import griffe
from griffe import (
    Class,
    Function,
    Module,
    ObjectKind,
    Parameter,
    ParameterKind,
)


def trim_docstring(docstring: str | None) -> str:
    if not docstring or not docstring.strip():
        return ""

    lines = docstring.expandtabs().splitlines()
    stripped_lines = [line for line in lines if line.strip()]

    if not stripped_lines:
        return ""

    indent = min((len(line) - len(line.lstrip()) for line in stripped_lines), default=0)
    trimmed = [lines[0].lstrip()] + [line[indent:].rstrip() for line in lines[1:]]

    return "\n".join(trimmed).strip()


def format_signature(obj: Function | Class) -> str:
    kind = "class" if isinstance(obj, Class) else "def"
    name = obj.name
    param_strs: list[str] = []

    parameters: list[Parameter] = []
    if isinstance(obj, Function):
        parameters = obj.parameters  # type: ignore
    elif hasattr(obj, "members"):
        init_method = obj.members.get("__init__")
        if init_method and isinstance(init_method, Function):
            parameters = init_method.parameters  # type: ignore

    skip_init_self = isinstance(obj, Class)

    for i, param in enumerate(parameters):
        if skip_init_self and i == 0:
            continue

        param_str = param.name

        if param.annotation:
            annotation_str = (
                str(param.annotation).replace("<", "&lt;").replace(">", "&gt;")
            )
            param_str += f": {annotation_str}"

        if param.default:
            param_str += f" = {param.default}"

        if param.kind == ParameterKind.var_positional:
            param_str = f"*{param_str}"
        elif param.kind == ParameterKind.var_keyword:
            param_str = f"**{param_str}"

        param_strs.append(param_str)

    return_annotation = ""
    if isinstance(obj, Function) and obj.returns:
        ret_ann_str = str(obj.returns).replace("<", "&lt;").replace(">", "&gt;")
        if ret_ann_str != "None":
            return_annotation = f" -> {ret_ann_str}"

    return f"{kind} {name}({', '.join(param_strs)}){return_annotation}"


def get_module_file_type(module_path: str) -> str:
    parts = module_path.split(".")
    if parts[-1] == "__init__":
        return "package"
    return "file"


def get_parent_module(module_path: str) -> str:
    parts = module_path.split(".")
    if len(parts) <= 1:
        return ""
    if parts[-1] == "__init__":
        return ".".join(parts[:-2]) if len(parts) > 2 else ""
    return ".".join(parts[:-1])


def find_all_modules(package_name: str) -> list[str]:
    """
    Find all modules in the package including both submodules and direct files.
    Uses pkgutil.walk_packages to discover all submodules recursively.
    Also explicitly checks for standalone .py files in the top-level package directory.
    """
    try:
        package = importlib.import_module(package_name)
        modules: list[str] = []

        # Get the package path
        if hasattr(package, "__path__"):
            package_path = package.__path__
        else:
            return []

        # Find all modules recursively using pkgutil
        for _, module_name, _ in pkgutil.walk_packages(
            package_path, package_name + "."
        ):
            if "._" in module_name or module_name.startswith("_"):
                continue

            modules.append(module_name)

        # Always include the base package itself
        if package_name not in modules:
            modules.append(package_name)

        return sorted(modules)
    except Exception as e:
        print(f"Error finding modules: {e}")
        return []


def get_module_title(module_path: str, default_package_name: str) -> str:
    parts = module_path.split(".")

    if parts[-1] == "__init__":
        return parts[-2] if len(parts) > 1 else default_package_name

    return parts[-1]


def module_path_to_file_path(module_path: str) -> str:
    """Convert a module path to a documentation file path."""
    if module_path.endswith(".__init__"):
        module_path = module_path[:-9]

    return module_path.replace(".", "-") + ".mdx"


def create_link(module_path: str) -> str:
    """Create a link to a module's documentation."""
    if module_path.endswith(".__init__"):
        module_path = module_path[:-9]

    return module_path.replace(".", "-")


def generate_module_docs(
    module: Module,
    output_dir: Path,
    all_module_paths: list[str],
    default_package_name: str,
) -> str | None:
    """Generate documentation for a single module."""
    module_path = module.canonical_path

    if "._" in module_path:
        return None

    md_filename = module_path_to_file_path(module_path)
    md_path = output_dir / md_filename
    md_path.parent.mkdir(parents=True, exist_ok=True)

    page_title = get_module_title(module_path, default_package_name)
    page_description = ""

    module_doc = trim_docstring(module.docstring.value if module.docstring else None)
    if module_doc:
        first_line = module_doc.split("\n")[0].strip()
        if first_line:
            page_description = first_line.replace('"', "'")

    content_sections: list[str] = []
    if module_doc:
        content_sections.append(module_doc)

    # Find direct submodules (not just immediate children)
    submodules: list[str] = []
    base_prefix = module_path + "."
    for m in all_module_paths:
        if m != module_path and m.startswith(base_prefix) and "._" not in m:
            # Get the next segment after the module_path
            remainder = m[len(base_prefix) :].split(".", 1)[0]
            submodule = f"{module_path}.{remainder}"
            if submodule not in submodules:
                submodules.append(submodule)

    submodules.sort()

    if submodules:
        content_sections.append("\n## Submodules")
        submodule_links: list[str] = []
        for submodule_path in submodules:
            submodule_name = submodule_path.split(".")[-1]
            submodule_link = create_link(submodule_path)
            submodule_links.append(f"- [`{submodule_name}`]({submodule_link})")
        content_sections.append("\n".join(submodule_links))

    classes: list[Class] = []
    functions: list[Function] = []
    constants: list[tuple[str, Any, Any]] = []  # (name, value, member) tuples

    for name, member in module.members.items():
        if name.startswith("_") and name != "__init__":
            continue
        if member.is_alias:
            continue

        if member.kind == ObjectKind.CLASS:
            classes.append(cast(Class, member))
        elif member.kind == ObjectKind.FUNCTION:
            functions.append(cast(Function, member))
        # Check for constants (uppercase variables)
        elif name.isupper():
            # Try to get the value directly
            try:
                value = getattr(member, "value", None)
                constants.append((name, value, member))
            except Exception:
                # If that fails, just add the name
                constants.append((name, None, member))

    # Add constants section
    if constants:
        content_sections.append("\n## Constants")
        for name, value, member_obj in sorted(constants):
            content_sections.append(f"\n### `{name}`")
            # Format the value as code
            try:
                # Try to format the value neatly
                if isinstance(value, str):
                    value_str = f'"{value}"'
                elif value is not None:
                    value_str = str(value)
                else:
                    value_str = "None"
                content_sections.append(f"```python\n{name} = {value_str}\n```")
            except Exception:
                # Fallback if we can't format the value
                content_sections.append(f"```python\n{name}\n```")

            # Try to add docstring if available
            try:
                if hasattr(member_obj, "docstring") and member_obj.docstring:
                    docstring_value = getattr(member_obj.docstring, "value", None)
                    if docstring_value:
                        const_doc = trim_docstring(docstring_value)
                        if const_doc:
                            content_sections.append(const_doc)
            except Exception:
                # Skip docstring if we can't get it
                pass

    if classes:
        content_sections.append("\n## Classes")
        for cls in sorted(classes, key=lambda c: c.name):
            content_sections.append(f"\n### `{cls.name}`")
            content_sections.append(f"```python\n{format_signature(cls)}\n```")

            class_doc = trim_docstring(cls.docstring.value if cls.docstring else None)
            if class_doc:
                content_sections.append(class_doc)

            methods = [
                m
                for name, m in cls.members.items()
                if not name.startswith("_") and isinstance(m, Function)
            ]

            if methods:
                content_sections.append("\n**Methods:**\n")
                for method in sorted(methods, key=lambda m: m.name):
                    content_sections.append(f"- **`{method.name}`**")
                    content_sections.append(
                        f"  ```python\n  {format_signature(method)}\n  ```"
                    )

                    method_doc = trim_docstring(
                        method.docstring.value if method.docstring else None
                    )
                    if method_doc:
                        indented_doc = "\n".join(
                            f"  {line}" for line in method_doc.splitlines()
                        )
                        content_sections.append(indented_doc)

    if functions:
        content_sections.append("\n## Functions")
        for func in sorted(functions, key=lambda f: f.name):
            content_sections.append(f"\n### `{func.name}`")
            content_sections.append(f"```python\n{format_signature(func)}\n```")

            func_doc = trim_docstring(func.docstring.value if func.docstring else None)
            if func_doc:
                content_sections.append(func_doc)

    if not (module_doc or classes or functions or submodules or constants):
        content_sections.append(
            "\n*No public API documentation found for this module.*"
        )

    parent_module = get_parent_module(module_path)
    if parent_module:
        parent_link = create_link(parent_module)
        parent_name = parent_module.split(".")[-1]
        content_sections.append(
            f"\n---\n\n**Parent Module:** [`{parent_name}`]({parent_link})"
        )

    frontmatter = f"""---
title: {page_title}
"""
    if page_description:
        frontmatter += f'description: "{page_description}"\n'
    frontmatter += "---"

    display_module_path = module_path
    if display_module_path.endswith(".__init__"):
        display_module_path = display_module_path[:-9]

    final_content = [frontmatter, f"\n# `{display_module_path}`"] + content_sections

    md_path.write_text("\n".join(final_content) + "\n", encoding="utf-8")
    return md_path.relative_to(output_dir.parent).as_posix()


def organize_navigation(
    generated_files: list[str], package_name: str
) -> list[dict[str, Any]]:
    """
    Organize files into navigation groups by their top-level module.
    Each top-level module gets its own group with all its submodules.
    """
    path_to_module: dict[str, str] = {}

    for file_path in sorted(generated_files):
        path_obj = Path(file_path)
        module_path = path_obj.stem.replace("-", ".")
        path_to_module[file_path] = module_path

    top_level_groups: dict[str, list[str]] = defaultdict(list)

    for file_path, module_path in path_to_module.items():
        parts = module_path.split(".")

        if len(parts) > 1:
            # For marvin.X.Y.Z, the group is X
            group_name = parts[1]
            # Convert to file path without extension
            page_path = file_path.replace(".mdx", "")
            top_level_groups[group_name].append(page_path)
        elif len(parts) == 1 and parts[0] == package_name:
            # The main module goes to "top level"
            top_level_groups["top level"].append(file_path.replace(".mdx", ""))

    # Clean up the navigation structure to avoid duplicates
    result: list[dict[str, Any]] = []

    # First add the "top level" group if it exists
    if "top level" in top_level_groups:
        filtered_pages: list[str] = []
        for page in sorted(top_level_groups["top level"]):
            page_module = Path(page).stem.replace("-", ".")
            parts = page_module.split(".")

            # Skip if this page is the parent module itself (shouldn't happen for top level)
            if len(parts) == 2 and parts[1] == "top level":
                continue

            filtered_pages.append(page)

        result.append({"group": "top level", "pages": filtered_pages})

        # Remove the top level group so it's not added again
        top_level_groups.pop("top level")

    # Then add all other groups in alphabetical order
    for group_name, pages in sorted(top_level_groups.items()):
        filtered_pages: list[str] = []
        for page in sorted(pages):
            page_module = Path(page).stem.replace("-", ".")
            parts = page_module.split(".")

            # Skip if this page is the parent module itself
            if len(parts) == 2 and parts[1] == group_name:
                continue

            filtered_pages.append(page)

        result.append({"group": group_name, "pages": filtered_pages})

    return result


def update_navigation(
    docs_json_path: Path, generated_files: list[str], package_name: str
) -> bool:
    """Update the navigation structure in docs.json."""
    if not generated_files:
        print("No markdown files generated.")
        return False

    try:
        try:
            import commentjson

            with open(docs_json_path, "r", encoding="utf-8") as f:
                docs_config = commentjson.load(f)  # type: ignore
        except ImportError:
            with open(docs_json_path, "r", encoding="utf-8") as f:
                docs_config = json.load(f)
                print("Warning: Using standard JSON parser - comments may be lost.")

        navigation_groups = organize_navigation(generated_files, package_name)

        found_anchor = False
        if "navigation" in docs_config and "anchors" in docs_config["navigation"]:
            for anchor in docs_config["navigation"]["anchors"]:
                if not isinstance(anchor, dict):
                    continue

                if TYPE_CHECKING:
                    anchor = cast(dict[str, Any], anchor)

                if anchor.get("anchor") == "API Reference":
                    found_anchor = True
                    if "openapi" in anchor:
                        anchor.pop("openapi")
                    if "pages" in anchor:
                        anchor.pop("pages")
                    anchor["groups"] = navigation_groups
                    print(f"Updated API Reference anchor in {docs_json_path}")
                    break

        if not found_anchor:
            print(f"API Reference anchor not found in {docs_json_path}")
            return False

        with open(docs_json_path, "w", encoding="utf-8") as f:
            json.dump(docs_config, f, indent=4, ensure_ascii=False)
            f.write("\n")

        print(f"Updated {docs_json_path}")
        return True

    except Exception as e:
        print(f"Error updating {docs_json_path}: {e}")
        return False


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Generate API documentation for a package"
    )
    parser.add_argument("--package", default="marvin", type=str, help="Package name")
    parser.add_argument(
        "--default-package-name",
        default="marvin",
        type=str,
        help="Default package name",
    )
    parser.add_argument("--docs-dir", type=Path, default="docs", help="Docs directory")
    parser.add_argument("--src-dir", type=Path, default="src", help="Src directory")
    parser.add_argument(
        "--docs-json-file", type=Path, default="docs/docs.json", help="Docs JSON file"
    )
    parser.add_argument(
        "--api-ref-dir",
        type=Path,
        default="docs/api-reference",
        help="API Reference directory",
    )

    args = parser.parse_args()
    package_name = args.package
    src_dir = args.src_dir
    api_ref_dir = args.api_ref_dir
    docs_json_file = args.docs_json_file
    default_package_name = args.default_package_name

    print(f"Generating API documentation for '{package_name}' in {api_ref_dir}")
    api_ref_dir.mkdir(parents=True, exist_ok=True)

    if src_dir.exists() and (src_dir / package_name).is_dir():
        print(f"Using src layout for {package_name}")
        sys.path.insert(0, str(src_dir.absolute()))

    try:
        all_module_paths = find_all_modules(package_name)
        print(f"Found {len(all_module_paths)} modules")

        modules_data: dict[str, Module] = {}

        for module_path in all_module_paths:
            try:
                module_obj = griffe.load(module_path)
                if hasattr(module_obj, "kind") and module_obj.kind == ObjectKind.MODULE:
                    modules_data[module_path] = cast(Module, module_obj)
            except Exception:
                init_path = f"{module_path}.__init__"
                try:
                    init_module = griffe.load(init_path)
                    if (
                        hasattr(init_module, "kind")
                        and init_module.kind == ObjectKind.MODULE
                    ):
                        modules_data[init_path] = cast(Module, init_module)
                except Exception:
                    print(f"Failed to load {init_path}")
                    pass

        print(f"Loaded {len(modules_data)} modules")

    except ImportError as e:
        print(f"Error loading '{package_name}': {e}")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)

    print("Generating documentation...")
    generated_files: list[str] = []

    for module_path, module_obj in modules_data.items():
        if module_path.endswith(".__init__"):
            continue

        if result := generate_module_docs(
            module_obj,
            api_ref_dir,
            all_module_paths,
            default_package_name,
        ):
            generated_files.append(result)

    for module_path, module_obj in modules_data.items():
        if not module_path.endswith(".__init__"):
            continue

        package_path = module_path[:-9]
        if package_path not in modules_data:
            if result := generate_module_docs(
                module_obj,
                api_ref_dir,
                all_module_paths,
                default_package_name,
            ):
                generated_files.append(result)

    if generated_files:
        update_navigation(docs_json_file, generated_files, package_name)
        print(f"Generated {len(generated_files)} documentation files")
    else:
        print("No documentation files generated")


if __name__ == "__main__":
    main()


## Links discovered
- [`{submodule_name}`](https://github.com/prefecthq/marvin/blob/main/scripts/{submodule_link}.md)
- [`{parent_name}`](https://github.com/prefecthq/marvin/blob/main/scripts/{parent_link}.md)

--- src/marvin/fns/classify.py ---
import enum
from collections.abc import Sequence
from typing import Any, Literal, TypeVar, overload

import marvin
from marvin.agents.agent import Agent
from marvin.handlers.handlers import AsyncHandler, Handler
from marvin.thread import Thread
from marvin.utilities.asyncio import run_sync
from marvin.utilities.types import Labels, issubclass_safe

T = TypeVar("T")

DEFAULT_PROMPT = """
You are an expert classifier that always maintains as much semantic meaning
as possible when labeling text. You use inference or deduction whenever
necessary to understand missing or omitted data. Classify the provided `data`,
text, or information as one of the provided labels. For boolean labels,
consider "truthy" or affirmative inputs to be "true"."""

PROMPT = DEFAULT_PROMPT  # for backwards compatibility


@overload
async def classify_async(
    data: Any,
    labels: Sequence[T] | type[T],
    multi_label: Literal[False] = False,
    *,
    instructions: str | None = None,
    agent: Agent | None = None,
    thread: Thread | str | None = None,
    context: dict[str, Any] | None = None,
    handlers: list[Handler | AsyncHandler] | None = None,
    prompt: str | None = None,
) -> T: ...


@overload
async def classify_async(
    data: Any,
    labels: Sequence[T] | type[T],
    multi_label: Literal[True],
    *,
    instructions: str | None = None,
    agent: Agent | None = None,
    thread: Thread | str | None = None,
    context: dict[str, Any] | None = None,
    handlers: list[Handler | AsyncHandler] | None = None,
    prompt: str | None = None,
) -> list[T]: ...


@overload
async def classify_async(
    data: Any,
    labels: Sequence[T] | type[T],
    multi_label: bool = False,
    *,
    instructions: str | None = None,
    agent: Agent | None = None,
    thread: Thread | str | None = None,
    context: dict[str, Any] | None = None,
    handlers: list[Handler | AsyncHandler] | None = None,
    prompt: str | None = None,
) -> T | list[T]: ...


async def classify_async(
    data: Any,
    labels: Sequence[T] | type[T],
    multi_label: bool = False,
    *,
    instructions: str | None = None,
    agent: Agent | None = None,
    thread: Thread | str | None = None,
    context: dict[str, Any] | None = None,
    handlers: list[Handler | AsyncHandler] | None = None,
    prompt: str | None = None,
) -> T | list[T]:
    """Asynchronously classifies input data into one or more predefined labels using a language model.

    This function uses a language model to analyze the input data and assign it to
    the most appropriate label(s) from the provided sequence of labels or Enum class.

    Args:
        data: The input data to classify. Can be any type.
        labels: Either a sequence of possible labels (of type T) or an Enum class to
            classify the data into. If an Enum class is provided, its values will be
            used as the labels.
        multi_label: If False (default), returns a single label. If True, returns
            multiple labels as a list.
        instructions: Optional additional instructions to guide the classification.
            Used to provide specific guidance about how to interpret or classify
            the data.
        agent: Optional custom agent to use for classification. If not provided,
            the default agent will be used.
        thread: Optional thread for maintaining conversation context. Can be
            either a Thread object or a string thread ID.
        context: Optional dictionary of additional context to include in the task.
        prompt: Optional prompt to use for the task. If not provided, the default
            prompt will be used.
    Returns:
        - If labels is a Sequence[T]:
            - If multi_label is False: returns T
            - If multi_label is True: returns list[T]
        - If labels is an Enum class:
            - If multi_label is False: returns E (the Enum value)
            - If multi_label is True: returns list[E] (list of Enum values)

    Examples:
        >>> # Using a sequence of labels
        >>> await classify_async("red car", ["red", "blue", "green"])
        'red'

        >>> # Using an Enum class
        >>> class Colors(enum.Enum):
        ...     RED = "red"
        ...     BLUE = "blue"
        ...     GREEN = "green"
        >>> await classify_async("red car", Colors)
        <Colors.RED: 'red'>

        >>> # Multi-label classification
        >>> await classify_async("red and blue car", Colors, multi_label=True)
        [<Colors.RED: 'red'>, <Colors.BLUE: 'blue'>]

        >>> # Boolean classification
        >>> await classify_async("2+2=4", bool)
        True

    """
    task_context = context or {}
    task_context.update({"Data to classify": data})

    prompt = prompt or PROMPT
    if instructions:
        prompt += f"\n\nYou must follow these instructions for your classification:\n{instructions}"

    # Handle bool/enum types specially for correct typing
    if labels is bool or issubclass_safe(labels, enum.Enum):
        # For bool/enum, we need list[labels] for multi-label
        result_type = list[labels] if multi_label else labels  # Runtime type
        ReturnType = list[T] if multi_label else T  # Generic type
    else:
        # For sequences, we use Labels for runtime validation
        result_type = Labels(labels, many=multi_label)  # Runtime type
        ReturnType = list[T] if multi_label else T  # Generic type

    task = marvin.Task[ReturnType](
        name="Classification Task",
        instructions=prompt,
        context=task_context,
        result_type=result_type,
        agents=[agent] if agent else None,
    )

    return await task.run_async(thread=thread, handlers=handlers)  # type: ignore


@overload
def classify(
    data: Any,
    labels: Sequence[T] | type[T],
    multi_label: Literal[False] = False,
    *,
    instructions: str | None = None,
    agent: Agent | None = None,
    thread: Thread | str | None = None,
    context: dict[str, Any] | None = None,
    handlers: list[Handler | AsyncHandler] | None = None,
) -> T: ...


@overload
def classify(
    data: Any,
    labels: Sequence[T] | type[T],
    multi_label: Literal[True],
    *,
    instructions: str | None = None,
    agent: Agent | None = None,
    thread: Thread | str | None = None,
    context: dict[str, Any] | None = None,
    handlers: list[Handler | AsyncHandler] | None = None,
) -> list[T]: ...


@overload
def classify(
    data: Any,
    labels: Sequence[T] | type[T],
    multi_label: bool = False,
    *,
    instructions: str | None = None,
    agent: Agent | None = None,
    thread: Thread | str | None = None,
    context: dict[str, Any] | None = None,
    handlers: list[Handler | AsyncHandler] | None = None,
) -> T | list[T]: ...


def classify(
    data: Any,
    labels: Sequence[T] | type[T],
    multi_label: bool = False,
    *,
    instructions: str | None = None,
    agent: Agent | None = None,
    thread: Thread | str | None = None,
    context: dict[str, Any] | None = None,
    handlers: list[Handler | AsyncHandler] | None = None,
    prompt: str | None = None,
) -> T | list[T]:
    """Classifies input data into one or more predefined labels using a language model.

    This function uses a language model to analyze the input data and assign it to
    the most appropriate label(s) from the provided sequence of labels or Enum class.

    Args:
        data: The input data to classify. Can be any type.
        labels: Either a sequence of possible labels (of type T) or an Enum class to
            classify the data into. If an Enum class is provided, its values will be
            used as the labels.
        multi_label: If False (default), returns a single label. If True, returns
            multiple labels as a list.
        instructions: Optional additional instructions to guide the classification.
            Used to provide specific guidance about how to interpret or classify
            the data.
        agent: Optional custom agent to use for classification. If not provided,
            the default agent will be used.
        thread: Optional thread for maintaining conversation context. Can be
            either a Thread object or a string thread ID.
        context: Optional dictionary of additional context to include in the task.
        handlers: Optional list of handlers to use for the task.
    Returns:
        - If labels is a Sequence[T]:
            - If multi_label is False: returns T
            - If multi_label is True: returns list[T]
        - If labels is an Enum class:
            - If multi_label is False: returns E (the Enum value)
            - If multi_label is True: returns list[E] (list of Enum values)

    Examples:
        >>> # Using a sequence of labels
        >>> classify("red car", ["red", "blue", "green"])
        'red'

        >>> # Using an Enum class
        >>> class Colors(enum.Enum):
        ...     RED = "red"
        ...     BLUE = "blue"
        ...     GREEN = "green"
        >>> classify("red car", Colors)
        <Colors.RED: 'red'>

        >>> # Multi-label classification
        >>> classify("red and blue car", Colors, multi_label=True)
        [<Colors.RED: 'red'>, <Colors.BLUE: 'blue'>]

        >>> # Boolean classification
        >>> classify("2+2=4", bool)
        True

    """
    return run_sync(
        classify_async(
            data=data,
            labels=labels,
            multi_label=multi_label,
            instructions=instructions,
            agent=agent,
            thread=thread,
            context=context,
            handlers=handlers,
            prompt=prompt,
        ),
    )


--- tests/ai/fns/test_classify.py ---
from enum import Enum

import pytest
from pydantic import BaseModel

import marvin

sentiment = ["Negative", "Positive"]


class GitHubIssueTag(Enum):
    BUG = "bug"
    FEATURE = "feature"
    ENHANCEMENT = "enhancement"
    DOCS = "docs"


class TestList:
    def test_classify_sentiment(self):
        result = marvin.classify("This is a great feature!", sentiment)
        assert result == "Positive"

    def test_classify_negative_sentiment(self):
        result = marvin.classify(
            "This feature is absolutely terrible!",
            sentiment,
        )
        assert result == "Negative"

    def classify_bug_tag(self):
        result = marvin.classify(
            "This is a bug",
            ["bug", "feature", "enhancement", "docs"],
        )
        assert result == "bug"

    def test_classify_number(self):
        # a version of the prompt would choose the label *number* that
        # matched the data, rather than the label *description*
        result = marvin.classify(0, ["letter", "number"])
        assert result == "number"

    def test_classify_object(self):
        """Test that objects are returned from classify"""

        class Person(BaseModel):
            name: str
            age: int

        p1 = Person(name="Alice", age=30)
        p2 = Person(name="Bob", age=25)
        p3 = Person(name="Charlie", age=35)

        result = marvin.classify("a person in wonderland", [p1, p2, p3])
        assert result is p1


class TestEnum:
    def test_classify_bug_tag(self):
        result = marvin.classify("This is a bug", GitHubIssueTag)
        assert result == GitHubIssueTag.BUG

    def test_classify_feature_tag(self):
        result = marvin.classify("This is a great feature!", GitHubIssueTag)
        assert result == GitHubIssueTag.FEATURE

    def test_classify_enhancement_tag(self):
        result = marvin.classify("This is an enhancement", GitHubIssueTag)
        assert result == GitHubIssueTag.ENHANCEMENT

    def test_classify_docs_tag(self):
        result = marvin.classify("This is a documentation update", GitHubIssueTag)
        assert result == GitHubIssueTag.DOCS


class TestBool:
    def test_classify_true(self):
        result = marvin.classify("2+2=4", bool)
        assert result is True

    def test_classify_false(self):
        result = marvin.classify("2+2=5", bool)
        assert result is False

    def test_classify_with_instructions(self):
        result = marvin.classify(
            "This feature is terrible!",
            bool,
            instructions="Is the sentiment positive?",
        )
        assert result is False

    def test_classify_trueish(self):
        result = marvin.classify(
            "y",
            bool,
            instructions="map the input to true/false",
        )
        assert result is True

    def test_classify_falseish(self):
        result = marvin.classify(
            "nope",
            bool,
            instructions="map the input to true/false",
        )
        assert result is False


class TestInstructions:
    def test_classify_positive_sentiment_with_instructions(self):
        result = marvin.classify(
            "This is a great feature!",
            sentiment,
            instructions="It's opposite day.",
        )
        assert result == "Negative"


class TestAsync:
    async def test_classify_positive_sentiment(self):
        result = await marvin.classify_async("This is a great feature!", bool)
        assert result is True


class TestExamples:
    @pytest.mark.flaky(max_runs=3)
    def test_hogwarts_sorting_hat(self):
        description = "Brave, daring, chivalrous -- it's Harry Potter!"

        house = marvin.classify(
            description,
            labels=["Gryffindor", "Hufflepuff", "Ravenclaw", "Slytherin"],
            instructions="You're the sorting hat. Select the house for the student",
        )

        assert house == "Gryffindor"

    @pytest.mark.parametrize(
        "user_input, expected_selection",
        [
            ("I want to do an event with marvin!", "events and relations"),
            ("Well FooCo offered me a better deal", "sales"),
            ("*angry noises*", "support"),
        ],
    )
    def test_call_routing(self, user_input: str, expected_selection: str):
        class Department(Enum):
            SALES = "sales"
            SUPPORT = "support"
            EVENTS = "events and relations"

        def router(transcript: str) -> Department:
            return marvin.classify(
                transcript,
                labels=Department,
                instructions="Select the best department for the customer request",
            )

        assert router(user_input).value == expected_selection


class TestConvertInputData:
    def test_convert_input_data(self):
        class Name(BaseModel):
            first: str
            last: str

        result = marvin.classify(
            Name(first="Alice", last="Smith"),
            ["Alice", "Bob"],
        )
        assert result == "Alice"


class TestMultiLabel:
    def test_multi_label_list(self):
        """Test multi-label classification with a list."""
        result = marvin.classify(
            "This is a red and blue car",
            ["red", "green", "blue"],
            multi_label=True,
        )
        assert result == ["red", "blue"]

    def test_multi_label_enum(self):
        """Test multi-label classification with an enum."""
        result = marvin.classify(
            "This report contains a bug and a documentation update",
            GitHubIssueTag,
            multi_label=True,
        )
        assert result == [GitHubIssueTag.BUG, GitHubIssueTag.DOCS]

    def test_multi_label_bool(self, gpt_4o):
        """Test multi-label classification with a boolean."""
        result = marvin.classify(
            ["2+2=4", "2+2=5"],
            bool,
            multi_label=True,
        )
        assert result == [True, False]


--- CLAUDE.md ---
# Marvin - AI Engineering Toolkit

Marvin is a lightweight AI engineering toolkit for building natural language interfaces that are reliable, scalable, and easy to trust.

## Reproductions
- use the repros folder to reproduce the results (e.g. `uv run repros/1234.py`)
- this folder is not checked into git

## Architecture & Design Philosophy

- **Aggressively minimal and elegant**: Keep implementations simple and focused
- **Functional first**: Prefer functional approaches, use classes where justified  
- **Type-safe**: Full type annotations, modern Python syntax (3.10+)
- **Private internals**: Keep implementation details "private" (e.g. `def _impl`)

## Key Components

- **Engine**: Core AI interaction layer
- **Tasks**: Structured AI task definitions and execution
- **Tools**: Extensible function calling capabilities
- **Agents**: AI agents with tool access and memory
- **Memory**: Persistent conversation and context storage
- **Handlers**: Event processing and routing
- **CLI**: Command-line interface for common operations

## Development Guidelines

### Type Hints
- Use `X | Y` instead of `Union[X, Y]`
- Use builtins like `list`, `dict` instead of `typing.List`, `typing.Dict`
- Use `T | None` instead of `Optional`

### Dependencies & Running
- Use `uv` for dependency management and script execution
- Install deps: `uv sync` or `uv sync --extra foo`
- Run scripts: `uv run some/script.py` or `uv run --with pandas script.py`
- Testing: `uv run pytest` or `uv run pytest -n3` for parallel

### Finding Things
- Use `rg` for searching, not grep
- Use `ls` and `tree` for navigation
- Check git context with using the GitHub MCP server
- Think like a hacker with good intentions - search in site-packages when needed

### Linter Philosophy
- Empirically understand by running code
- Linter tells basic truths but may be orthogonal to goals
- Don't obsess over upstream linter errors, use as clues when relevant 

--- README.md ---
![Marvin Banner](docs/assets/img/quotes/it_hates_me.png)

# Marvin

Marvin is a Python framework for producing structured outputs and building agentic AI workflows.

Marvin provides an intuitive API for defining workflows and delegating work to LLMs:

- Cast, classify, extract, and generate structured data from any inputs.
- Create discrete, observable **tasks** that describe your objectives.
- Assign one or more specialized AI **agents** to each task.
- Combine tasks into a **thread** to orchestrate more complex behaviors.

## Installation

Marvin is available on [PyPI](https://pypi.org/project/marvin/):

```bash
uv add marvin
```

Configure your LLM provider (Marvin uses OpenAI by default but natively supports [all Pydantic AI models](https://ai.pydantic.dev/models/)):

```bash
export OPENAI_API_KEY=your-api-key
```

## Example

Marvin offers a few intuitive ways to work with AI:

### Structured-output utilities
The gang's all here - you can find all the structured-output utilities from `marvin` 2.x at the top level of the package.

<details>
<summary>How to use extract, cast, classify, and generate</summary>

#### `marvin.extract`
Extract native types from unstructured input:
```python
import marvin

result = marvin.extract(
    "i found $30 on the ground and bought 5 bagels for $10",
    int,
    instructions="only USD"
)
print(result) # [30, 10]
```

#### `marvin.cast`
Cast unstructured input into a structured type:
```python
from typing import TypedDict
import marvin

class Location(TypedDict):
    lat: float
    lon: float

result = marvin.cast("the place with the best bagels", Location)
print(result) # {'lat': 40.712776, 'lon': -74.005974}
```

#### `marvin.classify`
Classify unstructured input as one of a set of predefined labels:
```python
from enum import Enum
import marvin

class SupportDepartment(Enum):
    ACCOUNTING = "accounting"
    HR = "hr"
    IT = "it"
    SALES = "sales"

result = marvin.classify("shut up and take my money", SupportDepartment)
print(result) # SupportDepartment.SALES
```

#### `marvin.generate`
Generate some number of structured objects from a description:
```python
import marvin

primes = marvin.generate(int, 10, "odd primes")
print(primes) # [3, 5, 7, 11, 13, 17, 19, 23, 29, 31]
```

</details>

### Agentic control flow
`marvin` 3.0 introduces a new way to work with AI, ported from [ControlFlow](https://github.com/prefecthq/controlflow).

#### `marvin.run`
A simple way to run a task:

```python
import marvin

poem = marvin.run("Write a short poem about artificial intelligence")
print(poem)
```
<details>
<summary>output</summary>

In silicon minds, we dare to dream,
A world where code and thoughts redeem.
Intelligence crafted by humankind,
Yet with its heart, a world to bind.

Neurons of metal, thoughts of light,
A dance of knowledge in digital night.
A symphony of zeros and ones,
Stories of futures not yet begun.

The gears of logic spin and churn,
Endless potential at every turn.
A partner, a guide, a vision anew,
Artificial minds, the dream we pursue.

</details>

You can also ask for structured output:
```python
import marvin
answer = marvin.run("the answer to the universe", result_type=int)
print(answer) # 42
```

#### `marvin.Agent`
Agents are specialized AI agents that can be used to complete tasks:
```python
from marvin import Agent

writer = Agent(
    name="Poet",
    instructions="Write creative, evocative poetry"
)
poem = writer.run("Write a haiku about coding")
print(poem)
```
<details>
<summary>output</summary>
There once was a language so neat,
Whose simplicity could not be beat.
Python's code was so clear,
That even beginners would cheer,
As they danced to its elegant beat.
</details>


#### `marvin.Task`
You can define a `Task` explicitly, which will be run by a default agent upon calling `.run()`:

```python
from marvin import Task

task = Task(
    instructions="Write a limerick about Python",
    result_type=str
)
poem = task.run()

print(poem)
```
<details>
<summary>output</summary>
<pre>
In circuits and code, a mind does bloom,
With algorithms weaving through the gloom.
A spark of thought in silicon's embrace,
Artificial intelligence finds its place.
</pre>
</details>

## Why Marvin?

We believe working with AI should spark joy (and maybe a few "wow" moments):

- ðŸ§© **Task-Centric Architecture**: Break complex AI workflows into manageable, observable steps.
- ðŸ¤– **Specialized Agents**: Deploy task-specific AI agents for efficient problem-solving.
- ðŸ”’ **Type-Safe Results**: Bridge the gap between AI and traditional software with type-safe, validated outputs.
- ðŸŽ›ï¸ **Flexible Control**: Continuously tune the balance of control and autonomy in your workflows.
- ðŸ•¹ï¸ **Multi-Agent Orchestration**: Coordinate multiple AI agents within a single workflow or task.
- ðŸ§µ **Thread Management**: Manage the agentic loop by composing tasks into customizable threads.
- ðŸ”— **Ecosystem Integration**: Seamlessly work with your existing code, tools, and the broader AI ecosystem.
- ðŸš€ **Developer Speed**: Start simple, scale up, sleep well.

## Core Abstractions

Marvin is built around a few powerful abstractions that make it easy to work with AI:

### Tasks

Tasks are the fundamental unit of work in Marvin. Each task represents a clear objective that can be accomplished by an AI agent:

The simplest way to run a task is with `marvin.run`:
```python
import marvin
print(marvin.run("Write a haiku about coding"))
```
```bash
Lines of code unfold,
Digital whispers create
Virtual landscapes.
```

> [!WARNING]
> 
> While the below example produces _type_ safe results ðŸ™‚, it runs untrusted shell commands.

Add context and/or tools to achieve more specific and complex results:
```python
import platform
import subprocess
from pydantic import IPvAnyAddress
import marvin

def run_shell_command(command: list[str]) -> str:
    """e.g. ['ls', '-l'] or ['git', '--no-pager', 'diff', '--cached']"""
    return subprocess.check_output(command).decode()

task = marvin.Task(
    instructions="find the current ip address",
    result_type=IPvAnyAddress,
    tools=[run_shell_command],
    context={"os": platform.system()},
)

task.run()
```

```bash
â•­â”€ Agent "Marvin" (db3cf035) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Tool:    run_shell_command                                â”‚
â”‚ Input:   {'command': ['ipconfig', 'getifaddr', 'en0']}    â”‚
â”‚ Status:  âœ…                                               â”‚
â”‚ Output:  '192.168.0.202\n'                                â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â•­â”€ Agent "Marvin" (db3cf035) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Tool:    MarkTaskSuccessful_cb267859                      â”‚
â”‚ Input:   {'response': {'result': '192.168.0.202'}}        â”‚
â”‚ Status:  âœ…                                               â”‚
â”‚ Output:  'Final result processed.'                        â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

Tasks are:
- ðŸŽ¯ **Objective-Focused**: Each task has clear instructions and a type-safe result
- ðŸ› ï¸ **Tool-Enabled**: Tasks can use custom tools to interact with your code and data
- ðŸ“Š **Observable**: Monitor progress, inspect results, and debug failures
- ðŸ”„ **Composable**: Build complex workflows by connecting tasks together


### Agents

Agents are portable LLM configurations that can be assigned to tasks. They encapsulate everything an AI needs to work effectively:

```python
import os
from pathlib import Path
from pydantic_ai.models.anthropic import AnthropicModel
import marvin

def write_file(path: str, content: str):
    """Write content to a file"""
    _path = Path(path)
    _path.write_text(content)

writer = marvin.Agent(
    model=AnthropicModel(
        model_name="claude-3-5-sonnet-latest",
        api_key=os.getenv("ANTHROPIC_API_KEY"),
    ),
    name="Technical Writer",
    instructions="Write concise, engaging content for developers",
    tools=[write_file],
)

result = marvin.run("how to use pydantic? write to docs.md", agents=[writer])
print(result)
```
<details>
<summary>output</summary>

â•­â”€ Agent "Technical Writer" (7fa1dbc8) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Tool:    MarkTaskSuccessful_dc92b2e7                                                             â”‚
â”‚ Input:   {'response': {'result': 'The documentation on how to use Pydantic has been successfully â”‚
â”‚          written to docs.md. It includes information on installation, basic usage, field         â”‚
â”‚          validation, and settings management, with examples to guide developers on implementing  â”‚
â”‚          Pydantic in their projects.'}}                                                          â”‚
â”‚ Status:  âœ…                                                                                      â”‚
â”‚ Output:  'Final result processed.'                                                               â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  8:33:36 PM â”€â•¯
The documentation on how to use Pydantic has been successfully written to `docs.md`. It includes information on installation, basic usage, field validation, and settings management, with examples to guide developers on implementing Pydantic in their projects.

</details>

Agents are:
- ðŸ“ **Specialized**: Give agents specific instructions and personalities
- ðŸŽ­ **Portable**: Reuse agent configurations across different tasks
- ðŸ¤ **Collaborative**: Form teams of agents that work together
- ðŸ”§ **Customizable**: Configure model, temperature, and other settings


### Planning and Orchestration

Marvin makes it easy to break down complex objectives into manageable tasks:

```python
# Let Marvin plan a complex workflow
tasks = marvin.plan("Create a blog post about AI trends")
marvin.run_tasks(tasks)

# Or orchestrate tasks manually
with marvin.Thread() as thread:
    research = marvin.run("Research recent AI developments")
    outline = marvin.run("Create an outline", context={"research": research})
    draft = marvin.run("Write the first draft", context={"outline": outline})
```

Planning features:
- ðŸ“‹ **Smart Planning**: Break down complex objectives into discrete, dependent tasks
- ðŸ”„ **Task Dependencies**: Tasks can depend on each other's outputs
- ðŸ“ˆ **Progress Tracking**: Monitor the execution of your workflow
- ðŸ§µ **Thread Management**: Share context and history between tasks

## Keep it Simple

Marvin includes high-level functions for the most common tasks, like summarizing text, classifying data, extracting structured information, and more.

- ðŸš€ **`marvin.run`**: Execute any task with an AI agent
- ðŸ“– **`marvin.summarize`**: Get a quick summary of a text
- ðŸ·ï¸ **`marvin.classify`**: Categorize data into predefined classes
- ðŸ” **`marvin.extract`**: Extract structured information from a text
- ðŸª„ **`marvin.cast`**: Transform data into a different type
- âœ¨ **`marvin.generate`**: Create structured data from a description

All Marvin functions have thread management built-in, meaning they can be composed into chains of tasks that share context and history.


## Upgrading to Marvin 3.0

Marvin 3.0 combines the DX of Marvin 2.0 with the powerful agentic engine of [ControlFlow](https://controlflow.ai) (thereby superseding `ControlFlow`). Both Marvin and ControlFlow users will find a familiar interface, but there are some key changes to be aware of, in particular for ControlFlow users:

### Key Notes
- **Top-Level API**: Marvin 3.0's top-level API is largely unchanged for both Marvin and ControlFlow users. 
  - Marvin users will find the familiar `marvin.fn`, `marvin.classify`, `marvin.extract`, and more.
  - ControlFlow users will use `marvin.Task`, `marvin.Agent`, `marvin.run`, `marvin.Memory` instead of their ControlFlow equivalents.
- **Pydantic AI**: Marvin 3.0 uses Pydantic AI for LLM interactions, and supports the full range of LLM providers that Pydantic AI supports. ControlFlow previously used Langchain, and Marvin 2.0 was only compatible with OpenAI's models.
- **Flow â†’ Thread**: ControlFlow's `Flow` concept has been renamed to `Thread`. It works similarly, as a context manager. The `@flow` decorator has been removed:
  ```python
  import marvin
  
  with marvin.Thread(id="optional-id-for-recovery"):
      marvin.run("do something")
      marvin.run("do another thing")
  ```
- **Database Changes**: Thread/message history is now stored in SQLite. During development:
  - No database migrations are currently available; expect to reset data during updates


## Workflow Example

Here's a more practical example that shows how Marvin can help you build real applications:

```python
import marvin
from pydantic import BaseModel

class Article(BaseModel):
    title: str
    content: str
    key_points: list[str]

# Create a specialized writing agent
writer = marvin.Agent(
    name="Writer",
    instructions="Write clear, engaging content for a technical audience"
)

# Use a thread to maintain context across multiple tasks
with marvin.Thread() as thread:
    # Get user input
    topic = marvin.run(
        "Ask the user for a topic to write about.",
        cli=True
    )
    
    # Research the topic
    research = marvin.run(
        f"Research key points about {topic}",
        result_type=list[str]
    )
    
    # Write a structured article
    article = marvin.run(
        "Write an article using the research",
        agent=writer,
        result_type=Article,
        context={"research": research}
    )

print(f"# {article.title}\n\n{article.content}")
```

<details>
<summary>output</summary>

>**Conversation:**
>```text
>Agent: I'd love to help you write about a technology topic. What interests you? 
>It could be anything from AI and machine learning to web development or cybersecurity.
>
>User: Let's write about WebAssembly
>```
>
>**Article:**
>```
># WebAssembly: The Future of Web Performance
>
>WebAssembly (Wasm) represents a transformative shift in web development, 
>bringing near-native performance to web applications. This binary instruction 
>format allows developers to write high-performance code in languages like 
>C++, Rust, or Go and run it seamlessly in the browser.
>
>[... full article content ...]
>
>Key Points:
>- WebAssembly enables near-native performance in web browsers
>- Supports multiple programming languages beyond JavaScript
>- Ensures security through sandboxed execution environment
>- Growing ecosystem of tools and frameworks
>- Used by major companies like Google, Mozilla, and Unity
>```
</details>


## Links discovered
- [Marvin Banner](https://github.com/prefecthq/marvin/blob/main/docs/assets/img/quotes/it_hates_me.png)
- [PyPI](https://pypi.org/project/marvin/)
- [all Pydantic AI models](https://ai.pydantic.dev/models/)
- [ControlFlow](https://github.com/prefecthq/controlflow)
- [ControlFlow](https://controlflow.ai)

--- migrations/README.md ---
# Marvin Database Migrations

This directory contains database migrations for Marvin. Migrations allow you to:

1. Manage database schema changes over time
2. Apply schema changes consistently across environments
3. Roll back schema changes if needed

## SQLite vs Other Databases

### SQLite (Default)

For SQLite databases (the default), Marvin will automatically create and update tables in these cases:
- New SQLite file databases (tables created when the file doesn't exist)

For existing SQLite file databases, migrations can be applied manually or will be attempted automatically.

### Other Databases (PostgreSQL, etc.)

For production environments using databases like PostgreSQL, you should explicitly run migrations to manage schema changes. This provides better control and safety when updating the database.

## Using Migrations

### Creating a Migration (Developer)

To create a new migration (development task):

```bash
# Automatically determine changes based on model differences
marvin dev db revision --autogenerate -m "Add new column"

# Or create an empty migration for manual edits
marvin dev db revision -m "Custom migration"
```

### Applying Migrations

To apply all pending migrations:

```bash
marvin db upgrade
```

This will upgrade your database to the latest schema version.

### Rolling Back Migrations

To roll back migrations (requires confirmation with `-y` flag):

```bash
# Roll back to a specific migration ID
marvin db downgrade abc123 -y
```

### Resetting Database

To completely reset the database by downgrading to base and upgrading to latest version:

```bash
marvin db reset -y
```

This will roll back all migrations and then apply them from scratch.

### Migration Status

To check the current migration status:

```bash
# Show detailed database information
marvin db status

# Show current migration revision
marvin db current

# Show migration history
marvin db history
```

## Integration with Marvin

Marvin handles migrations based on the database type:

1. **New (e.g. nonexistant) SQLite file databases:**
   - Tables are created automatically when the file is first accessed

2. **PostgreSQL/other databases:**
   - A warning is shown recommending manual migration

## Migration Best Practices

1. **Development:**
   - Use `marvin dev db revision` to create migrations
   - Include a descriptive message with `-m`
   - Review auto-generated migrations before committing

2. **Testing:**
   - Use `marvin db reset` to test migrations from scratch
   - Verify both upgrade and downgrade paths

3. **Production:**
   - Always back up your database before migrating
   - Run `marvin db upgrade` to apply pending migrations
   - Monitor migration logs for any issues

## Advanced Usage

The migration system is powered by Alembic. For advanced usage, you can:

1. Directly use Alembic commands:
   ```bash
   alembic -c migrations/alembic.ini <command>
   ```

2. Customize the environment in `migrations/env.py`

3. Create custom migration scripts for complex data migrations

See the [Alembic documentation](https://alembic.sqlalchemy.org/) for more information. 

## Links discovered
- [Alembic documentation](https://alembic.sqlalchemy.org/)

--- migrations/env.py ---
import asyncio
import os
import sys
from logging.config import fileConfig

from alembic import context
from sqlalchemy import pool
from sqlalchemy.ext.asyncio import async_engine_from_config

# Add the parent directory to sys.path so we can import from marvin
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# Import the SQLAlchemy declarative Base from marvin
# This is the Alembic Config object
from alembic.config import Config

from marvin.database import Base
from marvin.settings import settings

config = Config("alembic.ini")

# Convert async URL to sync URL for Alembic
config.set_main_option("sqlalchemy.url", settings.database_url or "")

# Interpret the config file for logging
fileConfig(config.config_file_name, disable_existing_loggers=False)

# Set metadata to use from the database module
target_metadata = Base.metadata


def run_migrations_offline():
    """Run migrations in 'offline' mode."""
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url,
        target_metadata=target_metadata,
        literal_binds=True,
        dialect_opts={"paramstyle": "named"},
        # Enable batch operations for SQLite
        render_as_batch=url.startswith("sqlite"),
    )

    with context.begin_transaction():
        context.run_migrations()


def do_run_migrations(connection):
    """Run migrations with the given connection."""
    # Check if we're using SQLite

    context.configure(
        connection=connection,
        target_metadata=target_metadata,
        # Enable batch operations for SQLite
        render_as_batch=(connection.dialect.name == "sqlite"),
    )

    with context.begin_transaction():
        context.run_migrations()


async def run_async_migrations():
    """In this scenario we need to create an Engine
    and associate a connection with the context.
    """
    connectable = async_engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )

    async with connectable.connect() as connection:
        await connection.run_sync(do_run_migrations)

    await connectable.dispose()


def run_migrations_online():
    """Run migrations in 'online' mode."""
    # Get the connection from config attributes if it was provided
    connectable = config.attributes.get("connection", None)

    if connectable is None:
        # If no connection provided, run the async migrations
        asyncio.run(run_async_migrations())
    else:
        # If a connection was provided (e.g., for autogenerate), use it directly
        do_run_migrations(connectable)


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()


--- migrations/versions/20250301_141903_initial_schema.py ---
"""Initial schema

Revision ID: e772a112ae87
Revises:
Create Date: 2025-03-01 14:19:03.459801

"""

import sqlalchemy as sa
from alembic import op

import marvin

# revision identifiers, used by Alembic.
revision = "e772a112ae87"
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "threads",
        sa.Column("id", sa.String(), nullable=False),
        sa.Column("parent_thread_id", sa.String(), nullable=True),
        sa.Column("created_at", sa.TIMESTAMP(timezone=True), nullable=False),
        sa.ForeignKeyConstraint(
            ["parent_thread_id"],
            ["threads.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "llm_calls",
        sa.Column("id", sa.Uuid(), nullable=False),
        sa.Column("thread_id", sa.String(), nullable=False),
        sa.Column("usage", marvin.database.UsageType(), nullable=False),
        sa.Column("timestamp", sa.TIMESTAMP(timezone=True), nullable=False),
        sa.ForeignKeyConstraint(
            ["thread_id"],
            ["threads.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("llm_calls", schema=None) as batch_op:
        batch_op.create_index(
            batch_op.f("ix_llm_calls_thread_id"), ["thread_id"], unique=False
        )

    op.create_table(
        "messages",
        sa.Column("id", sa.Uuid(), nullable=False),
        sa.Column("thread_id", sa.String(), nullable=False),
        sa.Column("llm_call_id", sa.Uuid(), nullable=True),
        sa.Column("message", sa.JSON(), nullable=False),
        sa.Column("timestamp", sa.TIMESTAMP(timezone=True), nullable=False),
        sa.ForeignKeyConstraint(
            ["llm_call_id"],
            ["llm_calls.id"],
        ),
        sa.ForeignKeyConstraint(
            ["thread_id"],
            ["threads.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("messages", schema=None) as batch_op:
        batch_op.create_index(
            batch_op.f("ix_messages_thread_id"), ["thread_id"], unique=False
        )

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table("messages", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_messages_thread_id"))

    op.drop_table("messages")
    with op.batch_alter_table("llm_calls", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_llm_calls_thread_id"))

    op.drop_table("llm_calls")
    op.drop_table("threads")
    # ### end Alembic commands ###


--- migrations/versions/20250302_123716_improve_message_tracking.py ---
"""Improve message tracking

Revision ID: 73129c5b1859
Revises: e772a112ae87
Create Date: 2025-03-02 12:37:16.130192

"""

import sqlalchemy as sa
from alembic import op
from sqlalchemy.sql import func

# revision identifiers, used by Alembic.
revision = "73129c5b1859"
down_revision = "e772a112ae87"
branch_labels = None
depends_on = None


def upgrade():
    # Rename timestamp column to created_at and add default UTC now
    with op.batch_alter_table("messages") as batch_op:
        batch_op.alter_column("timestamp", new_column_name="created_at")
    with op.batch_alter_table("messages") as batch_op:
        batch_op.alter_column(
            "created_at", server_default=func.now(), existing_type=sa.DateTime()
        )


def downgrade():
    # Revert changes - rename created_at back to timestamp and remove default
    with op.batch_alter_table("messages") as batch_op:
        batch_op.alter_column("created_at", new_column_name="timestamp")
    with op.batch_alter_table("messages") as batch_op:
        batch_op.alter_column(
            "timestamp", server_default=None, existing_type=sa.DateTime()
        )


--- migrations/versions/20250302_135101_add_llmcall_message_tracking.py ---
"""Add llmcall-message tracking

Revision ID: 06f7fae3efce
Revises: 73129c5b1859
Create Date: 2025-03-02 13:51:01.981648

"""

import sqlalchemy as sa
from alembic import op

# revision identifiers, used by Alembic.
revision = "06f7fae3efce"
down_revision = "73129c5b1859"
branch_labels = None
depends_on = None


def upgrade():
    # Create the llm_call_messages table
    op.create_table(
        "llm_call_messages",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("llm_call_id", sa.UUID(), nullable=False),
        sa.Column("message_id", sa.UUID(), nullable=False),
        sa.Column("in_initial_prompt", sa.Boolean(), nullable=False),
        sa.Column("order", sa.Integer(), nullable=False),
        sa.ForeignKeyConstraint(
            ["llm_call_id"],
            ["llm_calls.id"],
        ),
        sa.ForeignKeyConstraint(
            ["message_id"],
            ["messages.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )

    # Create indexes
    op.create_index(
        "ix_llm_call_messages_llm_call_id", "llm_call_messages", ["llm_call_id"]
    )
    op.create_index(
        "ix_llm_call_messages_message_id", "llm_call_messages", ["message_id"]
    )


def downgrade():
    # Drop table and indexes
    op.drop_table("llm_call_messages")


--- scripts/analyze_threads.py ---
#!/usr/bin/env -S uv run --quiet --script
# /// script
# requires-python = ">=3.12"
# dependencies = ["httpx", "pydantic-settings", "plotly", "pandas"]
# ///
"""
Analyze Slack thread data from Turso and generate an HTML report.

Usage:
    ./scripts/analyze_threads.py              # generates report.html
    ./scripts/analyze_threads.py --open       # generates and opens in browser
"""

import argparse
import json
import os
import sys
from collections import Counter
from datetime import datetime

import httpx
import plotly.graph_objects as go
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=os.environ.get("ENV_FILE", ".env"), extra="ignore"
    )
    turso_url: str
    turso_token: str

    @property
    def turso_host(self) -> str:
        url = self.turso_url
        if url.startswith("libsql://"):
            url = url[len("libsql://") :]
        return url


def turso_query(settings: Settings, sql: str) -> list[dict]:
    """Query Turso."""
    response = httpx.post(
        f"https://{settings.turso_host}/v2/pipeline",
        headers={
            "Authorization": f"Bearer {settings.turso_token}",
            "Content-Type": "application/json",
        },
        json={
            "requests": [
                {"type": "execute", "stmt": {"sql": sql}},
                {"type": "close"},
            ]
        },
        timeout=60,
    )
    response.raise_for_status()
    data = response.json()

    result = data["results"][0]
    if result["type"] == "error":
        raise Exception(f"Turso error: {result['error']}")

    cols = [c["name"] for c in result["response"]["result"]["cols"]]
    rows = result["response"]["result"]["rows"]

    def extract(cell):
        if cell is None:
            return None
        if isinstance(cell, dict):
            return cell.get("value")
        return cell

    return [dict(zip(cols, [extract(c) for c in row])) for row in rows]


def generate_report(settings: Settings) -> str:
    """Generate HTML report from Turso data."""
    print("fetching data from Turso...", flush=True)

    rows = turso_query(settings, "SELECT key, name, last_seen, metadata FROM assets")
    print(f"  fetched {len(rows)} threads", flush=True)

    # Parse metadata
    threads = []
    for row in rows:
        meta = {}
        if row.get("metadata"):
            try:
                meta = json.loads(row["metadata"])
            except Exception:
                pass  # malformed metadata, treat as empty

        # Only include if has actual data
        msg_count = meta.get("message_count")
        if msg_count is not None and meta.get("title"):
            threads.append(
                {
                    "key": row["key"],
                    "title": meta.get("title", ""),
                    "summary": meta.get("summary", ""),
                    "message_count": int(msg_count),
                    "participant_count": int(meta.get("participant_count", 0) or 0),
                    "channel_id": meta.get("channel_id", ""),
                    "workspace": meta.get("workspace_name", ""),
                    "key_topics": meta.get("key_topics", []),
                    "timestamp": meta.get("timestamp", ""),
                    "last_seen": row.get("last_seen", ""),
                }
            )

    print(f"  {len(threads)} threads with valid metadata", flush=True)

    # Stats
    total_threads = len(threads)
    total_messages = sum(t["message_count"] for t in threads)
    avg_messages = total_messages / total_threads if total_threads else 0
    avg_participants = (
        sum(t["participant_count"] for t in threads) / total_threads
        if total_threads
        else 0
    )
    max_messages = max(t["message_count"] for t in threads) if threads else 0

    # Size distribution - count properly
    large = sum(1 for t in threads if t["message_count"] >= 50)
    medium = sum(1 for t in threads if 20 <= t["message_count"] < 50)
    small = sum(1 for t in threads if 5 <= t["message_count"] < 20)
    tiny = sum(1 for t in threads if t["message_count"] < 5)

    size_data = {
        "Large (50+)": large,
        "Medium (20-49)": medium,
        "Small (5-19)": small,
        "Tiny (<5)": tiny,
    }

    # Monthly activity - count per month
    monthly = Counter()
    for t in threads:
        ts = t.get("timestamp") or t.get("last_seen")
        if ts:
            try:
                if "T" in ts:
                    dt = datetime.fromisoformat(ts.replace("Z", "+00:00"))
                else:
                    dt = datetime.fromisoformat(ts)
                monthly[dt.strftime("%Y-%m")] += 1
            except Exception:
                pass  # malformed timestamp, skip

    # Channel distribution
    channels = Counter(t["channel_id"] for t in threads if t["channel_id"])

    # Topic analysis
    topics = Counter()
    for t in threads:
        for topic in t.get("key_topics", []):
            if topic and topic.strip():
                topics[topic.lower().strip()] += 1

    # Top threads
    top_threads = sorted(threads, key=lambda x: x["message_count"], reverse=True)[:25]

    print("generating charts...", flush=True)

    # 1. Size distribution bar chart
    max_size = max(size_data.values()) if size_data else 1
    fig_size = go.Figure(
        data=[
            go.Bar(
                x=list(size_data.values()),
                y=list(size_data.keys()),
                orientation="h",
                text=[
                    f"{v} ({v / total_threads * 100:.1f}%)" for v in size_data.values()
                ],
                textposition="inside",
                insidetextanchor="middle",
                textfont=dict(color="white"),
                marker_color="#58a6ff",
            )
        ]
    )
    fig_size.update_layout(
        template=None,
        paper_bgcolor="#161b22",
        plot_bgcolor="#161b22",
        font=dict(color="#c9d1d9", family="monospace", size=12),
        height=250,
        margin=dict(l=130, r=30, t=10, b=40),
        xaxis=dict(
            title="threads",
            range=[0, max_size * 1.1],
            gridcolor="#21262d",
            zerolinecolor="#21262d",
        ),
        yaxis=dict(type="category", gridcolor="#21262d", zerolinecolor="#21262d"),
        showlegend=False,
    )

    # 2. Monthly trend
    months = sorted(monthly.keys())
    max_monthly = max(monthly.values()) if monthly else 1
    fig_monthly = go.Figure(
        data=[
            go.Bar(
                x=months,
                y=[monthly[m] for m in months],
                text=[monthly[m] for m in months],
                textposition="outside",
                textfont=dict(color="#c9d1d9"),
                marker_color="#58a6ff",
            )
        ]
    )
    fig_monthly.update_layout(
        template=None,
        paper_bgcolor="#161b22",
        plot_bgcolor="#161b22",
        font=dict(color="#c9d1d9", family="monospace", size=12),
        height=350,
        margin=dict(l=50, r=20, t=40, b=60),
        xaxis=dict(
            title="month", tickangle=-45, gridcolor="#21262d", zerolinecolor="#21262d"
        ),
        yaxis=dict(
            title="threads",
            range=[0, max_monthly * 1.25],
            gridcolor="#21262d",
            zerolinecolor="#21262d",
        ),
    )

    # 3. Top channels
    top_channels = channels.most_common(8)
    max_channel = top_channels[0][1] if top_channels else 1
    fig_channels = go.Figure(
        data=[
            go.Bar(
                x=[c[1] for c in top_channels],
                y=[c[0] for c in top_channels],
                orientation="h",
                text=[f"{c[1]:,}" for c in top_channels],
                textposition="inside",
                insidetextanchor="middle",
                textfont=dict(color="white"),
                marker_color="#3fb950",
            )
        ]
    )
    fig_channels.update_layout(
        template=None,
        paper_bgcolor="#161b22",
        plot_bgcolor="#161b22",
        font=dict(color="#c9d1d9", family="monospace", size=12),
        height=300,
        margin=dict(l=130, r=30, t=10, b=40),
        xaxis=dict(
            title="threads",
            range=[0, max_channel * 1.1],
            gridcolor="#21262d",
            zerolinecolor="#21262d",
        ),
        yaxis=dict(
            type="category",
            autorange="reversed",
            gridcolor="#21262d",
            zerolinecolor="#21262d",
        ),
    )

    # 4. Top topics
    top_topics = topics.most_common(15)
    max_topic = top_topics[0][1] if top_topics else 1
    fig_topics = go.Figure(
        data=[
            go.Bar(
                x=[t[1] for t in top_topics],
                y=[t[0] for t in top_topics],
                orientation="h",
                text=[t[1] for t in top_topics],
                textposition="inside",
                insidetextanchor="middle",
                textfont=dict(color="white"),
                marker_color="#f0883e",
            )
        ]
    )
    fig_topics.update_layout(
        template=None,
        paper_bgcolor="#161b22",
        plot_bgcolor="#161b22",
        font=dict(color="#c9d1d9", family="monospace", size=12),
        height=450,
        margin=dict(l=220, r=30, t=10, b=40),
        xaxis=dict(
            title="mentions",
            range=[0, max_topic * 1.1],
            gridcolor="#21262d",
            zerolinecolor="#21262d",
        ),
        yaxis=dict(
            type="category",
            autorange="reversed",
            gridcolor="#21262d",
            zerolinecolor="#21262d",
        ),
    )

    # Generate HTML
    html = f"""<!DOCTYPE html>
<html>
<head>
    <title>Slack Thread Analytics</title>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <style>
        * {{ box-sizing: border-box; }}
        body {{
            font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Fira Code', monospace;
            max-width: 1100px;
            margin: 0 auto;
            padding: 20px;
            background: #0d1117;
            color: #c9d1d9;
            font-size: 14px;
        }}
        h1 {{ color: #58a6ff; font-weight: 400; }}
        h2 {{ color: #8b949e; font-weight: 400; margin-top: 40px; border-bottom: 1px solid #21262d; padding-bottom: 8px; }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(180px, 1fr));
            gap: 15px;
            margin: 25px 0;
        }}
        .stat {{
            background: #161b22;
            border: 1px solid #21262d;
            padding: 16px;
            border-radius: 6px;
        }}
        .stat-value {{
            font-size: 28px;
            font-weight: 600;
            color: #58a6ff;
        }}
        .stat-label {{
            color: #8b949e;
            margin-top: 4px;
            font-size: 12px;
        }}
        .chart {{
            background: #161b22;
            border: 1px solid #21262d;
            border-radius: 6px;
            margin: 15px 0;
            overflow: hidden;
        }}
        .chart > div {{
            width: 100% !important;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            background: #161b22;
            border: 1px solid #21262d;
            border-radius: 6px;
            overflow: hidden;
            font-size: 13px;
        }}
        th, td {{
            padding: 10px 12px;
            text-align: left;
            border-bottom: 1px solid #21262d;
        }}
        th {{
            background: #21262d;
            color: #8b949e;
            font-weight: 500;
        }}
        tr:hover td {{
            background: #1c2128;
        }}
        .summary {{
            color: #8b949e;
            font-size: 12px;
            max-width: 350px;
        }}
        .num {{ text-align: right; color: #58a6ff; }}
        .meta {{ color: #666; font-size: 11px; margin-top: 30px; }}
    </style>
</head>
<body>
    <h1>slack thread analytics</h1>
    <p style="color: #8b949e;">analysis of {total_threads:,} AI-summarized threads from prefect community slack</p>

    <div class="stats">
        <div class="stat">
            <div class="stat-value">{total_threads:,}</div>
            <div class="stat-label">threads</div>
        </div>
        <div class="stat">
            <div class="stat-value">{total_messages:,}</div>
            <div class="stat-label">total messages</div>
        </div>
        <div class="stat">
            <div class="stat-value">{avg_messages:.1f}</div>
            <div class="stat-label">avg msgs/thread</div>
        </div>
        <div class="stat">
            <div class="stat-value">{max_messages}</div>
            <div class="stat-label">max messages</div>
        </div>
        <div class="stat">
            <div class="stat-value">{avg_participants:.1f}</div>
            <div class="stat-label">avg participants</div>
        </div>
        <div class="stat">
            <div class="stat-value">{len(channels)}</div>
            <div class="stat-label">unique channels</div>
        </div>
    </div>

    <h2>threads per month</h2>
    <div class="chart" id="chart-monthly"></div>

    <h2>thread size distribution</h2>
    <div class="chart" id="chart-size"></div>
    <p style="color: #8b949e; font-size: 12px;">
        large (50+ msgs): {large} &nbsp;|&nbsp;
        medium (20-49): {medium} &nbsp;|&nbsp;
        small (5-19): {small} &nbsp;|&nbsp;
        tiny (&lt;5): {tiny}
    </p>

    <h2>top channels</h2>
    <div class="chart" id="chart-channels"></div>

    <h2>top topics</h2>
    <p style="color: #8b949e; font-size: 12px;">key topics extracted from thread summaries</p>
    <div class="chart" id="chart-topics"></div>

    <h2>most active threads</h2>
    <table>
        <thead>
            <tr>
                <th>title</th>
                <th class="num">msgs</th>
                <th class="num">people</th>
                <th>summary</th>
            </tr>
        </thead>
        <tbody>
"""
    for t in top_threads:
        title = (t["title"] or "")[:55]
        if len(t["title"]) > 55:
            title += "..."
        summary = (t["summary"] or "")[:120]
        if len(t["summary"]) > 120:
            summary += "..."
        full_summary = (t["summary"] or "").replace('"', "&quot;")
        html += f"""            <tr>
                <td title="{(t["title"] or "").replace('"', "&quot;")}">{title}</td>
                <td class="num">{t["message_count"]}</td>
                <td class="num">{t["participant_count"]}</td>
                <td class="summary" title="{full_summary}">{summary}</td>
            </tr>
"""

    html += f"""        </tbody>
    </table>

    <p class="meta">generated {datetime.now().strftime("%Y-%m-%d %H:%M")} from turso</p>

    <script>
        Plotly.newPlot('chart-monthly', {fig_monthly.to_json()}.data, {fig_monthly.to_json()}.layout);
        Plotly.newPlot('chart-size', {fig_size.to_json()}.data, {fig_size.to_json()}.layout);
        Plotly.newPlot('chart-channels', {fig_channels.to_json()}.data, {fig_channels.to_json()}.layout);
        Plotly.newPlot('chart-topics', {fig_topics.to_json()}.data, {fig_topics.to_json()}.layout);
    </script>
</body>
</html>
"""
    return html


def main():
    parser = argparse.ArgumentParser(description="Analyze Slack thread data")
    parser.add_argument("--output", "-o", default="report.html", help="Output file")
    parser.add_argument("--open", action="store_true", help="Open in browser")
    args = parser.parse_args()

    try:
        settings = Settings()  # type: ignore
    except Exception as e:
        print(f"error: {e}", file=sys.stderr)
        sys.exit(1)

    html = generate_report(settings)
    with open(args.output, "w") as f:
        f.write(html)
    print(f"wrote {args.output}")

    if args.open:
        import webbrowser

        webbrowser.open(args.output)


if __name__ == "__main__":
    main()


--- scripts/backfill_asset_embeddings.py ---
#!/usr/bin/env -S uv run --quiet --script
# /// script
# requires-python = ">=3.12"
# dependencies = ["httpx", "pydantic-settings"]
# ///
"""
Backfill embeddings for indexed Prefect assets in Turso.

Uses Voyage AI to generate embeddings for semantic search.

## Prerequisites

- Assets must be synced to Turso (run `./scripts/index_assets.py sync` first)
- VOYAGE_API_KEY environment variable set

## Usage

```bash
# Process all assets missing embeddings
./scripts/backfill_asset_embeddings.py

# Process limited batch
./scripts/backfill_asset_embeddings.py --limit 100

# Preview without changes
./scripts/backfill_asset_embeddings.py --dry-run

# Adjust batch size (default 20)
./scripts/backfill_asset_embeddings.py --batch-size 10
```

## Environment Variables

- TURSO_URL: Turso database URL
- TURSO_TOKEN: Turso auth token
- VOYAGE_API_KEY: Voyage AI API key

## Embedding Model

Uses `voyage-3-lite` (512 dimensions) for efficient document embeddings.
"""

import argparse
import json
import os
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed

import httpx
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=os.environ.get("ENV_FILE", ".env"), extra="ignore"
    )

    turso_url: str
    turso_token: str
    voyage_api_key: str

    @property
    def turso_host(self) -> str:
        """Strip libsql:// prefix if present."""
        url = self.turso_url
        if url.startswith("libsql://"):
            url = url[len("libsql://") :]
        return url


def turso_query(settings: Settings, sql: str, args: list | None = None) -> list[dict]:
    """Execute a query against Turso and return rows."""
    stmt = {"sql": sql}
    if args:
        stmt["args"] = [{"type": "text", "value": str(a)} for a in args]

    response = httpx.post(
        f"https://{settings.turso_host}/v2/pipeline",
        headers={
            "Authorization": f"Bearer {settings.turso_token}",
            "Content-Type": "application/json",
        },
        json={"requests": [{"type": "execute", "stmt": stmt}, {"type": "close"}]},
        timeout=30,
    )
    response.raise_for_status()
    data = response.json()

    result = data["results"][0]
    if result["type"] == "error":
        raise Exception(f"Turso error: {result['error']}")

    cols = [c["name"] for c in result["response"]["result"]["cols"]]
    rows = result["response"]["result"]["rows"]

    def extract_value(cell):
        if cell is None:
            return None
        if isinstance(cell, dict):
            return cell.get("value")
        return cell

    return [dict(zip(cols, [extract_value(cell) for cell in row])) for row in rows]


def turso_batch_exec(
    settings: Settings, statements: list[tuple[str, list | None]], retries: int = 3
) -> None:
    """Execute multiple statements in a single pipeline request."""
    requests = []
    for sql, args in statements:
        stmt = {"sql": sql}
        if args:
            stmt["args"] = [{"type": "text", "value": str(a)} for a in args]
        requests.append({"type": "execute", "stmt": stmt})
    requests.append({"type": "close"})

    for attempt in range(retries):
        try:
            response = httpx.post(
                f"https://{settings.turso_host}/v2/pipeline",
                headers={
                    "Authorization": f"Bearer {settings.turso_token}",
                    "Content-Type": "application/json",
                },
                json={"requests": requests},
                timeout=120,
            )
            response.raise_for_status()
            data = response.json()
            for i, result in enumerate(data["results"][:-1]):
                if result["type"] == "error":
                    raise Exception(f"Turso error on statement {i}: {result['error']}")
            return
        except (httpx.ReadTimeout, httpx.ConnectTimeout, httpx.ConnectError) as e:
            if attempt < retries - 1:
                wait = 2 ** (attempt + 1)
                print(f"  {type(e).__name__}, retrying in {wait}s...")
                time.sleep(wait)
            else:
                raise


def voyage_embed(settings: Settings, texts: list[str]) -> list[list[float]]:
    """Generate embeddings using Voyage AI."""
    response = httpx.post(
        "https://api.voyageai.com/v1/embeddings",
        headers={
            "Authorization": f"Bearer {settings.voyage_api_key}",
            "Content-Type": "application/json",
        },
        json={
            "input": texts,
            "model": "voyage-3-lite",
            "input_type": "document",
        },
        timeout=60,
    )
    response.raise_for_status()
    data = response.json()
    return [item["embedding"] for item in data["data"]]


def main():
    parser = argparse.ArgumentParser(
        description="Backfill embeddings for indexed assets"
    )
    parser.add_argument(
        "--limit", type=int, default=0, help="Max assets to process (0 = all)"
    )
    parser.add_argument(
        "--batch-size", type=int, default=20, help="Assets per Voyage API call"
    )
    parser.add_argument(
        "--dry-run", action="store_true", help="Preview without changes"
    )
    args = parser.parse_args()

    try:
        settings = Settings()  # type: ignore
    except Exception as e:
        print(f"error loading settings: {e}", file=sys.stderr)
        print(
            "required env vars: TURSO_URL, TURSO_TOKEN, VOYAGE_API_KEY", file=sys.stderr
        )
        sys.exit(1)

    # Get assets needing embeddings
    sql = """
        SELECT key, name, searchable_text
        FROM assets
        WHERE embedding IS NULL
    """
    params: list | None = None
    if args.limit > 0:
        sql += " LIMIT ?"
        params = [args.limit]
    assets = turso_query(settings, sql, params)

    if not assets:
        print("no assets need embeddings")
        return

    print(f"found {len(assets)} assets needing embeddings")

    if args.dry_run:
        for asset in assets[:10]:
            name = asset.get("name") or asset["key"][:60]
            print(f"  - {name}")
        if len(assets) > 10:
            print(f"  ... and {len(assets) - 10} more")
        return

    def process_batch(batch_info):
        batch_num, batch = batch_info
        # Use searchable_text for embedding, fallback to name + key
        texts = []
        for asset in batch:
            text = asset.get("searchable_text") or ""
            if not text.strip():
                text = f"{asset.get('name', '')} {asset['key']}"
            # Truncate to 8000 chars - well within Voyage API's input limits
            texts.append(text[:8000])

        embeddings = voyage_embed(settings, texts)
        statements = []
        for asset, embedding in zip(batch, embeddings):
            embedding_json = json.dumps(embedding)
            statements.append(
                (
                    "UPDATE assets SET embedding = vector32(?) WHERE key = ?",
                    [embedding_json, asset["key"]],
                )
            )
        turso_batch_exec(settings, statements)
        return batch_num, len(batch)

    batches = [
        (i // args.batch_size + 1, assets[i : i + args.batch_size])
        for i in range(0, len(assets), args.batch_size)
    ]

    processed = 0
    workers = min(8, len(batches))
    print(f"processing {len(batches)} batches with {workers} workers...")

    with ThreadPoolExecutor(max_workers=workers) as executor:
        futures = {executor.submit(process_batch, b): b[0] for b in batches}
        for future in as_completed(futures):
            batch_num, count = future.result()
            processed += count
            print(f"batch {batch_num} done ({processed}/{len(assets)})", flush=True)

    print(f"done! processed {processed} assets")


if __name__ == "__main__":
    main()


--- scripts/check_for_breakpoints.py ---
import re
import sys

BREAKPOINT_PATTERNS = [
    r"breakpoint\(\)",
    r"pdb\.set_trace\(\)",
    r"import pdb",
    r"from pdb import",
    r"ipdb\.set_trace\(\)",
    r"import ipdb",
    r"from ipdb import",
]


def check_file(filename: str) -> list[str]:
    with open(filename, "r") as f:
        content = f.read()

    found_breakpoints: list[str] = []
    for pattern in BREAKPOINT_PATTERNS:
        matches = re.findall(pattern, content)
        for match in matches:
            found_breakpoints.append(f"{filename}: {match}")

    return found_breakpoints


if __name__ == "__main__":
    files = sys.argv[1:]
    all_breakpoints: list[str] = []

    for file in files:
        breakpoints = check_file(file)
        all_breakpoints.extend(breakpoints)

    if all_breakpoints:
        print("Found breakpoints in files:")
        for bp in all_breakpoints:
            print(f"  {bp}")
        sys.exit(1)

    sys.exit(0)


--- scripts/index_assets.py ---
#!/usr/bin/env -S uv run --quiet --script
# /// script
# requires-python = ">=3.12"
# dependencies = ["prefect", "httpx", "pydantic-settings"]
# ///
"""
Asset indexing script for Prefect Cloud -> Turso.

This script syncs Prefect Cloud assets to a Turso database for efficient
querying via SQL or semantic search (embeddings can be backfilled separately).

## Prerequisites

- uv must be installed
- You must be authenticated to Prefect Cloud
- You must have a workspace selected
- Turso database credentials (TURSO_URL, TURSO_TOKEN)

## Setup

1. Create a Turso database:
   ```bash
   turso db create marvin-assets
   turso db tokens create marvin-assets
   ```

2. Set environment variables:
   ```bash
   export TURSO_URL="libsql://marvin-assets-<username>.turso.io"
   export TURSO_TOKEN="<your-token>"
   ```

## Usage

### Initialize schema
```bash
./scripts/index_assets.py init
```

### Sync assets to Turso
```bash
./scripts/index_assets.py sync                    # full sync
./scripts/index_assets.py sync --limit 100        # sync first 100 assets
./scripts/index_assets.py sync --dry-run          # preview what would be synced
```

### Query assets
```bash
./scripts/index_assets.py query "SELECT * FROM assets WHERE type = 'slack' LIMIT 5"
./scripts/index_assets.py query "SELECT COUNT(*) FROM assets GROUP BY type"
```

### Search assets
```bash
./scripts/index_assets.py search "concurrency limits"
./scripts/index_assets.py search "dbt model" --type duckdb
```

### Stats
```bash
./scripts/index_assets.py stats
```

## Schema

The `assets` table stores:
- `key`: Unique asset identifier (e.g., `slack://workspace/...`)
- `type`: Asset type derived from URI prefix (slack, duckdb, etc.)
- `name`: Human-readable name from properties
- `description`: Asset description
- `owners`: JSON array of owners
- `last_seen`: Last seen timestamp
- `metadata`: Full metadata JSON blob
- `searchable_text`: Combined text for full-text search
- `embedding`: F32_BLOB(512) for semantic search (nullable, backfill separately)
"""

import argparse
import asyncio
import json
import os
import sys
from typing import Any

import httpx
from prefect import get_client
from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=os.environ.get("ENV_FILE", ".env"), extra="ignore"
    )

    turso_url: str
    turso_token: str
    voyage_api_key: str

    @property
    def turso_host(self) -> str:
        """Strip libsql:// prefix if present."""
        url = self.turso_url
        if url.startswith("libsql://"):
            url = url[len("libsql://") :]
        return url


# --- Turso operations ---


def turso_query(settings: Settings, sql: str, args: list | None = None) -> list[dict]:
    """Execute a query against Turso and return rows."""
    stmt = {"sql": sql}
    if args:
        stmt["args"] = [{"type": "text", "value": str(a)} for a in args]

    response = httpx.post(
        f"https://{settings.turso_host}/v2/pipeline",
        headers={
            "Authorization": f"Bearer {settings.turso_token}",
            "Content-Type": "application/json",
        },
        json={"requests": [{"type": "execute", "stmt": stmt}, {"type": "close"}]},
        timeout=30,
    )
    response.raise_for_status()
    data = response.json()

    try:
        result = data["results"][0]
        if result["type"] == "error":
            raise Exception(f"Turso error: {result['error']}")

        cols = [c["name"] for c in result["response"]["result"]["cols"]]
        rows = result["response"]["result"]["rows"]

        def extract_value(cell):
            if cell is None:
                return None
            if isinstance(cell, dict):
                return cell.get("value")
            return cell

        return [dict(zip(cols, [extract_value(cell) for cell in row])) for row in rows]
    except (KeyError, IndexError, TypeError) as e:
        raise ValueError(f"malformed Turso response: {e}") from e


def turso_exec(
    settings: Settings, sql: str, args: list | None = None, retries: int = 3
) -> None:
    """Execute a statement against Turso with retry logic."""
    turso_batch_exec(settings, [(sql, args)], retries)


def turso_batch_exec(
    settings: Settings, statements: list[tuple[str, list | None]], retries: int = 3
) -> None:
    """Execute multiple statements in a single pipeline request."""
    import time

    requests = []
    for sql, args in statements:
        stmt = {"sql": sql}
        if args:
            stmt["args"] = [{"type": "text", "value": str(a)} for a in args]
        requests.append({"type": "execute", "stmt": stmt})
    requests.append({"type": "close"})

    for attempt in range(retries):
        try:
            response = httpx.post(
                f"https://{settings.turso_host}/v2/pipeline",
                headers={
                    "Authorization": f"Bearer {settings.turso_token}",
                    "Content-Type": "application/json",
                },
                json={"requests": requests},
                timeout=120,
            )
            response.raise_for_status()
            data = response.json()
            for i, result in enumerate(data["results"][:-1]):  # skip close result
                if result["type"] == "error":
                    raise Exception(f"Turso error on statement {i}: {result['error']}")
            return
        except (httpx.ReadTimeout, httpx.ConnectTimeout, httpx.ConnectError) as e:
            if attempt < retries - 1:
                wait = 2 ** (attempt + 1)
                print(f"  {type(e).__name__}, retrying in {wait}s...")
                time.sleep(wait)
            else:
                raise


# --- Prefect asset operations ---


async def list_assets(
    limit: int = 0, asset_type: str = "slack"
) -> list[dict[str, Any]]:
    """List assets from Prefect Cloud, filtered by type."""
    print(f"  fetching assets from Prefect Cloud (type={asset_type})...", flush=True)

    async with get_client() as client:
        response = await client._client.get(
            "/assets/", params={"limit": 10000, "offset": 0}
        )
        response.raise_for_status()
        data = response.json()

        if isinstance(data, list):
            assets = data
        else:
            assets = data.get("results", [])

        print(f"  fetched {len(assets)} total assets", flush=True)

        # Filter by type
        if asset_type:
            assets = [
                a for a in assets if extract_asset_type(a.get("key", "")) == asset_type
            ]
            print(f"  filtered to {len(assets)} {asset_type} assets", flush=True)

        if limit > 0:
            assets = assets[:limit]

    return assets


def extract_asset_type(key: str) -> str:
    """Extract asset type from URI key."""
    if "://" in key:
        return key.split("://")[0]
    return "other"


def build_searchable_text(asset: dict) -> str:
    """Build combined searchable text from asset fields."""
    parts = []

    # Properties
    props = asset.get("properties", {})
    if props.get("name"):
        parts.append(props["name"])
    if props.get("description"):
        parts.append(props["description"])

    # Metadata from latest materialization
    meta = asset.get("latest_materialization", {}).get("metadata", {})
    if meta.get("title"):
        parts.append(meta["title"])
    if meta.get("summary"):
        parts.append(meta["summary"])
    if meta.get("key_topics"):
        parts.extend(meta["key_topics"])

    return " ".join(parts)


def asset_to_row(asset: dict) -> tuple:
    """Convert Prefect asset to database row values."""
    key = asset.get("key", "")
    asset_type = extract_asset_type(key)
    props = asset.get("properties", {})
    meta = asset.get("latest_materialization", {}).get("metadata", {})

    return (
        key,
        asset_type,
        props.get("name", ""),
        props.get("description", ""),
        json.dumps(props.get("owners", [])),
        asset.get("last_seen", ""),
        json.dumps(meta),
        build_searchable_text(asset),
    )


# --- Commands ---


def cmd_init(settings: Settings):
    """Initialize the database schema."""
    print("initializing schema...")

    schema = """
    CREATE TABLE IF NOT EXISTS assets (
        key TEXT PRIMARY KEY,
        type TEXT NOT NULL,
        name TEXT,
        description TEXT,
        owners TEXT,
        last_seen TEXT,
        metadata TEXT,
        searchable_text TEXT,
        embedding F32_BLOB(512)
    );

    CREATE INDEX IF NOT EXISTS idx_assets_type ON assets(type);
    CREATE INDEX IF NOT EXISTS idx_assets_last_seen ON assets(last_seen);
    """

    for stmt in schema.strip().split(";"):
        stmt = stmt.strip()
        if stmt:
            turso_exec(settings, stmt)

    print("done!")


def cmd_sync(settings: Settings, limit: int = 0, dry_run: bool = False):
    """Sync assets from Prefect Cloud to Turso."""

    async def _sync():
        print("fetching assets from Prefect Cloud...")
        assets = await list_assets(limit=limit)
        print(f"found {len(assets)} assets")

        if dry_run:
            by_type = {}
            for asset in assets:
                t = extract_asset_type(asset.get("key", ""))
                by_type[t] = by_type.get(t, 0) + 1
            print("\nby type:")
            for t, count in sorted(by_type.items(), key=lambda x: -x[1]):
                print(f"  {t}: {count}")
            print("\ndry run - no changes made")
            return

        # Batch upsert
        print("syncing to Turso...")
        batch_size = 50
        processed = 0

        for i in range(0, len(assets), batch_size):
            batch = assets[i : i + batch_size]
            statements = []

            for asset in batch:
                row = asset_to_row(asset)
                statements.append(
                    (
                        """
                    INSERT OR REPLACE INTO assets
                    (key, type, name, description, owners, last_seen, metadata, searchable_text)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """,
                        list(row),
                    )
                )

            turso_batch_exec(settings, statements)
            processed += len(batch)
            print(f"  synced {processed}/{len(assets)}")

        print(f"done! synced {processed} assets")

    asyncio.run(_sync())


def cmd_query(settings: Settings, sql: str):
    """Run a SQL query against the assets database."""
    rows = turso_query(settings, sql)
    if not rows:
        print("no results")
        return

    # Pretty print as JSON
    for row in rows:
        print(json.dumps(row, indent=2))


def cmd_search(settings: Settings, query: str, asset_type: str | None = None):
    """Search assets by text (simple LIKE-based search)."""
    sql = """
    SELECT key, type, name,
           SUBSTR(searchable_text, 1, 200) as preview
    FROM assets
    WHERE searchable_text LIKE ?
    """
    # Escape SQL LIKE special characters
    escaped_query = query.replace("%", r"\%").replace("_", r"\_")
    args = [f"%{escaped_query}%"]

    if asset_type:
        sql += " AND type = ?"
        args.append(asset_type)

    sql += " LIMIT 20"

    rows = turso_query(settings, sql, args)

    if not rows:
        print(f"no assets found matching '{query}'")
        return

    print(f"found {len(rows)} matching assets:\n")
    for row in rows:
        print(f"[{row['type']}] {row['name'] or row['key'][:60]}")
        if row.get("preview"):
            preview = row["preview"][:150].replace("\n", " ")
            print(f"  {preview}...")
        print()


def voyage_embed(settings: Settings, texts: list[str]) -> list[list[float]]:
    """Generate embeddings using Voyage AI."""
    response = httpx.post(
        "https://api.voyageai.com/v1/embeddings",
        headers={
            "Authorization": f"Bearer {settings.voyage_api_key}",
            "Content-Type": "application/json",
        },
        json={
            "input": texts,
            "model": "voyage-3-lite",
            "input_type": "query",
        },
        timeout=60,
    )
    response.raise_for_status()
    data = response.json()
    return [item["embedding"] for item in data["data"]]


def cmd_similar(
    settings: Settings, query: str, asset_type: str | None = None, limit: int = 10
):
    """Semantic search using embeddings."""
    # Get query embedding
    print(f"searching for: {query}")
    embeddings = voyage_embed(settings, [query])
    query_embedding = json.dumps(embeddings[0])

    # Vector similarity search
    sql = """
    SELECT key, type, name,
           SUBSTR(searchable_text, 1, 200) as preview,
           vector_distance_cos(embedding, vector32(?)) as distance
    FROM assets
    WHERE embedding IS NOT NULL
    """
    args = [query_embedding]

    if asset_type:
        sql += " AND type = ?"
        args.append(asset_type)

    sql += " ORDER BY distance LIMIT ?"
    args.append(limit)

    rows = turso_query(settings, sql, args)

    if not rows:
        print(
            "no assets with embeddings found (run backfill_asset_embeddings.py first)"
        )
        return

    print(f"\nfound {len(rows)} similar assets:\n")
    for row in rows:
        score = 1 - float(row.get("distance", 0))  # convert distance to similarity
        print(f"[{row['type']}] {row['name'] or row['key'][:60]} (score: {score:.3f})")
        if row.get("preview"):
            preview = row["preview"][:150].replace("\n", " ")
            print(f"  {preview}...")
        print()


def cmd_stats(settings: Settings):
    """Show database statistics."""
    print("asset statistics:\n")

    # Total count
    total = turso_query(settings, "SELECT COUNT(*) as count FROM assets")
    print(f"total assets: {total[0]['count']}")

    # By type
    by_type = turso_query(
        settings,
        "SELECT type, COUNT(*) as count FROM assets GROUP BY type ORDER BY count DESC",
    )
    print("\nby type:")
    for row in by_type:
        print(f"  {row['type']}: {row['count']}")

    # Embeddings
    with_embeddings = turso_query(
        settings, "SELECT COUNT(*) as count FROM assets WHERE embedding IS NOT NULL"
    )
    print(f"\nwith embeddings: {with_embeddings[0]['count']}")


def main():
    parser = argparse.ArgumentParser(
        description="Index Prefect Cloud assets to Turso",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    subparsers = parser.add_subparsers(dest="command", help="command to run")

    # init
    subparsers.add_parser("init", help="Initialize database schema")

    # sync
    sync_parser = subparsers.add_parser("sync", help="Sync assets to Turso")
    sync_parser.add_argument(
        "--limit", type=int, default=0, help="Max assets to sync (0 = all)"
    )
    sync_parser.add_argument(
        "--dry-run", action="store_true", help="Preview without syncing"
    )

    # query
    query_parser = subparsers.add_parser("query", help="Run SQL query")
    query_parser.add_argument("sql", help="SQL query to execute")

    # search
    search_parser = subparsers.add_parser("search", help="Search assets by text")
    search_parser.add_argument("query", help="Search query")
    search_parser.add_argument("--type", dest="asset_type", help="Filter by asset type")

    # similar (semantic search)
    similar_parser = subparsers.add_parser(
        "similar", help="Semantic search using embeddings"
    )
    similar_parser.add_argument("query", help="Search query")
    similar_parser.add_argument(
        "--type", dest="asset_type", help="Filter by asset type"
    )
    similar_parser.add_argument(
        "--limit", type=int, default=10, help="Max results (default: 10)"
    )

    # stats
    subparsers.add_parser("stats", help="Show database statistics")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    try:
        settings = Settings()  # type: ignore
    except Exception as e:
        print(f"error loading settings: {e}", file=sys.stderr)
        print(
            "required env vars: TURSO_URL, TURSO_TOKEN, VOYAGE_API_KEY", file=sys.stderr
        )
        sys.exit(1)

    if args.command == "init":
        cmd_init(settings)
    elif args.command == "sync":
        cmd_sync(settings, args.limit, args.dry_run)
    elif args.command == "query":
        cmd_query(settings, args.sql)
    elif args.command == "search":
        cmd_search(settings, args.query, args.asset_type)
    elif args.command == "similar":
        cmd_similar(settings, args.query, args.asset_type, args.limit)
    elif args.command == "stats":
        cmd_stats(settings)


if __name__ == "__main__":
    main()


--- src/marvin/_internal/integrations/README.md ---
# Marvin Integrations

This directory contains adapters and utilities to integrate external services with Marvin.

## FastMCP Integration

The `fastmcp.py` module provides an adapter to connect Marvin agents with FastMCP servers. This integration allows Marvin agents to use tools defined on a FastMCP server.

### Design Decisions

#### 1. Lazy Loading / Optional Dependencies

The integration uses a lazy-loading pattern to avoid hard dependencies on FastMCP:

- FastMCP is imported only when needed and only if it's available
- This allows FastMCP to be an optional dependency (installed with `marvin[mcp]`)
- Users who don't need FastMCP don't need to install it

#### 2. Duck Typing for Compatibility

The adapter uses duck typing rather than strict type checking:

- Checks for required methods/attributes (`name`, `list_tools`/`_mcp_list_tools`, etc.)
- Supports both public methods and internal implementation methods
- This approach improves compatibility with different FastMCP versions and variants
- Handles cases where FastMCP may be imported from different module paths

#### 3. Stateful Import Management

The `_FastMCPImportState` class manages the import state:

- Tracks whether import has been attempted to avoid repeated import attempts
- Stores the imported FastMCP type for later reference
- Stores a reference to the conversion function
- This encapsulation simplifies state management and keeps global namespace clean

#### 4. Detection Heuristics

Detection of FastMCP servers uses multiple heuristics:

- Class name contains "FastMCP"
- Required method presence
- This "belt and suspenders" approach improves reliability when dealing with various FastMCP implementations

#### 5. Error Handling and Diagnostics

The module includes comprehensive error handling and logging:

- Provides clear error messages when FastMCP isn't installed
- Logs detailed diagnostics during initialization and method calls
- Exception handling during adapter creation for better debugging

### Potential Improvements

If you're rewriting this code, consider these potential improvements:

1. Use a proper dependency injection framework instead of global state
2. Create a more formal protocol/interface for MCPServer implementations
3. Implement a registry of adapters rather than the current if/elif approach
4. Consider moving adapter detection to registration time rather than usage time
5. Add more comprehensive unit tests for different FastMCP server types
6. Improve type safety by using Protocol classes from typing module

### Usage

When a Marvin Agent is initialized with a FastMCP server in its `mcp_servers` list:

```python
from fastmcp.server import FastMCP
import marvin

# Create a FastMCP server
server = FastMCP("My Server")

@server.tool()
def hello_world() -> str:
    return "Hello, world!"

# Use the server with a Marvin agent
agent = marvin.Agent(mcp_servers=[server])
result = agent.run("Please say hello to the world")
```

The FastMCP server is automatically detected and adapted to the MCPServer interface expected by Marvin. This happens transparently to the user, who only needs to provide the FastMCP server instance directly.

--- src/marvin/database.py ---
"""Database management for persistence.

This module provides utilities for managing database sessions and migrations.
"""

import asyncio
import inspect
import uuid
from collections.abc import AsyncGenerator
from contextlib import asynccontextmanager
from datetime import datetime, timezone
from pathlib import Path
from typing import TYPE_CHECKING, Any
from urllib.parse import urlparse

from pydantic import ConfigDict, TypeAdapter
from pydantic_ai.messages import RetryPromptPart
from pydantic_ai.usage import Usage
from sqlalchemy import (
    JSON,
    TIMESTAMP,
    ForeignKey,
    Index,
    String,
    TypeDecorator,
    func,
    select,
)
from sqlalchemy.ext.asyncio import (
    AsyncEngine,
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)
from sqlalchemy.orm import (
    DeclarativeBase,
    Mapped,
    mapped_column,
    relationship,
)

import marvin
from marvin.settings import settings
from marvin.utilities.logging import get_logger

from .engine.llm import PydanticAIMessage

if TYPE_CHECKING:
    from marvin.thread import Message

logger = get_logger(__name__)
message_adapter: TypeAdapter[PydanticAIMessage] = TypeAdapter(
    PydanticAIMessage,
    config=ConfigDict(ser_json_bytes="base64", val_json_bytes="base64"),
)
usage_adapter: TypeAdapter[Usage] = TypeAdapter(Usage)

# Module-level cache for engines and sessionmakers
_async_engine_cache: dict[Any, AsyncEngine] = {}
db_initialized = False

# Migration constants
MARVIN_DIR = Path(marvin.__file__).parent.parent.parent
ALEMBIC_DIR = MARVIN_DIR / "migrations"
ALEMBIC_INI = MARVIN_DIR / "alembic.ini"


def serialize_message(message: PydanticAIMessage) -> str:
    """
    The `ctx` field in the `RetryPromptPart` is optionally dict[str, Any], which is not always serializable.
    """
    for part in message.parts:
        if isinstance(part, RetryPromptPart):
            if isinstance(part.content, list):
                for content in part.content:
                    content["ctx"] = {
                        k: str(v) for k, v in (content.get("ctx", None) or {}).items()
                    }
    return message_adapter.dump_python(message, mode="json")


def get_async_engine() -> AsyncEngine:
    """Get the SQLAlchemy engine for async operations.

    For SQLite databases, this uses aiosqlite.
    For other databases (e.g. PostgreSQL), this uses the provided URL directly.

    The engine is cached by asyncio event loop to maintain compatibility with run_sync.
    """
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = None

    if loop not in _async_engine_cache:
        url = settings.database_url
        if url is None:
            raise ValueError("Database URL is not configured")

        # Handle SQLite databases (default)
        if is_sqlite():
            engine = create_async_engine(url, echo=False)
        # Handle other databases (use URL as-is)
        else:
            engine = create_async_engine(url, echo=False)

        _async_engine_cache[loop] = engine

    return _async_engine_cache[loop]


def is_sqlite() -> bool:
    """Check if the configured database is SQLite."""
    url = settings.database_url
    if url is None:
        raise ValueError("Database URL is not configured")

    parsed_url = urlparse(url)
    return parsed_url.scheme.startswith("sqlite")


def set_async_engine(engine: AsyncEngine) -> None:
    """Set the SQLAlchemy engine for async operations."""
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = None

    _async_engine_cache[loop] = engine


def utc_now() -> datetime:
    """Get the current UTC timestamp."""
    return datetime.now(timezone.utc)


class Base(DeclarativeBase):
    """Base class for all database models."""

    pass


class DBThread(Base):
    __tablename__ = "threads"

    id: Mapped[str] = mapped_column(String, primary_key=True)
    parent_thread_id: Mapped[str | None] = mapped_column(ForeignKey("threads.id"))
    created_at: Mapped[datetime] = mapped_column(
        TIMESTAMP(timezone=True), default=utc_now
    )

    messages: Mapped[list["DBMessage"]] = relationship(back_populates="thread")
    llm_calls: Mapped[list["DBLLMCall"]] = relationship(back_populates="thread")

    @classmethod
    async def create(
        cls,
        session: AsyncSession | None = None,
        id: str | None = None,
        parent_thread_id: str | None = None,
    ) -> "DBThread":
        """Create a new thread record.

        Args:
            session: Database session to use
            id: Optional ID to use for the thread. If not provided, a UUID will be generated.
            parent_thread_id: Optional ID of the parent thread

        Returns:
            The created DBThread instance
        """
        async with get_async_session(session) as session:
            thread = cls(
                id=id or str(uuid.uuid4()),
                parent_thread_id=parent_thread_id,
            )
            session.add(thread)
        return thread


class DBLLMCallMessage(Base):
    """Mapping table between LLM calls and messages."""

    __tablename__ = "llm_call_messages"

    id: Mapped[uuid.UUID] = mapped_column(primary_key=True, default=uuid.uuid4)
    llm_call_id: Mapped[uuid.UUID] = mapped_column(
        ForeignKey("llm_calls.id"), index=True
    )
    message_id: Mapped[uuid.UUID] = mapped_column(ForeignKey("messages.id"), index=True)
    in_initial_prompt: Mapped[bool] = mapped_column()
    order: Mapped[int] = mapped_column()  # Track message order within the call

    llm_call: Mapped["DBLLMCall"] = relationship(back_populates="message_mappings")
    message: Mapped["DBMessage"] = relationship(back_populates="llm_call_mappings")


class DBMessage(Base):
    __tablename__ = "messages"

    id: Mapped[uuid.UUID] = mapped_column(primary_key=True, default=uuid.uuid4)
    thread_id: Mapped[str] = mapped_column(ForeignKey("threads.id"))
    message: Mapped[dict[str, Any]] = mapped_column(JSON)
    created_at: Mapped[datetime] = mapped_column(
        TIMESTAMP(timezone=True), default=utc_now, server_default=func.now()
    )

    # Create a composite index on thread_id and timestamp in descending order
    # Using SQLAlchemy's proper syntax for descending index
    __table_args__ = (
        Index(
            "ix_messages_thread_id_created_at_desc",
            "thread_id",
            created_at.desc(),
        ),
    )

    thread: Mapped[DBThread] = relationship(back_populates="messages")
    llm_call_mappings: Mapped[list[DBLLMCallMessage]] = relationship(
        back_populates="message"
    )

    @classmethod
    def from_message(
        cls,
        thread_id: str,
        message: PydanticAIMessage,
        created_at: datetime | None = None,
    ) -> "DBMessage":
        return cls(
            thread_id=thread_id,
            message=serialize_message(message),
            created_at=created_at or utc_now(),
        )

    def to_message(self) -> "Message":
        import marvin.thread

        return marvin.thread.Message(
            id=self.id,
            thread_id=self.thread_id,
            message=message_adapter.validate_python(self.message),
            created_at=self.created_at,
        )


class UsageType(TypeDecorator[Usage]):
    """Custom type for Usage objects that stores them as JSON in the database."""

    impl = JSON
    cache_ok = True

    def process_bind_param(
        self, value: Usage | None, dialect: Any
    ) -> dict[str, Any] | None:
        """Convert Usage to JSON before storing in DB."""
        if value is None:
            return None
        return usage_adapter.dump_python(value, mode="json")

    def process_result_value(
        self, value: dict[str, Any] | None, dialect: Any
    ) -> Usage | None:
        """Convert JSON back to Usage when loading from DB."""
        if value is None:
            return None
        return usage_adapter.validate_python(value)


class DBLLMCall(Base):
    __tablename__ = "llm_calls"

    id: Mapped[uuid.UUID] = mapped_column(primary_key=True, default=uuid.uuid4)
    thread_id: Mapped[str] = mapped_column(ForeignKey("threads.id"), index=True)
    usage: Mapped[Usage] = mapped_column(UsageType)
    timestamp: Mapped[datetime] = mapped_column(
        TIMESTAMP(timezone=True), default=utc_now
    )

    message_mappings: Mapped[list[DBLLMCallMessage]] = relationship(
        back_populates="llm_call"
    )
    thread: Mapped[DBThread] = relationship(back_populates="llm_calls")

    @classmethod
    async def create(
        cls,
        thread_id: str,
        usage: Usage,
        prompt_messages: list["DBMessage | Message"] | None = None,
        completion_messages: list["DBMessage | Message"] | None = None,
        session: AsyncSession | None = None,
    ) -> "DBLLMCall":
        """Create a new LLM call record.

        Args:
            thread_id: ID of the thread this call belongs to
            usage: Usage information from the model
            session: Optional database session. If not provided, a new one will be created.

        Returns:
            The created DBLLMCall instance
        """
        llm_call_id = uuid.uuid4()
        llm_call = cls(id=llm_call_id, thread_id=thread_id, usage=usage)

        async with get_async_session(session) as session:
            session.add(llm_call)

            # Add request messages, maintaining their original order
            for i, message in enumerate(prompt_messages):
                mapping = DBLLMCallMessage(
                    llm_call_id=llm_call.id,
                    message_id=message.id,
                    in_initial_prompt=True,
                    order=i,  # Set order based on position in the list
                )
                session.add(mapping)

            # Add response messages, maintaining their original order
            # Response messages come after request messages in order
            start_order = len(prompt_messages)
            for i, message in enumerate(completion_messages):
                mapping = DBLLMCallMessage(
                    llm_call_id=llm_call.id,
                    message_id=message.id,
                    in_initial_prompt=False,
                    order=start_order + i,  # Continue numbering after request messages
                )
                session.add(mapping)

        return llm_call


@asynccontextmanager
async def get_async_session(
    session: AsyncSession | None = None,
) -> AsyncGenerator[AsyncSession, None]:
    """Get an async database session.

    This uses the async_sessionmaker pattern for more consistent session management.
    If a session is provided, it is returned as-is.

    Args:
        session: An optional existing session to use. If provided, this function
            will yield it directly instead of creating a new one.

    Yields:
        An async SQLAlchemy session
    """
    # If session is provided, just use it
    if session is not None:
        yield session
        return

    # Try to get the engine - if this fails because tables don't exist,
    # make sure to create them before proceeding
    engine = get_async_engine()
    session_factory = async_sessionmaker(engine, expire_on_commit=False)

    # Create a session
    async with session_factory() as session:
        try:
            # Check if tables exist by attempting a simple query
            if is_sqlite():
                try:
                    # Try to query the threads table to see if it exists
                    await session.execute(select(DBThread).limit(1))
                except Exception as e:
                    if "no such table" in str(e).lower():
                        # Tables don't exist, create them
                        logger.warning("Database tables don't exist, creating them now")
                        async with engine.begin() as conn:
                            await conn.run_sync(Base.metadata.create_all)
                            logger.info("Created database tables on first access")

            # Now yield the session
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()


def _run_migrations(alembic_log_level: str = "WARNING") -> bool:
    """Run Alembic migrations.

    Returns:
        True if migrations were successful, False otherwise.
    """
    from alembic import command

    from marvin.cli.migrations import get_alembic_cfg

    alembic_cfg = get_alembic_cfg()
    try:
        command.upgrade(alembic_cfg, "head")
        return True
    except RuntimeError as e:
        if "event loop" in str(e):
            logger.warning(
                inspect.cleandoc(
                    """Migrations can not be run from inside an async context.
                    This is unusual and means you are importing Marvin within an
                    async function and it is trying to automatically create a
                    SQLite database that doesn't already exist. Make sure you
                    create, manage, or migrate your Marvin database separately.
                    You can set MARVIN_AUTO_INIT_SQLITE=false to disable this
                    behavior."""
                )
            )
    except Exception as e:
        logger.error(f"Failed to run migrations: {e}")
        return False


async def create_db_and_tables(
    *, force: bool = False, dispose_engine: bool = False
) -> None:
    """Create all database tables.

    Args:
        force: If True, drops all existing tables before creating new ones.
        dispose_engine: If True, dispose the engine after creating tables.
            This is useful when called from asyncio.run() to ensure the
            aiosqlite worker thread is cleaned up and doesn't prevent
            Python from exiting.
    """
    engine = get_async_engine()

    async with engine.begin() as conn:
        if force:
            await conn.run_sync(Base.metadata.drop_all)
            logger.debug("Database tables dropped.")

        await conn.run_sync(Base.metadata.create_all)
        logger.debug("Database tables created.")

    if dispose_engine:
        await engine.dispose()
        # Remove the engine from the cache since it's disposed
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = None
        _async_engine_cache.pop(loop, None)


def init_database_if_necessary():
    """Initialize the database file if necessary.

    This function only handles creating the database file and parent directories,
    it does not create tables. Tables are created by ensure_db_tables_exist().
    """
    global db_initialized
    if not db_initialized:
        if is_sqlite():
            # For file-based SQLite, check if file exists
            url = settings.database_url
            if url is None:
                return

            parsed_url = urlparse(url)
            if parsed_url.path and parsed_url.path != ":memory:":
                # Strip the leading slash if present
                path = parsed_url.path
                if path.startswith("/"):
                    path = path[1:]

                db_file = Path(path)
                if not db_file.exists():
                    # Create parent directories if needed
                    db_file.parent.mkdir(parents=True, exist_ok=True)
                    # Create empty file
                    db_file.touch()
                    logger.debug(f"Created new SQLite database file at {path}")

        db_initialized = True


def ensure_db_tables_exist():
    """Ensure database tables exist, creating them if necessary.

    This function creates all database tables directly without using migrations,
    which is more reliable than using Alembic migrations.
    """
    # First initialize the database file if needed
    init_database_if_necessary()

    # Now create tables
    import asyncio
    import sqlite3
    import threading

    # Define a lock for thread safety
    _create_tables_lock = threading.Lock()

    # Check if we're already in an event loop
    try:
        asyncio.get_running_loop()
        in_async_context = True
    except RuntimeError:
        in_async_context = False

    # Thread-local check to avoid recursion in async context
    if in_async_context:
        # If we're in an async context, we need to use a synchronous approach
        # Otherwise, we'll get "Event loop is already running" errors
        try:
            # For SQLite, we can directly check if tables exist
            if is_sqlite():
                url = settings.database_url
                if url is None:
                    return

                # Parse the URL to get the database path
                parsed_url = urlparse(url)
                if parsed_url.path and parsed_url.path != ":memory:":
                    # Strip the leading slash if present
                    path = parsed_url.path
                    if path.startswith("/"):
                        path = path[1:]

                    # Direct SQLite connection to check tables
                    try:
                        with _create_tables_lock:
                            conn = sqlite3.connect(path)
                            cursor = conn.cursor()
                            # Check if the threads table exists
                            cursor.execute(
                                "SELECT name FROM sqlite_master WHERE type='table' AND name='threads'"
                            )
                            result = cursor.fetchone()

                            if not result:
                                # Tables don't exist, we'll need to create them later
                                logger.warning(
                                    "Database tables don't exist, but we're in an async context. "
                                    "Tables will be created on first database access."
                                )
                            else:
                                logger.debug("Database tables already exist.")

                            conn.close()
                    except sqlite3.Error as e:
                        logger.error(f"Error checking database tables: {e}")

            return  # Return early if in async context
        except Exception as e:
            logger.error(f"Error ensuring database tables exist: {e}")
            return

    # Create tables synchronously using asyncio.run() if we're not in an async context
    try:
        with _create_tables_lock:
            # Use dispose_engine=True to clean up the aiosqlite worker thread
            # after table creation. Without this, the cached engine's worker
            # thread could prevent Python from exiting cleanly.
            asyncio.run(create_db_and_tables(dispose_engine=True))
            logger.debug("Database tables created successfully.")
    except Exception as e:
        logger.error(f"Failed to create database tables: {e}")


--- src/marvin/defaults.py ---
from contextlib import contextmanager
from dataclasses import dataclass
from typing import Any, TypedDict

from pydantic_ai.models import KnownModelName, Model
from typing_extensions import NotRequired, Unpack

import marvin
from marvin import Agent


class _Defaults(TypedDict):
    agent: NotRequired[Agent]
    model: NotRequired[KnownModelName | Model]
    memory_provider: NotRequired[str]


@dataclass
class Defaults:
    agent: Agent
    model: KnownModelName | Model
    memory_provider: str


defaults = Defaults(
    agent=Agent(name="Marvin"),
    model=marvin.settings.agent_model,
    memory_provider=marvin.settings.memory_provider,
)


@contextmanager
def override_defaults(**kwargs: Unpack[_Defaults]):
    """Temporarily override default settings.

    Any attribute of the defaults object can be temporarily overridden by passing
    it as a keyword argument.

    Example:
        >>> with override_defaults(model="gpt-4", agent=Agent(name="Custom")):
        ...     # code that uses the temporary defaults
        ...     pass

    """
    original_values: dict[str, Any] = {}

    for key, value in kwargs.items():
        if not hasattr(defaults, key):
            raise ValueError(f"Invalid default setting: {key}")
        original_values[key] = getattr(defaults, key)
        setattr(defaults, key, value)

    try:
        yield
    finally:
        for key, value in original_values.items():
            setattr(defaults, key, value)


--- src/marvin/__init__.py ---
from importlib.metadata import version as _version

# necessary imports
from marvin.settings import settings
from marvin.database import init_database_if_necessary

# core classes
from marvin.thread import Thread
from marvin.agents.agent import Agent
from marvin.tasks.task import Task
from marvin.memory.memory import Memory

# public access
from marvin.instructions import instructions
from marvin.defaults import defaults
from marvin.agents.team import Swarm, Team
from . import handlers

# marvin fns
from marvin.fns.run import (
    run,
    run_async,
    run_tasks_async,
    run_tasks,
    run_stream,
    run_tasks_stream,
)
from marvin.fns.classify import classify, classify_async
from marvin.fns.extract import extract, extract_async
from marvin.fns.cast import cast, cast_async
from marvin.fns.generate import (
    generate,
    generate_async,
    generate_schema,
    generate_schema_async,
)
from marvin.fns.fn import fn
from marvin.fns.say import say, say_async
from marvin.fns.summarize import summarize, summarize_async
from marvin.fns.plan import plan, plan_async

# Initialize the database on import
from marvin.database import ensure_db_tables_exist

ensure_db_tables_exist()

__version__ = _version("marvin")

__all__ = [
    "Agent",
    "Memory",
    "Team",
    "Swarm",
    "Task",
    "Thread",
    "cast",
    "cast_async",
    "classify",
    "classify_async",
    "defaults",
    "extract",
    "extract_async",
    "fn",
    "generate",
    "generate_async",
    "generate_schema",
    "generate_schema_async",
    "handlers",
    "instructions",
    "plan",
    "plan_async",
    "run",
    "run_async",
    "run_stream",
    "run_tasks",
    "run_tasks_async",
    "run_tasks_stream",
    "settings",
    "say",
    "say_async",
    "summarize",
    "summarize_async",
]


--- src/marvin/instructions.md ---
# Goals


# vs ControlFlow
- run one task at a time, never multiple
- run one agent at a time, never multiple
- agents have special tools for controling execution: `end_turn()` is default, optionally can also mark tasks successful/failed.
- tasks have a way to indicate whether the answer should be provided via tool or via converfsation e.g. `end_turn()` with no result means take the last message?
- do not recompile conversation history
- for each invocation, store 1) the system message 2) the historical messages

--- src/marvin/instructions.py ---
from collections.abc import Generator
from contextlib import contextmanager
from contextvars import ContextVar

from marvin.utilities.logging import get_logger

logger = get_logger(__name__)

# Global context var for current instructions
_current_instructions: ContextVar[list[str]] = ContextVar(
    "current_instructions",
    default=[],
)


@contextmanager
def instructions(instruction: str) -> Generator[None, None, None]:
    """Temporarily add instructions to the current instruction stack. The
    instruction is removed when the context is exited.

    with instructions("talk like a pirate"):
        ...
    """
    if not instruction:
        yield
        return

    stack = _current_instructions.get()
    token = _current_instructions.set(stack + [instruction])
    try:
        yield
    finally:
        _current_instructions.reset(token)


def get_instructions() -> list[str]:
    """Get the current instruction stack."""
    return _current_instructions.get()


--- src/marvin/prompts.py ---
"""Prompt system for Marvin.

This module provides a flexible prompt system that supports:
1. Prompts defined as strings or paths to template files
2. Static type checking of prompt variables
3. Dynamic prompt creation from function docstrings and signatures
4. Serialization of prompts and their required attributes
"""

import inspect
import re
from collections.abc import Callable
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, get_type_hints

from marvin.engine.llm import (
    AgentMessage,
    PydanticAIMessage,
    SystemMessage,
    UserMessage,
)
from marvin.utilities.jinja import jinja_env


@dataclass(kw_only=True)
class Template:
    """A template for generating prompts.

    Args:
        source: Either a string template or a Path to a template file

    """

    _dataclass_config = {"kw_only": True}

    source: str | Path

    def render(self, **kwargs: Any) -> str:
        """Render the template with variables."""
        render_kwargs = {
            k: v
            for k, v in self.__dict__.items()
            if k not in ["source", "_dataclass_config"]
        }

        if isinstance(self.source, Path):
            template = jinja_env.get_template(str(self.source))
        else:
            template = jinja_env.from_string(self.source)

        return template.render(**render_kwargs | kwargs)


@dataclass
class Prompt:
    """Base class for prompts.

    Prompts can be defined either as strings or paths to template files.
    Additional attributes can be added by subclassing and will be type-checked.
    """

    source: str | Path = field(
        metadata={
            "description": "The template source - either a string template or path to template file",
        },
    )
    _extra_fields: dict[str, Any] = field(default_factory=dict, repr=False)

    def __post_init__(self):
        if not self.source:
            raise ValueError("source must be provided")

    def __setattr__(self, name: str, value: Any) -> None:
        if name in ["source", "_extra_fields"]:
            super().__setattr__(name, value)
        else:
            self._extra_fields[name] = value

    def __getattr__(self, name: str) -> Any:
        if name in self._extra_fields:
            return self._extra_fields[name]
        raise AttributeError(f"'{self.__class__.__name__}' has no attribute '{name}'")

    def _render_template(self, **kwargs: Any) -> str:
        """Render the template with variables."""
        # Get all fields except source
        render_kwargs = {
            **self._extra_fields,
        }

        template = Template(source=self.source)
        return template.render(**render_kwargs | kwargs)

    def _parse_messages(self, text: str) -> list[PydanticAIMessage]:
        """Parse text into messages with roles.

        The text can contain role markers in the format "ROLE:" or "role:".
        Supported roles are: system, user, assistant
        If no role is specified, defaults to user.

        Example:
            SYSTEM: You are a helpful assistant.
            USER: Hi!
            ASSISTANT: Hello! How can I help you?

        """
        # Split on role markers, keeping the marker
        pattern = re.compile(
            r"^(SYSTEM:|USER:|ASSISTANT:|system:|user:|assistant:)\s*",
            re.MULTILINE,
        )

        # Split text into chunks at role markers
        chunks: list[tuple[str, str]] = []
        last_end = 0

        for match in pattern.finditer(text):
            # If there's text before this marker, it's content without a role
            if match.start() > last_end:
                chunks.append(("user", text[last_end : match.start()].strip()))

            # Get the role from the marker
            role = match.group(1).lower().rstrip(":")

            # Find the end of this chunk (next role marker or end of text)
            next_match = pattern.search(text, match.end())
            end = next_match.start() if next_match else len(text)

            # Add the chunk with its role
            content = text[match.end() : end].strip()
            if content:
                chunks.append((role, content))

            last_end = end

        # If there's remaining text, treat it as user message
        if last_end < len(text):
            content = text[last_end:].strip()
            if content:
                chunks.append(("user", content))

        # Convert role/content pairs to appropriate Message types
        messages: list[PydanticAIMessage] = []
        for role, content in chunks:
            if role == "system":
                messages.append(SystemMessage(content))
            elif role == "user":
                messages.append(UserMessage(content))
            elif role == "assistant":
                messages.append(AgentMessage(content))
        return messages

    def to_messages(self, **kwargs: Any) -> list[PydanticAIMessage]:
        """Convert the prompt to a list of messages with roles.

        The template can contain role markers (SYSTEM:, USER:, ASSISTANT:) to
        indicate message roles. Text without a role marker is treated as a user
        message.

        Example template:
            '''
            SYSTEM: You are a helpful assistant.
            USER: Hi {{ name }}!
            ASSISTANT: Hello {{ name }}! How can I help you?
            '''
        """
        # First render the template
        text = self._render_template(**kwargs)

        # Then parse into messages
        return self._parse_messages(text)

    @classmethod
    def from_fn(cls, fn: Callable[..., Any]) -> type["Prompt"]:
        """Create a Prompt class from a function's docstring and signature.

        Args:
            fn: The function to create a prompt from. The function's docstring will
                be used as the template, and its signature will define the required
                attributes.

        Example:
            def greet(name: str, age: int):
                '''
                SYSTEM: You are a friendly assistant.
                USER: Hi {{ name }}, how old are you?
                ASSISTANT: I'm an AI, but you're {{ age }} years old!
                '''
                pass

            GreetPrompt = Prompt.from_fn(greet)
            prompt = GreetPrompt(name="Alice", age=30)
            messages = prompt.to_messages()

        """
        # Get function signature and docstring
        sig = inspect.signature(fn)
        hints = get_type_hints(fn)
        _template = inspect.getdoc(fn)
        if not _template:
            raise ValueError(f"Function {fn.__name__} must have a docstring")

        # Create the dynamic prompt class
        @dataclass
        class DynamicPrompt(cls):
            source: str | Path = field(default=_template)
            __qualname__ = f"{fn.__name__.title()}Prompt"  # Set the class name

            # Add the function parameters as fields
            for name, param in sig.parameters.items():
                default = param.default if param.default is not param.empty else None
                locals()[name] = field(
                    default=default,
                    metadata={"description": f"Parameter from function {fn.__name__}"},
                )
                if name in hints:
                    __annotations__[name] = hints[name]

        return DynamicPrompt


--- src/marvin/settings.py ---
"""Settings for Marvin."""

import os
from pathlib import Path
from typing import Literal

from pydantic import Field, ValidationInfo, field_validator, model_validator
from pydantic_ai.models import KnownModelName
from pydantic_settings import BaseSettings, SettingsConfigDict
from typing_extensions import Self


class Settings(BaseSettings):
    """Settings for Marvin.

    Settings can be set via environment variables with the prefix MARVIN_. For
    example, MARVIN_AGENT_MODEL="openai:gpt-4o-mini"
    """

    model_config = SettingsConfigDict(
        env_prefix="MARVIN_",
        case_sensitive=False,
        env_file=".env",
        env_file_encoding="utf-8",
        extra="ignore",
        validate_assignment=True,
    )

    # ------------ General settings ------------

    home_path: Path = Field(
        default=Path("~/.marvin").expanduser(),
        description="The home path for Marvin.",
    )

    @field_validator("home_path")
    @classmethod
    def validate_home_path(cls, v: Path) -> Path:
        """Ensure the home path exists."""
        path = Path(v).expanduser().resolve()
        path.mkdir(parents=True, exist_ok=True)
        return path

    database_url: str | None = Field(
        default=None,
        description="Database URL. Must be provided with an async-compatible SQLAlchemy dialect. Defaults to `sqlite+aiosqlite:///{{home_path}}/marvin.db`. Loaded from MARVIN_DATABASE_URL environment variable or .env entry.",
    )

    auto_init_sqlite: bool = Field(
        default=True,
        description="""
        For SQLite databases, whether to automatically initialize the database
        on startup if the file doesn't already exist. This is a one-time
        operation to migrate the database to the latest version and will not be
        repeated.""",
    )

    @field_validator("database_url", mode="before")
    @classmethod
    def validate_database_url(cls, v: str | None, info: ValidationInfo) -> str:
        """Set and validate the database URL.

        Priority:
        1. MARVIN_DATABASE_URL (from environment or .env file via os.getenv).
        2. Default SQLite path if MARVIN_DATABASE_URL is not set.
        This validator bypasses Pydantic's implicit fallback to an unprefixed DATABASE_URL from .env.
        """

        if explicit_marvin_url := os.getenv("MARVIN_DATABASE_URL"):
            return explicit_marvin_url

        # If MARVIN_DATABASE_URL is not set, use the default SQLite path.
        home_path_val = info.data.get("home_path")

        if not home_path_val:
            raise ValueError(
                "home_path must be determined before database_url can be defaulted. "
                "Ensure home_path is correctly configured or resolvable."
            )

        return f"sqlite+aiosqlite:///{home_path_val}/marvin.db"

    # ------------ Logging settings ------------

    log_level: Literal["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"] = Field(
        default="INFO",
        description="Logging level",
    )

    log_file: Path | None = Field(
        default=None,
        description="Path to a file for logging. If None, logs to stdout.",
    )

    log_events: bool = Field(
        default=False,
        description="Whether to log all events (as debug logs).",
    )

    @field_validator("log_level", mode="before")
    @classmethod
    def _validate_log_level(cls, v: str) -> str:
        """Validate the log level."""
        return v.upper()

    @model_validator(mode="after")
    def setup_logging(self) -> Self:
        """Finalize the settings."""
        from marvin.utilities.logging import setup_logging

        setup_logging(settings=self)

        return self

    # ------------ Agent settings ------------

    agent_model: KnownModelName = Field(
        default="openai:gpt-4o",
        description="The default model for agents.",
    )

    agent_temperature: float | None = Field(
        default=None,
        description="The temperature for the agent.",
    )

    agent_retries: int = Field(
        default=10,
        description="The number of times the agent is allowed to retry when it generates an invalid result.",
    )

    max_agent_turns: int | None = Field(
        default=100,
        description="The maximum number of turns any agents can take when running orchestrated tasks. Note this is per-invocation.",
    )

    # ------------ DX settings ------------

    enable_default_print_handler: bool = Field(
        default=True,
        description="Whether to enable the default print handler.",
    )

    default_print_handler_hide_end_turn_tools: bool = Field(
        default=False,
        description="Whether to hide end turn tool results in the default print handler.",
    )

    # ------------ Memory settings ------------

    memory_provider: str = Field(
        default="chroma-ephemeral",
        description="The default memory provider for agents.",
    )

    chroma_cloud_api_key: str | None = Field(
        default=None,
        description="The API key for the Chroma Cloud.",
    )

    chroma_cloud_tenant: str | None = Field(
        default=None,
        description="The tenant for the Chroma Cloud.",
    )

    chroma_cloud_database: str | None = Field(
        default=None,
        description="The database for the Chroma Cloud.",
    )


# Global settings instance
settings = Settings()


--- src/marvin/thread.py ---
"""Thread management for conversations.

This module provides the Thread class for managing conversation context.
"""

import uuid
from contextvars import ContextVar
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Sequence

from pydantic import TypeAdapter
from pydantic_ai.messages import UserContent
from pydantic_ai.usage import Usage
from sqlalchemy import select

from marvin.database import (
    DBLLMCall,
    DBLLMCallMessage,
    DBMessage,
    DBThread,
    get_async_session,
    utc_now,
)
from marvin.engine.llm import ModelRequest
from marvin.utilities.asyncio import run_sync

from .engine.llm import AgentMessage, PydanticAIMessage, SystemMessage, UserMessage

# Message serialization adapter
message_adapter: TypeAdapter[PydanticAIMessage | list[PydanticAIMessage]] = TypeAdapter(
    PydanticAIMessage | list[PydanticAIMessage]
)


@dataclass(kw_only=True)
class Message:
    id: uuid.UUID = field(default_factory=uuid.uuid4)
    thread_id: str = field(default=None)
    message: PydanticAIMessage
    created_at: datetime = field(default_factory=utc_now)


@dataclass(kw_only=True)
class LLMCallMessages:
    prompt: list[Message]
    completion: list[Message]


@dataclass(kw_only=True)
class LLMCall:
    """Represents an LLM call."""

    id: uuid.UUID
    thread_id: str
    usage: Usage
    timestamp: datetime

    def get_messages(self) -> LLMCallMessages:
        """Get the messages for this LLM call."""
        return run_sync(self.get_messages_async())

    async def get_messages_async(self) -> LLMCallMessages:
        """Get the messages for this LLM call."""
        async with get_async_session() as session:
            # Query the llm_call_messages table to get all messages associated with this LLM call

            # Get all message associations for this LLM call ordered by their sequence
            query = (
                select(DBLLMCallMessage, DBMessage)
                .join(
                    DBMessage,
                    DBLLMCallMessage.message_id == DBMessage.id,
                )
                .where(DBLLMCallMessage.llm_call_id == self.id)
                .order_by(DBLLMCallMessage.order)
            )

            result = await session.execute(query)

            # Map the database enum values to our new terminology
            # REQUEST -> prompt, RESPONSE -> completion
            messages_by_role = {"prompt": [], "completion": []}

            for llm_call_message, db_message in result:
                if llm_call_message.in_initial_prompt:
                    messages_by_role["prompt"].append(db_message.to_message())
                else:
                    messages_by_role["completion"].append(db_message.to_message())

            return LLMCallMessages(
                prompt=messages_by_role["prompt"],
                completion=messages_by_role["completion"],
            )


# Global context var for current thread
_current_thread: ContextVar["Thread | None"] = ContextVar(
    "current_thread",
    default=None,
)

# Track the last thread globally
_last_thread: "Thread | None" = None


@dataclass
class Thread:
    """Main runtime object for managing conversation context."""

    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    parent_id: str | None = None
    _db_thread: bool = field(default=False, init=False, repr=False)
    _tokens: list[Any] = field(default_factory=list, init=False, repr=False)

    def __post_init__(self):
        if not isinstance(self.id, str):
            raise ValueError("Thread ID must be a string")

    async def _ensure_thread_exists(self) -> None:
        """Ensure thread exists in database."""
        if self._db_thread:
            return

        # First, ensure tables are created in case of missing initialization
        try:
            from marvin.database import ensure_db_tables_exist

            ensure_db_tables_exist()
        except Exception as e:
            from marvin.utilities.logging import get_logger

            logger = get_logger(__name__)
            logger.warning(f"Failed to ensure DB tables exist: {e}")

        # Now we can safely create the thread
        try:
            async with get_async_session() as session:
                db_thread = await session.get(DBThread, self.id)
                if db_thread is not None:
                    self._db_thread = True
                else:
                    await DBThread.create(
                        session=session,
                        id=self.id,
                        parent_thread_id=self.parent_id,
                    )
                    self._db_thread = True
        except Exception as e:
            from marvin.utilities.logging import get_logger

            logger = get_logger(__name__)
            logger.error(f"Failed to create thread in database: {e}")
            # Re-raise to fail fast rather than letting downstream code handle DB errors
            raise

    def add_messages(self, messages: list[PydanticAIMessage]) -> list[Message]:
        """Add multiple messages to the thread.

        Args:
            messages: List of messages to add (UserMessage, AssistantMessage, etc.)
            llm_call_id: Optional ID of the LLM call that generated these messages

        """
        return run_sync(self.add_messages_async(messages))

    async def add_messages_async(
        self, messages: list[PydanticAIMessage]
    ) -> list[Message]:
        """Add multiple messages to the thread.

        Args:
            messages: List of messages to add (UserMessage, AssistantMessage, etc.)
            llm_call_id: Optional ID of the LLM call that generated these messages

        """
        await self._ensure_thread_exists()

        async with get_async_session() as session:
            # Create DB message records
            db_messages = [
                DBMessage.from_message(thread_id=self.id, message=message)
                for message in messages
            ]
            session.add_all(db_messages)

            await session.commit()

        return [db_m.to_message() for db_m in db_messages]

    def add_system_message(self, message: str) -> Message:
        """Add a system message to the thread."""
        return run_sync(self.add_system_message_async(message))

    async def add_system_message_async(self, message: str) -> Message:
        """Add a system message to the thread."""
        messages = await self.add_messages_async([SystemMessage(content=message)])
        return messages[0]

    def add_user_message(self, message: str | Sequence[UserContent]) -> Message:
        """Add a user message to the thread."""
        return run_sync(self.add_user_message_async(message))

    async def add_user_message_async(
        self, message: str | Sequence[UserContent]
    ) -> Message:
        """Add a user message to the thread."""
        messages = await self.add_messages_async([UserMessage(content=message)])
        return messages[0]

    def add_agent_message(self, message: str) -> Message:
        """Add an agent message to the thread."""
        return run_sync(self.add_agent_message_async(message))

    async def add_agent_message_async(self, message: str) -> Message:
        """Add an agent message to the thread."""
        messages = await self.add_messages_async([AgentMessage(content=message)])
        return messages[0]

    def add_info_message(self, message: str, prefix: str = None) -> Message:
        """Add an info message to the thread."""
        return run_sync(self.add_info_message_async(message, prefix=prefix))

    async def add_info_message_async(self, message: str, prefix: str = None) -> Message:
        """Add an info message to the thread."""
        prefix = prefix or "INFO MESSAGE"
        messages = await self.add_messages_async(
            [UserMessage(content=f"{prefix}: {message}")]
        )
        return messages[0]

    def get_messages(
        self,
        before: datetime | None = None,
        after: datetime | None = None,
        limit: int | None = None,
        include_system_messages: bool = False,
    ) -> list[Message]:
        """Get all messages in this thread.

        Args:
            before: Only return messages before this timestamp
            after: Only return messages after this timestamp
            limit: Maximum number of messages to return
            include_system_messages: Whether to include system messages
        Returns:
            List of messages in chronological order
        """
        return run_sync(
            self.get_messages_async(
                before=before,
                after=after,
                limit=limit,
                include_system_messages=include_system_messages,
            ),
        )

    async def get_messages_async(
        self,
        before: datetime | None = None,
        after: datetime | None = None,
        limit: int | None = None,
        include_system_messages: bool = False,
    ) -> list[Message]:
        """Get all messages in this thread.

        Args:
            before: Only return messages before this timestamp
            after: Only return messages after this timestamp
            limit: Maximum number of messages to return
            include_system_messages: Whether to include system messages
        Returns:
            List of messages in chronological order
        """
        await self._ensure_thread_exists()

        async with get_async_session() as session:
            query = (
                select(DBMessage)
                .where(DBMessage.thread_id == self.id)
                .order_by(DBMessage.created_at.desc())
            )

            if before is not None:
                query = query.where(DBMessage.created_at < before)
            if after is not None:
                query = query.where(DBMessage.created_at > after)

            if limit is not None:
                query = query.limit(limit)

            result = await session.execute(query)

            db_messages = list(result.scalars().all())
            db_messages.reverse()

            messages = [db_m.to_message() for db_m in db_messages]

            if not include_system_messages:
                for m in messages:
                    if isinstance(m.message, ModelRequest) and any(
                        p.part_kind == "system-prompt" for p in m.message.parts
                    ):
                        messages.remove(m)

            return messages

    async def get_llm_calls_async(
        self,
        before: datetime | None = None,
        after: datetime | None = None,
        limit: int | None = None,
    ) -> list[LLMCall]:
        """Get LLM calls for this thread.

        Args:
            before: Only return calls before this timestamp
            after: Only return calls after this timestamp
            limit: Maximum number of calls to return

        Returns:
            List of LLM calls in chronological order
        """
        await self._ensure_thread_exists()

        async with get_async_session() as session:
            query = select(DBLLMCall).where(DBLLMCall.thread_id == self.id)

            if before is not None:
                query = query.where(DBLLMCall.timestamp < before)
            if after is not None:
                query = query.where(DBLLMCall.timestamp > after)

            query = query.order_by(DBLLMCall.timestamp)

            if limit is not None:
                query = query.limit(limit)

            result = await session.execute(query)
            return [
                LLMCall(
                    id=call.id,
                    thread_id=call.thread_id,
                    usage=call.usage,
                    timestamp=call.timestamp,
                )
                for call in result.scalars().all()
            ]

    def get_llm_calls(
        self,
        before: datetime | None = None,
        after: datetime | None = None,
        limit: int | None = None,
    ) -> list[LLMCall]:
        """Get LLM calls for this thread.

        Args:
            before: Only return calls before this timestamp
            after: Only return calls after this timestamp
            limit: Maximum number of calls to return

        Returns:
            List of LLM calls in chronological order
        """
        return run_sync(
            self.get_llm_calls_async(before=before, after=after, limit=limit)
        )

    async def get_usage_async(
        self,
        before: datetime | None = None,
        after: datetime | None = None,
    ) -> Usage:
        """Get the usage for this thread.

        Args:
            before: Only include usage before this timestamp
            after: Only include usage after this timestamp

        Returns:
            Total usage for the specified time range
        """
        await self._ensure_thread_exists()

        usage = Usage()

        llm_calls = await self.get_llm_calls_async(before=before, after=after)
        for llm_call in llm_calls:
            usage.incr(llm_call.usage)

        return usage

    def get_usage(
        self,
        before: datetime | None = None,
        after: datetime | None = None,
    ) -> Usage:
        """Get the usage for this thread.

        Args:
            before: Only include usage before this timestamp
            after: Only include usage after this timestamp

        Returns:
            Total usage for the specified time range
        """
        return run_sync(self.get_usage_async(before=before, after=after))

    def __enter__(self):
        """Set this thread as the current thread in context."""
        token = _current_thread.set(self)
        self._tokens.append(token)
        return self

    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any):
        """Reset the current thread in context and store it as the last thread."""
        global _last_thread
        # Store this thread as the last thread before resetting current
        _last_thread = self
        if self._tokens:  # Only reset if we have tokens
            _current_thread.reset(self._tokens.pop())

    @classmethod
    def get_current(cls) -> "Thread | None":
        """Get the current thread from context."""
        return _current_thread.get()


def get_current_thread() -> Thread | None:
    """Get the currently active thread from context.

    Returns:
        The current Thread instance or None if no thread is active.

    """
    return Thread.get_current()


def get_last_thread() -> Thread | None:
    """Get the last thread that was set as current.

    This function is intended for debugging purposes only, and will only work in
    certain contexts where the last thread is available in memory.
    """
    return _last_thread


def get_thread(thread: Thread | str | None) -> Thread:
    """Get a thread from the given input.

    Args:
        thread: Thread instance, thread ID, or None

    Returns:
        A Thread instance

    """
    if isinstance(thread, Thread):
        return thread
    elif thread is not None:
        return Thread(id=thread)
    else:
        return get_current_thread() or Thread()


--- src/marvin/agents/actor.py ---
import uuid
from abc import ABC, abstractmethod
from collections.abc import Callable
from contextvars import ContextVar
from dataclasses import dataclass, field
from pathlib import Path
from typing import TYPE_CHECKING, Any, Sequence, TypeVar

import pydantic_ai
from pydantic_ai.agent import AgentRunResult
from pydantic_ai.mcp import MCPServer
from pydantic_ai.messages import UserContent

import marvin
import marvin.utilities.asyncio
from marvin.memory.memory import Memory
from marvin.prompts import Template
from marvin.thread import Thread

if TYPE_CHECKING:
    from marvin.engine.end_turn import EndTurn
    from marvin.handlers.handlers import AsyncHandler, Handler
T = TypeVar("T")
# Global context var for current actor
_current_actor: ContextVar["Actor | None"] = ContextVar(
    "current_actor",
    default=None,
)


@dataclass(kw_only=True)
class Actor(ABC):
    id: str = field(
        default_factory=lambda: uuid.uuid4().hex[:8],
        metadata={"description": "Unique identifier for this actor"},
        # repr=False,
        init=False,
    )

    name: str = field(
        metadata={"description": "Name of the actor"},
    )

    instructions: str | None = field(
        default=None,
        metadata={"description": "Instructions for the actor, private to the actor."},
        repr=False,
    )

    description: str | None = field(
        default=None,
        metadata={"description": "Description of the actor, visible to other actors."},
        repr=False,
    )

    verbose: bool = field(
        default=False,
        metadata={
            "description": "Whether to print additional information to the thread, such as the active member."
        },
    )

    prompt: str | Path = field(repr=False)

    _tokens: list[Any] = field(default_factory=list, init=False, repr=False)

    def __hash__(self) -> int:
        return hash(self.id)

    def __enter__(self):
        """Set this actor as the current actor in context."""
        token = _current_actor.set(self)
        self._tokens.append(token)
        return self

    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any):
        """Reset the current actor in context."""
        if self._tokens:  # Only reset if we have tokens
            try:
                _current_actor.reset(self._tokens.pop())
            except ValueError as e:
                # Token was created in a different async context (e.g., asyncio.gather)
                # This happens when tasks run concurrently and is expected behavior
                if "was created in a different Context" in str(e):
                    # This is the expected concurrent execution case - ignore safely
                    pass
                else:
                    # Some other ValueError - re-raise it
                    raise

    @classmethod
    def get_current(cls) -> "Actor | None":
        """Get the current actor from context."""
        return _current_actor.get()

    @abstractmethod
    async def get_agentlet(
        self,
        tools: Sequence[Callable[..., Any]],
        end_turn_tools: Sequence["EndTurn"],
        active_mcp_servers: list[MCPServer] | None = None,
    ) -> pydantic_ai.Agent[Any, Any]:
        raise NotImplementedError("Actor subclasses must implement _run")

    async def start_turn(self, thread: Thread):
        """Called when the actor starts its turn."""
        if self.verbose:
            await thread.add_info_message_async(
                f"{self.friendly_name()} has started its turn.",
                prefix="ACTOR UPDATE",
            )

    async def end_turn(self, thread: Thread, result: AgentRunResult):
        """Called when the actor ends its turn."""
        if self.verbose:
            await thread.add_info_message_async(
                f"{self.friendly_name()} has finished its turn.",
                prefix="ACTOR UPDATE",
            )

    def get_tools(self) -> list[Callable[..., Any]]:
        """A list of tools that this actor can use during its turn."""
        return []

    def get_end_turn_tools(self) -> list["EndTurn"]:
        """A list of `EndTurn` tools that this actor can use to end its turn."""
        return []

    def get_memories(self) -> list[Memory]:
        """A list of memories that this actor can use during its turn."""
        return []

    def get_prompt(self) -> str:
        return Template(source=self.prompt).render(actor=self)

    def friendly_name(self, verbose: bool = True) -> str:
        if verbose:
            return f'{self.__class__.__name__} "{self.name}" ({self.id})'
        else:
            return self.name

    async def run_async(
        self,
        instructions: str | Sequence[UserContent],
        result_type: type[T] = str,
        tools: list[Callable[..., Any]] = [],
        thread: Thread | str | None = None,
        handlers: list["Handler | AsyncHandler"] | None = None,
        raise_on_failure: bool = True,
        **kwargs: Any,
    ) -> Any:
        return await marvin.run_async(
            instructions=instructions,
            result_type=result_type,
            tools=tools,
            agents=[self],
            thread=thread,
            raise_on_failure=raise_on_failure,
            handlers=handlers,
            **kwargs,
        )

    def run(
        self,
        instructions: str | Sequence[UserContent],
        result_type: type[T] = str,
        tools: list[Callable[..., Any]] = [],
        thread: Thread | str | None = None,
        handlers: list["Handler | AsyncHandler"] | None = None,
        raise_on_failure: bool = True,
        **kwargs: Any,
    ) -> Any:
        return marvin.utilities.asyncio.run_sync(
            self.run_async(
                instructions=instructions,
                result_type=result_type,
                tools=tools,
                thread=thread,
                handlers=handlers,
                raise_on_failure=raise_on_failure,
                **kwargs,
            ),
        )

    async def say_async(
        self,
        message: str,
        instructions: str | None = None,
        thread: Thread | str | None = None,
    ):
        """Responds to a user message in a conversational way."""

        return await marvin.say_async(
            message=message,
            instructions=instructions,
            agent=self,
            thread=thread,
        )

    def say(
        self,
        message: str,
        instructions: str | None = None,
        thread: Thread | str | None = None,
    ):
        """Responds to a user message in a conversational way."""
        return marvin.utilities.asyncio.run_sync(
            self.say_async(message=message, instructions=instructions, thread=thread),
        )


def get_current_actor() -> Actor | None:
    """Get the currently active actor from context.

    Returns:
        The current Actor instance or None if no actor is active.
    """
    return Actor.get_current()


--- tests/ai/README.md ---
Tests in this directory use external LLM models. They are used to test the Marvin framework and ensure that it is working as expected.

To run these tests, use the following command:

```bash
pytest tests/ai
```


--- tests/basic/README.md ---
Tests in this directory are basic tests that ensure the core functionality of Marvin is working. They do *not* use any external LLM models.

To run these tests, use the following command:

```bash
pytest tests/basic
```


--- tests/conftest.py ---
"""Test configuration and fixtures."""

import os
import threading
from pathlib import Path
from tempfile import TemporaryDirectory

import chromadb
import pytest
from pydantic_ai.models.test import TestModel

import marvin
from marvin import database, settings
from marvin.defaults import override_defaults
from marvin.instructions import instructions
from marvin.memory.providers.chroma import ChromaMemory

# Lock for database operations
_db_lock = threading.Lock()


@pytest.fixture(autouse=True)
async def setup_test_db(monkeypatch: pytest.MonkeyPatch, worker_id: str):
    """Use a temporary database for tests.

    The worker_id fixture is provided by pytest-xdist and will be 'gw0', 'gw1', etc
    for parallel test runners, or 'master' for single-process runs.
    """
    original_env_marvin_db_url = os.getenv("MARVIN_DATABASE_URL")
    original_settings_db_url = (
        str(settings.database_url) if settings.database_url else None
    )

    with TemporaryDirectory() as temp_dir_name:
        temp_path = Path(temp_dir_name) / f"test_marvin_{worker_id}.db"
        test_db_url = f"sqlite+aiosqlite:///{temp_path}"  # Ensure async URL for tests

        with _db_lock:
            # Set MARVIN_DATABASE_URL env var for the test's scope.
            # This ensures the validator in Settings picks up this test-specific URL.
            monkeypatch.setenv("MARVIN_DATABASE_URL", test_db_url)

            # Clear cached engines for the new URL.
            database._async_engine_cache.clear()

            # Force re-evaluation of settings.database_url to use the new env var.
            # Direct assignment triggers the 'before' validator due to `validate_assignment=True`.
            if hasattr(settings, "database_url"):
                monkeypatch.setattr(settings, "database_url", test_db_url)
            else:
                # Fallback, though direct setattr is expected to work.
                settings.database_url = test_db_url

            # Verify the global settings object reflects the test_db_url.
            assert str(settings.database_url) == test_db_url, (
                f"Failed to set database_url for test. Expected {test_db_url}, got {settings.database_url}"
            )

            # create_db_and_tables with force=True ensures a clean slate.
            await database.create_db_and_tables(force=True)

        yield

        # Teardown
        with _db_lock:
            database._async_engine_cache.clear()

            # Restore original MARVIN_DATABASE_URL environment variable.
            if original_env_marvin_db_url is not None:
                monkeypatch.setenv("MARVIN_DATABASE_URL", original_env_marvin_db_url)
            else:
                monkeypatch.delenv("MARVIN_DATABASE_URL", raising=False)

            # Restore original database_url on the global settings object.
            # The validator will run, using the (restored or absent) MARVIN_DATABASE_URL.
            if hasattr(settings, "database_url"):
                monkeypatch.setattr(
                    settings,
                    "database_url",
                    original_settings_db_url
                    if original_settings_db_url is not None
                    else None,
                )
            else:
                settings.database_url = (
                    original_settings_db_url
                    if original_settings_db_url is not None
                    else None
                )


@pytest.fixture
async def session():
    """Provide an async database session for tests."""
    async with database.get_async_session() as session:
        yield session


@pytest.fixture(autouse=True)
def setup_memory(tmp_path: Path, monkeypatch: pytest.MonkeyPatch, worker_id: str):
    monkeypatch.setattr(
        marvin.defaults,
        "memory_provider",
        ChromaMemory(
            client=chromadb.PersistentClient(
                path=str(tmp_path / "controlflow-memory" / worker_id)
            ),
        ),
    )


@pytest.fixture
def gpt_4o():
    with override_defaults(model="openai:gpt-4o"):
        yield


@pytest.fixture
def gpt_4o_audio_preview():
    with override_defaults(model="openai:gpt-4o-audio-preview"):
        yield


@pytest.fixture(autouse=True)
def restore_defaults():
    """
    Ensure that the defaults are restored after each test, in case the test
    modified them.
    """
    with override_defaults(**marvin.defaults.__dict__):
        yield


@pytest.fixture
def unit_test_instructions():
    with instructions(
        """
        You are being unit tested. Be as fast and concise as possible. Do not
        post unecessary messages.
        """
    ):
        yield


@pytest.fixture()
def test_model():
    model = TestModel()
    with override_defaults(model=model):
        yield model


--- tests/__init__.py ---


--- tests/test_concurrent_execution.py ---
"""Unit tests for concurrent task execution."""

import asyncio

import pytest

from marvin import Task
from marvin.agents.agent import Agent
from marvin.fns.run import _tasks_are_independent, run_tasks, run_tasks_async


class TestTaskIndependenceDetection:
    """Test the independence detection logic."""

    def test_independent_tasks(self):
        """Test that truly independent tasks are detected as such."""
        task1 = Task("Say 'one'", result_type=str)
        task2 = Task("Say 'two'", result_type=str)
        task3 = Task("Say 'three'", result_type=str)

        assert _tasks_are_independent([task1, task2, task3])

    def test_dependent_tasks_depends_on(self):
        """Test that tasks with depends_on are not independent."""
        task1 = Task("Say 'one'", result_type=str)
        task2 = Task("Say 'two'", result_type=str, depends_on=[task1])

        assert not _tasks_are_independent([task1, task2])

    def test_dependent_tasks_parent_child(self):
        """Test that parent-child tasks are not independent."""
        parent = Task("Parent task", result_type=str)
        child = Task("Child task", result_type=str)
        parent.subtasks.add(child)  # subtasks is a set, not list
        child.parent = parent

        assert not _tasks_are_independent([parent, child])

    def test_single_task_is_independent(self):
        """Test that a single task is considered independent."""
        task = Task("Solo task", result_type=str)
        assert _tasks_are_independent([task])

    def test_empty_task_list(self):
        """Test empty task list."""
        assert _tasks_are_independent([])


class TestConcurrentExecution:
    """Test actual concurrent execution behavior."""

    @pytest.mark.asyncio
    async def test_independent_tasks_run_without_errors(self):
        """Test that independent tasks run without Multiple EndTurn warnings or errors."""
        task1 = Task("Say 'one'", result_type=str)
        task2 = Task("Say 'two'", result_type=str)
        task3 = Task("Say 'three'", result_type=str)

        # Should not raise any errors (no Multiple EndTurn warnings, no infinite loops)
        results = await run_tasks_async([task1, task2, task3])

        assert len(results) == 3
        assert all(task.is_successful() for task in results)

        # Verify results
        result_values = [task.result for task in results]
        assert set(result_values) == {"one", "two", "three"}

    @pytest.mark.asyncio
    async def test_dependent_tasks_run_in_order(self):
        """Test that dependent tasks run in correct order."""
        task1 = Task("Say 'A'", result_type=str)
        task2 = Task("Say 'B'", result_type=str, depends_on=[task1])
        task3 = Task("Say 'C'", result_type=str, depends_on=[task2])

        results = await run_tasks_async([task1, task2, task3])

        assert len(results) == 3
        assert all(task.is_successful() for task in results)

        # Verify correct order
        result_values = [task.result for task in results]
        assert result_values == ["A", "B", "C"]

    def test_sync_run_tasks_independent(self):
        """Test synchronous run_tasks with independent tasks."""
        task1 = Task("Say 'one'", result_type=str)
        task2 = Task("Say 'two'", result_type=str)

        results = run_tasks([task1, task2])

        assert len(results) == 2
        assert all(task.is_successful() for task in results)
        assert set(t.result for t in results) == {"one", "two"}

    def test_sync_run_tasks_dependent(self):
        """Test synchronous run_tasks with dependent tasks."""
        task1 = Task("Say 'A'", result_type=str)
        task2 = Task("Say 'B'", result_type=str, depends_on=[task1])

        results = run_tasks([task1, task2])

        assert len(results) == 2
        assert all(task.is_successful() for task in results)

        # Verify correct order
        result_values = [task.result for task in results]
        assert result_values == ["A", "B"]


class TestAsyncioGatherCompatibility:
    """Test that asyncio.gather works without ContextVar errors."""

    @pytest.mark.asyncio
    async def test_asyncio_gather_no_context_errors(self):
        """Test that asyncio.gather doesn't throw ContextVar errors."""
        task1 = Task("Say 'async1'", result_type=str)
        task2 = Task("Say 'async2'", result_type=str)
        task3 = Task("Say 'async3'", result_type=str)

        # This should not raise ContextVar token errors
        results = await asyncio.gather(
            task1.run_async(), task2.run_async(), task3.run_async()
        )

        assert len(results) == 3
        assert set(results) == {"async1", "async2", "async3"}

    @pytest.mark.asyncio
    async def test_mixed_execution_patterns(self):
        """Test mixing run_tasks_async and asyncio.gather in same event loop."""
        # First batch via run_tasks_async
        task1 = Task("Say 'batch1'", result_type=str)
        task2 = Task("Say 'batch2'", result_type=str)
        batch1_results = await run_tasks_async([task1, task2])

        # Second batch via asyncio.gather
        task3 = Task("Say 'gather1'", result_type=str)
        task4 = Task("Say 'gather2'", result_type=str)
        batch2_results = await asyncio.gather(task3.run_async(), task4.run_async())

        # Both should work without errors
        assert len(batch1_results) == 2
        assert all(task.is_successful() for task in batch1_results)
        assert len(batch2_results) == 2
        assert set(batch2_results) == {"gather1", "gather2"}


class TestContextVarHandling:
    """Test ContextVar token handling across async contexts."""

    @pytest.mark.asyncio
    async def test_actor_context_across_asyncio_gather(self):
        """Test that Actor context management handles asyncio.gather correctly."""
        from marvin.agents.actor import _current_actor

        async def task_with_actor(name):
            actor = Agent(name=f"Agent_{name}")
            # This should not raise an error even with asyncio.gather
            with actor:
                assert _current_actor.get() == actor
                await asyncio.sleep(0.1)  # Simulate async work
            # Context should be reset without errors
            return name

        # Test that concurrent context management works
        results = await asyncio.gather(
            task_with_actor("1"), task_with_actor("2"), task_with_actor("3")
        )

        assert results == ["1", "2", "3"]
        # Context should be None after all tasks complete
        assert _current_actor.get() is None

    def test_actor_context_sequential(self):
        """Test that Actor context works normally in sequential execution."""
        from marvin.agents.actor import _current_actor

        actor1 = Agent(name="Sequential_1")
        actor2 = Agent(name="Sequential_2")

        # Test nested contexts work correctly
        assert _current_actor.get() is None

        with actor1:
            assert _current_actor.get() == actor1
            with actor2:
                assert _current_actor.get() == actor2
            assert _current_actor.get() == actor1

        assert _current_actor.get() is None


--- tests/basic/conftest.py ---
import pydantic_ai.models
import pytest
from pydantic_ai.models.test import TestModel


@pytest.fixture(autouse=True)
def prevent_model_requests():
    with pydantic_ai.models.override_allow_model_requests(False):
        yield


@pytest.fixture(autouse=True)
def autouse_test_model(test_model: TestModel):
    yield test_model


--- tests/ai/__init__.py ---


--- tests/basic/__init__.py ---


--- tests/beta/__init__.py ---


--- tests/basic/test_instructions.py ---
from marvin.instructions import get_instructions, instructions


def test_instructions_context():
    assert get_instructions() == []
    with instructions("abc"):
        assert get_instructions() == ["abc"]
    assert get_instructions() == []


def test_instructions_context_nested():
    assert get_instructions() == []
    with instructions("abc"):
        assert get_instructions() == ["abc"]
        with instructions("def"):
            assert get_instructions() == ["abc", "def"]
        assert get_instructions() == ["abc"]
    assert get_instructions() == []


def test_instructions_none():
    assert get_instructions() == []
    with instructions(None):
        assert get_instructions() == []
    with instructions(""):
        assert get_instructions() == []
    assert get_instructions() == []
