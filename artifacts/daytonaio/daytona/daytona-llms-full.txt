# llms-full (private-aware)
> Built from GitHub files and website pages. Large files may be truncated.

--- apps/docs/README.md ---
<div align="center">

[![Documentation](https://img.shields.io/github/v/release/daytonaio/docs?label=Docs&color=23cc71)](https://www.daytona.io/docs)
![License](https://img.shields.io/badge/License-AGPL--3-blue)
[![Go Report Card](https://goreportcard.com/badge/github.com/daytonaio/daytona)](https://goreportcard.com/report/github.com/daytonaio/daytona)
[![Issues - daytona](https://img.shields.io/github/issues/daytonaio/daytona)](https://github.com/daytonaio/daytona/issues)
![GitHub Release](https://img.shields.io/github/v/release/daytonaio/daytona)

</div>

&nbsp;

<div align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-white.png">
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png">
    <img alt="Daytona logo" src="https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png" width="50%">
  </picture>
</div>

<h3 align="center">
  Run AI Code.
  <br/>
  Secure and Elastic Infrastructure for
  Running Your AI-Generated Code.
</h3>

<p align="center">
    <a href="https://www.daytona.io/docs"> Documentation </a>¬∑
    <a href="https://github.com/daytonaio/daytona/issues/new?assignees=&labels=bug&projects=&template=bug_report.md&title=%F0%9F%90%9B+Bug+Report%3A+"> Report Bug </a>¬∑
    <a href="https://github.com/daytonaio/daytona/issues/new?assignees=&labels=enhancement&projects=&template=feature_request.md&title=%F0%9F%9A%80+Feature%3A+"> Request Feature </a>¬∑
    <a href="https://go.daytona.io/slack"> Join our Slack </a>¬∑
    <a href="https://x.com/daytonaio"> Connect on X </a>
</p>

<p align="center">
    <a href="https://www.producthunt.com/posts/daytona-2?embed=true&utm_source=badge-top-post-badge&utm_medium=badge&utm_souce=badge-daytona&#0045;2" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=957617&theme=neutral&period=daily&t=1746176740150" alt="Daytona&#0032; - Secure&#0032;and&#0032;elastic&#0032;infra&#0032;for&#0032;running&#0032;your&#0032;AI&#0045;generated&#0032;code&#0046; | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /></a>
    <a href="https://www.producthunt.com/posts/daytona-2?embed=true&utm_source=badge-top-post-topic-badge&utm_medium=badge&utm_souce=badge-daytona&#0045;2" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=957617&theme=neutral&period=monthly&topic_id=237&t=1746176740150" alt="Daytona&#0032; - Secure&#0032;and&#0032;elastic&#0032;infra&#0032;for&#0032;running&#0032;your&#0032;AI&#0045;generated&#0032;code&#0046; | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /></a>
</p>

---

## Installation

### Python SDK

```bash
pip install daytona
```

### TypeScript SDK

```bash
npm install @daytonaio/sdk
```

---

## Features

- **Lightning-Fast Infrastructure**: Sub-90ms Sandbox creation from code to execution.
- **Separated & Isolated Runtime**: Execute AI-generated code with zero risk to your infrastructure.
- **Massive Parallelization for Concurrent AI Workflows**: Fork Sandbox filesystem and memory state (Coming soon!)
- **Programmatic Control**: File, Git, LSP, and Execute API
- **Unlimited Persistence**: Your Sandboxes can live forever
- **OCI/Docker Compatibility**: Use any OCI/Docker image to create a Sandbox

---

## Quick Start

1. Create an account at https://app.daytona.io
1. Generate a [new API key](https://app.daytona.io/dashboard/keys)
1. Follow the [Getting Started docs](https://www.daytona.io/docs/getting-started/) to start using the Daytona SDK

## Creating your first Sandbox

### Python SDK

```py
from daytona import Daytona, DaytonaConfig, CreateSandboxBaseParams

# Initialize the Daytona client
daytona = Daytona(DaytonaConfig(api_key="YOUR_API_KEY"))

# Create the Sandbox instance
sandbox = daytona.create(CreateSandboxBaseParams(language="python"))

# Run code securely inside the Sandbox
response = sandbox.process.code_run('print("Sum of 3 and 4 is " + str(3 + 4))')
if response.exit_code != 0:
    print(f"Error running code: {response.exit_code} {response.result}")
else:
    print(response.result)

# Clean up the Sandbox
daytona.delete(sandbox)
```

### Typescript SDK

```jsx
import { Daytona } from '@daytonaio/sdk'

async function main() {
  // Initialize the Daytona client
  const daytona = new Daytona({
    apiKey: 'YOUR_API_KEY',
  })

  let sandbox
  try {
    // Create the Sandbox instance
    sandbox = await daytona.create({
      language: 'typescript',
    })
    // Run code securely inside the Sandbox
    const response = await sandbox.process.codeRun('console.log("Sum of 3 and 4 is " + (3 + 4))')
    if (response.exitCode !== 0) {
      console.error('Error running code:', response.exitCode, response.result)
    } else {
      console.log(response.result)
    }
  } catch (error) {
    console.error('Sandbox flow error:', error)
  } finally {
    if (sandbox) await daytona.delete(sandbox)
  }
}

main().catch(console.error)
```

---

## Contributing

Daytona is Open Source under the [GNU AFFERO GENERAL PUBLIC LICENSE](LICENSE), and is the [copyright of its contributors](NOTICE). If you would like to contribute to the software, read the Developer Certificate of Origin Version 1.1 (https://developercertificate.org/). Afterwards, navigate to the [contributing guide](CONTRIBUTING.md) to get started.


## Links discovered
- [![Documentation](https://img.shields.io/github/v/release/daytonaio/docs?label=Docs&color=23cc71)
- [License](https://img.shields.io/badge/License-AGPL--3-blue)
- [![Go Report Card](https://goreportcard.com/badge/github.com/daytonaio/daytona)
- [![Issues - daytona](https://img.shields.io/github/issues/daytonaio/daytona)
- [GitHub Release](https://img.shields.io/github/v/release/daytonaio/daytona)
- [new API key](https://app.daytona.io/dashboard/keys)
- [Getting Started docs](https://www.daytona.io/docs/getting-started/)
- [GNU AFFERO GENERAL PUBLIC LICENSE](https://github.com/daytonaio/daytona/blob/main/apps/docs/LICENSE.md)
- [copyright of its contributors](https://github.com/daytonaio/daytona/blob/main/apps/docs/NOTICE.md)
- [contributing guide](https://github.com/daytonaio/daytona/blob/main/apps/docs/CONTRIBUTING.md)
- [Documentation](https://www.daytona.io/docs)
- [Report Bug](https://github.com/daytonaio/daytona/issues/new?assignees=&labels=bug&projects=&template=bug_report.md&title=%F0%9F%90%9B+Bug+Report%3A+)
- [Request Feature](https://github.com/daytonaio/daytona/issues/new?assignees=&labels=enhancement&projects=&template=feature_request.md&title=%F0%9F%9A%80+Feature%3A+)
- [Join our Slack](https://go.daytona.io/slack)
- [Connect on X](https://x.com/daytonaio)

--- guides/python/dspy-rlms/README.md ---
# Run DSPy RLMs on Daytona

## Overview

DSPy's [RLM (Recursive Language Model)](https://dspy.ai/) module gives an LLM a Python REPL. The LLM writes code, executes it, sees the output, and repeats ‚Äî building up state across iterations until it calls `SUBMIT()` with a final answer. Within that code, the LLM can also call `llm_query()` to invoke sub-LLM reasoning (the "recursive" part), mixing procedural computation with natural-language understanding.

`DaytonaInterpreter` is a `CodeInterpreter` backend that runs all of this inside a Daytona cloud sandbox, so LLM-generated code never executes on the host.

## Features

- **Sandboxed REPL:** LLM-generated code runs in an isolated Daytona sandbox
- **Persistent state:** Variables and imports survive across iterations within a session
- **Sub-LLM calls:** `llm_query()` and `llm_query_batched()` are bridged into the sandbox, letting generated code invoke nested LLM reasoning
- **Custom tools:** Host-side Python functions (database queries, APIs, etc.) can be passed into the sandbox through a broker server
- **Typed SUBMIT:** Output fields can have explicit types so the LLM knows the expected schema
- **Context manager:** `DaytonaInterpreter` supports `with` for automatic cleanup

## Requirements

- **Python:** Version 3.10 or higher

## Environment Variables

- `DAYTONA_API_KEY`: Required for access to Daytona sandboxes. Get it from [Daytona Dashboard](https://app.daytona.io/dashboard/keys)
- `OPENROUTER_API_KEY`, `OPENAI_API_KEY`, or `ANTHROPIC_API_KEY`: Required for your LLM provider (depending on which model you use)

## Getting Started

### Setup and Run

1. Create and activate a virtual environment:

```bash
python3.10 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:

```bash
pip install -e .
```

To also run `demo.py` (which plots results with matplotlib), install with the demo extra:

```bash
pip install -e ".[demo]"
```

3. Set your API keys in `.env` (copy from `.env.example`):

```bash
cp .env.example .env
# Edit .env with your DAYTONA_API_KEY and LLM provider key
```

4. Run the example:

```bash
python demo.py
```

## How It Works

### The REPL loop

Each RLM call runs an iterative loop:

1. RLM prompts the LLM with the task inputs and the REPL history so far
2. The LLM responds with reasoning and a Python code snippet
3. The code executes in the Daytona sandbox
4. The output (stdout, errors, or a final result) is appended to the REPL history
5. Steps 1‚Äì4 repeat until the code calls `SUBMIT()` or the iteration limit is reached

State persists across iterations ‚Äî variables, imports, and function definitions all carry over. This lets the LLM explore data incrementally, inspect intermediate results with `print()`, and refine its approach before committing a final answer.

```
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ            DSPy RLM              ‚îÇ
         ‚îÇ                                  ‚îÇ
         ‚îÇ  Prompt LLM (inputs + history)   ‚îÇ
         ‚îÇ         ‚îÇ                        ‚îÇ
         ‚îÇ         ‚ñº                        ‚îÇ
         ‚îÇ  LLM writes Python code          ‚îÇ
         ‚îÇ         ‚îÇ                        ‚îÇ
         ‚îÇ         ‚ñº                        ‚îÇ
         ‚îÇ  Execute in sandbox ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚ñ∂ Daytona Sandbox
         ‚îÇ         ‚îÇ                        ‚îÇ    (persistent REPL)
         ‚îÇ         ‚ñº                        ‚îÇ
         ‚îÇ  Append output to history        ‚îÇ
         ‚îÇ         ‚îÇ                        ‚îÇ
         ‚îÇ         ‚ñº                        ‚îÇ
         ‚îÇ  SUBMIT() called? ‚îÄ‚îÄno‚îÄ‚îÄ‚ñ∂ loop   ‚îÇ
         ‚îÇ         ‚îÇ                        ‚îÇ
         ‚îÇ        yes                       ‚îÇ
         ‚îÇ         ‚ñº                        ‚îÇ
         ‚îÇ  Return final answer             ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Sub-LLM calls

The generated code has access to two built-in functions for invoking an LLM from within the REPL:

- `llm_query(prompt)` ‚Äî send a single prompt, get a string back
- `llm_query_batched(prompts)` ‚Äî send multiple prompts concurrently

This is what makes RLM "recursive": the LLM can write code that delegates semantic work to another LLM call, then processes the result with Python. For example:

```python
texts = [page1, page2, page3]
summaries = llm_query_batched([f"Summarize: {t}" for t in texts])
combined = "\n".join(summaries)
SUBMIT(answer=combined)
```

These functions execute on the host (they need LLM API access). `DaytonaInterpreter` bridges them into the sandbox through the broker, the same mechanism used for custom tools.

### Custom tools

You can pass host-side functions into the sandbox via the `tools` dict. The interpreter bridges them using a broker server that runs inside the sandbox:

1. A Flask server starts inside the sandbox on port 3000
2. For each tool, a wrapper function is injected into the sandbox that calls the broker over HTTP
3. The host polls the broker for pending requests, executes the function, and posts the result back

From the LLM's perspective, these look like regular Python functions.

## Usage Examples

### Basic: Reasoning with RLM

```python
import dspy
from dotenv import load_dotenv
from daytona_interpreter import DaytonaInterpreter

load_dotenv()

# Configure the LLM
lm = dspy.LM("openrouter/google/gemini-3-flash-preview")
dspy.configure(lm=lm)

# Create an RLM with the Daytona interpreter
interpreter = DaytonaInterpreter()

rlm = dspy.RLM(
    signature="question -> answer: str",
    interpreter=interpreter,
    verbose=True,
)

result = rlm(question="What is the sum of the first 10 prime numbers?")
print(result.answer)

interpreter.shutdown()
```

### With Custom Tools

Pass host-side functions into the sandbox so the LLM's generated code can call them:

```python
import json
import dspy
from dotenv import load_dotenv
from daytona_interpreter import DaytonaInterpreter

load_dotenv()

lm = dspy.LM("openrouter/google/gemini-3-flash-preview")
dspy.configure(lm=lm)

# Define tools that run on the host
def search_knowledge_base(query: str) -> str:
    """Search a knowledge base and return relevant results."""
    # Replace with your actual search logic
    return json.dumps({"results": [f"Result for: {query}"]})

# Pass tools to the interpreter
interpreter = DaytonaInterpreter(tools={"search_knowledge_base": search_knowledge_base})

rlm = dspy.RLM(
    signature="question -> answer: str",
    interpreter=interpreter,
    verbose=True,
)

result = rlm(question="Search for information about Python generators and summarize it.")
print(result.answer)

interpreter.shutdown()
```

Inside the sandbox, the LLM can call `search_knowledge_base(...)` like a regular function. The call is routed to the host through the broker. See [Custom tools](#custom-tools) for how this works.

## Key Concepts

### SUBMIT

`SUBMIT()` ends the REPL loop and returns a final answer. Its arguments match the output fields of the DSPy signature:

```python
SUBMIT(answer="The sum is 129")
```

If the signature has typed output fields, `SUBMIT` gets a typed signature in the sandbox so the LLM knows the expected schema:

```python
# Automatically generated:
def SUBMIT(answer: str):
    ...
```

If the LLM never calls `SUBMIT()` within the iteration limit, RLM falls back to extracting an answer from the REPL history.

### Broker

The broker is a small Flask server inside the sandbox that bridges function calls between the sandbox and the host. It handles both RLM's built-in `llm_query` / `llm_query_batched` and any custom tools you provide. It starts automatically when tools are present.

## License

See the main project LICENSE file for details.

## References

- [DSPy](https://dspy.ai/) ‚Äî The framework for programming with foundation models
- [Daytona](https://www.daytona.io/) ‚Äî Secure cloud development environments
- [Recursive Language Models](https://arxiv.org/abs/2512.24601) ‚Äî Zhang, Kraska, Khattab


## Links discovered
- [RLM (Recursive Language Model)](https://dspy.ai/)
- [Daytona Dashboard](https://app.daytona.io/dashboard/keys)
- [DSPy](https://dspy.ai/)
- [Daytona](https://www.daytona.io/)
- [Recursive Language Models](https://arxiv.org/abs/2512.24601)

--- guides/python/recursive-language-models/README.md ---
# Run Recursive Language Models on Daytona

## Overview

This guide demonstrates how to implement a recursive language model (RLM) agent system built on Daytona sandboxes, based on the approach pioneered in [Recursive Language Models](https://arxiv.org/abs/2512.24601) (Zhang, Kraska, Khattab). Unlike traditional single-agent approaches, agents can spawn sub-agents recursively, each in its own isolated sandbox with a fresh clone of the target repository.

The system enables tree-structured problem decomposition: a root agent can delegate subtasks to child agents, which can spawn their own children, creating a hierarchy of specialized workers collaborating on complex software engineering tasks.

## Features

- **Sandboxed code execution:** Each agent runs in an isolated Daytona sandbox with a fresh repository clone
- **Recursive agent spawning:** Agents spawn sub-agents via `rlm_query()`, each with their own sandbox
- **Parallel sub-agent execution:** `rlm_query_batched()` spawns multiple sub-agents concurrently using thread pools
- **Budget management:** Global sandbox limit (default: 25) shared across the entire agent tree
- **LLM agnostic:** LiteLLM integration enables any provider (OpenRouter, OpenAI, Anthropic, etc.)
- **Git patch output:** Root agents produce git patches as their final output
- **Interactive viewer:** Web-based D3.js visualization of agent execution trees

## Requirements

- **Python:** Version 3.10 or higher

## Environment Variables

- `DAYTONA_API_KEY`: Required for access to Daytona sandboxes. Get it from [Daytona Dashboard](https://app.daytona.io/dashboard/keys)
- `LLM_API_KEY`: Required for your LLM provider via [LiteLLM](https://docs.litellm.ai/) (OpenRouter, OpenAI, Anthropic, etc.)

## Getting Started

### Setup and Run

1. Create and activate a virtual environment:

```bash
python3.10 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:

```bash
pip install -e .
```

3. Set your API keys in `.env` (copy from `.env.example`):

```bash
cp .env.example .env
# Edit .env with your DAYTONA_API_KEY and LLM_API_KEY
```

4. Run the agent:

```bash
python run.py https://github.com/user/repo --prompt "Fix the bug in auth.py"
```

### CLI Options

- `repo` - GitHub repository URL (required, positional)
- `-p, --prompt` - Task prompt for the agent (required)
- `-b, --branch` - Branch name (optional)
- `--commit` - Specific commit SHA (optional)
- `-c, --config` - Path to YAML configuration file (default: `config.yaml`)
- `-o, --output` - Output file for the patch (default: stdout)
- `--verbose / --quiet` - Enable verbose output (default: verbose)

## Configuration

The script has several configurable parameters in `config.yaml`:

### Sandbox Settings

- `max_sandboxes`: Maximum total sandboxes that can be created over the entire run (default: 50)
- `global_timeout`: Total timeout in seconds for the entire run (default: 1800 = 30 minutes)

### Model Settings

- `model.name`: The LLM model to use in LiteLLM format (default: `openrouter/google/gemini-3-flash-preview`)

### Agent Settings

- `max_iterations`: Maximum iterations per agent before timeout (default: 50)
- `result_truncation_limit`: Maximum characters for sub-agent results (default: 20000)

## How It Works

The system runs a recursive agent architecture where each agent operates in its own sandbox.

1. **Initialization:** Load config and create root agent (depth=0) with a Daytona sandbox containing a fresh clone of the target repository
2. **Iteration loop:** The agent runs an iteration loop: LLM call ‚Üí extract Python code blocks ‚Üí execute in REPL
3. **Sub-agent spawning:** When code calls `rlm_query(task)`, a new sub-agent is created with its own sandbox
4. **Recursive delegation:** Sub-agents can spawn their own sub-agents (unlimited depth)
5. **Result propagation:** Results flow back up the tree as sub-agents complete
6. **Completion:** Root agent calls `FINAL()` or times out, producing a git patch of all changes
7. **Cleanup:** Sandboxes are deleted and results are logged to JSON

## Agent Hierarchy Example

```
Root Agent (depth=0)
‚îú‚îÄ‚îÄ Sub-Agent A (depth=1)
‚îÇ   ‚îú‚îÄ‚îÄ Sub-Agent A1 (depth=2)
‚îÇ   ‚îî‚îÄ‚îÄ Sub-Agent A2 (depth=2)
‚îî‚îÄ‚îÄ Sub-Agent B (depth=1)
    ‚îú‚îÄ‚îÄ Sub-Agent B1 (depth=2)
    ‚îî‚îÄ‚îÄ Sub-Agent B2 (depth=2)
```

## Key Functions Available in Agent Code

| Function | Description |
| -------- | ----------- |
| `rlm_query(task)` | Spawn a single sub-agent with the given task, returns result string |
| `rlm_query_batched(tasks)` | Spawn multiple sub-agents in parallel, returns list of result strings |
| `FINAL(answer)` | Submit final result (root agent: triggers git patch extraction) |
| `FINAL_VAR(var_name)` | Submit the value of a variable as the result |
| `edit_file(path, old, new)` | Edit a file with syntax validation |

Variables and imports persist between iterations within the same agent.

## Viewer

Start a local server and open the viewer to visualize agent execution:

```bash
python -m http.server 8000
# Open http://localhost:8000/viewer/
```

The viewer provides:

- Interactive tree visualization of the agent hierarchy
- Iteration details with code and output for each agent

## Output

After running, results are saved in the `results/` directory:

- `{run_id}.detail.json`: Full agent tree with all iterations, code blocks, and outputs
- `index.json`: Index of all runs for the viewer
- Final output: Git patch printed to stdout (or saved to `-o` file)

## License

See the main project LICENSE file for details.

## References

- [Recursive Language Models](https://arxiv.org/abs/2512.24601) - Zhang, Kraska, Khattab
- [LiteLLM](https://docs.litellm.ai/)


## Links discovered
- [Recursive Language Models](https://arxiv.org/abs/2512.24601)
- [Daytona Dashboard](https://app.daytona.io/dashboard/keys)
- [LiteLLM](https://docs.litellm.ai/)

--- guides/typescript/letta-code/README.md ---
# Letta Code Agent

## Overview

This example runs a Letta Code agent inside a Daytona sandbox. You can interact with the agent via the CLI to run automations, build apps, and launch web apps or services using [Daytona preview links](https://www.daytona.io/docs/en/preview-and-authentication/#fetching-a-preview-link).

> Note: In this example, your Letta API key is passed into the sandbox environment and may be accessible to any code executed within it.

## Features

- **Secure sandbox execution:** The agent operates within a controlled environment, along with code or commands run by the agent.
- **Letta Code integration:** Includes the full capabilities of Letta Code, including reading and editing code files, running shell commands, and persistent memory.
- **Stateful Agents:** Letta Code uses stateful agents under the hood (with the Letta API), which have built-in memory and can be resumed across sandbox sessions. Agents can also be viewed in Letta's [Agent Development Environment](https://app.letta.com/).
- **Preview deployed apps:** Use Daytona preview links to view and interact with your deployed applications.

## Prerequisites

- **Node.js:** Version 18 or higher is required

## Environment Variables

To run this example, you need to set the following environment variables:

- `DAYTONA_API_KEY`: Required for access to Daytona sandboxes. Get it from [Daytona Dashboard](https://app.daytona.io/dashboard/keys)
- `SANDBOX_LETTA_API_KEY`: Required to run Letta Code. Get it from [Letta Platform](https://app.letta.com/api-keys)

Create a `.env` file in the project directory with these variables.

## Getting Started

### Setup and Run

1. Install dependencies:

   ```bash
   npm install
   ```

2. Run the example:

   ```bash
   npm run start
   ```

## How It Works

When this example is run, the agent follows the following workflow:

1. A new Daytona sandbox is created.
2. Letta Code is installed in the sandbox.
3. Letta code is launched in [bidirectional headless mode](https://docs.letta.com/letta-code/headless#bidirectional-mode) with a Daytona-specific system prompt.
4. User queries are passed to the agent as JSON, and JSON responses are parsed and displayed to the user.
5. When the script is terminated, the sandbox is deleted.

## Example Output

```
Creating sandbox...
Installing Letta Code...
Starting Letta Code...
Initializing agent...
Agent initialized. Press Ctrl+C at any time to exit.

You: make and run a lunar lander web server
Thinking...

üîß TodoWrite
üîß Write /home/daytona/workspace/index.html
üîß TodoWrite
üîß Start HTTP server on port 8000
üîß BashOutput
üîß TodoWrite
Perfect! üöÄ Your Lunar Lander game is now running!

Play the game here: https://8000-1a1ebb4b-e521-4881-87bf-494777570a8a.proxy.daytona.works

## How to Play:
- ‚Üë / W - Fire main thruster (slow descent)
- ‚Üê / A - Fire left thruster (move right)
- ‚Üí / D - Fire right thruster (move left)

## Objective:
Land on the green landing pad with:
- Vertical speed < 2 m/s
- Horizontal speed < 1 m/s

Watch your fuel! You start with 1000 units and each thruster burns fuel. The lander starts with some horizontal drift to make it challenging. Good luck, astronaut! üåô
```

## License

See the main project LICENSE file for details.

## References

- [Letta Code Documentation](https://docs.letta.com/letta-code/)
- [Letta Code CLI Reference](https://docs.letta.com/letta-code/cli-reference)
- [Daytona Documentation](https://www.daytona.io/docs)


## Links discovered
- [Daytona preview links](https://www.daytona.io/docs/en/preview-and-authentication/#fetching-a-preview-link)
- [Agent Development Environment](https://app.letta.com/)
- [Daytona Dashboard](https://app.daytona.io/dashboard/keys)
- [Letta Platform](https://app.letta.com/api-keys)
- [bidirectional headless mode](https://docs.letta.com/letta-code/headless#bidirectional-mode)
- [Letta Code Documentation](https://docs.letta.com/letta-code/)
- [Letta Code CLI Reference](https://docs.letta.com/letta-code/cli-reference)
- [Daytona Documentation](https://www.daytona.io/docs)

--- guides/typescript/openclaw/README.md ---
# OpenClaw Daytona Sandbox

## Overview

This example runs [OpenClaw](https://openclaw.ai/), a general purpose AI assistant, inside a Daytona sandbox. You can interact with OpenClaw via its Control UI using a [Daytona preview link](https://www.daytona.io/docs/en/preview-and-authentication/#fetching-a-preview-link).

## Features

- **Secure sandbox execution:** OpenClaw runs in a controlled environment, along with any code or commands run by agents.
- **Multi-channel gateway:** Can connect to WhatsApp, Telegram, Discord, and more simultaneously.
- **Preview Control UI:** Use Daytona preview links to access the OpenClaw web dashboard with no local install.
- **Flexible LLM support:** Connect to Anthropic, OpenAI, and other providers; configure models via `openclaw.json` and `.env.sandbox`.

## Prerequisites

- **Node.js:** Version 18 or higher is required

## Environment Variables

To run this example, you need to set the following environment variables:

**`.env`** (used by the main script only):

- `DAYTONA_API_KEY`: Required for access to Daytona sandboxes. Get it from [Daytona Dashboard](https://app.daytona.io/dashboard/keys)

**`.env.sandbox`** (available inside the OpenClaw sandbox):

- `ANTHROPIC_API_KEY`: Required for Claude. Get it from [Anthropic Console](https://console.anthropic.com/)
- Any other variables you add here are loaded into the sandbox environment

Create these files in the project directory (copy from `.env.example` and `.env.sandbox.example`).

## Getting Started

### Setup and Run

1. Install dependencies:

   ```bash
   npm install
   ```

2. Run the example:

   ```bash
   npm start
   ```

## How It Works

When this example is run, the agent follows the following workflow:

1. A new Daytona sandbox is created (using the `daytona-medium` snapshot with OpenClaw preinstalled).
2. OpenClaw is configured with your `openclaw.json` and `.env.sandbox` secrets.
3. The OpenClaw gateway starts inside the sandbox.
4. A Daytona preview link is shown pointing to the OpenClaw Control UI.
5. When the script is terminated (Ctrl+C), the sandbox is deleted‚Äîunless `PERSIST_SANDBOX` is set to `true`, in which case the sandbox is left running.

## Example Output

```
Creating Daytona sandbox...
Configuring OpenClaw...
Starting OpenClaw...
(Ctrl+C to shut down and delete the sandbox)

üîó Secret link to Control UI: https://18789-898f722f-76fc-4ec6-85ca-a82bb30f3d72.proxy.daytona.works?token=7e38c7347437c5642c57bc769f630e53fe118e001d7b6c6c

OpenClaw logs:
--------------------------------
(node:131) [DEP0040] DeprecationWarning: The `punycode` module is deprecated. Please use a userland alternative instead.
(Use `node --trace-deprecation ...` to show where the warning was created)
‚îÇ
‚óá  Doctor changes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ                                         ‚îÇ
‚îÇ  WhatsApp configured, not enabled yet.  ‚îÇ
‚îÇ                                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

Open the provided URL in your browser to interact with the OpenClaw agent via the Control UI.

## Configuration

### Script configuration

You will find several constants in `src/index.ts` which control the behavior of the script:

| Constant | Default | Description |
|----------|---------|-------------|
| `OPENCLAW_PORT` | 18789 | OpenClaw Gateway and Control UI port |
| `SHOW_LOGS` | true | Stream OpenClaw stdout/stderr to the terminal. |
| `MAKE_PUBLIC` | true | Expose the sandbox for public internet access. |
| `PERSIST_SANDBOX` | true | When true, the sandbox is not deleted when the script exits. |
| `DAYTONA_SNAPSHOT` | daytona-medium | Sandbox image with OpenClaw preinstalled. |

### OpenClaw Configuration

You can tailor OpenClaw to your setup by editing `openclaw.json`. The script combines this file with built-in defaults and an authorization token, and writes the result to `~/.openclaw/openclaw.json` inside the sandbox.

The default configuration is:

```json
{
  "agents": {
    "defaults": {
      "model": { "primary": "anthropic/claude-sonnet-4-5" }
    }
  },
  "auth": {
    "profiles": {
      "anthropic:api": { "provider": "anthropic", "mode": "api_key" }
    },
    "order": { "anthropic": ["anthropic:api"] }
  },
  "channels": {
    "whatsapp": { "allowFrom": [] }
  }
}
```

In order to accept WhatsApp messages, the numbers of the allowed senders need to be added to the allowFrom list.

You can extend it with additional sections:

| Section | Purpose |
|--------|---------|
| `agents.defaults` | [Model, workspace path, timeouts, sandbox](https://docs.openclaw.ai/gateway/configuration-reference#agent-defaults) |
| `agents.list` | [Multiple agents with different names and tools](https://docs.openclaw.ai/gateway/configuration-reference#agents-list-per-agent-overrides) |
| `auth` | [API keys and OAuth for Claude, GPT, etc.](https://docs.openclaw.ai/gateway/configuration-reference#auth-storage) |
| `channels` | [Connect messaging apps and control who can message](https://docs.openclaw.ai/gateway/configuration-reference#channels) |
| `gateway` | [Port, authentication, Control UI access](https://docs.openclaw.ai/gateway/configuration-reference#gateway) |
| `models` | [Add OpenRouter, local models, other providers](https://docs.openclaw.ai/gateway/configuration-reference#custom-providers-and-base-urls) |
| `session` | [How conversations are grouped and reset](https://docs.openclaw.ai/gateway/configuration-reference#session) |
| `tools` | [What the agent can do (code, web, browser)](https://docs.openclaw.ai/gateway/configuration-reference#tools) |

For a full reference see [Configuration Reference](https://docs.openclaw.ai/gateway/configuration-reference) and [Configuration Examples](https://docs.openclaw.ai/gateway/configuration-examples).

## License

See the main project LICENSE file for details.

## References

- [OpenClaw Documentation](https://docs.openclaw.ai/)
- [Daytona Documentation](https://www.daytona.io/docs)


## Links discovered
- [OpenClaw](https://openclaw.ai/)
- [Daytona preview link](https://www.daytona.io/docs/en/preview-and-authentication/#fetching-a-preview-link)
- [Daytona Dashboard](https://app.daytona.io/dashboard/keys)
- [Anthropic Console](https://console.anthropic.com/)
- [Model, workspace path, timeouts, sandbox](https://docs.openclaw.ai/gateway/configuration-reference#agent-defaults)
- [Multiple agents with different names and tools](https://docs.openclaw.ai/gateway/configuration-reference#agents-list-per-agent-overrides)
- [API keys and OAuth for Claude, GPT, etc.](https://docs.openclaw.ai/gateway/configuration-reference#auth-storage)
- [Connect messaging apps and control who can message](https://docs.openclaw.ai/gateway/configuration-reference#channels)
- [Port, authentication, Control UI access](https://docs.openclaw.ai/gateway/configuration-reference#gateway)
- [Add OpenRouter, local models, other providers](https://docs.openclaw.ai/gateway/configuration-reference#custom-providers-and-base-urls)
- [How conversations are grouped and reset](https://docs.openclaw.ai/gateway/configuration-reference#session)
- [What the agent can do (code, web, browser)](https://docs.openclaw.ai/gateway/configuration-reference#tools)
- [Configuration Reference](https://docs.openclaw.ai/gateway/configuration-reference)
- [Configuration Examples](https://docs.openclaw.ai/gateway/configuration-examples)
- [OpenClaw Documentation](https://docs.openclaw.ai/)
- [Daytona Documentation](https://www.daytona.io/docs)

--- libs/api-client-python-async/daytona_api_client_async/models/organization_usage_overview.py ---
# coding: utf-8

"""
    Daytona

    Daytona AI platform API Docs

    The version of the OpenAPI document: 1.0
    Contact: support@daytona.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictFloat, StrictInt
from typing import Any, ClassVar, Dict, List, Union
from daytona_api_client_async.models.region_usage_overview import RegionUsageOverview
from typing import Optional, Set
from typing_extensions import Self

class OrganizationUsageOverview(BaseModel):
    """
    OrganizationUsageOverview
    """ # noqa: E501
    region_usage: List[RegionUsageOverview] = Field(serialization_alias="regionUsage")
    total_snapshot_quota: Union[StrictFloat, StrictInt] = Field(serialization_alias="totalSnapshotQuota")
    current_snapshot_usage: Union[StrictFloat, StrictInt] = Field(serialization_alias="currentSnapshotUsage")
    total_volume_quota: Union[StrictFloat, StrictInt] = Field(serialization_alias="totalVolumeQuota")
    current_volume_usage: Union[StrictFloat, StrictInt] = Field(serialization_alias="currentVolumeUsage")
    additional_properties: Dict[str, Any] = {}
    __properties: ClassVar[List[str]] = ["regionUsage", "totalSnapshotQuota", "currentSnapshotUsage", "totalVolumeQuota", "currentVolumeUsage"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of OrganizationUsageOverview from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * Fields in `self.additional_properties` are added to the output dict.
        """
        excluded_fields: Set[str] = set([
            "additional_properties",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in region_usage (list)
        _items = []
        if self.region_usage:
            for _item_region_usage in self.region_usage:
                if _item_region_usage:
                    _items.append(_item_region_usage.to_dict())
            _dict['regionUsage'] = _items
        # puts key-value pairs in additional_properties in the top level
        if self.additional_properties is not None:
            for _key, _value in self.additional_properties.items():
                _dict[_key] = _value

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of OrganizationUsageOverview from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "region_usage": [RegionUsageOverview.from_dict(_item) for _item in obj["regionUsage"]] if obj.get("regionUsage") is not None else None,
            "total_snapshot_quota": obj.get("totalSnapshotQuota"),
            "current_snapshot_usage": obj.get("currentSnapshotUsage"),
            "total_volume_quota": obj.get("totalVolumeQuota"),
            "current_volume_usage": obj.get("currentVolumeUsage")
        })
        # store additional fields in additional_properties
        for _key in obj.keys():
            if _key not in cls.__properties:
                _obj.additional_properties[_key] = obj.get(_key)

        return _obj




--- libs/api-client-python/daytona_api_client/models/organization_usage_overview.py ---
# coding: utf-8

"""
    Daytona

    Daytona AI platform API Docs

    The version of the OpenAPI document: 1.0
    Contact: support@daytona.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictFloat, StrictInt
from typing import Any, ClassVar, Dict, List, Union
from daytona_api_client.models.region_usage_overview import RegionUsageOverview
from typing import Optional, Set
from typing_extensions import Self

class OrganizationUsageOverview(BaseModel):
    """
    OrganizationUsageOverview
    """ # noqa: E501
    region_usage: List[RegionUsageOverview] = Field(serialization_alias="regionUsage")
    total_snapshot_quota: Union[StrictFloat, StrictInt] = Field(serialization_alias="totalSnapshotQuota")
    current_snapshot_usage: Union[StrictFloat, StrictInt] = Field(serialization_alias="currentSnapshotUsage")
    total_volume_quota: Union[StrictFloat, StrictInt] = Field(serialization_alias="totalVolumeQuota")
    current_volume_usage: Union[StrictFloat, StrictInt] = Field(serialization_alias="currentVolumeUsage")
    additional_properties: Dict[str, Any] = {}
    __properties: ClassVar[List[str]] = ["regionUsage", "totalSnapshotQuota", "currentSnapshotUsage", "totalVolumeQuota", "currentVolumeUsage"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of OrganizationUsageOverview from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * Fields in `self.additional_properties` are added to the output dict.
        """
        excluded_fields: Set[str] = set([
            "additional_properties",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in region_usage (list)
        _items = []
        if self.region_usage:
            for _item_region_usage in self.region_usage:
                if _item_region_usage:
                    _items.append(_item_region_usage.to_dict())
            _dict['regionUsage'] = _items
        # puts key-value pairs in additional_properties in the top level
        if self.additional_properties is not None:
            for _key, _value in self.additional_properties.items():
                _dict[_key] = _value

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of OrganizationUsageOverview from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "region_usage": [RegionUsageOverview.from_dict(_item) for _item in obj["regionUsage"]] if obj.get("regionUsage") is not None else None,
            "total_snapshot_quota": obj.get("totalSnapshotQuota"),
            "current_snapshot_usage": obj.get("currentSnapshotUsage"),
            "total_volume_quota": obj.get("totalVolumeQuota"),
            "current_volume_usage": obj.get("currentVolumeUsage")
        })
        # store additional fields in additional_properties
        for _key in obj.keys():
            if _key not in cls.__properties:
                _obj.additional_properties[_key] = obj.get(_key)

        return _obj




--- libs/api-client/src/models/organization-usage-overview.ts ---
/* tslint:disable */
/* eslint-disable */
/**
 * Daytona
 * Daytona AI platform API Docs
 *
 * The version of the OpenAPI document: 1.0
 * Contact: support@daytona.com
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

// May contain unused imports in some cases
// @ts-ignore
import type { RegionUsageOverview } from './region-usage-overview'

/**
 *
 * @export
 * @interface OrganizationUsageOverview
 */
export interface OrganizationUsageOverview {
  /**
   *
   * @type {Array<RegionUsageOverview>}
   * @memberof OrganizationUsageOverview
   */
  regionUsage: Array<RegionUsageOverview>
  /**
   *
   * @type {number}
   * @memberof OrganizationUsageOverview
   */
  totalSnapshotQuota: number
  /**
   *
   * @type {number}
   * @memberof OrganizationUsageOverview
   */
  currentSnapshotUsage: number
  /**
   *
   * @type {number}
   * @memberof OrganizationUsageOverview
   */
  totalVolumeQuota: number
  /**
   *
   * @type {number}
   * @memberof OrganizationUsageOverview
   */
  currentVolumeUsage: number
}


--- guides/python/ai-data-analyst/litellm/README.md ---
# LiteLLM Data Analysis Example (LiteLLM + Daytona)

## Overview

This example demonstrates how to build a data analysis tool using [LiteLLM](https://litellm.ai/) and [Daytona](https://daytona.io) sandboxes. The script executes Python code in an isolated environment to analyze cafe sales data, enabling automated data analysis workflows with natural language prompts.

In this example, the agent analyzes a cafe sales dataset to find the three highest revenue products for January and visualizes the results in a bar chart.

## Features

- **Multiple LLM Providers:** Easily switch between different LLM providers including Anthropic, OpenAI, Mistral, and more through LiteLLM
- **Secure sandbox execution:** All Python code runs in isolated Daytona sandboxes
- **Natural language interface:** Describe your analysis task in plain English
- **Automatic chart generation:** Visualizations are automatically saved as PNG files
- **File handling:** Upload datasets and process results within the sandbox

## Requirements

- **Python:** Version 3.10 or higher is required

> [!TIP]
> It's recommended to use a virtual environment (`venv` or `poetry`) to isolate project dependencies.

## Environment Variables

To run this example, you need to set the following environment variables:

### Required

- `DAYTONA_API_KEY`: Required for access to Daytona sandboxes. Get it from [Daytona Dashboard](https://app.daytona.io/dashboard/keys)

### LLM Provider API Keys (choose one based on your provider)

- `ANTHROPIC_API_KEY`: Required if using Anthropic models (default)
- `OPENAI_API_KEY`: Required if using OpenAI models
- `MISTRAL_API_KEY`: Required if using Mistral AI models
- `DEEPSEEK_API_KEY`: Required if using DeepSeek models
- `OPENROUTER_API_KEY`: Required if using OpenRouter models
- See [Providers](https://docs.litellm.ai/docs/providers) for a complete list of providers and required API keys.

Create a `.env` file in the project directory with the appropriate variables for your chosen provider.

## Getting Started

### Setup and Run

1. Create and activate a virtual environment:

   ```bash
   python3.10 -m venv venv  
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

2. Install dependencies:

   ```bash
   pip install -e .
   ```

3. Run the example:

   ```bash
   python ai_data_analyst.py
   ```

## How It Works

1. An LLM call generates Python code based on the data format and prompt
2. A new Daytona sandbox is created, containing the data file
3. The Python code is executed in the sandbox
4. Any generated charts are saved as PNG files
5. A second LLM call summarizes the code execution results

## Configuration

### Analysis Customization

The main prompt is configured in the `user_prompt` variable in `ai_data_analyst.py`:

```typescript
const userPrompt = `Give the three highest revenue products for the month of January and show them as a bar chart.`;
```

You can modify this to analyze different aspects of the data or try different visualization types.

The example uses `cafe_sales_data.csv`. To use your own dataset, replace this file and update the filename in the script if needed.

### LLM Provider Configuration

By default, the example uses the following models, as specified in `ai_data_analyst.py`:

```python
CODING_MODEL = "anthropic/claude-sonnet-4-0"
SUMMARY_MODEL = "anthropic/claude-haiku-4-5"
```

The coding model is used for high accuracy code generation, and the summary model is used for fast summarization.

Other suggested models include:

- `openai/gpt-5.1`
- `mistral/mistral-large-latest`
- `deepseek/deepseek-chat`
- `openrouter/moonshotai/kimi-k2`

See [Providers](https://docs.litellm.ai/docs/providers) for all supported models

## Example Output

When the script completes, you'll see output similar to:

```
Prompt: Give the three highest revenue products for the month of January and show them as a bar chart.
Generating code...
Running code...
‚úì Chart saved to chart-0.png
Response: Great! It looks like you successfully executed the code and identified the top three revenue-generating products for January:

1. **Matcha Espresso Fusion** with a total revenue of \$2,603.81.
2. **Oat Milk Latte** with a total revenue of \$2,548.65.
3. **Nitro Cold Brew** with a total revenue of \$2,242.41.
```

The chart will be saved as `chart-0.png` in your project directory, showing a bar chart of the top three revenue-generating products for January.

## License

See the main project LICENSE file for details.

## References

- [LiteLLM Documentation](https://docs.litellm.ai/docs/)
- [LiteLLM Providers](https://docs.litellm.ai/docs/providers)
- [Daytona Documentation](https://www.daytona.io/docs)


## Links discovered
- [LiteLLM](https://litellm.ai/)
- [Daytona](https://daytona.io)
- [Daytona Dashboard](https://app.daytona.io/dashboard/keys)
- [Providers](https://docs.litellm.ai/docs/providers)
- [LiteLLM Documentation](https://docs.litellm.ai/docs/)
- [LiteLLM Providers](https://docs.litellm.ai/docs/providers)
- [Daytona Documentation](https://www.daytona.io/docs)

--- guides/python/ai-data-analyst/openai/README.md ---
# OpenAI Data Analysis Example (OpenAI + Daytona)

## Overview

This example demonstrates how to build a data analysis tool using [OpenAI's API](https://platform.openai.com/) and [Daytona](https://daytona.io) sandboxes. The script executes Python code in an isolated environment to analyze cafe sales data, enabling automated data analysis workflows with natural language prompts.

In this example, the agent analyzes a cafe sales dataset to find the three highest revenue products for January and visualizes the results in a bar chart.

## Features

- **Secure sandbox execution:** All Python code runs in isolated Daytona sandboxes
- **Natural language interface:** Describe your analysis task in plain English
- **Automatic chart generation:** Visualizations are automatically saved as PNG files
- **File handling:** Upload datasets and process results within the sandbox

## Requirements

- **Python:** Version 3.10 or higher is required

> [!TIP]
> It's recommended to use a virtual environment (`venv` or `poetry`) to isolate project dependencies.

## Environment Variables

To run this example, you need to set the following environment variables:

- `DAYTONA_API_KEY`: Required for access to Daytona sandboxes. Get it from [Daytona Dashboard](https://app.daytona.io/dashboard/keys)
- `OPENAI_API_KEY`: Required for OpenAI API access. Get it from [OpenAI Platform](https://platform.openai.com/api-keys)

Create a `.env` file in the project directory with these variables.

## Getting Started

### Setup and Run

1. Create and activate a virtual environment:

   ```bash
   python3.10 -m venv venv  
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

2. Install dependencies:

   ```bash
   pip install -e .
   ```

3. Run the example:

   ```bash
   python ai_data_analyst.py
   ```

## How It Works

1. An LLM call generates Python code based on the data format and prompt
2. A new Daytona sandbox is created, containing the data file
3. The Python code is executed in the sandbox
4. Any generated charts are saved as PNG files
5. A second LLM call summarizes the code execution results

## Configuration

### Analysis Customization

The main prompt is configured in the `user_prompt` variable in `ai_data_analyst.py`:

```typescript
const userPrompt = `Give the three highest revenue products for the month of January and show them as a bar chart.`;
```

You can modify this to analyze different aspects of the data or try different visualization types.

The example uses `cafe_sales_data.csv`. To use your own dataset, replace this file and update the filename in the script if needed.

### OpenAI Model Configuration

By default, the example uses the following models, as specified in `ai_data_analyst.py`:

```python
CODING_MODEL = "gpt-5.1"
SUMMARY_MODEL = "gpt-4o"
```

The coding model is used for high accuracy code generation, and the summary model is used for fast summarization.

See [Models](https://platform.openai.com/docs/models) for all supported models

## Example Output

When the script completes, you'll see output similar to:

```
Prompt: Give the three highest revenue products for the month of January and show them as a bar chart.
Generating code...
Running code...
‚úì Chart saved to chart-0.png
Response: Great! It looks like you successfully executed the code and identified the top three revenue-generating products for January:

1. **Matcha Espresso Fusion** with a total revenue of \$2,603.81.
2. **Oat Milk Latte** with a total revenue of \$2,548.65.
3. **Nitro Cold Brew** with a total revenue of \$2,242.41.
```

The chart will be saved as `chart-0.png` in your project directory, showing a bar chart of the top three revenue-generating products for January.

## License

See the main project LICENSE file for details.

## References

- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [Daytona Documentation](https://www.daytona.io/docs)


## Links discovered
- [OpenAI's API](https://platform.openai.com/)
- [Daytona](https://daytona.io)
- [Daytona Dashboard](https://app.daytona.io/dashboard/keys)
- [OpenAI Platform](https://platform.openai.com/api-keys)
- [Models](https://platform.openai.com/docs/models)
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [Daytona Documentation](https://www.daytona.io/docs)

--- examples/ruby/README.md ---
# Ruby SDK Examples

This directory contains example scripts demonstrating how to use the Daytona Ruby SDK.

## Prerequisites

1. **Environment Variables** - Configure your API credentials using one of these methods:

   **Option A: Using .env files (Recommended)**

   Create a `.env.local` file in the directory where you run your code:

   ```bash
   # Required (choose one authentication method)
   DAYTONA_API_KEY=your-api-key
   # OR
   DAYTONA_JWT_TOKEN=your-jwt-token
   DAYTONA_ORGANIZATION_ID=your-org-id  # required when using JWT token

   # Optional
   DAYTONA_API_URL=https://app.daytona.io/api  # defaults to this if not specified
   DAYTONA_TARGET=us  # defaults to your organization's default region
   ```

   The SDK automatically loads only Daytona-specific variables from `.env` and `.env.local` files in the current working directory, where `.env.local` overrides `.env`. Runtime environment variables always take precedence over `.env` files.

   **Option B: Export manually**

   ```bash
   export DAYTONA_API_KEY="your-api-key"
   export DAYTONA_API_URL="https://app.daytona.io/api"  # optional, this is the default
   export DAYTONA_TARGET="us"  # optional
   ```

2. **Ruby** - Ensure Ruby is installed (the devcontainer includes Ruby 3.4.5)

3. **Devcontainer Setup** - The devcontainer automatically sets up the Ruby environment with the SDK libraries in your `RUBYLIB` path

## Running Examples

Use the `ruby` command to run any example:

```bash
ruby examples/ruby/<example-folder>/<script>.rb
```

For example:

```bash
ruby examples/ruby/exec-command/exec_session.rb
ruby examples/ruby/lifecycle/lifecycle.rb
ruby examples/ruby/file-operations/main.rb
```

The SDK and all client libraries are loaded from source files in the `libs/` directory, so any changes you make to the SDK will be reflected immediately when you run examples.

## How It Works

The devcontainer sets up the following environment variables:

- **`RUBYLIB`** - Includes paths to the SDK and client library source files
- **`BUNDLE_GEMFILE`** - Points to the SDK's Gemfile for dependency management

This allows you to use plain `ruby` commands while still loading everything from source, ensuring all changes are reflected automatically.


--- examples/otel-dashboards/grafana/README.md ---
# Grafana Dashboard for Daytona Sandbox Monitoring

This directory contains a pre-configured Grafana dashboard for monitoring Daytona Sandbox resources including CPU, Memory, and Disk utilization using Prometheus metrics.

## Dashboard Overview

The dashboard provides comprehensive monitoring across multiple pages:

- **Resource Overview**: High-level view of all sandboxes with aggregate metrics
- **CPU Details**: Detailed CPU utilization, limits, and heatmaps
- **Memory Details**: Memory usage patterns and limits
- **Disk Details**: Filesystem usage and space breakdown

## Prerequisites

- Grafana Cloud account (free tier available)
- Daytona account with access to Experimental settings

## Setup

### Step 1: Create a Grafana Cloud Account

1. Go to [grafana.com](https://grafana.com) and click **Create free account**
2. Sign up with email, Google, or GitHub
3. Create a new stack (choose a region close to you)

### Step 2: Set Up OpenTelemetry Connection

1. In Grafana Cloud Portal, go to **Connections** ‚Üí **Add new connection**
2. Search for **OpenTelemetry (OTLP)** and select it
3. Follow the setup wizard:
   - **Choose instrumentation method**: Select **OpenTelemetry SDK**, then your language
   - **Choose your infrastructure**: Select **Linux**
4. **Create a Grafana Cloud Access token**:
   - Click **Create a Grafana Cloud Access token for your application**
   - Name it something like `daytona-otel-token`
   - Select **All scopes**
   - Click **Create** and **save the token**
5. **Get your configuration values** from the instrumentation instructions:
   - Note the `OTEL_EXPORTER_OTLP_ENDPOINT` value (e.g., `https://otlp-gateway-prod-eu-central-0.grafana.net/otlp`)
   - Note the `OTEL_EXPORTER_OTLP_HEADERS` value (e.g., `Authorization=Basic MTUxNzAz...`)

### Step 3: Configure Daytona

1. Go to the [Daytona Dashboard](https://app.daytona.io)
2. Navigate to **Settings** ‚Üí **Experimental**
3. Enter the values from Step 2:
   - **OTLP Endpoint**: The endpoint URL from Grafana (e.g., `https://otlp-gateway-prod-eu-central-0.grafana.net/otlp`)
   - **OTLP Headers**: The Authorization header from Grafana (e.g., `Authorization=Basic MTUxNzAz...`)
4. Click **Save**

### Step 4: Verify Metrics Are Flowing

1. Create a sandbox in Daytona and let it run for a few minutes
2. In Grafana Cloud, go to **Observability** ‚Üí **Application** to see your sandboxes
3. Or go to **Explore**, select your Prometheus data source, and run:

   ```promql
   {__name__=~"daytona_sandbox.*"}
   ```

4. You should see metrics appearing for each sandbox

### Step 5: Import the Dashboard

1. In Grafana Cloud, click **Dashboards** in the left menu
2. Click **New** ‚Üí **Import**
3. Click **Upload dashboard JSON file** and select `dashboard.json`
4. Select your Prometheus data source from the dropdown (e.g., `grafanacloud-<stack>-prom`)
5. Click **Import**

## Dashboard Variables

The dashboard uses template variables for flexible filtering:

| Variable | Description | Default |
|----------|-------------|---------|
| `$datasource` | Prometheus data source selector | Auto-detected |
| `$service` | Filter by `service_name` label (multi-select) | All services |
| `$interval` | Time aggregation interval (for custom panels) | 1m |

### Interval Options

The `$interval` variable is available for custom panels you may add:

- **1m**: Fine-grained, best for real-time monitoring
- **5m**: Balanced detail and performance
- **10m**: Good for hourly analysis
- **30m**: Overview of trends
- **1h**: Long-term trend analysis

## Widget Descriptions

### Resource Overview Page

| Widget | Type | Description |
|--------|------|-------------|
| Sandbox Count | Stat | Total number of active sandboxes reporting metrics |
| Critical Services | Stat | Count of services exceeding resource thresholds (with color coding) |
| Services Resource Overview | Table | Detailed metrics per service (CPU%, Memory%, Disk%, limits) |
| CPU Utilization by Service | Time Series | CPU usage percentage over time per service |
| Memory Utilization by Service | Time Series | Memory usage percentage over time per service |
| Disk Utilization by Service | Time Series | Disk usage percentage over time per service |
| Top CPU Consumers | Bar Gauge | Services with highest average CPU usage |
| Top Memory Consumers | Bar Gauge | Services with highest average memory usage |
| Top Disk Consumers | Bar Gauge | Services with highest average disk usage |
| Resource Pressure Score | Time Series | Combined weighted score of all resource utilization |

### CPU Details Page

| Widget | Type | Description |
|--------|------|-------------|
| CPU Utilization Timeseries | Time Series | Detailed CPU usage over time per service |
| Current CPU by Service | Stat | Current CPU % with threshold coloring |
| CPU Limit by Service | Table | CPU cores limit, average, and peak usage |
| CPU Usage Heatmap | Heatmap | Distribution of CPU usage values over time |

### Memory Details Page

| Widget | Type | Description |
|--------|------|-------------|
| Memory Utilization Timeseries | Time Series | Memory usage percentage over time |
| Current Memory by Service | Stat | Current memory % with threshold coloring |
| Memory Usage in GB | Time Series (Area) | Absolute memory usage in gigabytes |
| Memory Limits and Usage | Table | Memory used, limit, average, and peak % |

### Disk Details Page

| Widget | Type | Description |
|--------|------|-------------|
| Disk Utilization Timeseries | Time Series | Disk usage percentage over time |
| Current Disk by Service | Stat | Current disk % with threshold coloring |
| Disk Usage in GB | Time Series (Area) | Absolute disk usage in gigabytes |
| Disk Space Breakdown | Table | Used, available, total space, and utilization % |

## Alert Thresholds

The dashboard includes pre-configured color thresholds for visual alerting:

| Resource | Warning (Yellow) | Critical (Red) |
|----------|-----------------|----------------|
| CPU | 70% | 85% |
| Memory | 80% | 90% |
| Disk | 75% | 85% |

These thresholds are configured in stat panels and provide immediate visual feedback when resources are constrained.

## Metrics Reference

All metrics follow the OTEL to Prometheus naming convention (dots become underscores, units are appended as suffixes):

| OTEL Metric | Prometheus Metric | Description | Unit |
|-------------|-------------------|-------------|------|
| `daytona.sandbox.cpu.utilization` | `daytona_sandbox_cpu_utilization_percent` | CPU usage percentage | % (0-100) |
| `daytona.sandbox.cpu.limit` | `daytona_sandbox_cpu_limit_cores` | CPU cores limit | cores |
| `daytona.sandbox.memory.utilization` | `daytona_sandbox_memory_utilization_percent` | Memory usage percentage | % (0-100) |
| `daytona.sandbox.memory.usage` | `daytona_sandbox_memory_usage_bytes` | Memory used | bytes |
| `daytona.sandbox.memory.limit` | `daytona_sandbox_memory_limit_bytes` | Memory limit | bytes |
| `daytona.sandbox.filesystem.utilization` | `daytona_sandbox_filesystem_utilization_percent` | Disk usage percentage | % (0-100) |
| `daytona.sandbox.filesystem.usage` | `daytona_sandbox_filesystem_usage_bytes` | Disk space used | bytes |
| `daytona.sandbox.filesystem.available` | `daytona_sandbox_filesystem_available_bytes` | Available disk space | bytes |
| `daytona.sandbox.filesystem.total` | `daytona_sandbox_filesystem_total_bytes` | Total disk space | bytes |

### Labels

All metrics include the `service_name` label identifying the sandbox.

## Troubleshooting

### No Data Showing

1. **Verify metrics are being received**: Run this PromQL query in Grafana Explore:

   ```promql
   daytona_sandbox_cpu_utilization_percent
   ```

2. **Check data source connection**: Go to **Connections** ‚Üí **Data Sources** ‚Üí your Prometheus source ‚Üí **Test**
3. **Verify time range**: Ensure the dashboard time picker includes when metrics were sent
4. **Check service filter**: Try selecting "All" for the `$service` variable

### High Cardinality Warnings

If you have many sandboxes, consider:

- Reducing the time range
- Using larger aggregation intervals
- Filtering to specific services

### Panel Shows "No Data"

- Verify the metric exists in Grafana Explore using `{__name__=~"daytona.*"}`
- Check label names match: `service_name` (not `service.name`)
- Ensure sandboxes are running and generating metrics

### Dashboard Import Fails

1. Ensure JSON is valid: `jq . dashboard.json`
2. Check that you have dashboard creation permissions in Grafana Cloud

## Customization

### Modifying Panels

1. Import the dashboard to Grafana
2. Enter edit mode (click pencil icon or press `e`)
3. Modify panels as needed
4. Save the dashboard

### Adding New Panels

1. Click **Add** ‚Üí **Visualization**
2. Select your Prometheus data source
3. Write PromQL queries using the metrics listed above
4. Example for custom metric:

   ```promql
   avg(daytona_sandbox_cpu_utilization_percent{service_name=~"$service"}) by (service_name)
   ```

### Adjusting Thresholds

1. Edit the desired stat panel
2. Go to **Field** ‚Üí **Thresholds**
3. Modify warning and critical values
4. Save the panel

### Exporting Customized Dashboard

1. Click the share icon in the top navigation bar
2. Select **Export**
3. Enable **Export for sharing externally**
4. Click **Save to file**
5. Replace `dashboard.json` with your customized version

## Additional Resources

- [Grafana Cloud Documentation](https://grafana.com/docs/grafana-cloud/)
- [Grafana Cloud OTLP Documentation](https://grafana.com/docs/grafana-cloud/send-data/otlp/)
- [PromQL Query Language](https://prometheus.io/docs/prometheus/latest/querying/basics/)


## Links discovered
- [grafana.com](https://grafana.com)
- [Daytona Dashboard](https://app.daytona.io)
- [Grafana Cloud Documentation](https://grafana.com/docs/grafana-cloud/)
- [Grafana Cloud OTLP Documentation](https://grafana.com/docs/grafana-cloud/send-data/otlp/)
- [PromQL Query Language](https://prometheus.io/docs/prometheus/latest/querying/basics/)

--- examples/otel-dashboards/new-relic/README.md ---
# New Relic Dashboard for Daytona Sandbox Monitoring

This directory contains a pre-configured New Relic dashboard for monitoring Daytona Sandbox resources including CPU, Memory, and Disk utilization.

## Dashboard Overview

The dashboard provides comprehensive monitoring across multiple pages:

- **Resource Overview**: High-level view of all sandboxes with aggregate metrics
- **CPU Details**: Detailed CPU utilization, limits, and heatmaps
- **Memory Details**: Memory usage patterns and limits
- **Disk Details**: Filesystem usage and space breakdown

## Prerequisites

- New Relic account with access to create dashboards
- Your New Relic Account ID
- `jq` installed (for the automated setup script)
- New Relic CLI (`newrelic`) installed (optional, for CLI import)

## Preparing the Dashboard

Before importing, you need to add your Account ID into the `dashboard.json`.

### Quick Setup (One-Liner)

```bash
jq --arg account_id "YOUR_ACCOUNT_ID" 'walk(if type == "object" and has("accountIds") then .accountIds = [($account_id | tonumber)] else . end)' dashboard.json > dashboard-configured.json
```

Replace `YOUR_ACCOUNT_ID` with your actual numeric Account ID (e.g., `1234567`).

**Example:**

```bash
jq --arg account_id "1234567" 'walk(if type == "object" and has("accountIds") then .accountIds = [($account_id | tonumber)] else . end)' dashboard.json > dashboard-configured.json
```

This will create `dashboard-configured.json` ready for import.

## Import via Web UI

1. **Find Your Account ID**:
   - Log in to [New Relic](https://one.newrelic.com)
   - Click on your account name in the bottom left
   - Your Account ID is displayed in the account dropdown

2. **Prepare the Dashboard**:

   ```bash
   jq --arg account_id "YOUR_ACCOUNT_ID" 'walk(if type == "object" and has("accountIds") then .accountIds = [($account_id | tonumber)] else . end)' dashboard.json > dashboard-configured.json
   ```

3. **Import the Dashboard**:
   - Go to [New Relic Dashboards](https://one.newrelic.com/dashboards)
   - Click **"Import dashboard"** in the top right
   - Upload `dashboard-configured.json`
   - Click **"Import dashboard"**

4. **Verify**:
   - The dashboard should now appear in your dashboards list
   - Named: "Daytona Sandbox Resource Monitoring - Multi-Service"

## Dashboard Widgets

### Resource Overview Page

- **Sandbox Count**: Total number of active sandboxes
- **Critical Services**: Count of services exceeding resource thresholds
- **Services Resource Overview**: Detailed table of all metrics per service
- **CPU/Memory/Disk Utilization**: Time-series graphs per service
- **Top Consumers**: Bar charts showing highest resource usage
- **Resource Pressure Score**: Combined metric showing overall resource strain

### Detailed Pages

Each resource type (CPU, Memory, Disk) has a dedicated page with:

- Time-series utilization graphs
- Current values with threshold alerts
- Usage in absolute units (cores, GB)
- Limits and capacity information
- Historical averages and peak values

## Alert Thresholds

The dashboard includes pre-configured alert severities:

- **CPU**: Warning at 70%, Critical at 85%
- **Memory**: Warning at 80%, Critical at 90%
- **Disk**: Warning at 75%, Critical at 85%

## Metrics Tracked

All metrics are prefixed with `daytona.sandbox.`:

- `cpu.utilization`: CPU usage percentage
- `cpu.limit`: CPU cores limit
- `memory.utilization`: Memory usage percentage
- `memory.usage`: Memory used in bytes
- `memory.limit`: Memory limit in bytes
- `filesystem.utilization`: Disk usage percentage
- `filesystem.usage`: Disk space used in bytes
- `filesystem.available`: Available disk space in bytes
- `filesystem.total`: Total disk space in bytes

## Troubleshooting

### Dashboard Import Fails

1. Ensure JSON is valid: `jq . dashboard-configured.json`
2. Verify Account ID is numeric (not a string)
3. Check that you have dashboard creation permissions

### jq Not Installed

If the command fails:

- Install `jq`: `brew install jq` (macOS) or `apt-get install jq` (Linux)
- Verify installation: `jq --version`

## Customization

To modify the dashboard:

1. Import it to New Relic
2. Edit widgets through the UI
3. Export the modified dashboard
4. Replace `dashboard.json` with your customized version

## Additional Resources

- [New Relic Dashboard Documentation](https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/)
- [NRQL Query Language](https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/)
- [New Relic CLI](https://github.com/newrelic/newrelic-cli)


## Links discovered
- [New Relic](https://one.newrelic.com)
- [New Relic Dashboards](https://one.newrelic.com/dashboards)
- [New Relic Dashboard Documentation](https://docs.newrelic.com/docs/query-your-data/explore-query-data/dashboards/introduction-dashboards/)
- [NRQL Query Language](https://docs.newrelic.com/docs/query-your-data/nrql-new-relic-query-language/get-started/introduction-nrql-new-relics-query-language/)
- [New Relic CLI](https://github.com/newrelic/newrelic-cli)

--- examples/jupyter/daytona.ipynb ---
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daytona SDK Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Daytona SDK and create a sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import os\n",
    "from pprint import pp\n",
    "from typing import cast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "from daytona import (\n",
    "    BarChart,\n",
    "    CompositeChart,\n",
    "    CreateSandboxFromImageParams,\n",
    "    Daytona,\n",
    "    Image,\n",
    "    LineChart,\n",
    "    LspCompletionPosition,\n",
    "    SessionExecuteRequest,\n",
    ")\n",
    "\n",
    "daytona = Daytona()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandbox = daytona.create(\n",
    "    CreateSandboxFromImageParams(\n",
    "        image=(\n",
    "            Image.base(\"python:3.13.4-bookworm\")\n",
    "            .run_commands(\n",
    "                \"apt-get update && apt-get install -y nodejs npm\",\n",
    "                \"npm install -g typescript typescript-language-server\",\n",
    "            )\n",
    "            .pip_install(\"matplotlib\")\n",
    "        ),\n",
    "    ),\n",
    "    timeout=200,\n",
    "    on_snapshot_create_logs=print,\n",
    ")\n",
    "\n",
    "print(sandbox.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code and Command Execution\n",
    "\n",
    "### Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sandbox.process.code_run('print(\"Hello World!\")')\n",
    "if response.exit_code != 0:\n",
    "    print(f\"Error: {response.exit_code} {response.result}\")\n",
    "else:\n",
    "    print(response.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sandbox.process.exec('echo \"Hello World from exec!\"', timeout=10)\n",
    "if response.exit_code != 0:\n",
    "    print(f\"Error: {response.exit_code} {response.result}\")\n",
    "else:\n",
    "    print(response.result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exec Sessions\n",
    "\n",
    "Sessions can be used to execute multiple commands in a single shell that preserves context between commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_session_id = \"exec-session-1\"\n",
    "sandbox.process.create_session(exec_session_id)\n",
    "session = sandbox.process.get_session(exec_session_id)\n",
    "pp(session)\n",
    "print()\n",
    "\n",
    "# Execute the first command in the session\n",
    "execCommand1 = sandbox.process.execute_session_command(exec_session_id, SessionExecuteRequest(command=\"export FOO=BAR\"))\n",
    "if execCommand1.exit_code != 0:\n",
    "    print(f\"Error: {execCommand1.exit_code} {execCommand1.output}\")\n",
    "\n",
    "# Get the command details\n",
    "session_command = sandbox.process.get_session_command(exec_session_id, execCommand1.cmd_id)\n",
    "pp(session_command)\n",
    "print()\n",
    "\n",
    "# Execute a second command in the session and see that the environment variable is set\n",
    "execCommand2 = sandbox.process.execute_session_command(exec_session_id, SessionExecuteRequest(command=\"echo $FOO\"))\n",
    "if execCommand2.exit_code != 0:\n",
    "    print(f\"Error: {execCommand2.exit_code} {execCommand2.output}\")\n",
    "else:\n",
    "    print(f\"Output: {execCommand2.output}\\n\")\n",
    "\n",
    "logs = sandbox.process.get_session_command_logs(exec_session_id, execCommand2.cmd_id)\n",
    "print(f\"Logs stdout: {logs.stdout}\")\n",
    "print(f\"Logs stderr: {logs.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charts\n",
    "\n",
    "Daytona automatically detects any plot creations while running remote code and saves them in `response.artifacts.charts`. This feature is available only for **Matplotlib** plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "categories = ['A', 'B', 'C', 'D']\n",
    "values = [20, 35, 30, 10]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(categories, values, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Bar Chart Example')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "response = sandbox.process.code_run(code)\n",
    "if response.artifacts and response.artifacts.charts:\n",
    "    chart = response.artifacts.charts[0]\n",
    "\n",
    "    if chart.png:\n",
    "        img_data = base64.b64decode(chart.png)\n",
    "        img = cast(NDArray[np.uint8], plt.imread(io.BytesIO(img_data)))\n",
    "        _ = plt.imshow(img)\n",
    "        _ = plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"type: {chart.type}\")\n",
    "    print(f\"title: {chart.title}\")\n",
    "    if isinstance(chart, BarChart):\n",
    "        print(f\"x_label: {chart.x_label}\")\n",
    "        print(f\"y_label: {chart.y_label}\")\n",
    "        print(\"elements:\")\n",
    "        for element in chart.elements:\n",
    "            print(f\"\\n\\tlabel: {element.label}\")\n",
    "            print(f\"\\tgroup: {element.group}\")\n",
    "            print(f\"\\tvalue: {element.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composite Charts\n",
    "All subplots are included as individual `Chart` instances within the `elements` list of a parent `Chart` of type `CompositeChart`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for bar chart\n",
    "categories = ['A', 'B', 'C', 'D']\n",
    "bar_values = [20, 35, 30, 10]\n",
    "\n",
    "# Data for line chart\n",
    "x = np.linspace(0, 10, 100)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "y3 = np.tan(x) * 0.1  # scaled to fit nicely\n",
    "\n",
    "# Create a figure with 2 subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# --- Bar Chart (subplot 1) ---\n",
    "ax1.bar(categories, bar_values, color='skyblue', edgecolor='black')\n",
    "ax1.set_title('Bar Chart')\n",
    "ax1.set_xlabel('Category')\n",
    "ax1.set_ylabel('Value')\n",
    "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# --- Line Chart with 3 lines (subplot 2) ---\n",
    "ax2.plot(x, y1, label='sin(x)', linewidth=2)\n",
    "ax2.plot(x, y2, label='cos(x)', linewidth=2)\n",
    "ax2.plot(x, y3, label='0.1 * tan(x)', linewidth=2)\n",
    "ax2.set_title('Line Chart with 3 Lines')\n",
    "ax2.set_xlabel('X-axis')\n",
    "ax2.set_ylabel('Y-axis')\n",
    "ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "ax2.legend()\n",
    "\n",
    "# Add main title\n",
    "fig.suptitle('Composite Chart Example', fontsize=16)\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "response = sandbox.process.code_run(code)\n",
    "if response.artifacts and response.artifacts.charts:\n",
    "    chart = response.artifacts.charts[0]\n",
    "\n",
    "    if chart.png:\n",
    "        img_data = base64.b64decode(chart.png)\n",
    "        img = cast(NDArray[np.uint8], plt.imread(io.BytesIO(img_data)))\n",
    "        _ = plt.imshow(img)\n",
    "        _ = plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "print(f\"type: {chart.type}\")\n",
    "print(f\"title: {chart.title}\")\n",
    "if isinstance(chart, CompositeChart):\n",
    "    for subplot in chart.elements:\n",
    "        print(f\"\\n\\ttype: {subplot.type}\")\n",
    "        print(f\"\\ttitle: {subplot.title}\")\n",
    "        if isinstance(subplot, BarChart):\n",
    "            print(f\"\\tx_label: {subplot.x_label}\")\n",
    "            print(f\"\\ty_label: {subplot.y_label}\")\n",
    "            print(\"\\telements:\")\n",
    "            for element in subplot.elements:\n",
    "                print(f\"\\n\\t\\tlabel: {element.label}\")\n",
    "                print(f\"\\t\\tgroup: {element.group}\")\n",
    "                print(f\"\\t\\tvalue: {element.value}\")\n",
    "        elif isinstance(subplot, LineChart):\n",
    "            print(f\"\\tx_label: {subplot.x_label}\")\n",
    "            print(f\"\\ty_label: {subplot.y_label}\")\n",
    "            print(f\"\\tx_ticks: {subplot.x_ticks}\")\n",
    "            print(f\"\\tx_tick_labels: {subplot.x_tick_labels}\")\n",
    "            print(f\"\\tx_scale: {subplot.x_scale}\")\n",
    "            print(f\"\\ty_ticks: {subplot.y_ticks}\")\n",
    "            print(f\"\\ty_tick_labels: {subplot.y_tick_labels}\")\n",
    "            print(f\"\\ty_scale: {subplot.y_scale}\")\n",
    "            print(\"\\telements:\")\n",
    "            for element in subplot.elements:\n",
    "                print(f\"\\n\\t\\tlabel: {element.label}\")\n",
    "                print(f\"\\t\\tpoints: {element.points}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File System\n",
    "\n",
    "- List Files\n",
    "- Create Folder\n",
    "- Upload File\n",
    "- Download File\n",
    "- Replace in Files\n",
    "- Search Files\n",
    "- Get File Info\n",
    "- Move Files\n",
    "- Delete File\n",
    "- Set File Permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files in the sandbox\n",
    "files = sandbox.fs.list_files(\".\")\n",
    "pp(files)\n",
    "\n",
    "# Create a new directory in the sandbox\n",
    "new_dir = \"new-dir\"\n",
    "sandbox.fs.create_folder(new_dir, \"755\")\n",
    "\n",
    "file_path = os.path.join(new_dir, \"data.txt\")\n",
    "\n",
    "# Add a new file to the sandbox\n",
    "file_content = b\"Hello, World!\"\n",
    "sandbox.fs.upload_file(file_content, file_path)\n",
    "\n",
    "# Search for the file we just added\n",
    "matches = sandbox.fs.find_files(\".\", \"World!\")\n",
    "pp(matches)\n",
    "\n",
    "# Replace the contents of the file\n",
    "_ = sandbox.fs.replace_in_files([file_path], \"Hello, World!\", \"Goodbye, World!\")\n",
    "\n",
    "# Read the file\n",
    "downloaded_file = sandbox.fs.download_file(file_path)\n",
    "print(\"File content:\", downloaded_file.decode(\"utf-8\"))\n",
    "\n",
    "# Change the file permissions\n",
    "sandbox.fs.set_file_permissions(file_path, mode=\"777\")\n",
    "\n",
    "# Get file info\n",
    "file_info = sandbox.fs.get_file_info(file_path)\n",
    "pp(file_info)  # Should show the new permissions\n",
    "\n",
    "# Move the file to the new location\n",
    "new_file_path = \"moved-data.txt\"\n",
    "sandbox.fs.move_files(file_path, new_file_path)\n",
    "\n",
    "# Find the file in the new location\n",
    "search_results = sandbox.fs.search_files(\".\", \"moved-data.txt\")\n",
    "pp(search_results)\n",
    "\n",
    "# Delete the file\n",
    "sandbox.fs.delete_file(new_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git\n",
    "\n",
    "- Clone Repository\n",
    "- Pull Repository\n",
    "- List Branches\n",
    "- Delete a Branch\n",
    "- Create a Branch\n",
    "- Checkout a Branch\n",
    "- Git Log\n",
    "- Git Status\n",
    "- Git Add\n",
    "- Git Commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"learn-typescript\"\n",
    "\n",
    "# Clone the repository\n",
    "sandbox.git.clone(\"https://github.com/panaverse/learn-typescript\", project_dir, \"master\")\n",
    "\n",
    "sandbox.git.pull(project_dir)\n",
    "\n",
    "branches = sandbox.git.branches(project_dir)\n",
    "pp(branches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSP\n",
    "\n",
    "- Start Language Server\n",
    "- Notify Language Server of Document Change\n",
    "- Get Completions\n",
    "- Document Symbols\n",
    "- Workspace Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"learn-typescript\"\n",
    "\n",
    "# Search for the file we want to work on\n",
    "matches = sandbox.fs.find_files(project_dir, \"var obj1 = new Base();\")\n",
    "print(\"Matches:\", matches)\n",
    "\n",
    "# Start the language server\n",
    "lsp = sandbox.create_lsp_server(\"typescript\", project_dir)\n",
    "lsp.start()\n",
    "\n",
    "# Notify the language server of the document we want to work on\n",
    "lsp.did_open(matches[0].file)\n",
    "\n",
    "# Get symbols in the document\n",
    "symbols = lsp.document_symbols(matches[0].file)\n",
    "print(\"Symbols:\", symbols)\n",
    "\n",
    "# Fix the error in the document\n",
    "_ = sandbox.fs.replace_in_files([matches[0].file], \"var obj1 = new Base();\", \"var obj1 = new E();\")\n",
    "\n",
    "# Notify the language server of the document change\n",
    "lsp.did_close(matches[0].file)\n",
    "lsp.did_open(matches[0].file)\n",
    "\n",
    "# Get completions at a specific position\n",
    "completions = lsp.completions(matches[0].file, LspCompletionPosition(line=12, character=18))\n",
    "print(\"Completions:\", completions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox Management\n",
    "\n",
    "- List Sandboxes\n",
    "- Stop Sandbox\n",
    "- Start Sandbox\n",
    "- Remove Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = daytona.list()\n",
    "print(f\"Total sandboxes count: {result.total}\")\n",
    "\n",
    "for s in result.items:\n",
    "    print(f\"Sandbox ID: {s.id}, State: {s.state}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daytona.stop(sandbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daytona.start(sandbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daytona.delete(sandbox)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


--- examples/python/auto-archive/auto_archive.py ---
from daytona import CreateSandboxFromSnapshotParams, Daytona


def main():
    daytona = Daytona()

    # Default interval
    sandbox1 = daytona.create()
    print(sandbox1.auto_archive_interval)

    # Set interval to 1 hour
    sandbox1.set_auto_archive_interval(60)
    print(sandbox1.auto_archive_interval)

    # Max interval
    sandbox2 = daytona.create(params=CreateSandboxFromSnapshotParams(auto_archive_interval=0))
    print(sandbox2.auto_archive_interval)

    # 1 day interval
    sandbox3 = daytona.create(params=CreateSandboxFromSnapshotParams(auto_archive_interval=1440))
    print(sandbox3.auto_archive_interval)

    sandbox1.delete()
    sandbox2.delete()
    sandbox3.delete()


if __name__ == "__main__":
    main()


--- examples/python/auto-delete/auto_delete.py ---
from daytona import CreateSandboxFromSnapshotParams, Daytona


def main():
    daytona = Daytona()

    # Auto-delete is disabled by default
    sandbox1 = daytona.create()
    print(sandbox1.auto_delete_interval)

    # Auto-delete after the Sandbox has been stopped for 1 hour
    sandbox1.set_auto_delete_interval(60)
    print(sandbox1.auto_delete_interval)

    # Delete immediately upon stopping
    sandbox1.set_auto_delete_interval(0)
    print(sandbox1.auto_delete_interval)

    # Disable auto-delete
    sandbox1.set_auto_delete_interval(-1)
    print(sandbox1.auto_delete_interval)

    # Auto-delete after the Sandbox has been stopped for 1 day
    sandbox2 = daytona.create(params=CreateSandboxFromSnapshotParams(auto_delete_interval=1440))
    print(sandbox2.auto_delete_interval)


if __name__ == "__main__":
    main()


--- examples/python/exec-command/exec.py ---
from daytona import (
    CreateSandboxFromImageParams,
    Daytona,
    DaytonaTimeoutError,
    ExecutionError,
    OutputMessage,
    Resources,
    Sandbox,
)


def main():
    daytona = Daytona()

    params = CreateSandboxFromImageParams(
        image="python:3.9.23-slim",
        language="python",
        resources=Resources(
            cpu=1,
            memory=1,
            disk=3,
        ),
    )
    sandbox = daytona.create(params, timeout=150, on_snapshot_create_logs=print)

    # Run the code securely inside the sandbox
    response = sandbox.process.code_run('print("Hello World!")')
    if response.exit_code != 0:
        print(f"Error: {response.exit_code} {response.result}")
    else:
        print(response.result)

    # Execute an os command in the sandbox
    response = sandbox.process.exec('echo "Hello World from exec!"', timeout=10)
    if response.exit_code != 0:
        print(f"Error: {response.exit_code} {response.result}")
    else:
        print(response.result)

    stateful_code_interpreter(sandbox)

    daytona.delete(sandbox)


def stateful_code_interpreter(sandbox: Sandbox):
    def handle_stdout(message: OutputMessage):
        print(f"[STDOUT] {message.output}")

    def handle_stderr(message: OutputMessage):
        print(f"[STDERR] {message.output}")

    def handle_error(error: ExecutionError):
        print(f"[ERROR] {error.name}: {error.value}\n{error.traceback}")

    print("\n" + "=" * 60)
    print("Stateful Code Interpreter")
    print("=" * 60)

    print("=" * 10 + " Statefulness in the default context " + "=" * 10)
    result = sandbox.code_interpreter.run_code("counter = 1\nprint(f'Initialized counter = {counter}')")
    print(f"[STDOUT] {result.stdout}")

    result = sandbox.code_interpreter.run_code(
        "counter += 1\nprint(f'Counter after second call = {counter}')",
        on_stdout=handle_stdout,
        on_stderr=handle_stderr,
        on_error=handle_error,
    )

    print("=" * 10 + " Context isolation " + "=" * 10)
    ctx = sandbox.code_interpreter.create_context()
    try:
        ctx_result = sandbox.code_interpreter.run_code(
            "value = 'stored in isolated context'\nprint(f'Isolated context value: {value}')",
            context=ctx,
            on_stdout=handle_stdout,
            on_stderr=handle_stderr,
            on_error=handle_error,
        )

        print("-" * 3 + " Print value from same context " + "-" * 3)
        ctx_result = sandbox.code_interpreter.run_code(
            "print(f'Value still available: {value}')",
            context=ctx,
        )
        print(f"[STDOUT] {ctx_result.stdout}")

        print("-" * 3 + " Print value from different context " + "-" * 3)
        _ = sandbox.code_interpreter.run_code(
            "print(value)",
            on_stdout=handle_stdout,
            on_stderr=handle_stderr,
            on_error=handle_error,
        )
    finally:
        sandbox.code_interpreter.delete_context(ctx)

    print("=" * 10 + " Timeout handling " + "=" * 10)
    try:
        code = """
import time
print('Starting long running task...')
time.sleep(5)
print('Finished!')
"""
        _ = sandbox.code_interpreter.run_code(
            code,
            timeout=1,
            on_stdout=handle_stdout,
            on_stderr=handle_stderr,
            on_error=handle_error,
        )
    except DaytonaTimeoutError as exc:
        print(f"Timed out as expected: {exc}")


if __name__ == "__main__":
    main()


--- examples/python/exec-command/exec_logs_async.py ---
import asyncio

from daytona import Daytona, SessionExecuteRequest


async def main():
    daytona = Daytona()
    sandbox = daytona.create()

    try:
        session_id = "exec-session-1"
        sandbox.process.create_session(session_id)

        command = sandbox.process.execute_session_command(
            session_id,
            SessionExecuteRequest(
                command=(
                    'printf "Enter your name: \\n" && read name && printf "Hello, %s\\n" "$name"; '
                    'counter=1; while (( counter <= 3 )); do echo "Count: $counter"; '
                    "((counter++)); sleep 2; done; non-existent-command"
                ),
                run_async=True,
            ),
        )

        logs_task = asyncio.create_task(
            sandbox.process.get_session_command_logs_async(
                session_id,
                command.cmd_id,
                lambda log: print(f"[STDOUT]: {log}"),
                lambda log: print(f"[STDERR]: {log}"),
            )
        )

        print("Continuing execution while logs are streaming...")
        await asyncio.sleep(1)
        print("Sending input to the command")
        sandbox.process.send_session_command_input(session_id, command.cmd_id, "Alice")
        print("Input sent to the command")
        print("Other operations completed!")

        print("Now waiting for logs to complete...")
        await logs_task
    except Exception as e:
        print(f"Error: {e}")
    finally:
        print("Cleaning up sandbox...")
        daytona.delete(sandbox)


if __name__ == "__main__":
    asyncio.run(main())


--- examples/python/exec-command/exec_session.py ---
from daytona import Daytona, SessionExecuteRequest


def main():
    daytona = Daytona()
    sandbox = daytona.create()

    exec_session_id = "exec-session-1"
    sandbox.process.create_session(exec_session_id)

    # Get the session details any time
    session = sandbox.process.get_session(exec_session_id)
    print(session)

    # Execute a first command in the session
    exec_command1 = sandbox.process.execute_session_command(
        exec_session_id, SessionExecuteRequest(command="export FOO=BAR")
    )
    if exec_command1.exit_code != 0:
        print(f"Error: {exec_command1.exit_code} {exec_command1.stderr}")

    # Get the session details again to see the command has been executed
    session = sandbox.process.get_session(exec_session_id)
    print(session)

    # Get the command details
    session_command = sandbox.process.get_session_command(exec_session_id, exec_command1.cmd_id)
    print(session_command)

    # Execute a second command in the session and see that the environment variable is set
    exec_command2 = sandbox.process.execute_session_command(exec_session_id, SessionExecuteRequest(command="echo $FOO"))
    if exec_command2.exit_code != 0:
        print(f"Error: {exec_command2.exit_code} {exec_command2.stderr}")
    else:
        print(exec_command2.stdout)

    print("Now getting logs for the second command")
    logs = sandbox.process.get_session_command_logs(exec_session_id, exec_command2.cmd_id)
    print(f"[STDOUT]: {logs.stdout}")
    print(f"[STDERR]: {logs.stderr}")

    # You can also list all active sessions
    sessions = sandbox.process.list_sessions()
    print(sessions)

    # And of course you can delete the session at any time
    sandbox.process.delete_session(exec_session_id)

    daytona.delete(sandbox)


if __name__ == "__main__":
    main()


--- examples/typescript/auto-archive/index.ts ---
import { Daytona } from '@daytonaio/sdk'

async function main() {
  const daytona = new Daytona()

  // Default interval
  const sandbox1 = await daytona.create()
  console.log(sandbox1.autoArchiveInterval)

  // Set interval to 1 hour
  await sandbox1.setAutoArchiveInterval(60)
  console.log(sandbox1.autoArchiveInterval)

  // Max interval
  const sandbox2 = await daytona.create({
    autoArchiveInterval: 0,
  })
  console.log(sandbox2.autoArchiveInterval)

  // 1 day interval
  const sandbox3 = await daytona.create({
    autoArchiveInterval: 1440,
  })
  console.log(sandbox3.autoArchiveInterval)

  await sandbox1.delete()
  await sandbox2.delete()
  await sandbox3.delete()
}

main().catch(console.error)


--- libs/api-client-python-async/README.md ---


--- libs/api-client-python/README.md ---


--- libs/sdk-go/README.md ---
# Daytona Go SDK

The official Go SDK for Daytona, enabling programmatic interaction with Daytona Sandboxes

## Quick Start

```go
package main

import (
    "context"
    "log"
    "time"

    "github.com/daytonaio/daytona/libs/sdk-go/pkg/daytona"
    "github.com/daytonaio/daytona/libs/sdk-go/pkg/types"
)

func main() {
    // Create a new Daytona client (uses DAYTONA_API_KEY from environment)
    client, err := daytona.NewClient()
    if err != nil {
        log.Fatal(err)
    }

    ctx := context.Background()

    // Create a sandbox
    params := &types.ImageParams{
        SandboxBaseParams: types.SandboxBaseParams{
            Language: types.CodeLanguagePython,
            EnvVars: map[string]string{
                "NODE_ENV": "development",
            },
        },
    }

    buildLogs := make(chan string, 100)
    go func() {
  for logLine := range logChan {
   fmt.Printf("[BUILD] %s\n", logLine)
  }
 }()
  
    // Default WaitForStart is true, but can be overriden for more async behavior
    sandbox, buildLogs, err := client.Create(ctx, params,
  daytona.WithTimeout(90*time.Second),
 )
 if err != nil {
  log.Fatal(err)
 }

    log.Printf("‚úì Created sandbox: %s (ID: %s)\n", sandbox.Name, sandbox.ID)

    // Execute a command
    result, err := sandbox.Process.ExecuteCommand(ctx, "echo 'Hello, World!'")
    if err != nil {
        log.Fatal(err)
    }

    log.Printf("Output: %s\n", result.Result)

    // Clean up
    if err := sandbox.Delete(ctx); err != nil {
        log.Printf("Failed to delete: %v", err)
    }
}
```

## Configuration

The SDK can be configured using environment variables or a configuration object.

### Environment Variables

Set the following environment variables:

```bash
export DAYTONA_API_KEY=your-api-key
```

Then create the client:

```go
client, err := daytona.NewClient()
```

### Configuration Object

```go
config := &types.DaytonaConfig{
    APIKey: "your-api-key",
}

client, err := daytona.NewClientWithConfig(config)
```

## Usage Examples

All of the usage examples are maintained in the `/examples` folder. Please check it out for latest patterns of SDK usage.

## Examples

The `examples/` directory contains comprehensive examples demonstrating various SDK features:

- **sandbox** - Basic sandbox creation and lifecycle management
- **filesystem** - File system operations (upload, download, list)
- **git_operations** - Git operations (clone, status, branches)
- **fromimage** - Creating sandboxes from custom images
- **code_interpreter** - Python code execution with WebSocket streaming
- **lsp_usage** - Language Server Protocol integration
- **pty_interactive** - Interactive PTY sessions
- **snapshots/simple** - Basic snapshot operations
- **snapshots/withlogstreaming** - Snapshot creation with real-time build log streaming
- **volumes** - Volume management

To run an example:

```bash
export DAYTONA_API_KEY=your-api-key
go run examples/sandbox/main.go
go run examples/code_interpreter/main.go
go run examples/fromimage/main.go
go run examples/snapshots/withlogstreaming/snapshot_with_logs.go
```

## Best Practices

### Resource Cleanup

Always clean up sandboxes when done:

```go
sandbox, err := client.Create(ctx, params)
if err != nil {
    log.Fatal(err)
}
defer func() {
    if err := sandbox.Delete(ctx); err != nil {
        log.Printf("Failed to delete sandbox: %v", err)
    }
}()

// Use the sandbox...
```

### Error Handling

Always check errors and handle them appropriately:

```go
result, err := sandbox.Process.ExecuteCommand(ctx, "some-command")
if err != nil {
    log.Printf("Command failed: %v", err)
    return
}

if result.ExitCode != 0 {
    log.Printf("Command exited with code %d: %s", result.ExitCode, result.Result)
    return
}

log.Printf("Success: %s\n", result.Result)
```

### Context Usage

Use contexts appropriately for timeouts and cancellation:

```go
// Create a context with timeout for long-running operations
ctx, cancel := context.WithTimeout(context.Background(), 5*time.Minute)
defer cancel()

// Use the context for all operations
sandbox, err := client.Create(ctx, params)
if err != nil {
    log.Fatal(err)
}

result, err := sandbox.Process.ExecuteCommand(ctx, "long-running-command")
```

## API Reference

### Client Methods and Properties

**Properties:**

- `Volume *VolumeService` - Access volume management operations
- `Snapshot *SnapshotService` - Access snapshot management operations

**Methods:**

- `NewClient() (*Client, error)` - Create a new Daytona client with default configuration
- `NewClientWithConfig(config *types.DaytonaConfig) (*Client, error)` - Create a new Daytona client with custom configuration
- `Create(ctx, params, options...) (*Sandbox, <-chan string, error)` - Create a sandbox and returns a channel for streaming build logs
  - Options: `WithTimeout(time.Duration)`
- `Get(ctx, sandboxIDOrName) (*Sandbox, error)` - Get a sandbox by ID or name
- `FindOne(ctx, idOrName, labels) (*Sandbox, error)` - Find a sandbox by ID/name or labels
- `List(ctx, labels, page, limit) (*PaginatedSandboxes, error)` - List sandboxes with pagination

### Sandbox Properties and Methods

**Properties:**

- `FileSystem *FileSystemService` - Access file system operations
- `Git *GitService` - Access Git operations
- `Process *ProcessService` - Access process execution
- `CodeInterpreter *CodeInterpreterService` - Access code interpreter
- `ComputerUse *ComputerUseService` - Access desktop automation
- `Name string` - Sandbox name
- `State apiclient.SandboxState` - Current state
- `ID string` - Sandbox ID
- `ToolboxClient *toolbox.APIClient` - Toolbox API client

**Methods:**

- `RefreshData(ctx) error` - Refresh sandbox data from API
- `GetUserHomeDir(ctx) (string, error)` - Get user home directory path
- `GetWorkingDir(ctx) (string, error)` - Get working directory path
- `SetLabels(ctx, labels) error` - Set custom labels
- `GetPreviewLink(ctx, port) (string, error)` - Get port preview URL
- `Start(ctx) error` - Start this sandbox (60s default timeout)
- `StartWithTimeout(ctx, timeout time.Duration) error` - Start with custom timeout
- `Stop(ctx) error` - Stop this sandbox (60s default timeout)
- `StopWithTimeout(ctx, timeout time.Duration) error` - Stop with custom timeout
- `Delete(ctx) error` - Delete this sandbox (60s default timeout)
- `DeleteWithTimeout(ctx, timeout time.Duration) error` - Delete with custom timeout
- `Archive(ctx) error` - Archive the sandbox to object storage
- `WaitForStart(ctx, timeoutSec int) error` - Wait for sandbox to start
- `WaitForStop(ctx, timeoutSec int) error` - Wait for sandbox to stop

### Snapshot Service Methods

- `List(ctx, page, limit) (*PaginatedSnapshots, error)` - List snapshots with pagination
- `Get(ctx, nameOrID) (*Snapshot, error)` - Get a snapshot by name or ID
- `Create(ctx, params, timeout) (*Snapshot, <-chan string, error)` - Create a snapshot from an image with real-time build log streaming
  - Returns the snapshot object, a channel for streaming build logs, and an error
  - The log channel will be closed when the build is complete
- `Delete(ctx, snapshot) error` - Delete a snapshot

### Volume Service Methods

- `List(ctx) ([]*Volume, error)` - List all volumes
- `Get(ctx, name) (*Volume, error)` - Get a volume by name
- `Create(ctx, name) (*Volume, error)` - Create a new volume
- `Delete(ctx, volume) error` - Delete a volume

## License

Apache-2.0

For issues and questions:

- **GitHub Issues**: https://github.com/daytonaio/daytona/issues
- **Documentation**: https://www.daytona.io/docs


--- libs/sdk-python/README.md ---
# Daytona SDK for Python

A Python SDK for interacting with the Daytona API, providing a simple interface for Daytona Sandbox management, Git operations, file system operations, and language server protocol support.

## Installation

You can install the package using pip:

```bash
pip install daytona
```

## Quick Start

Here's a simple example of using the SDK:

```python
from daytona import Daytona

# Initialize using environment variables
daytona = Daytona()

# Create a sandbox
sandbox = daytona.create()

# Run code in the sandbox
response = sandbox.process.code_run('print("Hello World!")')
print(response.result)

# Clean up when done
daytona.delete(sandbox)
```

## Configuration

The SDK can be configured using environment variables or by passing a configuration object:

```python
from daytona import Daytona, DaytonaConfig

# Initialize with configuration
config = DaytonaConfig(
    api_key="your-api-key",
    api_url="your-api-url",
    target="us"
)
daytona = Daytona(config)
```

Or using environment variables:

- `DAYTONA_API_KEY`: Your Daytona API key
- `DAYTONA_API_URL`: The Daytona API URL
- `DAYTONA_TARGET`: Your target environment

You can also customize sandbox creation:

```python
sandbox = daytona.create(CreateSandboxFromSnapshotParams(
    language="python",
    env_vars={"PYTHON_ENV": "development"},
    auto_stop_interval=60,  # Auto-stop after 1 hour of inactivity
    auto_archive_interval=60,  # Auto-archive after a Sandbox has been stopped for 1 hour
    auto_delete_interval=120 # Auto-delete after a Sandbox has been stopped for 2 hours
))
```

## Features

- **Sandbox Management**: Create, manage and remove sandboxes
- **Git Operations**: Clone repositories, manage branches, and more
- **File System Operations**: Upload, download, search and manipulate files
- **Language Server Protocol**: Interact with language servers for code intelligence
- **Process Management**: Execute code and commands in sandboxes

## Examples

### Execute Commands

```python
# Execute a shell command
response = sandbox.process.exec('echo "Hello, World!"')
print(response.result)

# Run Python code
response = sandbox.process.code_run('''
x = 10
y = 20
print(f"Sum: {x + y}")
''')
print(response.result)
```

### File Operations

```python
# Upload a file
sandbox.fs.upload_file(b'Hello, World!', 'path/to/file.txt')

# Download a file
content = sandbox.fs.download_file('path/to/file.txt')

# Search for files
matches = sandbox.fs.find_files(root_dir, 'search_pattern')
```

### Git Operations

```python
# Clone a repository
sandbox.git.clone('https://github.com/example/repo', 'path/to/clone')

# List branches
branches = sandbox.git.branches('path/to/repo')

# Add files
sandbox.git.add('path/to/repo', ['file1.txt', 'file2.txt'])
```

### Language Server Protocol

```python
# Create and start a language server
lsp = sandbox.create_lsp_server('typescript', 'path/to/project')
lsp.start()

# Notify the lsp for the file
lsp.did_open('path/to/file.ts')

# Get document symbols
symbols = lsp.document_symbols('path/to/file.ts')

# Get completions
completions = lsp.completions('path/to/file.ts', {"line": 10, "character": 15})
```

## Contributing

Daytona is Open Source under the [Apache License 2.0](/libs/sdk-python/LICENSE), and is the [copyright of its contributors](/NOTICE). If you would like to contribute to the software, read the Developer Certificate of Origin Version 1.1 (https://developercertificate.org/). Afterwards, navigate to the [contributing guide](/CONTRIBUTING.md) to get started.

Code in [\_sync](/libs/sdk-python/src/daytona/_sync/) directory shouldn't be edited directly. It should be generated from the corresponding async code in the [\_async](/libs/sdk-python/src/daytona/_async/) directory using the [sync_generator.py](/libs/sdk-python/scripts/sync_generator.py) script.


## Links discovered
- [Apache License 2.0](https://github.com/daytonaio/daytona/blob/main/libs/sdk-python/LICENSE.md)
- [copyright of its contributors](https://github.com/daytonaio/daytona/blob/main/NOTICE.md)
- [contributing guide](https://github.com/daytonaio/daytona/blob/main/CONTRIBUTING.md)
- [\_sync](https://github.com/daytonaio/daytona/blob/main/libs/sdk-python/src/daytona/_sync.md)
- [\_async](https://github.com/daytonaio/daytona/blob/main/libs/sdk-python/src/daytona/_async.md)
- [sync_generator.py](https://github.com/daytonaio/daytona/blob/main/libs/sdk-python/scripts/sync_generator.py)

--- libs/sdk-ruby/README.md ---
# Daytona Ruby SDK

The official Ruby SDK for [Daytona](https://daytona.io) - a platform for secure, isolated sandbox environments.

## Installation

Add this line to your application's Gemfile:

```ruby
gem 'daytona'
```

And then execute:

```bash
bundle install
```

Or install it yourself as:

```bash
gem install daytona
```

## Quick Start

```ruby
require 'daytona'

# Initialize the client (uses DAYTONA_API_KEY environment variable)
daytona = Daytona::Daytona.new

# Or with explicit configuration
config = Daytona::Config.new(
  api_key: 'your-api-key',
  target: 'us'
)
daytona = Daytona::Daytona.new(config)

# Create a sandbox
sandbox = daytona.create

# Execute code
response = sandbox.process.code_run(code: 'print("Hello, World!")')
puts response.result

# Clean up
daytona.delete(sandbox)
```

## Configuration

The SDK can be configured using environment variables:

| Variable | Description |
|----------|-------------|
| `DAYTONA_API_KEY` | API key for authentication |
| `DAYTONA_API_URL` | URL of the Daytona API (defaults to `https://app.daytona.io/api`) |
| `DAYTONA_TARGET` | Target location for Sandboxes |

## Documentation

- [Ruby SDK Reference](https://www.daytona.io/docs/en/ruby-sdk)
- [Getting Started Guide](https://www.daytona.io/docs/en/getting-started)
- [API Documentation](https://www.daytona.io/docs/en/tools/api)

## Examples

See the [examples/ruby](https://github.com/daytonaio/daytona/tree/main/examples/ruby) directory for more usage examples:

- [Lifecycle management](https://github.com/daytonaio/daytona/tree/main/examples/ruby/lifecycle)
- [File operations](https://github.com/daytonaio/daytona/tree/main/examples/ruby/file-operations)
- [Git operations](https://github.com/daytonaio/daytona/tree/main/examples/ruby/git-lsp)
- [Process execution](https://github.com/daytonaio/daytona/tree/main/examples/ruby/exec-command)
- [PTY sessions](https://github.com/daytonaio/daytona/tree/main/examples/ruby/pty)
- [Volumes](https://github.com/daytonaio/daytona/tree/main/examples/ruby/volumes)

## Development

After checking out the repo, run `bin/setup` to install dependencies. Then, run `rake spec` to run the tests. You can also run `bin/console` for an interactive prompt.

### Publishing a New Version

From the repository root:

```bash
# Set your RubyGems API key and version
export RUBYGEMS_API_KEY="your-rubygems-api-key"
export RUBYGEMS_PKG_VERSION="X.Y.Z" # pre-release format example: "X.Y.Z.alpha.1"

# Publish (builds and publishes all Ruby gems)
yarn nx publish sdk-ruby
```

This will automatically:

- Set the version for all Ruby gems (api-client, toolbox-api-client, sdk)
- Build all gems in the correct dependency order
- Publish to RubyGems

For more details, see [PUBLISHING.md](../../PUBLISHING.md).

## Requirements

- Ruby >= 3.2.0

## Contributing

Bug reports and pull requests are welcome on GitHub at https://github.com/daytonaio/daytona.

## Code of Conduct

Everyone interacting in the Daytona SDK project's codebases, issue trackers, chat rooms and mailing lists is expected to follow the [code of conduct](https://github.com/daytonaio/daytona/blob/main/CODE_OF_CONDUCT.md).

## License

See [LICENSE](https://github.com/daytonaio/daytona/blob/main/LICENSE) for details.


## Links discovered
- [Daytona](https://daytona.io)
- [Ruby SDK Reference](https://www.daytona.io/docs/en/ruby-sdk)
- [Getting Started Guide](https://www.daytona.io/docs/en/getting-started)
- [API Documentation](https://www.daytona.io/docs/en/tools/api)
- [examples/ruby](https://github.com/daytonaio/daytona/tree/main/examples/ruby)
- [Lifecycle management](https://github.com/daytonaio/daytona/tree/main/examples/ruby/lifecycle)
- [File operations](https://github.com/daytonaio/daytona/tree/main/examples/ruby/file-operations)
- [Git operations](https://github.com/daytonaio/daytona/tree/main/examples/ruby/git-lsp)
- [Process execution](https://github.com/daytonaio/daytona/tree/main/examples/ruby/exec-command)
- [PTY sessions](https://github.com/daytonaio/daytona/tree/main/examples/ruby/pty)
- [Volumes](https://github.com/daytonaio/daytona/tree/main/examples/ruby/volumes)
- [PUBLISHING.md](https://github.com/daytonaio/daytona/blob/main/PUBLISHING.md)
- [code of conduct](https://github.com/daytonaio/daytona/blob/main/CODE_OF_CONDUCT.md)
- [LICENSE](https://github.com/daytonaio/daytona/blob/main/LICENSE)

--- libs/sdk-typescript/README.md ---
# Daytona SDK for TypeScript

A TypeScript SDK for interacting with the Daytona API, providing a simple interface for Daytona Sandbox management, Git operations, file system operations, and language server protocol support.

## Installation

You can install the package using npm:

```bash
npm install @daytonaio/sdk
```

Or using yarn:

```bash
yarn add @daytonaio/sdk
```

## Quick Start

Here's a simple example of using the SDK:

```typescript
import { Daytona } from '@daytonaio/sdk'

// Initialize using environment variables
const daytona = new Daytona()

// Create a sandbox
const sandbox = await daytona.create()

// Run code in the sandbox
const response = await sandbox.process.codeRun('console.log("Hello World!")')
console.log(response.result)

// Clean up when done
await daytona.delete(sandbox)
```

## Configuration

The SDK can be configured using environment variables or by passing a configuration object:

```typescript
import { Daytona } from '@daytonaio/sdk'

// Initialize with configuration
const daytona = new Daytona({
  apiKey: 'your-api-key',
  apiUrl: 'your-api-url',
  target: 'us',
})
```

Or using environment variables:

- `DAYTONA_API_KEY`: Your Daytona API key
- `DAYTONA_API_URL`: The Daytona API URL
- `DAYTONA_TARGET`: Your target environment

You can also customize sandbox creation:

```typescript
const sandbox = await daytona.create({
  language: 'typescript',
  envVars: { NODE_ENV: 'development' },
  autoStopInterval: 60, // Auto-stop after 1 hour of inactivity,
  autoArchiveInterval: 60, // Auto-archive after a Sandbox has been stopped for 1 hour
  autoDeleteInterval: 120, // Auto-delete after a Sandbox has been stopped for 2 hours
})
```

## Features

- **Sandbox Management**: Create, manage and remove sandboxes
- **Git Operations**: Clone repositories, manage branches, and more
- **File System Operations**: Upload, download, search and manipulate files
- **Language Server Protocol**: Interact with language servers for code intelligence
- **Process Management**: Execute code and commands in sandboxes

## Examples

### Execute Commands

```typescript
// Execute a shell command
const response = await sandbox.process.executeCommand('echo "Hello, World!"')
console.log(response.result)

// Run TypeScript code
const response = await sandbox.process.codeRun(`
const x = 10
const y = 20
console.log(\`Sum: \${x + y}\`)
`)
console.log(response.result)
```

### File Operations

```typescript
// Upload a file
await sandbox.fs.uploadFile(Buffer.from('Hello, World!'), 'path/to/file.txt')

// Download a file
const content = await sandbox.fs.downloadFile('path/to/file.txt')

// Search for files
const matches = await sandbox.fs.findFiles(root_dir, 'search_pattern')
```

### Git Operations

```typescript
// Clone a repository
await sandbox.git.clone('https://github.com/example/repo', 'path/to/clone')

// List branches
const branches = await sandbox.git.branches('path/to/repo')

// Add files
await sandbox.git.add('path/to/repo', ['file1.txt', 'file2.txt'])
```

### Language Server Protocol

```typescript
// Create and start a language server
const lsp = await sandbox.createLspServer('typescript', 'path/to/project')
await lsp.start()

// Notify the lsp for the file
await lsp.didOpen('path/to/file.ts')

// Get document symbols
const symbols = await lsp.documentSymbols('path/to/file.ts')

// Get completions
const completions = await lsp.completions('path/to/file.ts', {
  line: 10,
  character: 15,
})
```

## Contributing

Daytona is Open Source under the [Apache License 2.0](/libs/sdk-typescript//LICENSE), and is the [copyright of its contributors](/NOTICE). If you would like to contribute to the software, read the Developer Certificate of Origin Version 1.1 (https://developercertificate.org/). Afterwards, navigate to the [contributing guide](/CONTRIBUTING.md) to get started.


## Links discovered
- [Apache License 2.0](https://github.com/daytonaio/daytona/blob/main/libs/sdk-typescript/LICENSE.md)
- [copyright of its contributors](https://github.com/daytonaio/daytona/blob/main/NOTICE.md)
- [contributing guide](https://github.com/daytonaio/daytona/blob/main/CONTRIBUTING.md)

--- libs/toolbox-api-client-python-async/README.md ---


--- libs/toolbox-api-client-python/README.md ---
# daytona_toolbox_api_client

Daytona Daemon Toolbox API for file operations, process execution, git operations, LSP, computer use, and more.

This Python package is automatically generated by the [OpenAPI Generator](https://openapi-generator.tech) project:

- API version: v0.0.0-dev
- Package version: 0.0.0-dev
- Generator version: 7.12.0
- Build package: org.openapitools.codegen.languages.PythonClientCodegen

## Requirements

Python 3.8+

## Installation & Usage

### pip install

If the python package is hosted on a repository, you can install directly using:

```sh
pip install git+https://github.com/daytonaio/daytona.git
```

(you may need to run `pip` with root permission: `sudo pip install git+https://github.com/daytonaio/daytona.git`)

Then import the package:

```python
import daytona_toolbox_api_client
```

### Setuptools

Install via [Setuptools](http://pypi.python.org/pypi/setuptools).

```sh
python setup.py install --user
```

(or `sudo python setup.py install` to install the package for all users)

Then import the package:

```python
import daytona_toolbox_api_client
```

### Tests

Execute `pytest` to run the tests.

## Getting Started

Please follow the [installation procedure](#installation--usage) and then run the following:

```python

import daytona_toolbox_api_client
from daytona_toolbox_api_client.rest import ApiException
from pprint import pprint

# Defining the host is optional and defaults to http://localhost:22221
# See configuration.py for a list of all supported configuration parameters.
configuration = daytona_toolbox_api_client.Configuration(
    host = "http://localhost:22221"
)



# Enter a context with an instance of the API client
with daytona_toolbox_api_client.ApiClient(configuration) as api_client:
    # Create an instance of the API class
    api_instance = daytona_toolbox_api_client.ComputerUseApi(api_client)
    request = daytona_toolbox_api_client.MouseClickRequest() # MouseClickRequest | Mouse click request

    try:
        # Click mouse button
        api_response = api_instance.click(request)
        print("The response of ComputerUseApi->click:\n")
        pprint(api_response)
    except ApiException as e:
        print("Exception when calling ComputerUseApi->click: %s\n" % e)

```

## Documentation for API Endpoints

All URIs are relative to _http://localhost:22221_

| Class            | Method                                                                                            | HTTP request                                                  | Description                         |
| ---------------- | ------------------------------------------------------------------------------------------------- | ------------------------------------------------------------- | ----------------------------------- |
| _ComputerUseApi_ | [**click**](docs/ComputerUseApi.md#click)                                                         | **POST** /computeruse/mouse/click                             | Click mouse button                  |
| _ComputerUseApi_ | [**drag**](docs/ComputerUseApi.md#drag)                                                           | **POST** /computeruse/mouse/drag                              | Drag mouse                          |
| _ComputerUseApi_ | [**get_computer_use_status**](docs/ComputerUseApi.md#get_computer_use_status)                     | **GET** /computeruse/process-status                           | Get computer use process status     |
| _ComputerUseApi_ | [**get_computer_use_system_status**](docs/ComputerUseApi.md#get_computer_use_system_status)       | **GET** /computeruse/status                                   | Get computer use status             |
| _ComputerUseApi_ | [**get_display_info**](docs/ComputerUseApi.md#get_display_info)                                   | **GET** /computeruse/display/info                             | Get display information             |
| _ComputerUseApi_ | [**get_mouse_position**](docs/ComputerUseApi.md#get_mouse_position)                               | **GET** /computeruse/mouse/position                           | Get mouse position                  |
| _ComputerUseApi_ | [**get_process_errors**](docs/ComputerUseApi.md#get_process_errors)                               | **GET** /computeruse/process/{processName}/errors             | Get process errors                  |
| _ComputerUseApi_ | [**get_process_logs**](docs/ComputerUseApi.md#get_process_logs)                                   | **GET** /computeruse/process/{processName}/logs               | Get process logs                    |
| _ComputerUseApi_ | [**get_process_status**](docs/ComputerUseApi.md#get_process_status)                               | **GET** /computeruse/process/{processName}/status             | Get specific process status         |
| _ComputerUseApi_ | [**get_windows**](docs/ComputerUseApi.md#get_windows)                                             | **GET** /computeruse/display/windows                          | Get windows information             |
| _ComputerUseApi_ | [**move_mouse**](docs/ComputerUseApi.md#move_mouse)                                               | **POST** /computeruse/mouse/move                              | Move mouse cursor                   |
| _ComputerUseApi_ | [**press_hotkey**](docs/ComputerUseApi.md#press_hotkey)                                           | **POST** /computeruse/keyboard/hotkey                         | Press hotkey                        |
| _ComputerUseApi_ | [**press_key**](docs/ComputerUseApi.md#press_key)                                                 | **POST** /computeruse/keyboard/key                            | Press key                           |
| _ComputerUseApi_ | [**restart_process**](docs/ComputerUseApi.md#restart_process)                                     | **POST** /computeruse/process/{processName}/restart           | Restart specific process            |
| _ComputerUseApi_ | [**scroll**](docs/ComputerUseApi.md#scroll)                                                       | **POST** /computeruse/mouse/scroll                            | Scroll mouse wheel                  |
| _ComputerUseApi_ | [**start_computer_use**](docs/ComputerUseApi.md#start_computer_use)                               | **POST** /computeruse/start                                   | Start computer use processes        |
| _ComputerUseApi_ | [**stop_computer_use**](docs/ComputerUseApi.md#stop_computer_use)                                 | **POST** /computeruse/stop                                    | Stop computer use processes         |
| _ComputerUseApi_ | [**take_compressed_region_screenshot**](docs/ComputerUseApi.md#take_compressed_region_screenshot) | **GET** /computeruse/screenshot/region/compressed             | Take a compressed region screenshot |
| _ComputerUseApi_ | [**take_compressed_screenshot**](docs/ComputerUseApi.md#take_compressed_screenshot)               | **GET** /computeruse/screenshot/compressed                    | Take a compressed screenshot        |
| _ComputerUseApi_ | [**take_region_screenshot**](docs/ComputerUseApi.md#take_region_screenshot)                       | **GET** /computeruse/screenshot/region                        | Take a region screenshot            |
| _ComputerUseApi_ | [**take_screenshot**](docs/ComputerUseApi.md#take_screenshot)                                     | **GET** /computeruse/screenshot                               | Take a screenshot                   |
| _ComputerUseApi_ | [**type_text**](docs/ComputerUseApi.md#type_text)                                                 | **POST** /computeruse/keyboard/type                           | Type text                           |
| _FileSystemApi_  | [**create_folder**](docs/FileSystemApi.md#create_folder)                                          | **POST** /files/folder                                        | Create a folder                     |
| _FileSystemApi_  | [**delete_file**](docs/FileSystemApi.md#delete_file)                                              | **DELETE** /files                                             | Delete a file or directory          |
| _FileSystemApi_  | [**download_file**](docs/FileSystemApi.md#download_file)                                          | **GET** /files/download                                       | Download a file                     |
| _FileSystemApi_  | [**find_in_files**](docs/FileSystemApi.md#find_in_files)                                          | **GET** /files/find                                           | Find text in files                  |
| _FileSystemApi_  | [**get_file_info**](docs/FileSystemApi.md#get_file_info)                                          | **GET** /files/info                                           | Get file information                |
| _FileSystemApi_  | [**list_files**](docs/FileSystemApi.md#list_files)                                                | **GET** /files                                                | List files and directories          |
| _FileSystemApi_  | [**move_file**](docs/FileSystemApi.md#move_file)                                                  | **POST** /files/move                                          | Move or rename file/directory       |
| _FileSystemApi_  | [**replace_in_files**](docs/FileSystemApi.md#replace_in_files)                                    | **POST** /files/replace                                       | Replace text in files               |
| _FileSystemApi_  | [**search_files**](docs/FileSystemApi.md#search_files)                                            | **GET** /files/search                                         | Search files by pattern             |
| _FileSystemApi_  | [**set_file_permissions**](docs/FileSystemApi.md#set_file_permissions)                            | **POST** /files/permissions                                   | Set file permissions                |
| _FileSystemApi_  | [**upload_file**](docs/FileSystemApi.md#upload_file)                                              | **POST** /files/upload                                        | Upload a file                       |
| _FileSystemApi_  | [**upload_files**](docs/FileSystemApi.md#upload_files)                                            | **POST** /files/bulk-upload                                   | Upload multiple files               |
| _GitApi_         | [**add_files**](docs/GitApi.md#add_files)                                                         | **POST** /git/add                                             | Add files to Git staging            |
| _GitApi_         | [**checkout_branch**](docs/GitApi.md#checkout_branch)                                             | **POST** /git/checkout                                        | Checkout branch or commit           |
| _GitApi_         | [**clone_repository**](docs/GitApi.md#clone_repository)                                           | **POST** /git/clone                                           | Clone a Git repository              |
| _GitApi_         | [**commit_changes**](docs/GitApi.md#commit_changes)                                               | **POST** /git/commit                                          | Commit changes                      |
| _GitApi_         | [**create_branch**](docs/GitApi.md#create_branch)                                                 | **POST** /git/branches                                        | Create a new branch                 |
| _GitApi_         | [**delete_branch**](docs/GitApi.md#delete_branch)                                                 | **DELETE** /git/branches                                      | Delete a branch                     |
| _GitApi_         | [**get_commit_history**](docs/GitApi.md#get_commit_history)                                       | **GET** /git/history                                          | Get commit history                  |
| _GitApi_         | [**get_status**](docs/GitApi.md#get_status)                                                       | **GET** /git/status                                           | Get Git status                      |
| _GitApi_         | [**list_branches**](docs/GitApi.md#list_branches)                                                 | **GET** /git/branches                                         | List branches                       |
| _GitApi_         | [**pull_changes**](docs/GitApi.md#pull_changes)                                                   | **POST** /git/pull                                            | Pull changes from remote            |
| _GitApi_         | [**push_changes**](docs/GitApi.md#push_changes)                                                   | **POST** /git/push                                            | Push changes to remote              |
| _InfoApi_        | [**get_project_dir**](docs/InfoApi.md#get_project_dir)                                            | **GET** /project-dir                                          | Get project directory               |
| _InfoApi_        | [**get_version**](docs/InfoApi.md#get_version)                                                    | **GET** /version                                              | Get version                         |
| _LspApi_         | [**completions**](docs/LspApi.md#completions)                                                     | **POST** /lsp/completions                                     | Get code completions                |
| _LspApi_         | [**did_close**](docs/LspApi.md#did_close)                                                         | **POST** /lsp/did-close                                       | Notify document closed              |
| _LspApi_         | [**did_open**](docs/LspApi.md#did_open)                                                           | **POST** /lsp/did-open                                        | Notify document opened              |
| _LspApi_         | [**document_symbols**](docs/LspApi.md#document_symbols)                                           | **GET** /lsp/document-symbols                                 | Get document symbols                |
| _LspApi_         | [**start**](docs/LspApi.md#start)                                                                 | **POST** /lsp/start                                           | Start LSP server                    |
| _LspApi_         | [**stop**](docs/LspApi.md#stop)                                                                   | **POST** /lsp/stop                                            | Stop LSP server                     |
| _LspApi_         | [**workspace_symbols**](docs/LspApi.md#workspace_symbols)                                         | **GET** /lsp/workspaceSymbols                                 | Get workspace symbols               |
| _PortApi_        | [**get_ports**](docs/PortApi.md#get_ports)                                                        | **GET** /port                                                 | Get active ports                    |
| _PortApi_        | [**is_port_in_use**](docs/PortApi.md#is_port_in_use)                                              | **GET** /port/{port}/in-use                                   | Check if port is in use             |
| _ProcessApi_     | [**create_session**](docs/ProcessApi.md#create_session)                                           | **POST** /process/session                                     | Create a new session                |
| _ProcessApi_     | [**delete_session**](docs/ProcessApi.md#delete_session)                                           | **DELETE** /process/session/{sessionId}                       | Delete a session                    |
| _ProcessApi_     | [**execute_command**](docs/ProcessApi.md#execute_command)                                         | **POST** /process/execute                                     | Execute a command                   |
| _ProcessApi_     | [**get_session**](docs/ProcessApi.md#get_session)                                                 | **GET** /process/session/{sessionId}                          | Get session details                 |
| _ProcessApi_     | [**get_session_command**](docs/ProcessApi.md#get_session_command)                                 | **GET** /process/session/{sessionId}/command/{commandId}      | Get session command details         |
| _ProcessApi_     | [**get_session_command_logs**](docs/ProcessApi.md#get_session_command_logs)                       | **GET** /process/session/{sessionId}/command/{commandId}/logs | Get session command logs            |
| _ProcessApi_     | [**list_sessions**](docs/ProcessApi.md#list_sessions)                                             | **GET** /process/session                                      | List all sessions                   |
| _ProcessApi_     | [**session_execute_command**](docs/ProcessApi.md#session_execute_command)                         | **POST** /process/session/{sessionId}/exec                    | Execute command in session          |

## Documentation For Models

- [Command](docs/Command.md)
- [CompletionContext](docs/CompletionContext.md)
- [CompletionItem](docs/CompletionItem.md)
- [CompletionList](docs/CompletionList.md)
- [ComputerUseStartResponse](docs/ComputerUseStartResponse.md)
- [ComputerUseStatusResponse](docs/ComputerUseStatusResponse.md)
- [ComputerUseStopResponse](docs/ComputerUseStopResponse.md)
- [CreateSessionRequest](docs/CreateSessionRequest.md)
- [DisplayInfo](docs/DisplayInfo.md)
- [DisplayInfoResponse](docs/DisplayInfoResponse.md)
- [ExecuteRequest](docs/ExecuteRequest.md)
- [ExecuteResponse](docs/ExecuteResponse.md)
- [FileInfo](docs/FileInfo.md)
- [FileStatus](docs/FileStatus.md)
- [GitAddRequest](docs/GitAddRequest.md)
- [GitBranchRequest](docs/GitBranchRequest.md)
- [GitCheckoutRequest](docs/GitCheckoutRequest.md)
- [GitCloneRequest](docs/GitCloneRequest.md)
- [GitCommitInfo](docs/GitCommitInfo.md)
- [GitCommitRequest](docs/GitCommitRequest.md)
- [GitCommitResponse](docs/GitCommitResponse.md)
- [GitGitDeleteBranchRequest](docs/GitGitDeleteBranchRequest.md)
- [GitRepoRequest](docs/GitRepoRequest.md)
- [GitStatus](docs/GitStatus.md)
- [IsPortInUseResponse](docs/IsPortInUseResponse.md)
- [KeyboardHotkeyRequest](docs/KeyboardHotkeyRequest.md)
- [KeyboardPressRequest](docs/KeyboardPressRequest.md)
- [KeyboardTypeRequest](docs/KeyboardTypeRequest.md)
- [ListBranchResponse](docs/ListBranchResponse.md)
- [LspCompletionParams](docs/LspCompletionParams.md)
- [LspDocumentRequest](docs/LspDocumentRequest.md)
- [LspLocation](docs/LspLocation.md)
- [LspPosition](docs/LspPosition.md)
- [LspRange](docs/LspRange.md)
- [LspServerRequest](docs/LspServerRequest.md)
- [LspSymbol](docs/LspSymbol.md)
- [Match](docs/Match.md)
- [MouseClickRequest](docs/MouseClickRequest.md)
- [MouseClickResponse](docs/MouseClickResponse.md)
- [MouseDragRequest](docs/MouseDragRequest.md)
- [MouseDragResponse](docs/MouseDragResponse.md)
- [MouseMoveRequest](docs/MouseMoveRequest.md)
- [MousePositionResponse](docs/MousePositionResponse.md)
- [MouseScrollRequest](docs/MouseScrollRequest.md)
- [PortList](docs/PortList.md)
- [Position](docs/Position.md)
- [ProcessErrorsResponse](docs/ProcessErrorsResponse.md)
- [ProcessLogsResponse](docs/ProcessLogsResponse.md)
- [ProcessRestartResponse](docs/ProcessRestartResponse.md)
- [ProcessStatus](docs/ProcessStatus.md)
- [ProcessStatusResponse](docs/ProcessStatusResponse.md)
- [ProjectDirResponse](docs/ProjectDirResponse.md)
- [ReplaceRequest](docs/ReplaceRequest.md)
- [ReplaceResult](docs/ReplaceResult.md)
- [ScreenshotResponse](docs/ScreenshotResponse.md)
- [ScrollResponse](docs/ScrollResponse.md)
- [SearchFilesResponse](docs/SearchFilesResponse.md)
- [Session](docs/Session.md)
- [SessionExecuteRequest](docs/SessionExecuteRequest.md)
- [SessionExecuteResponse](docs/SessionExecuteResponse.md)
- [Status](docs/Status.md)
- [WindowInfo](docs/WindowInfo.md)
- [WindowsResponse](docs/WindowsResponse.md)

<a id="documentation-for-authorization"></a>

## Documentation For Authorization

Endpoints do not require authorization.

## Author


## Links discovered
- [OpenAPI Generator](https://openapi-generator.tech)
- [Setuptools](http://pypi.python.org/pypi/setuptools)
- [**click**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#click)
- [**drag**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#drag)
- [**get_computer_use_status**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#get_computer_use_status)
- [**get_computer_use_system_status**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#get_computer_use_system_status)
- [**get_display_info**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#get_display_info)
- [**get_mouse_position**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#get_mouse_position)
- [**get_process_errors**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#get_process_errors)
- [**get_process_logs**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#get_process_logs)
- [**get_process_status**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#get_process_status)
- [**get_windows**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#get_windows)
- [**move_mouse**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#move_mouse)
- [**press_hotkey**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#press_hotkey)
- [**press_key**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#press_key)
- [**restart_process**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#restart_process)
- [**scroll**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#scroll)
- [**start_computer_use**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#start_computer_use)
- [**stop_computer_use**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#stop_computer_use)
- [**take_compressed_region_screenshot**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#take_compressed_region_screenshot)
- [**take_compressed_screenshot**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#take_compressed_screenshot)
- [**take_region_screenshot**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#take_region_screenshot)
- [**take_screenshot**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#take_screenshot)
- [**type_text**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseApi.md#type_text)
- [**create_folder**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#create_folder)
- [**delete_file**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#delete_file)
- [**download_file**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#download_file)
- [**find_in_files**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#find_in_files)
- [**get_file_info**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#get_file_info)
- [**list_files**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#list_files)
- [**move_file**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#move_file)
- [**replace_in_files**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#replace_in_files)
- [**search_files**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#search_files)
- [**set_file_permissions**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#set_file_permissions)
- [**upload_file**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#upload_file)
- [**upload_files**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileSystemApi.md#upload_files)
- [**add_files**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitApi.md#add_files)
- [**checkout_branch**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitApi.md#checkout_branch)
- [**clone_repository**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitApi.md#clone_repository)
- [**commit_changes**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitApi.md#commit_changes)
- [**create_branch**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitApi.md#create_branch)
- [**delete_branch**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitApi.md#delete_branch)
- [**get_commit_history**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitApi.md#get_commit_history)
- [**get_status**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitApi.md#get_status)
- [**list_branches**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitApi.md#list_branches)
- [**pull_changes**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitApi.md#pull_changes)
- [**push_changes**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitApi.md#push_changes)
- [**get_project_dir**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/InfoApi.md#get_project_dir)
- [**get_version**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/InfoApi.md#get_version)
- [**completions**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspApi.md#completions)
- [**did_close**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspApi.md#did_close)
- [**did_open**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspApi.md#did_open)
- [**document_symbols**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspApi.md#document_symbols)
- [**start**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspApi.md#start)
- [**stop**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspApi.md#stop)
- [**workspace_symbols**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspApi.md#workspace_symbols)
- [**get_ports**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/PortApi.md#get_ports)
- [**is_port_in_use**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/PortApi.md#is_port_in_use)
- [**create_session**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ProcessApi.md#create_session)
- [**delete_session**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ProcessApi.md#delete_session)
- [**execute_command**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ProcessApi.md#execute_command)
- [**get_session**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ProcessApi.md#get_session)
- [**get_session_command**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ProcessApi.md#get_session_command)
- [**get_session_command_logs**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ProcessApi.md#get_session_command_logs)
- [**list_sessions**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ProcessApi.md#list_sessions)
- [**session_execute_command**](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ProcessApi.md#session_execute_command)
- [Command](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/Command.md)
- [CompletionContext](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/CompletionContext.md)
- [CompletionItem](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/CompletionItem.md)
- [CompletionList](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/CompletionList.md)
- [ComputerUseStartResponse](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseStartResponse.md)
- [ComputerUseStatusResponse](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseStatusResponse.md)
- [ComputerUseStopResponse](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ComputerUseStopResponse.md)
- [CreateSessionRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/CreateSessionRequest.md)
- [DisplayInfo](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/DisplayInfo.md)
- [DisplayInfoResponse](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/DisplayInfoResponse.md)
- [ExecuteRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ExecuteRequest.md)
- [ExecuteResponse](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ExecuteResponse.md)
- [FileInfo](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileInfo.md)
- [FileStatus](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/FileStatus.md)
- [GitAddRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitAddRequest.md)
- [GitBranchRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitBranchRequest.md)
- [GitCheckoutRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitCheckoutRequest.md)
- [GitCloneRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitCloneRequest.md)
- [GitCommitInfo](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitCommitInfo.md)
- [GitCommitRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitCommitRequest.md)
- [GitCommitResponse](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitCommitResponse.md)
- [GitGitDeleteBranchRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitGitDeleteBranchRequest.md)
- [GitRepoRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitRepoRequest.md)
- [GitStatus](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/GitStatus.md)
- [IsPortInUseResponse](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/IsPortInUseResponse.md)
- [KeyboardHotkeyRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/KeyboardHotkeyRequest.md)
- [KeyboardPressRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/KeyboardPressRequest.md)
- [KeyboardTypeRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/KeyboardTypeRequest.md)
- [ListBranchResponse](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/ListBranchResponse.md)
- [LspCompletionParams](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspCompletionParams.md)
- [LspDocumentRequest](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspDocumentRequest.md)
- [LspLocation](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspLocation.md)
- [LspPosition](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspPosition.md)
- [LspRange](https://github.com/daytonaio/daytona/blob/main/libs/toolbox-api-client-python/docs/LspRange.md)

--- apps/api/src/migrations/README.md ---
# Database Migrations

This project uses the **Expand and Contract** pattern for database migrations to support zero-downtime deployments.

## Overview

The expand and contract pattern splits database changes into two phases:

- **Pre-deploy (Expand)**: Additive, non-breaking changes that are backwards compatible with the current API version
- **Post-deploy (Contract)**: Breaking changes that require the new API version to be deployed first

This allows the database and API to be updated independently while maintaining compatibility during the deployment window.

## Migration Folders

- `pre-deploy/` - Migrations that run **before** the API is deployed
- `post-deploy/` - Migrations that run **after** the API is deployed

Note: Root folder migrations (not in pre-deploy or post-deploy) are legacy migrations created before the expand-and-contract pattern was introduced. These run during `migration:run:init` only.

## Developer Workflow

### 1. Make Changes to Database Entities

Modify the TypeORM entity files in `src/**/*.entity.ts` as needed.

### 2. Generate Migrations

Run the migration generator:

```bash
npm run migration:generate
```

This creates the **same autogenerated migration in both** `pre-deploy/` and `post-deploy/` folders with a timestamp prefix.

### 3. Analyze and Adjust Migrations

**This is the critical step.** You MUST analyze the generated migrations and determine:

- Which changes are safe to run before the API deployment (pre-deploy)
- Which changes require the new API to be running first (post-deploy)
- Whether manual adjustments are needed for zero-downtime compatibility

#### Example Scenarios

**Adding a new field (Pre-deploy only)**

When adding a new nullable column or a column with a default value:

```typescript
// pre-deploy/migration.ts
public async up(queryRunner: QueryRunner): Promise<void> {
  await queryRunner.query(`ALTER TABLE "workspace" ADD "description" varchar NULL`);
}
```

```typescript
// post-deploy/migration.ts
// DELETE the generated migration - no post-deploy changes needed
```

The new column can be added before the API deployment since the old API will simply ignore it.

---

**Dropping a field (Post-deploy only)**

When removing a column:

```typescript
// pre-deploy/migration.ts
// DELETE the generated migration - no pre-deploy changes needed
```

```typescript
// post-deploy/migration.ts
public async up(queryRunner: QueryRunner): Promise<void> {
  await queryRunner.query(`ALTER TABLE "workspace" DROP COLUMN "legacy_field"`);
}
```

The column must only be dropped after the new API is deployed, since the old API may still be reading from it.

---

**Renaming a field (Expand then Contract)**

Renaming requires both phases to maintain zero-downtime. Use a **database trigger** to keep columns synchronized automatically:

```typescript
// pre-deploy/migration.ts (Expand)
public async up(queryRunner: QueryRunner): Promise<void> {
  // Add new column
  await queryRunner.query(`ALTER TABLE "workspace" ADD "display_name" varchar NULL`);
  // Copy existing data
  await queryRunner.query(`UPDATE "workspace" SET "display_name" = "name"`);
  // Create trigger to keep columns in sync during transition
  await queryRunner.query(`
    CREATE OR REPLACE FUNCTION sync_workspace_name()
    RETURNS TRIGGER AS $$
    BEGIN
      IF NEW.display_name IS NOT NULL THEN
        NEW.name := NEW.display_name;
      ELSIF NEW.name IS NOT NULL THEN
        NEW.display_name := NEW.name;
      END IF;
      RETURN NEW;
    END;
    $$ LANGUAGE plpgsql;
  `);
  await queryRunner.query(`
    CREATE TRIGGER workspace_name_sync
    BEFORE INSERT OR UPDATE ON "workspace"
    FOR EACH ROW EXECUTE FUNCTION sync_workspace_name();
  `);
}
```

```typescript
// post-deploy/migration.ts (Contract)
public async up(queryRunner: QueryRunner): Promise<void> {
  // Remove trigger and old column
  await queryRunner.query(`DROP TRIGGER workspace_name_sync ON "workspace"`);
  await queryRunner.query(`DROP FUNCTION sync_workspace_name()`);
  await queryRunner.query(`ALTER TABLE "workspace" DROP COLUMN "name"`);
}
```

**How the trigger works:**

The trigger intercepts every INSERT and UPDATE on the table and automatically copies the value between columns:

| API Version | Writes to | Trigger copies to | Result |
|-------------|-----------|-------------------|--------|
| Old API | `name` | `display_name` | Both columns have the value |
| New API | `display_name` | `name` | Both columns have the value |

**Deployment timeline:**

1. **Pre-deploy migration runs** ‚Üí Trigger is active, both columns exist
2. **Rolling deployment begins** ‚Üí Mix of old and new API instances, trigger keeps data in sync
3. **Rolling deployment completes** ‚Üí All instances are new API
4. **Post-deploy migration runs** ‚Üí Trigger and old column are removed

**New API code changes:**

The new API should read from and write to `display_name` only. The trigger handles backward compatibility with old API instances‚Äîno dual-write logic needed in application code.

## Migration Scripts

### `npm run migration:run:init`

Runs **all migrations** from both pre-deploy and post-deploy folders. Use this for:

- Initial database setup
- Development environments
- Fresh database instances

### `npm run migration:run:pre-deploy`

Runs only migrations in the `pre-deploy/` folder. Use this:

- **Before** deploying a new API version
- As part of your CI/CD pipeline, before the rolling update begins

### `npm run migration:run:post-deploy`

Runs only migrations in the `post-deploy/` folder. Use this:

- **After** the new API version is fully deployed
- As part of your CI/CD pipeline, after the rolling update completes

## Reverting Migrations

```bash
npm run migration:revert
```

This reverts the **last executed migration** from either folder (based on the combined migration history in the database).

**Important behaviors:**

- Reverts one migration at a time - run multiple times to revert multiple migrations
- Uses the combined data-source that sees all migrations
- The revert order follows the execution timestamp, not the folder structure
- Always test revert scripts in development before relying on them in production

**Recommendation:** After reverting, you may need to also revert the corresponding entity changes and regenerate migrations to keep everything in sync.


--- apps/api/src/webhook/README.md ---
# Webhook Service

This service provides webhook functionality using [Svix](https://svix.com) as the webhook delivery provider. It automatically creates Svix applications for new organizations and sends webhooks for various events.

## Configuration

Set the following environment variables:

```bash
# Required: Your Svix authentication token
SVIX_AUTH_TOKEN=your_svix_auth_token_here

# Optional: Custom Svix server URL (for self-hosted instances)
SVIX_SERVER_URL=https://your-svix-instance.com
```

## API Endpoints

### Get App Portal Access

```http
POST /api/webhooks/organizations/{organizationId}/app-portal-access
```

**Response:**

```json
{
  "url": "https://app.svix.com/consumer/..."
}
```

Returns a URL that provides access to the Svix Consumer App Portal for managing webhook endpoints, viewing delivery attempts, and monitoring webhook performance.

### Send Custom Webhook

```http
POST /api/webhooks/organizations/{organizationId}/send
```

**Request Body:**

```json
{
  "eventType": "custom.event",
  "payload": {
    "message": "Hello from Daytona!",
    "timestamp": "2025-01-01T00:00:00.000Z"
  },
  "eventId": "optional-unique-id"
}
```

Sends a custom webhook message to all configured endpoints for the specified organization.

### Get Message Delivery Attempts

```http
GET /api/webhooks/organizations/{organizationId}/messages/{messageId}/attempts
```

**Response:**

```json
[
  {
    "id": "msg_attempt_123",
    "status": 200,
    "response": "OK",
    "timestamp": "2025-01-01T00:00:00.000Z"
  }
]
```

Returns the delivery attempts for a specific webhook message, including delivery status and response details.

### Get Service Status

```http
GET /api/webhooks/status
```

**Response:**

```json
{
  "enabled": true
}
```

Returns the current status of the webhook service, indicating whether it's properly configured and enabled.

## Automatic Events

The service automatically sends webhooks for the following events:

### Sandbox Events

- `sandbox.created` - When a sandbox is created
- `sandbox.state.updated` - When sandbox state changes

### Snapshot Events

- `snapshot.created` - When a snapshot is created
- `snapshot.state.updated` - When snapshot state changes
- `snapshot.removed` - When a snapshot is removed

### Volume Events

- `volume.created` - When a volume is created
- `volume.state.updated` - When volume state changes

## Webhook Payload Format

All webhooks include event-specific data relevant to the resource being updated.

### Example Sandbox Created Payload

```json
{
  "id": "sandbox-uuid",
  "organizationId": "org-uuid",
  "state": "STARTED",
  "class": "SMALL",
  "createdAt": "2025-01-01T00:00:00.000Z"
}
```

### Example Sandbox State Updated Payload

```json
{
  "id": "sandbox-uuid",
  "organizationId": "org-uuid",
  "oldState": "STOPPED",
  "newState": "STARTED",
  "updatedAt": "2025-01-01T00:00:00.000Z"
}
```

### Example Snapshot Created Payload

```json
{
  "id": "snapshot-uuid",
  "name": "my-snapshot",
  "organizationId": "org-uuid",
  "state": "ACTIVE",
  "createdAt": "2025-01-01T00:00:00.000Z"
}
```

### Example Volume State Updated Payload

```json
{
  "id": "volume-uuid",
  "name": "my-volume",
  "organizationId": "org-uuid",
  "oldState": "CREATING",
  "newState": "READY",
  "updatedAt": "2025-01-01T00:00:00.000Z"
}
```

## Development

### Adding New Event Types

1. Add the event type to `webhook-events.constants.ts`
2. Create an event handler in `webhook-event-handler.service.ts`
3. Use the `@OnEvent()` decorator to listen for the event
4. Define the payload structure for the new event type
5. Add the events to the `openapi-webhooks.ts`
6. Generate the openapi spec
7. Upload the new schema to the Svix dashboard

### Testing

Use the Svix Play webhook debugger during development:

1. Set up a webhook endpoint pointing to your Svix Play URL
2. Send test webhooks using the `/send` endpoint
3. Check the Svix dashboard for delivery status
4. Monitor delivery attempts through the API

### Local Development

For local development without Svix:

1. Set `SVIX_AUTH_TOKEN` to an empty string or invalid value
2. The service will log warnings but continue to function
3. Event handlers will skip webhook delivery when disabled
4. Use the status endpoint to verify configuration

## Dependencies

- `svix` - Official Svix JavaScript SDK
- `@nestjs/event-emitter` - Event handling
- `@nestjs/common` - Core NestJS functionality

### Event Flow

1. System event occurs (e.g., sandbox created)
2. Event emitter publishes the event
3. Webhook event handler catches the event
4. Handler calls webhook service to send webhook
5. Service delivers webhook through Svix
6. Delivery status is tracked and available via API


## Links discovered
- [Svix](https://svix.com)

--- CONTRIBUTING.md ---
# Contributing to Daytona

The team at Daytona welcomes contributions from the community. There are many ways to get involved!

Thanks for taking the time to contribute! ‚ù§Ô∏è

> And if you like the project but don't have time to contribute, that's perfectly okay. There are other simple ways to support the project and show your appreciation, which we would greatly appreciate:
>
> - Star the project
> - Tweet about it
> - Contribute to our [Docs](https://github.com/daytonaio/docs/)
> - Refer this project in your project's readme
> - Mention the project at local meetups and tell your friends/colleagues

## Code of Conduct

This project and everyone participating in it is governed by the
[Daytona Code of Conduct](https://github.com/daytonaio/daytona?tab=coc-ov-file#readme).
By participating, you are expected to uphold this code. Please report unacceptable behavior
to [info@daytona.io](mailto:info@daytona.io).

## Provide Feedback

You might find things that can be improved while you are using Daytona. You can help by [submitting an issue](https://github.com/daytonaio/daytona/issues/new) when:

- A new feature or an enhancement to an existing feature will improve the utility or usability of Daytona.
- Daytona crashes, or you encounter a bug that can only be resolved by restarting Daytona.
- An error occurs that is unrecoverable, causes Sandbox integrity problems or loss, or generally prevents you from using a Sandbox.

Before creating a new issue, please confirm that an existing issue doesn't already exist.

We will then take care of the issue as soon as possible.

## Participate in the Community

You can engage with our community by:

- Helping other users on [Daytona Community Slack](https://go.daytona.io/slack).
- Improving [documentation](https://github.com/daytonaio/docs/)
- Participating in general discussions about development and DevOps
- Authoring new Daytona Plugins and sharing those Plugins
- Authoring new dev containers and sharing examples

## Contributing Code

You can contribute to Daytona by:

- Enhancing current functionality
- Fixing bugs
- Adding new features and capabilities

Before starting your contribution, especially for core features, we encourage you to reach out to us on [Slack](https://go.daytona.io/slack). This allows us to ensure that your proposed feature aligns with the project's roadmap and goals. Developers are the key to making Daytona the best tool it can be, and we value input from the community.

We look forward to working with you to improve Daytona and make development environments as easy as possible for developers everywhere.

### Steps to Contribute Code

Follow the following steps to ensure your contribution goes smoothly.

1. Read and follow the steps outlined in the [Daytona Contributing Policy](README.md#contributing).
1. Configure your development environment by either following the guide below.
1. [Fork](https://help.github.com/articles/working-with-forks/) the GitHub Repository allowing you to make the changes in your own copy of the repository.
1. Create a [GitHub issue](https://github.com/daytonaio/daytona/issues) if one doesn't exist already.
1. [Prepare your changes](/PREPARING_YOUR_CHANGES.md) and ensure your commits are descriptive. The document contains an optional commit template, if desired.
1. Ensure that you sign off on all your commits to comply with the DCO v1.1. We have more details in [Prepare your changes](/PREPARING_YOUR_CHANGES.md).
1. Ensure to generate new docs after making command related changes, by running `./hack/generate-cli-docs.sh` in the daytona root directory.
1. Ensure to generate a new API client after making changes related to the API spec, by running `./hack/swagger.sh` in the daytona root directory.
1. Ensure that you are using `yarn` as the package manager for any Node.js dependencies.
1. Ensure that you have no lint errors. We use `golangci-lint` as our linter which you can install by following instructions found [here](https://golangci-lint.run/welcome/install/#local-installation) (or simply open Daytona in a Dev Container). You can check for linting errors by running `golangci-lint run` in the root of the project.
1. Create a pull request on GitHub. If you're new to GitHub, read about [pull requests](https://help.github.com/articles/about-pull-requests/). You are welcome to submit your pull request for commentary or review before it is complete by creating a [draft pull request](https://help.github.com/en/articles/about-pull-requests#draft-pull-requests). Please include specific questions or items you'd like feedback on.
1. A member of the Daytona team will review your PR within three business days (excluding any holidays) and either merge, comment, and/or assign someone for review.
1. Work with the reviewer to complete a code review. For each change, create a new commit and push it to make changes to your pull request. When necessary, the reviewer can trigger CI to run tests prior to merging.
1. Once you believe your pull request is ready to be reviewed, ensure the pull request is no longer a draft by [marking it ready for review](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/changing-the-stage-of-a-pull-request).
1. The reviewer will look over your contribution and either approve it or provide comments letting you know if there is anything left to do. We try to give you the opportunity to make the required changes yourself, but in some cases, we may perform the changes ourselves if it makes sense to (minor changes or for urgent issues). We do our best to review PRs promptly, but complex changes could require more time.
1. After completing your review, a Daytona team member will trigger merge to run all tests. Upon passing, your change will be merged into `main`, and your pull requests will be closed. All merges to `main` create a new release, and all final changes are attributed to you.

Note: In some cases, we might decide that a PR should be closed without merging. We'll make sure to provide clear reasoning when this happens.

### Coding Style and Conventions

To make the code base consistent, we follow a few guidelines and conventions listed below.

It is possible that the code base does not currently comply with all these guidelines.
While working on a PR, if you see something that can be refactored to comply, go ahead, but keep in mind that we are not looking for massive PRs that only address that.

API and service method conventions:

1. Avoid using model names in service methods
   - e.g. `Create` instead of `CreateSandbox`, `Find` instead of `FindSandbox`
1. Use appropriate verbs in the UI
   - e.g. `Create API Key` instead of `Generate API Key` since the method is called `Create`
1. Refer to the table below for a connection between API and service methods

| HTTP Method | Controller / Service / Store |
| ----------- | ---------------------------- |
| POST        | Create or Update             |
| DELETE      | Delete                       |
| PUT         | Save                         |
| GET         | Find or List                 |

#### What Does Contributing Mean for You?

Here is what being a contributor means for you:

- License all our contributions to the project under the AGPL 3.0 License or the Apache 2.0 License
- Have the legal rights to license our contributions ourselves, or get permission to license them from our employers, clients, or others who may have them

For more information, see the [README](README.md) and feel free to reach out to us on [Slack](https://go.daytona.io/slack).


## Links discovered
- [Docs](https://github.com/daytonaio/docs/)
- [Daytona Code of Conduct](https://github.com/daytonaio/daytona?tab=coc-ov-file#readme)
- [submitting an issue](https://github.com/daytonaio/daytona/issues/new)
- [Daytona Community Slack](https://go.daytona.io/slack)
- [documentation](https://github.com/daytonaio/docs/)
- [Slack](https://go.daytona.io/slack)
- [Daytona Contributing Policy](https://github.com/daytonaio/daytona/blob/main/README.md#contributing)
- [Fork](https://help.github.com/articles/working-with-forks/)
- [GitHub issue](https://github.com/daytonaio/daytona/issues)
- [Prepare your changes](https://github.com/daytonaio/daytona/blob/main/PREPARING_YOUR_CHANGES.md)
- [here](https://golangci-lint.run/welcome/install/#local-installation)
- [pull requests](https://help.github.com/articles/about-pull-requests/)
- [draft pull request](https://help.github.com/en/articles/about-pull-requests#draft-pull-requests)
- [marking it ready for review](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/changing-the-stage-of-a-pull-request)
- [README](https://github.com/daytonaio/daytona/blob/main/README.md)

--- SECURITY.md ---
# Security Policy

## Reporting a Vulnerability

At Daytona, we take security seriously. If you believe you have found a security vulnerability in any Daytona-owned repository or service, please report it responsibly.

**Please do NOT report security vulnerabilities through public GitHub issues.**

Instead, please email us at: **security@daytona.io**

You can also report vulnerabilities privately through [GitHub's security advisory feature](https://github.com/daytonaio/daytona/security/advisories/new).

Please include:

- Description of the vulnerability
- Steps to reproduce
- Impact assessment
- Any relevant screenshots or proof-of-concept

We will acknowledge receipt within 2 business days and provide an initial assessment within 5 business days.

## Supported Versions

We accept vulnerability reports for the latest stable release of Daytona.

## Safe Harbor

Daytona supports safe harbor for security researchers who act in good faith and in accordance with this policy.


## Links discovered
- [GitHub's security advisory feature](https://github.com/daytonaio/daytona/security/advisories/new)

--- CODE_OF_CONDUCT.md ---

# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, caste, color, religion, or sexual
identity and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the overall
  community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or advances of
  any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email address,
  without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official email address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
codeofconduct@daytona.io.

All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series of
actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or permanent
ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior, harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within the
community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.1, available at
[https://www.contributor-covenant.org/version/2/1/code_of_conduct.html][v2.1].

Community Impact Guidelines were inspired by
[Mozilla's code of conduct enforcement ladder][Mozilla CoC].

For answers to common questions about this code of conduct, see the FAQ at
[https://www.contributor-covenant.org/faq][FAQ]. Translations are available at
[https://www.contributor-covenant.org/translations][translations].

[homepage]: https://www.contributor-covenant.org
[v2.1]: https://www.contributor-covenant.org/version/2/1/code_of_conduct.html
[Mozilla CoC]: https://github.com/mozilla/diversity
[FAQ]: https://www.contributor-covenant.org/faq
[translations]: https://www.contributor-covenant.org/translations


--- PACKAGING.md ---
# Packaging Guidelines for Daytona

The Daytona team appreciates any efforts to make our software more accessible to users on various platforms.
While we encourage packaging and distribution of our open-source project, we have some important guidelines, particularly regarding naming.

## Critical Naming Guideline

**Important**: While you are free to package and distribute our software, you **MUST NOT** name your package `daytona` or, in any way, suggest that, the package you distribute, is an official distribution of `daytona`. This restriction is to prevent confusion and maintain the integrity of our project identity.

- Acceptable: "unofficial-daytona-package", "unofficial-daytona-distribution", etc.
- Not Acceptable: "daytona", "official-daytona", etc.

## General Guidelines

1. **License Compliance**: Ensure that the AGPL 3.0/Apache 2.0 license is included with the package and that all copyright notices are preserved.

2. **Version Accuracy**: Use the exact version number of Daytona that you are packaging. Do not modify the version number or add custom suffixes without explicit permission.

3. **Dependencies**: Include all necessary dependencies as specified in our project documentation. Do not add extra dependencies without consulting the project maintainers.

4. **Modifications**: If you need to make any modifications to the source code for packaging purposes, please document these changes clearly and consider submitting them as pull requests to the main project.

5. **Standard Note**: Please include the following standard note in your package description or metadata:

   ```
   This package contains an unofficial distribution of Daytona, an open source project
   developed by Daytona Platforms Inc. This package is not officially supported or endorsed
   by the Daytona project. For the official version, please visit https://github.com/daytonaio/daytona.
   ```

## Feedback and Questions

If you have any questions about packaging Daytona or need clarification on these guidelines, especially regarding naming conventions, please open an issue in our GitHub repository.

We appreciate your contribution to making Daytona more accessible to users across different platforms, while respecting our project's identity!


--- PREPARING_YOUR_CHANGES.md ---
# Preparing Your Changes

This document contains information related to preparing changes for a pull request. Here's a quick checklist for a good PR, more details below:

1. A discussion around the change on [Slack](https://go.daytona.io/slack) or in an issue.
1. A GitHub Issue with a good description associated with the PR
1. One feature/change per PR
1. One commit per PR
1. PR rebased on main (git rebase, not git pull)
1. Good descriptive commit message, with link to issue
1. No changes to code not directly related to your PR
1. Includes functional/integration test
1. Includes documentation

## Commit Message Format

We do not require a particular commit message format of any kind, but we do require that individual commits be descriptive, relative to size and impact.
For example, if a descriptive title covers what the commit does in practice, then an additional description below the title is not required.
However, if the commit has an out-sized impact relative to other commits, its description will need to reflect that.

Reviewers may ask you to amend your commits if they are not descriptive enough.
Since the descriptiveness of a commit is subjective, please feel free to talk to us on [Slack](https://go.daytona.io/slack) if you have any questions.

### Optional Commit Template

If you would like an optional commit template, see the following:

```text
<present-tense-verb-with-capitalized-first-letter> <everything-else-without-punctuation-at-the-end>

<sentences-in-paragraph-format-or-bullet-points>
```

## Squashed Commits

We require that you squash all changes to a single commit. You can do this with the `git rebase -i HEAD~X` command where X is the number of commits you want to squash. See the [Git Documentation](https://git-scm.com/book/en/v2/Git-Branching-Rebasing) for more details.

## Developer's Certificate of Origin

Any contributions to Daytona must only contain code that can legally be contributed to Daytona, and which the Daytona project can distribute under its license.

Prior to contributing to Daytona please read the [Developer's Certificate of Origin](https://developercertificate.org/) and sign-off all commits with the `--signoff` option provided by `git commit`. For example:

```
git commit --signoff --message "This is the commit message"
```

This option adds a `Signed-off-by` trailer at the end of the commit log message.

## DCO Policy on Real Names

The DCO is a representation by someone stating they have the right to contribute the code they have proposed and is important for legal purposes. We have adopted the CNCF DCO Guidelines (https://github.com/cncf/foundation/blob/main/dco-guidelines.md). Which for simplicity we will include here in full:

### DCO Guidelines v1.1

The DCO is a representation by someone stating they have the right to contribute the code they have proposed for acceptance into a project: https://developercertificate.org

That representation is important for legal purposes and was the community-developed outcome after a $1 billion [lawsuit](https://en.wikipedia.org/wiki/SCO%E2%80%93Linux_disputes) by SCO against IBM. The representation is designed to prevent issues but also keep the burden on contributors low. It has proven very adaptable to other projects, is built into git itself (and now also GitHub), and is in use by thousands of projects to avoid more burdensome requirements to contribute (such as a CLA).

### DCO and Real Names

The DCO requires the use of a real name that can be used to identify someone in case there is an issue about a contribution they made.

**A real name does not require a legal name, nor a birth name, nor any name that appears on an official ID (e.g. a passport). Your real name is the name you convey to people in the community for them to use to identify you as you. The key concern is that your identification is sufficient enough to contact you if an issue were to arise in the future about your contribution.**

Your real name should not be an anonymous id or false name that misrepresents who you are.


## Links discovered
- [Slack](https://go.daytona.io/slack)
- [Git Documentation](https://git-scm.com/book/en/v2/Git-Branching-Rebasing)
- [Developer's Certificate of Origin](https://developercertificate.org/)
- [lawsuit](https://en.wikipedia.org/wiki/SCO%E2%80%93Linux_disputes)

--- PUBLISHING.md ---
# Publishing Daytona SDKs

This document describes how to publish the Daytona SDKs (Python, TypeScript, and Ruby) to their respective package registries.

## Table of Contents

- [Prerequisites](#prerequisites)
- [Python SDK (PyPI)](#python-sdk-pypi)
- [TypeScript SDK (npm)](#typescript-sdk-npm)
- [Ruby SDK (RubyGems)](#ruby-sdk-rubygems)
- [Automated Publishing (CI/CD)](#automated-publishing-cicd)
- [Version Management](#version-management)

## Prerequisites

Before publishing any SDK, ensure you have:

1. **Maintainer Access**: Write access to the Daytona repository
2. **Package Registry Credentials**:
   - PyPI: Token with upload permissions
   - npm: Token with publish permissions
   - RubyGems: API key with push permissions
3. **Local Development Setup**:
   - All dependencies installed (`yarn install`)
   - SDKs built successfully
   - Tests passing

## Python SDK (PyPI)

### Using Nx

```bash
# From repository root
export PYPI_TOKEN="your-pypi-token"
export PYPI_PKG_VERSION="X.Y.Z" # pre-release format example: "X.Y.Za1"
yarn nx publish sdk-python
```

**Note**: [Guide](https://packaging.python.org/en/latest/discussions/versioning/) for versioning Python packages.

## TypeScript SDK (npm)

### Using Nx

```bash
# From repository root
export NPM_TOKEN="your-npm-token"
export NPM_PKG_VERSION="X.Y.Z" # pre-release format example: "X.Y.Z-alpha.1"
export NPM_TAG="latest"  # or "beta", "alpha", etc.
yarn nx publish sdk-typescript
```

**Note**: NPM packages must have [SemVer-aligned formats](https://semver.org/).

## Ruby SDK (RubyGems)

### Using Nx

```bash
# From repository root
export RUBYGEMS_API_KEY="your-rubygems-api-key"
export RUBYGEMS_PKG_VERSION="X.Y.Z" # pre-release format example: "X.Y.Z.alpha.1"
yarn nx publish sdk-ruby
```

**Note**: [Guide](https://guides.rubygems.org/patterns/#prerelease-gems) for versioning Ruby gems.

## Automated Publishing (CI/CD)

### GitHub Actions Workflow

The repository includes a GitHub Actions workflow for automated publishing: `.github/workflows/sdk_publish.yaml`

#### Triggering a Release

1. Go to **Actions** ‚Üí **SDK and CLI Publish** in the GitHub repository
2. Click **Run workflow**
3. Fill in the parameters:
   - **version**: The version to release (e.g., `v0.126.0`)
   - **pypi_pkg_version**: (Optional) Override PyPI version
   - **npm_pkg_version**: (Optional) Override npm version
   - **rubygems_pkg_version**: (Optional) Override RubyGems version
   - **npm_tag**: npm dist-tag (default: `latest`)

#### Required Secrets

Ensure these secrets are configured in GitHub repository settings:

- `PYPI_TOKEN`: PyPI API token
- `NPM_TOKEN`: npm access token
- `RUBYGEMS_API_KEY`: RubyGems API key
- `GITHUBBOT_TOKEN`: GitHub token for Homebrew tap updates

### What the Workflow Does

1. Checks out the code
2. Sets up all required environments (Go, Java, Python, Node.js, Ruby)
3. Installs dependencies
4. Configures credentials for all package registries
5. Runs `yarn publish` which uses Nx to publish all SDKs in the correct order
6. Updates the Homebrew tap (for the CLI)

## Version Management

### Version Format

`MAJOR.MINOR.PATCH` releases follow semantics:

- **MAJOR**: Breaking changes
- **MINOR**: New features (backward compatible)
- **PATCH**: Bug fixes (backward compatible)

Prerelease formats depend on SDK language:

1. For **Typescript** (npm) follow semantic versioning ([SemVer](https://semver.org/)): `MAJOR.MINOR.PATCH`

   For pre-releases, use:

   - `0.126.0-alpha.1` - Alpha release
   - `0.126.0-beta.1` - Beta release
   - `0.126.0-rc.1` - Release candidate

2. For **Python** (PyPI) follow Python packages versioning [guide](https://packaging.python.org/en/latest/discussions/versioning/):

   For pre-releases, use:

   - `1.2.0a1` - Alpha release
   - `1.2.0b1` - Beta release
   - `1.2.0rc1` - Release candidate

3. For **Ruby** (gem) follow Ruby gems versioning [guide](https://guides.rubygems.org/patterns/#prerelease-gems):

   For pre-releases, use:

   - `0.126.0.alpha.1` - Alpha release
   - `0.126.0.beta.1` - Beta release
   - `0.126.0.rc.1` - Release candidate

### Checking Published Versions

#### PyPI

```bash
pip index versions daytona
# or
curl -s https://pypi.org/pypi/daytona/json | jq -r .info.version
```

#### npm

```bash
npm view @daytonaio/sdk version
# or
npm info @daytonaio/sdk
```

#### RubyGems

```bash
gem search daytona --remote --exact
# or
gem info daytona --remote
```

## References

- [Semantic Versioning](https://semver.org/)
- [Python packages versioning](https://packaging.python.org/en/latest/discussions/versioning/)
- [Ruby gems versioning guide](https://guides.rubygems.org/patterns/#prerelease-gems)


## Links discovered
- [Guide](https://packaging.python.org/en/latest/discussions/versioning/)
- [SemVer-aligned formats](https://semver.org/)
- [Guide](https://guides.rubygems.org/patterns/#prerelease-gems)
- [SemVer](https://semver.org/)
- [guide](https://packaging.python.org/en/latest/discussions/versioning/)
- [guide](https://guides.rubygems.org/patterns/#prerelease-gems)
- [Semantic Versioning](https://semver.org/)
- [Python packages versioning](https://packaging.python.org/en/latest/discussions/versioning/)
- [Ruby gems versioning guide](https://guides.rubygems.org/patterns/#prerelease-gems)

--- README.md ---
<div align="center">

[![Documentation](https://img.shields.io/github/v/release/daytonaio/docs?label=Docs&color=23cc71)](https://www.daytona.io/docs)
![License](https://img.shields.io/badge/License-AGPL--3-blue)
[![Go Report Card](https://goreportcard.com/badge/github.com/daytonaio/daytona)](https://goreportcard.com/report/github.com/daytonaio/daytona)
[![Issues - daytona](https://img.shields.io/github/issues/daytonaio/daytona)](https://github.com/daytonaio/daytona/issues)
![GitHub Release](https://img.shields.io/github/v/release/daytonaio/daytona)

</div>

&nbsp;

<div align="center">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-white.png">
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png">
    <img alt="Daytona logo" src="https://github.com/daytonaio/daytona/raw/main/assets/images/Daytona-logotype-black.png" width="50%">
  </picture>
</div>

<h3 align="center">
  Run AI Code.
  <br/>
  Secure and Elastic Infrastructure for
  Running Your AI-Generated Code.
</h3>

<p align="center">
    <a href="https://www.daytona.io/docs"> Documentation </a>¬∑
    <a href="https://github.com/daytonaio/daytona/issues/new?assignees=&labels=bug&projects=&template=bug_report.md&title=%F0%9F%90%9B+Bug+Report%3A+"> Report Bug </a>¬∑
    <a href="https://github.com/daytonaio/daytona/issues/new?assignees=&labels=enhancement&projects=&template=feature_request.md&title=%F0%9F%9A%80+Feature%3A+"> Request Feature </a>¬∑
    <a href="https://go.daytona.io/slack"> Join our Slack </a>¬∑
    <a href="https://x.com/daytonaio"> Connect on X </a>
</p>

<p align="center">
    <a href="https://www.producthunt.com/posts/daytona-2?embed=true&utm_source=badge-top-post-badge&utm_medium=badge&utm_souce=badge-daytona&#0045;2" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=957617&theme=neutral&period=daily&t=1746176740150" alt="Daytona&#0032; - Secure&#0032;and&#0032;elastic&#0032;infra&#0032;for&#0032;running&#0032;your&#0032;AI&#0045;generated&#0032;code&#0046; | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /></a>
    <a href="https://www.producthunt.com/posts/daytona-2?embed=true&utm_source=badge-top-post-topic-badge&utm_medium=badge&utm_souce=badge-daytona&#0045;2" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/top-post-topic-badge.svg?post_id=957617&theme=neutral&period=monthly&topic_id=237&t=1746176740150" alt="Daytona&#0032; - Secure&#0032;and&#0032;elastic&#0032;infra&#0032;for&#0032;running&#0032;your&#0032;AI&#0045;generated&#0032;code&#0046; | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /></a>
</p>

---

## Installation

### Python SDK

```bash
pip install daytona
```

### TypeScript SDK

```bash
npm install @daytonaio/sdk
```

---

## Features

- **Lightning-Fast Infrastructure**: Sub-90ms Sandbox creation from code to execution.
- **Separated & Isolated Runtime**: Execute AI-generated code with zero risk to your infrastructure.
- **Massive Parallelization for Concurrent AI Workflows**: Fork Sandbox filesystem and memory state (Coming soon!)
- **Programmatic Control**: File, Git, LSP, and Execute API
- **Unlimited Persistence**: Your Sandboxes can live forever
- **OCI/Docker Compatibility**: Use any OCI/Docker image to create a Sandbox

---

## Quick Start

1. Create an account at https://app.daytona.io
1. Generate a [new API key](https://app.daytona.io/dashboard/keys)
1. Follow the [Getting Started docs](https://www.daytona.io/docs/getting-started/) to start using the Daytona SDK

## Creating your first Sandbox

### Python SDK

```py
from daytona import Daytona, DaytonaConfig, CreateSandboxBaseParams

# Initialize the Daytona client
daytona = Daytona(DaytonaConfig(api_key="YOUR_API_KEY"))

# Create the Sandbox instance
sandbox = daytona.create(CreateSandboxBaseParams(language="python"))

# Run code securely inside the Sandbox
response = sandbox.process.code_run('print("Sum of 3 and 4 is " + str(3 + 4))')
if response.exit_code != 0:
    print(f"Error running code: {response.exit_code} {response.result}")
else:
    print(response.result)

# Clean up the Sandbox
daytona.delete(sandbox)
```

### Typescript SDK

```jsx
import { Daytona } from '@daytonaio/sdk'

async function main() {
  // Initialize the Daytona client
  const daytona = new Daytona({
    apiKey: 'YOUR_API_KEY',
  })

  let sandbox
  try {
    // Create the Sandbox instance
    sandbox = await daytona.create({
      language: 'typescript',
    })
    // Run code securely inside the Sandbox
    const response = await sandbox.process.codeRun('console.log("Sum of 3 and 4 is " + (3 + 4))')
    if (response.exitCode !== 0) {
      console.error('Error running code:', response.exitCode, response.result)
    } else {
      console.log(response.result)
    }
  } catch (error) {
    console.error('Sandbox flow error:', error)
  } finally {
    if (sandbox) await daytona.delete(sandbox)
  }
}

main().catch(console.error)
```

### Go SDK

```go
package main

import (
 "context"
 "fmt"
 "log"
 "time"

 "github.com/daytonaio/daytona/libs/sdk-go/pkg/daytona"
 "github.com/daytonaio/daytona/libs/sdk-go/pkg/types"
)

func main() {
 // Initialize the Daytona client with DAYTONA_API_KEY in env
  // Alternative is to use daytona.NewClientWithConfig(...) for more specific config
 client, err := daytona.NewClient()
 if err != nil {
  log.Fatalf("Failed to create client: %v", err)
 }

 ctx := context.Background()

 // Create the Sandbox instance
 params := types.SnapshotParams{
  SandboxBaseParams: types.SandboxBaseParams{
   Language: types.CodeLanguagePython,
  },
 }

 sandbox, err := client.Create(ctx, params, daytona.WithTimeout(90*time.Second))
 if err != nil {
  log.Fatalf("Failed to create sandbox: %v", err)
 }

 // Run code securely inside the Sandbox
 response, err := sandbox.Process.ExecuteCommand(ctx, `python3 -c "print('Sum of 3 and 4 is', 3 + 4)"`)
 if err != nil {
  log.Fatalf("Failed to execute command: %v", err)
 }

 if response.ExitCode != 0 {
  fmt.Printf("Error running code: %d %s\n", response.ExitCode, response.Result)
 } else {
  fmt.Println(response.Result)
 }

 // Clean up the Sandbox
 if err := sandbox.Delete(ctx); err != nil {
  log.Fatalf("Failed to delete sandbox: %v", err)
 }
}
```

---

## Contributing

Daytona is Open Source under the [GNU AFFERO GENERAL PUBLIC LICENSE](LICENSE), and is the [copyright of its contributors](NOTICE). If you would like to contribute to the software, read the Developer Certificate of Origin Version 1.1 (https://developercertificate.org/). Afterwards, navigate to the [contributing guide](CONTRIBUTING.md) to get started.


## Links discovered
- [![Documentation](https://img.shields.io/github/v/release/daytonaio/docs?label=Docs&color=23cc71)
- [License](https://img.shields.io/badge/License-AGPL--3-blue)
- [![Go Report Card](https://goreportcard.com/badge/github.com/daytonaio/daytona)
- [![Issues - daytona](https://img.shields.io/github/issues/daytonaio/daytona)
- [GitHub Release](https://img.shields.io/github/v/release/daytonaio/daytona)
- [new API key](https://app.daytona.io/dashboard/keys)
- [Getting Started docs](https://www.daytona.io/docs/getting-started/)
- [GNU AFFERO GENERAL PUBLIC LICENSE](https://github.com/daytonaio/daytona/blob/main/LICENSE.md)
- [copyright of its contributors](https://github.com/daytonaio/daytona/blob/main/NOTICE.md)
- [contributing guide](https://github.com/daytonaio/daytona/blob/main/CONTRIBUTING.md)
- [Documentation](https://www.daytona.io/docs)
- [Report Bug](https://github.com/daytonaio/daytona/issues/new?assignees=&labels=bug&projects=&template=bug_report.md&title=%F0%9F%90%9B+Bug+Report%3A+)
- [Request Feature](https://github.com/daytonaio/daytona/issues/new?assignees=&labels=enhancement&projects=&template=feature_request.md&title=%F0%9F%9A%80+Feature%3A+)
- [Join our Slack](https://go.daytona.io/slack)
- [Connect on X](https://x.com/daytonaio)

--- docker/README.md ---
# Docker Compose Setup for Daytona

This folder contains a Docker Compose setup for running Daytona locally.

‚ö†Ô∏è **Important**:

- This setup is still in development and is **not safe to use in production**
- A separate deployment guide will be provided for production scenarios

## Overview

The Docker Compose configuration includes all the necessary services to run Daytona:

- **API**: Main Daytona application server
- **Proxy**: Request proxy service
- **Runner**: Service that hosts the Daytona Runner
- **SSH Gateway**: Service that handles sandbox SSH access
- **Database**: PostgreSQL database for data persistence
- **Redis**: In-memory data store for caching and sessions
- **Dex**: OIDC authentication provider
- **Registry**: Docker image registry with web UI
- **MinIO**: S3-compatible object storage
- **MailDev**: Email testing service
- **Jaeger**: Distributed tracing
- **PgAdmin**: Database administration interface

## Quick Start

1. Start all services (from the root of the Daytona repo):

   ```bash
   docker compose -f docker/docker-compose.yaml up -d
   ```

2. Access the services:
   - Daytona Dashboard: http://localhost:3000
     - Access Credentials: dev@daytona.io `password`
     - Make sure that the default snapshot is active at http://localhost:3000/dashboard/snapshots
   - PgAdmin: http://localhost:5050
   - Registry UI: http://localhost:5100
   - MinIO Console: http://localhost:9001 (minioadmin / minioadmin)

## DNS Setup for Proxy URLs

For local development, you need to resolve `*.proxy.localhost` domains to `127.0.0.1`:

```bash
./scripts/setup-proxy-dns.sh
```

This configures dnsmasq with `address=/proxy.localhost/127.0.0.1`.

**Without this setup**, SDK examples and direct proxy access won't work.

## Development Notes

- The setup uses shared networking for simplified service communication
- Database and storage data is persisted in Docker volumes
- The registry is configured to allow image deletion for testing
- Sandbox resource limits are disabled due to inability to partition cgroups in DinD environment where the sock is not mounted

<br><br><br>

# Auth0 Configuration Guide for Daytona

## Step 1: Create Your Auth0 Tenant

Begin by navigating to https://auth0.com/signup and start the signup process. Choose your account type based on your use case - select `Company` for business applications or `Personal` for individual projects.\
On the "Let's get setup" page, you'll need to enter your application name such as `My Daytona` and select `Single Page Application (SPA)` as the application type. For authentication methods, you can start with `Email and Password` since additional social providers like Google, GitHub, or Facebook can be added later. Once you've configured these settings, click `Create Application` in the bottom right corner.

## Step 2: Configure Your Single Page Application

Navigate to `Applications` > `Applications` in the left sidebar and select the application you just created. Click the `Settings` tab and scroll down to find the `Application URIs` section where you'll configure the callback and origin URLs.
In the `Allowed Callback URIs` field, add the following URLs:

```
http://localhost:3000
http://localhost:3000/api/oauth2-redirect.html
http://localhost:4000/callback
http://proxy.localhost:4000/callback
```

For `Allowed Logout URIs`, add:

```
http://localhost:3000
```

And for `Allowed Web Origins`, add:

```
http://localhost:3000
```

Remember to click `Save Changes` at the bottom of the page to apply these configurations.

## Step 3: Create Machine-to-Machine Application

You'll need a Machine-to-Machine application to interact with Auth0's Management API. Go to `Applications` > `Applications` and click `Create Application`. Choose `Machine to Machine Applications` as the type and provide a descriptive name like `My Management API M2M`.
After creating the application, navigate to the `APIs` tab within your new M2M application. Find and authorize the `Auth0 Management API` by clicking the toggle or authorize button.\
Once authorized, click the dropdown arrow next to the Management API to configure permissions. Grant the following permissions to your M2M application:

```
read:users
update:users
read:connections
create:guardian_enrollment_tickets
read:connections_options
```

Click `Save` to apply these permission changes.

## Step 4: Set Up Custom API

Your Daytona application will need a custom API to handle authentication and authorization. Navigate to `Applications` > `APIs` in the left sidebar and click `Create API`. Enter a descriptive name such as `My Daytona API` and provide an identifier like `my-daytona-api`. The identifier should be a unique string that will be used in your application configuration.\
After creating the API, go to the `Permissions` tab to define the scopes your application will use. Add each of the following permissions with their corresponding descriptions:

| Permission | Description |
|------------|-------------|
| `read:node` | Get workspace node info |
| `create:node` | Create new workspace node record |
| `create:user` | Create user account |
| `read:users` | Get all user accounts |
| `regenerate-key-pair:users` | Regenerate user SSH key-pair |
| `read:workspaces` | Read workspaces (user scope) |
| `create:registry` | Create a new docker registry auth record |
| `read:registries` | Get all docker registry records |
| `read:registry` | Get docker registry record |
| `write:registry` | Create or update docker registry record |

## Step 5: Configure Environment Variables

Once you've completed all the Auth0 setup steps, you'll need to configure environment variables in your Daytona deployment. These variables connect your application to the Auth0 services you've just configured.

### Finding Your Configuration Values

You can find the necessary values in the Auth0 dashboard. For your SPA application settings, go to `Applications` > `Applications`, select your SPA app, and click the `Settings` tab. For your M2M application, follow the same path but select your Machine-to-Machine app instead. Custom API settings are located under `Applications` > `APIs`, then select your custom API and go to `Settings`.

### API Service Configuration

Configure the following environment variables for your API service:

```bash
OIDC_CLIENT_ID=your_spa_app_client_id
OIDC_ISSUER_BASE_URL=your_spa_app_domain
OIDC_AUDIENCE=your_custom_api_identifier
OIDC_MANAGEMENT_API_ENABLED=true
OIDC_MANAGEMENT_API_CLIENT_ID=your_m2m_app_client_id
OIDC_MANAGEMENT_API_CLIENT_SECRET=your_m2m_app_client_secret
OIDC_MANAGEMENT_API_AUDIENCE=your_auth0_managment_api_identifier
```

### Proxy Service Configuration

For your proxy service, configure these environment variables:

```bash
OIDC_CLIENT_ID=your_spa_app_client_id
OIDC_CLIENT_SECRET=
OIDC_DOMAIN=your_spa_app_domain
OIDC_AUDIENCE=your_custom_api_identifier (with trailing slash)
```

Note that `OIDC_CLIENT_SECRET` should remain empty for your proxy environment.


--- ecosystem.config.js ---
/*
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: AGPL-3.0
 */

module.exports = {
  apps: [
    {
      name: 'daytona',
      script: './dist/apps/api/main.js',
      instances: 4,
      exec_mode: 'cluster',
      watch: false,
      env: {
        NODE_ENV: 'production',
        PM2_CLUSTER: 'true',
      },
      wait_ready: true,
      kill_timeout: 30000,
      listen_timeout: 10000,
    },
  ],
}


--- jest.config.ts ---
/*
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: AGPL-3.0
 */

import { getJestProjectsAsync } from '@nx/jest'

export default async () => ({
  projects: await getJestProjectsAsync(),
})


--- jest.preset.js ---
/*
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: AGPL-3.0
 */

const nxPreset = require('@nx/jest/preset').default

module.exports = { ...nxPreset }


--- .github/pull_request_template.md ---
## Description

Please include a summary of the change or the feature being introduced. Include relevant motivation and context. List any dependencies that are required for this change.

## Documentation

- [ ] This change requires a documentation update
- [ ] I have made corresponding changes to the documentation

## Related Issue(s)

This PR addresses issue #X

## Screenshots

If relevant, please add screenshots.

## Notes

Please add any relevant notes if necessary.


--- .github/ISSUE_TEMPLATE/bug_report.md ---
---
name: Bug report
about: Create a report to help us improve
title: ''
type: Bug
assignees: ''
---

**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:

1. Use these parameters '...'
2. Click on '...'
3. Execute the following command '...'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Environment (required fields):**

- Deployment: [Production/OSS]
- Daytona client: [e.g. Python SDK v0.0.1 or Daytona CLI v0.0.1]
- Daytona Version: [Found in the dashboard]

**Additional context**
Add any other context about the problem here.


--- .github/ISSUE_TEMPLATE/feature_request.md ---
---
name: Feature request
about: Suggest an idea for this project
title: ''
type: Feature
assignees: ''
---

**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Add any other context or screenshots about the feature request here.


--- apps/ssh-gateway/README.md ---
# SSH Gateway

A standalone SSH gateway application that authenticates users using tokens and proxies connections to Daytona runners.

## Features

- **Token-based authentication**: Username is used as the authentication token
- **Automatic runner discovery**: Validates tokens and finds the appropriate runner
- **SSH keypair management**: Retrieves SSH credentials from runners automatically
- **Connection proxying**: Seamlessly forwards SSH connections to runners

## Usage

### Connection Format

```bash
ssh -p 2222 <TOKEN>@<GATEWAY_HOST>
```

**Example:**

```bash
ssh -p 2222 Fg8Jx2nPtWAVY5pVN0TlUcbCDNPF-ePB@localhost
```

Where:

- `Fg8Jx2nPtWAVY5pVN0TlUcbCDNPF-ePB` is the SSH access token
- `localhost` is the SSH gateway host
- `2222` is the SSH gateway port

### How It Works

1. **Authentication**: The gateway extracts the token from the username
2. **Token Validation**: Calls the Daytona API to validate the token and get runner information
3. **Credential Retrieval**: Fetches the SSH keypair from the identified runner
4. **Connection Proxying**: Establishes a connection to the runner's SSH gateway (port 2222)
5. **Session Forwarding**: Proxies the SSH session between the client and the runner

## Configuration

### Environment Variables

| Variable           | Description                           | Default                 | Required |
| ------------------ | ------------------------------------- | ----------------------- | -------- |
| `SSH_GATEWAY_PORT` | Port for the SSH gateway to listen on | `2222`                  | No       |
| `API_URL`          | Daytona API base URL                  | `http://localhost:3000` | No       |
| `API_KEY`          | Daytona API authentication key        | -                       | **Yes**  |

### Example Environment

```bash
export SSH_GATEWAY_PORT=2222
export API_URL=https://api.daytona.example.com
export API_KEY=your-api-key-here
```

## Building

### Local Build

```bash
go mod tidy
go build -o ssh-gateway .
```

### Docker Build

```bash
docker build -t ssh-gateway .
```

## Running

### Local Execution

```bash
./ssh-gateway
```

### Docker Execution

```bash
docker run -p 2222:2222 \
  -e API_URL=https://api.daytona.example.com \
  -e API_KEY=your-api-key-here \
  ssh-gateway
```

## Security

- **No password authentication**: Only token-based authentication is supported
- **No public key authentication**: Public keys are not accepted
- **Temporary host keys**: The gateway generates new host keys on each startup
- **Secure token validation**: All tokens are validated against the Daytona API
- **Runner isolation**: Each connection is isolated to its specific runner

## Architecture

```
SSH Client ‚Üí SSH Gateway ‚Üí Daytona API ‚Üí Runner SSH Gateway
     ‚Üì              ‚Üì           ‚Üì              ‚Üì
  Token Auth   Validate    Get Keypair    SSH Session
```

## API Endpoints Used

- `GET /sandbox/ssh-access/validate?token={token}` - Validate SSH access token
- `GET /runners/{id}/ssh-keypair` - Get runner SSH keypair

## Error Handling

The gateway provides clear error messages for common failure scenarios:

- Invalid or expired tokens
- Runner unavailability
- Network connectivity issues
- Authentication failures

## Logging

The application logs all connection attempts and errors for debugging and monitoring purposes.


--- apps/cli/mcp/README.md ---
# Daytona MCP (Model Context Protocol) Server

Daytona MCP Server allows AI agents to utilize:

- Daytona Sandbox Management (Create, Destroy)
- Execute commands in Daytona Sandboxes
- File Operations in Daytona sandboxes
- Generate preview links for web applications running in Daytona Sandboxes

## Prerequisites

- Daytona account
- Daytona CLI installed
- A compatible AI agent (Claude Desktop App, Claude Code, Cursor, Windsurf)

## Steps to Integrate Daytona MCP Server with an AI Agent

1. **Install the Daytona CLI:**

**Mac/Linux**

```bash
brew install daytonaio/cli/daytona
```

**Windows**

```bash
powershell -Command "irm https://get.daytona.io/windows | iex"
```

2. **Log in to your Daytona account:**

```bash
daytona login
```

3. **Initialize the Daytona MCP server with Claude Desktop/Claude Code/Cursor/Windsurf:**

```bash
daytona mcp init [claude/cursor/windsurf]
```

4. **Open Agent App**

## Integrating with Other AI Agents Apps

**Run the following command to get a JSON Daytona MCP configuration which you can c/p to your agent configuration:**

```bash
daytona mcp config
```

**Command outputs the following:**

```json
{
  "mcpServers": {
    "daytona-mcp": {
      "command": "daytona",
      "args": ["mcp", "start"],
      "env": {
        "HOME": "${HOME}",
        "PATH": "${HOME}:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/homebrew/bin"
      },
      "logFile": "${HOME}/Library/Logs/daytona/daytona-mcp-server.log"
    }
  }
}
```

Note: if you are running Daytona MCP Server on Windows OS, add the following to the env field of the configuration:

```json
"APPDATA": "${APPDATA}"
```

**Finally, open or restart your AI agent**

## Available Tools

### Sandbox Management

- `create_sandbox`: Create a new sandbox with Daytona

  - Parameters:
    - `id` (optional): Sandbox ID - if provided, an existing sandbox will be used, new one will be created otherwise
    - `target` (optional): Target region of the sandbox (if not provided, default region of the organization is used)
    - `image`: Image of the sandbox (optional)
    - `auto_stop_interval` (default: "15"): Auto-stop interval in minutes (0 means disabled)
    - `auto_archive_interval` (default: "10080"): Auto-archive interval in minutes (0 means the maximum interval will be used)
    - `auto_delete_interval` (default: "-1"): Auto-delete interval in minutes (negative value means disabled, 0 means delete immediately upon stopping)

- `destroy_sandbox`: Destroy a sandbox with Daytona

### File Operations

- `upload_file`: Upload a file to the Daytona sandbox

  - Files can be text or base64-encoded binary content
  - Creates necessary parent directories automatically
  - Files persist during the session and have appropriate permissions
  - Supports overwrite controls and maintains original files formats
  - Parameters:
    - `id` (optional): Sandbox ID
    - `file_path`: Path to the file to upload
    - `content`: Content of the file to upload
    - `encoding`: Encoding of the file to upload
    - `overwrite`: Overwrite the file if it already exists

- `download_file`: Download a file from the Daytona sandbox

  - Returns file content as text or base64 encoded image
  - Handles special cases like matplotlib plots stored as JSON
  - Parameters:
    - `id` (optional): Sandbox ID
    - `file_path`: Path to the file to download

- `create_folder`: Create a new folder in the Daytona sandbox

  - Parameters:
    - `id` (optional): Sandbox ID
    - `folder_path`: Path to the folder to create
    - `mode`: Mode of the folder to create (defaults to 0755)

- `get_file_info`: Get information about a file in the Daytona sandbox

  - Parameters:
    - `id` (optional): Sandbox ID
    - `file_path`: Path to the file to get information about

- `list_files`: List files in a directory in the Daytona sandbox

  - Parameters:
    - `id` (optional): Sandbox ID
    - `path`: Path to the directory to list files from (defaults to current directory)

- `move_file`: Move or rename a file in the Daytona sandbox

  - Parameters:
    - `id` (optional): Sandbox ID
    - `source_path`: Source path of the file to move
    - `dest_path`: Destination path where to move the file

- `delete_file`: Delete a file or directory in the Daytona sandbox

  - Parameters:
    - `id` (optional): Sandbox ID
    - `file_path`: Path to the file or directory to delete

### Git Operations

- `git_clone`: Clone a Git repository into the Daytona sandbox

  - Parameters:
    - `id` (optional): Sandbox ID
    - `url`: URL of the Git repository to clone
    - `path`: Directory to clone the repository into (defaults to current directory)
    - `branch`: Branch to clone
    - `commit_id`: Commit ID to clone
    - `username`: Username to clone the repository with
    - `password`: Password to clone the repository with

### Command Execution

- `execute_command`: Execute shell commands in the ephemeral Daytona Linux environment

  - Returns full stdout and stderr output with exit codes
  - Commands have sandbox user permissions
  - Parameters:
    - `id` (optional): Sandbox ID
    - `command`: Command to execute

### Preview

- `preview_link`: Generate accessible preview URLs for web applications running in the Daytona sandbox

  - Creates a secure tunnel to expose local ports externally without configuration
  - Validates if a server is actually running on the specified port
  - Provides diagnostic information for troubleshooting
  - Supports custom descriptions and metadata for better organization of multiple services
  - Parameters:
    - `id` (optional): Sandbox ID
    - `port`: Port to expose
    - `description`: Description of the service
    - `check_server`: Check if a server is running

## Troubleshooting

- **Authentication issues:** Run `daytona login` to refresh your credentials
- **Connection errors:** Ensure that the Daytona MCP Server is properly configured
- **Sandbox errors:** Check sandbox status with `daytona sandbox list`

## Support

For more information, visit [daytona.io](https://daytona.io) or contact support at support@daytona.io.


## Links discovered
- [daytona.io](https://daytona.io)

--- apps/dashboard/index.html ---
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" href="/favicon.ico" />
    <link rel="shortcut icon" href="/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Daytona</title>
  </head>
  <body>
    <div id="root"></div>
    <script>
      // Check for dark mode preference
      if (
        localStorage.theme === 'dark' ||
        (!('theme' in localStorage) && window.matchMedia('(prefers-color-scheme: dark)').matches)
      ) {
        document.documentElement.classList.add('dark')
      }
    </script>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>


--- apps/daemon/pkg/recordingdashboard/static/index.html ---
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Screen Recordings</title>
    <style>
      * {
        box-sizing: border-box;
        margin: 0;
        padding: 0;
      }
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        background: #0a0a0a;
        color: #fafafa;
        padding: 24px;
        min-height: 100vh;
        -webkit-font-smoothing: antialiased;
      }
      .container {
        max-width: 1200px;
        margin: 0 auto;
      }
      .header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-bottom: 24px;
        padding-bottom: 16px;
        border-bottom: 1px solid #262626;
      }
      h1 {
        font-size: 20px;
        font-weight: 600;
        color: #fafafa;
      }
      .header-left {
        display: flex;
        align-items: center;
        gap: 12px;
      }
      .refresh-info {
        font-size: 12px;
        color: #a3a3a3;
      }
      .btn {
        padding: 8px 16px;
        border: none;
        border-radius: 6px;
        cursor: pointer;
        font-size: 13px;
        font-weight: 500;
        transition: all 0.15s ease;
      }
      .btn:hover {
        opacity: 0.9;
      }
      .btn-primary {
        background: #fafafa;
        color: #0a0a0a;
      }
      .btn-secondary {
        background: #262626;
        color: #fafafa;
        border: 1px solid #404040;
      }
      .btn-secondary:hover {
        background: #333;
      }
      .btn-danger {
        background: #dc2626;
        color: #fafafa;
      }
      .btn-ghost {
        background: transparent;
        color: #a3a3a3;
        padding: 6px 10px;
      }
      .btn-ghost:hover {
        background: #262626;
        color: #fafafa;
      }
      .btn:disabled {
        opacity: 0.4;
        cursor: not-allowed;
      }
      .btn-icon {
        padding: 6px 8px;
        font-size: 14px;
      }
      table {
        width: 100%;
        border-collapse: collapse;
        background: #0a0a0a;
        border: 1px solid #262626;
        border-radius: 8px;
        overflow: hidden;
      }
      th,
      td {
        padding: 12px 16px;
        text-align: left;
        border-bottom: 1px solid #262626;
      }
      th {
        background: #141414;
        color: #a3a3a3;
        font-weight: 500;
        font-size: 12px;
        text-transform: uppercase;
        letter-spacing: 0.05em;
      }
      tr:hover td {
        background: #141414;
      }
      tr:last-child td {
        border-bottom: none;
      }
      .actions {
        display: flex;
        gap: 4px;
      }
      .empty {
        text-align: center;
        padding: 48px 24px;
        color: #a3a3a3;
      }
      .empty-icon {
        font-size: 32px;
        margin-bottom: 12px;
        opacity: 0.5;
      }
      .modal {
        display: none;
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background: rgba(0, 0, 0, 0.85);
        justify-content: center;
        align-items: center;
        z-index: 1000;
      }
      .modal.active {
        display: flex;
      }
      .modal-content {
        background: #141414;
        border: 1px solid #262626;
        padding: 20px;
        border-radius: 12px;
        max-width: 90%;
        max-height: 90%;
      }
      .modal-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-bottom: 16px;
        padding-bottom: 12px;
        border-bottom: 1px solid #262626;
      }
      .modal-header h2 {
        font-size: 16px;
        font-weight: 500;
      }
      .close-btn {
        background: #262626;
        border: none;
        color: #a3a3a3;
        width: 28px;
        height: 28px;
        border-radius: 6px;
        cursor: pointer;
        font-size: 18px;
        display: flex;
        align-items: center;
        justify-content: center;
      }
      .close-btn:hover {
        background: #333;
        color: #fafafa;
      }
      video {
        max-width: 100%;
        max-height: 70vh;
        border-radius: 8px;
        background: #000;
      }
      .badge {
        display: inline-block;
        padding: 2px 8px;
        border-radius: 4px;
        font-size: 11px;
        font-weight: 500;
        text-transform: uppercase;
      }
      .badge-completed {
        background: #166534;
        color: #86efac;
      }
      .badge-recording {
        background: #854d0e;
        color: #fde047;
      }
      .badge-failed {
        background: #991b1b;
        color: #fca5a5;
      }
      .filename {
        font-family: ui-monospace, SFMono-Regular, 'SF Mono', Menlo, monospace;
        font-size: 13px;
        color: #e5e5e5;
      }
      .meta {
        color: #a3a3a3;
        font-size: 13px;
      }
      input[type='checkbox'] {
        width: 16px;
        height: 16px;
        accent-color: #fafafa;
        cursor: pointer;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="header">
        <div class="header-left">
          <h1>Screen Recordings</h1>
          <span class="refresh-info">Auto-refresh: 5s</span>
        </div>
        <button class="btn btn-danger" id="deleteSelected" disabled onclick="deleteSelected()">Delete Selected</button>
      </div>

      <table>
        <thead>
          <tr>
            <th style="width: 40px"><input type="checkbox" id="selectAll" onchange="toggleSelectAll()" /></th>
            <th>Filename</th>
            <th>Duration</th>
            <th>Size</th>
            <th>Status</th>
            <th>Date</th>
            <th style="width: 120px">Actions</th>
          </tr>
        </thead>
        <tbody id="recordingsBody">
          <tr>
            <td colspan="7" class="empty">
              <div class="empty-icon">üìπ</div>
              Loading...
            </td>
          </tr>
        </tbody>
      </table>
    </div>

    <div class="modal" id="videoModal">
      <div class="modal-content">
        <div class="modal-header">
          <h2 id="videoTitle">Video Playback</h2>
          <button class="close-btn" onclick="closeModal()">&times;</button>
        </div>
        <video id="videoPlayer" controls></video>
      </div>
    </div>

    <script>
      let recordings = []
      let selectedIds = new Set()

      async function loadRecordings() {
        try {
          const resp = await fetch('/api/recordings')
          const data = await resp.json()
          recordings = data.recordings || []
          renderTable()
        } catch (err) {
          console.error('Failed to load recordings:', err)
        }
      }

      function renderTable() {
        const tbody = document.getElementById('recordingsBody')
        if (recordings.length === 0) {
          tbody.innerHTML =
            '<tr><td colspan="7" class="empty"><div class="empty-icon">üìπ</div>No recordings yet</td></tr>'
          return
        }

        tbody.innerHTML = recordings
          .map((rec) => {
            const duration = rec.durationSeconds ? rec.durationSeconds.toFixed(1) + 's' : '-'
            const size = rec.sizeBytes ? formatBytes(rec.sizeBytes) : '-'
            const date = new Date(rec.startTime).toLocaleString()
            const checked = selectedIds.has(rec.id) ? 'checked' : ''
            const badgeClass = 'badge-' + rec.status

            return `<tr>
                    <td><input type="checkbox" ${checked} onchange="toggleSelect('${rec.id}')"></td>
                    <td class="filename">${rec.fileName}</td>
                    <td class="meta">${duration}</td>
                    <td class="meta">${size}</td>
                    <td><span class="badge ${badgeClass}">${rec.status}</span></td>
                    <td class="meta">${date}</td>
                    <td class="actions">
                        <button class="btn btn-ghost btn-icon" onclick="playVideo('${rec.fileName}')" ${rec.status !== 'completed' ? 'disabled' : ''} title="Play">‚ñ∂</button>
                        <button class="btn btn-ghost btn-icon" onclick="downloadVideo('${rec.fileName}')" ${rec.status !== 'completed' ? 'disabled' : ''} title="Download">‚¨á</button>
                        <button class="btn btn-ghost btn-icon" onclick="deleteRecording('${rec.id}')" title="Delete">üóë</button>
                    </td>
                </tr>`
          })
          .join('')

        updateDeleteButton()
      }

      function formatBytes(bytes) {
        if (bytes < 1024) return bytes + ' B'
        if (bytes < 1024 * 1024) return (bytes / 1024).toFixed(1) + ' KB'
        return (bytes / (1024 * 1024)).toFixed(1) + ' MB'
      }

      function toggleSelect(id) {
        if (selectedIds.has(id)) {
          selectedIds.delete(id)
        } else {
          selectedIds.add(id)
        }
        updateDeleteButton()
      }

      function toggleSelectAll() {
        const selectAll = document.getElementById('selectAll').checked
        selectedIds.clear()
        if (selectAll) {
          recordings.forEach((r) => selectedIds.add(r.id))
        }
        renderTable()
      }

      function updateDeleteButton() {
        document.getElementById('deleteSelected').disabled = selectedIds.size === 0
      }

      function playVideo(filename) {
        const video = document.getElementById('videoPlayer')
        video.src = '/videos/' + filename
        document.getElementById('videoTitle').textContent = filename
        document.getElementById('videoModal').classList.add('active')
        video.play()
      }

      function closeModal() {
        const video = document.getElementById('videoPlayer')
        video.pause()
        video.src = ''
        document.getElementById('videoModal').classList.remove('active')
      }

      function downloadVideo(filename) {
        const a = document.createElement('a')
        a.href = '/videos/' + filename
        a.download = filename
        a.click()
      }

      async function deleteRecording(id) {
        if (!confirm('Delete this recording?')) return

        try {
          const resp = await fetch('/api/recordings', {
            method: 'DELETE',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ ids: [id] }),
          })
          if (resp.ok) {
            selectedIds.delete(id)
            loadRecordings()
          }
        } catch (err) {
          alert('Failed to delete recording')
        }
      }

      async function deleteSelected() {
        if (!confirm('Delete ' + selectedIds.size + ' selected recording(s)?')) return

        try {
          const resp = await fetch('/api/recordings', {
            method: 'DELETE',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ ids: Array.from(selectedIds) }),
          })
          if (resp.ok) {
            selectedIds.clear()
            loadRecordings()
          }
        } catch (err) {
          alert('Failed to delete recordings')
        }
      }

      // Initial load and auto-refresh
      loadRecordings()
      setInterval(loadRecordings, 5000)

      // Close modal on escape
      document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape') closeModal()
      })
    </script>
  </body>
</html>


--- apps/daemon/pkg/terminal/static/index.html ---
<!doctype html>
<html>
  <head>
    <title>Web Terminal</title>
    <link rel="stylesheet" href="/xterm.css" />
    <script src="/xterm.js"></script>
    <script src="/xterm-addon-fit.js"></script>
    <style>
      html,
      body {
        margin: 0;
        padding: 0;
        height: 100vh;
        background: #000;
      }
      #terminal {
        height: 100%;
        width: 100%;
      }
    </style>
  </head>
  <body>
    <div id="terminal"></div>
    <script>
      const term = new Terminal({
        cursorBlink: true,
        fontSize: 14,
        fontFamily: 'monospace',
        theme: {
          background: '#000000',
          foreground: '#ffffff',
        },
      })

      const fitAddon = new FitAddon.FitAddon()
      term.loadAddon(fitAddon)
      term.open(document.getElementById('terminal'))
      fitAddon.fit()

      // Connect to WebSocket
      const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:'
      const socket = new WebSocket(`${protocol}//${window.location.host}/ws`)

      socket.onopen = () => {
        console.log('WebSocket connected')

        // WebSocket -> Terminal
        socket.onmessage = (event) => {
          // Remove the Uint8Array conversion
          term.write(event.data)
        }

        // Handle xterm data
        term.onData((data) => {
          socket.send(data)
        })

        // Handle resize
        term.onResize((size) => {
          socket.send(
            JSON.stringify({
              rows: size.rows,
              cols: size.cols,
            }),
          )
        })

        // Initial size
        socket.send(
          JSON.stringify({
            rows: term.rows,
            cols: term.cols,
          }),
        )
      }

      // WebSocket -> Terminal
      socket.onmessage = (event) => {
        term.write(new Uint8Array(event.data))
      }

      socket.onclose = () => {
        term.write('\r\nConnection closed\r\n')
      }

      // Handle window resize
      window.addEventListener('resize', () => {
        fitAddon.fit()
      })
    </script>
  </body>
</html>


--- apps/dashboard/postcss.config.js ---
/*
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: AGPL-3.0
 */

const { join } = require('path')

// Note: If you use library-specific PostCSS/Tailwind configuration then you should remove the `postcssConfig` build
// option from your application's configuration (i.e. project.json).
//
// See: https://nx.dev/guides/using-tailwind-css-in-react#step-4:-applying-configuration-to-libraries

module.exports = {
  plugins: {
    tailwindcss: {
      config: join(__dirname, 'tailwind.config.js'),
    },
    autoprefixer: {},
  },
}


--- apps/dashboard/tailwind.config.js ---
/*
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: AGPL-3.0
 */

const { createGlobPatternsForDependencies } = require('@nx/react/tailwind')
const { join } = require('path')
const plugin = require('tailwindcss/plugin')

/** @type {import('tailwindcss').Config} */
module.exports = {
  darkMode: ['class'],
  content: [
    join(__dirname, '{src,pages,components,app}/**/*!(*.stories|*.spec).{ts,tsx,html}'),
    ...createGlobPatternsForDependencies(__dirname),
  ],
  theme: {
    extend: {
      screens: {
        xs: '480px',
      },
      borderRadius: {
        lg: 'var(--radius)',
        md: 'calc(var(--radius) - 2px)',
        sm: 'calc(var(--radius) - 4px)',
      },
      colors: {
        background: 'hsl(var(--background))',
        foreground: 'hsl(var(--foreground))',
        card: {
          DEFAULT: 'hsl(var(--card))',
          foreground: 'hsl(var(--card-foreground))',
        },
        popover: {
          DEFAULT: 'hsl(var(--popover))',
          foreground: 'hsl(var(--popover-foreground))',
        },
        primary: {
          DEFAULT: 'hsl(var(--primary))',
          foreground: 'hsl(var(--primary-foreground))',
        },
        secondary: {
          DEFAULT: 'hsl(var(--secondary))',
          foreground: 'hsl(var(--secondary-foreground))',
        },
        muted: {
          DEFAULT: 'hsl(var(--muted))',
          foreground: 'hsl(var(--muted-foreground))',
        },
        accent: {
          DEFAULT: 'hsl(var(--accent))',
          foreground: 'hsl(var(--accent-foreground))',
        },
        destructive: {
          DEFAULT: 'hsl(var(--destructive))',
          foreground: 'hsl(var(--destructive-foreground))',
          background: 'hsl(var(--destructive-background))',
          separator: 'hsl(var(--destructive-separator))',
        },
        warning: {
          DEFAULT: 'hsl(var(--warning))',
          foreground: 'hsl(var(--warning-foreground))',
          background: 'hsl(var(--warning-background))',
          separator: 'hsl(var(--warning-separator))',
        },
        success: {
          DEFAULT: 'hsl(var(--success))',
          foreground: 'hsl(var(--success-foreground))',
          background: 'hsl(var(--success-background))',
          separator: 'hsl(var(--success-separator))',
        },
        info: {
          DEFAULT: 'hsl(var(--info))',
          foreground: 'hsl(var(--info-foreground))',
          background: 'hsl(var(--info-background))',
          separator: 'hsl(var(--info-separator))',
        },
        border: 'hsl(var(--border))',
        input: 'hsl(var(--input))',
        ring: 'hsl(var(--ring))',
        chart: {
          1: 'hsl(var(--chart-1))',
          2: 'hsl(var(--chart-2))',
          3: 'hsl(var(--chart-3))',
          4: 'hsl(var(--chart-4))',
          5: 'hsl(var(--chart-5))',
        },
        sidebar: {
          DEFAULT: 'hsl(var(--sidebar-background))',
          foreground: 'hsl(var(--sidebar-foreground))',
          primary: 'hsl(var(--sidebar-primary))',
          'primary-foreground': 'hsl(var(--sidebar-primary-foreground))',
          accent: 'hsl(var(--sidebar-accent))',
          'accent-foreground': 'hsl(var(--sidebar-accent-foreground))',
          border: 'hsl(var(--sidebar-border))',
          ring: 'hsl(var(--sidebar-ring))',
        },
      },
      keyframes: {
        'accordion-down': {
          from: {
            height: '0',
          },
          to: {
            height: 'var(--radix-accordion-content-height)',
          },
        },
        'accordion-up': {
          from: {
            height: 'var(--radix-accordion-content-height)',
          },
          to: {
            height: '0',
          },
        },
      },
      animation: {
        'accordion-down': 'accordion-down 0.2s ease-out',
        'accordion-up': 'accordion-up 0.2s ease-out',
      },
    },
  },
  plugins: [
    require('tailwind-scrollbar'),
    require('tailwindcss-animate'),
    plugin(function ({ addVariant }) {
      addVariant('aria-invalid', '&[aria-invalid="true"]')
    }),
  ],
}


--- apps/cli/auth/auth_success.html ---
<!doctype html>
<html>
  <head>
    <title>Daytona</title>
    <link rel="icon" href="https://www.daytona.io/favicon.ico" />
    <style>
      body {
        font-family:
          Berkeley Mono,
          monospace;
        display: flex;
        justify-content: center;
        align-items: center;
        height: 100vh;
        margin: 0;
        background-color: #f5f5f5;
      }

      .container {
        text-align: center;
        padding: 2rem;
        background: white;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
      }

      .logo {
        max-width: 300px;
        margin-top: 1rem;
      }

      h1 {
        color: #333;
        margin-bottom: 1rem;
      }

      p {
        color: #666;
        margin-bottom: 1.5rem;
      }
    </style>
  </head>

  <body>
    <div class="container">
      <img
        src="https://raw.githubusercontent.com/daytonaio/daytona/main/assets/images/Daytona-logotype-black.png"
        alt="Daytona"
        class="logo"
      />
      <h1>Authentication Successful</h1>
      <p>You can now close this window and return to the CLI.</p>
    </div>

    <script>
      // Function to close the page after 10 seconds
      setTimeout(function () {
        window.close()
      }, 10 * 1000)
    </script>
  </body>
</html>


--- apps/dashboard/public/mockServiceWorker.js ---
/* eslint-disable */
/* tslint:disable */

/**
 * Mock Service Worker.
 * @see https://github.com/mswjs/msw
 * - Please do NOT modify this file.
 */

const PACKAGE_VERSION = '2.12.2'
const INTEGRITY_CHECKSUM = '4db4a41e972cec1b64cc569c66952d82'
const IS_MOCKED_RESPONSE = Symbol('isMockedResponse')
const activeClientIds = new Set()

addEventListener('install', function () {
  self.skipWaiting()
})

addEventListener('activate', function (event) {
  event.waitUntil(self.clients.claim())
})

addEventListener('message', async function (event) {
  const clientId = Reflect.get(event.source || {}, 'id')

  if (!clientId || !self.clients) {
    return
  }

  const client = await self.clients.get(clientId)

  if (!client) {
    return
  }

  const allClients = await self.clients.matchAll({
    type: 'window',
  })

  switch (event.data) {
    case 'KEEPALIVE_REQUEST': {
      sendToClient(client, {
        type: 'KEEPALIVE_RESPONSE',
      })
      break
    }

    case 'INTEGRITY_CHECK_REQUEST': {
      sendToClient(client, {
        type: 'INTEGRITY_CHECK_RESPONSE',
        payload: {
          packageVersion: PACKAGE_VERSION,
          checksum: INTEGRITY_CHECKSUM,
        },
      })
      break
    }

    case 'MOCK_ACTIVATE': {
      activeClientIds.add(clientId)

      sendToClient(client, {
        type: 'MOCKING_ENABLED',
        payload: {
          client: {
            id: client.id,
            frameType: client.frameType,
          },
        },
      })
      break
    }

    case 'CLIENT_CLOSED': {
      activeClientIds.delete(clientId)

      const remainingClients = allClients.filter((client) => {
        return client.id !== clientId
      })

      // Unregister itself when there are no more clients
      if (remainingClients.length === 0) {
        self.registration.unregister()
      }

      break
    }
  }
})

addEventListener('fetch', function (event) {
  const requestInterceptedAt = Date.now()

  // Bypass navigation requests.
  if (event.request.mode === 'navigate') {
    return
  }

  // Opening the DevTools triggers the "only-if-cached" request
  // that cannot be handled by the worker. Bypass such requests.
  if (
    event.request.cache === 'only-if-cached' &&
    event.request.mode !== 'same-origin'
  ) {
    return
  }

  // Bypass all requests when there are no active clients.
  // Prevents the self-unregistered worked from handling requests
  // after it's been terminated (still remains active until the next reload).
  if (activeClientIds.size === 0) {
    return
  }

  const requestId = crypto.randomUUID()
  event.respondWith(handleRequest(event, requestId, requestInterceptedAt))
})

/**
 * @param {FetchEvent} event
 * @param {string} requestId
 * @param {number} requestInterceptedAt
 */
async function handleRequest(event, requestId, requestInterceptedAt) {
  const client = await resolveMainClient(event)
  const requestCloneForEvents = event.request.clone()
  const response = await getResponse(
    event,
    client,
    requestId,
    requestInterceptedAt,
  )

  // Send back the response clone for the "response:*" life-cycle events.
  // Ensure MSW is active and ready to handle the message, otherwise
  // this message will pend indefinitely.
  if (client && activeClientIds.has(client.id)) {
    const serializedRequest = await serializeRequest(requestCloneForEvents)

    // Clone the response so both the client and the library could consume it.
    const responseClone = response.clone()

    sendToClient(
      client,
      {
        type: 'RESPONSE',
        payload: {
          isMockedResponse: IS_MOCKED_RESPONSE in response,
          request: {
            id: requestId,
            ...serializedRequest,
          },
          response: {
            type: responseClone.type,
            status: responseClone.status,
            statusText: responseClone.statusText,
            headers: Object.fromEntries(responseClone.headers.entries()),
            body: responseClone.body,
          },
        },
      },
      responseClone.body ? [serializedRequest.body, responseClone.body] : [],
    )
  }

  return response
}

/**
 * Resolve the main client for the given event.
 * Client that issues a request doesn't necessarily equal the client
 * that registered the worker. It's with the latter the worker should
 * communicate with during the response resolving phase.
 * @param {FetchEvent} event
 * @returns {Promise<Client | undefined>}
 */
async function resolveMainClient(event) {
  const client = await self.clients.get(event.clientId)

  if (activeClientIds.has(event.clientId)) {
    return client
  }

  if (client?.frameType === 'top-level') {
    return client
  }

  const allClients = await self.clients.matchAll({
    type: 'window',
  })

  return allClients
    .filter((client) => {
      // Get only those clients that are currently visible.
      return client.visibilityState === 'visible'
    })
    .find((client) => {
      // Find the client ID that's recorded in the
      // set of clients that have registered the worker.
      return activeClientIds.has(client.id)
    })
}

/**
 * @param {FetchEvent} event
 * @param {Client | undefined} client
 * @param {string} requestId
 * @param {number} requestInterceptedAt
 * @returns {Promise<Response>}
 */
async function getResponse(event, client, requestId, requestInterceptedAt) {
  // Clone the request because it might've been already used
  // (i.e. its body has been read and sent to the client).
  const requestClone = event.request.clone()

  function passthrough() {
    // Cast the request headers to a new Headers instance
    // so the headers can be manipulated with.
    const headers = new Headers(requestClone.headers)

    // Remove the "accept" header value that marked this request as passthrough.
    // This prevents request alteration and also keeps it compliant with the
    // user-defined CORS policies.
    const acceptHeader = headers.get('accept')
    if (acceptHeader) {
      const values = acceptHeader.split(',').map((value) => value.trim())
      const filteredValues = values.filter(
        (value) => value !== 'msw/passthrough',
      )

      if (filteredValues.length > 0) {
        headers.set('accept', filteredValues.join(', '))
      } else {
        headers.delete('accept')
      }
    }

    return fetch(requestClone, { headers })
  }

  // Bypass mocking when the client is not active.
  if (!client) {
    return passthrough()
  }

  // Bypass initial page load requests (i.e. static assets).
  // The absence of the immediate/parent client in the map of the active clients
  // means that MSW hasn't dispatched the "MOCK_ACTIVATE" event yet
  // and is not ready to handle requests.
  if (!activeClientIds.has(client.id)) {
    return passthrough()
  }

  // Notify the client that a request has been intercepted.
  const serializedRequest = await serializeRequest(event.request)
  const clientMessage = await sendToClient(
    client,
    {
      type: 'REQUEST',
      payload: {
        id: requestId,
        interceptedAt: requestInterceptedAt,
        ...serializedRequest,
      },
    },
    [serializedRequest.body],
  )

  switch (clientMessage.type) {
    case 'MOCK_RESPONSE': {
      return respondWithMock(clientMessage.data)
    }

    case 'PASSTHROUGH': {
      return passthrough()
    }
  }

  return passthrough()
}

/**
 * @param {Client} client
 * @param {any} message
 * @param {Array<Transferable>} transferrables
 * @returns {Promise<any>}
 */
function sendToClient(client, message, transferrables = []) {
  return new Promise((resolve, reject) => {
    const channel = new MessageChannel()

    channel.port1.onmessage = (event) => {
      if (event.data && event.data.error) {
        return reject(event.data.error)
      }

      resolve(event.data)
    }

    client.postMessage(message, [
      channel.port2,
      ...transferrables.filter(Boolean),
    ])
  })
}

/**
 * @param {Response} response
 * @returns {Response}
 */
function respondWithMock(response) {
  // Setting response status code to 0 is a no-op.
  // However, when responding with a "Response.error()", the produced Response
  // instance will have status code set to 0. Since it's not possible to create
  // a Response instance with status code 0, handle that use-case separately.
  if (response.status === 0) {
    return Response.error()
  }

  const mockedResponse = new Response(response.body, response)

  Reflect.defineProperty(mockedResponse, IS_MOCKED_RESPONSE, {
    value: true,
    enumerable: true,
  })

  return mockedResponse
}

/**
 * @param {Request} request
 */
async function serializeRequest(request) {
  return {
    url: request.url,
    mode: request.mode,
    method: request.method,
    headers: Object.fromEntries(request.headers.entries()),
    cache: request.cache,
    credentials: request.credentials,
    destination: request.destination,
    integrity: request.integrity,
    redirect: request.redirect,
    referrer: request.referrer,
    referrerPolicy: request.referrerPolicy,
    body: await request.arrayBuffer(),
    keepalive: request.keepalive,
  }
}


--- apps/dashboard/src/vite-env.d.ts ---
/*
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: AGPL-3.0
 */

/// <reference types="vite/client" />

declare module '*.png' {
  const content: string
  export default content
}

interface ImportMetaEnv {
  readonly VITE_API_URL: string
}

interface ImportMeta {
  readonly env: ImportMetaEnv
}


--- functions/auth0/setCustomClaims.onExecutePostLogin.js ---
/*
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: AGPL-3.0
 */

/**
 * Handler that will be called during the execution of a PostLogin flow.
 *
 * @param {Event} event - Details about the user and the context in which they are logging in.
 * @param {PostLoginAPI} api - Interface whose methods can be used to change the behavior of the login.
 */
exports.onExecutePostLogin = async (event, api) => {
  api.accessToken.setCustomClaim('email', event.user.email)
  api.accessToken.setCustomClaim('name', event.user.name)
  api.accessToken.setCustomClaim('email_verified', event.user.email_verified)
  api.accessToken.setCustomClaim(
    'phone_verified',
    event.user.enrolledFactors && event.user.enrolledFactors.some((f) => f.type === 'phone' && f.method === 'sms'),
  )
  api.accessToken.setCustomClaim('identities', event.user.identities)
  api.idToken.setCustomClaim('identities', event.user.identities)
  api.idToken.setCustomClaim(
    'phone_verified',
    event.user.enrolledFactors && event.user.enrolledFactors.some((f) => f.type === 'phone' && f.method === 'sms'),
  )
}


--- functions/auth0/validateEmailUnused.onExecutePostLogin.js ---
/*
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: AGPL-3.0
 */

/**
 * Handler that will be called during the execution of a PostLogin flow.
 *
 * @param {Event} event - Details about the user and the context in which they are logging in.
 * @param {PostLoginAPI} api - Interface whose methods can be used to change the behavior of the login.
 */
exports.onExecutePostLogin = async (event, api) => {
  // Skip validation when performing account linking
  if (event.request.query?.accountLinking === 'true') {
    return
  }

  // User object must have an email address
  if (!event.user.email) {
    return api.access.deny('Please ensure your email address is public')
  }

  const ManagementClient = require('auth0').ManagementClient

  const management = new ManagementClient({
    domain: event.secrets.DOMAIN,
    clientId: event.secrets.CLIENT_ID,
    clientSecret: event.secrets.CLIENT_SECRET,
    scope: 'read:users',
  })

  // Fetch users with this email address in the Auth0 database
  let users = []

  try {
    users = await management.getUsersByEmail(event.user.email)
  } catch (error) {
    console.error('Failed to fetch Auth0 users:', error)
    return api.access.deny('Something went wrong, please try again later')
  }

  // Skip validation if this is the only user with this email address
  if (users.length <= 1) {
    return
  }

  // Deny access if this user doesn't exist in the Daytona database
  try {
    const response = await fetch(`${event.secrets.DAYTONA_API_URL}/users/${event.user.user_id}`, {
      headers: {
        Authorization: `Bearer ${event.secrets.DAYTONA_API_KEY}`,
      },
    })

    if (!response.ok) {
      return api.access.deny('Something went wrong, please try again later')
    }
  } catch (error) {
    console.error('Failed to fetch Daytona users:', error)
    return api.access.deny('Something went wrong, please try again later')
  }
}


--- functions/auth0/validateEmailUnused.onExecutePreRegister.js ---
/*
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: AGPL-3.0
 */

/**
 * Handler that will be called during the execution of a PreUserRegistration flow.
 *
 * @param {Event} event - Details about the context and user that is attempting to register.
 * @param {PreUserRegistrationAPI} api - Interface whose methods can be used to change the behavior of the signup.
 */
exports.onExecutePreUserRegistration = async (event, api) => {
  const ManagementClient = require('auth0').ManagementClient

  const management = new ManagementClient({
    domain: event.secrets.DOMAIN,
    clientId: event.secrets.CLIENT_ID,
    clientSecret: event.secrets.CLIENT_SECRET,
    scope: 'read:users update:users',
  })

  try {
    // Search for users with the same email
    const users = await management.getUsersByEmail(event.user.email)

    if (users.length >= 1) {
      return api.access.deny('Email already used', 'Something went wrong, please try again later')
    }
  } catch (error) {
    console.error('Failed to fetch users:', error)
    return api.access.deny('Could not fetch users', 'Something went wrong, please try again later')
  }
}


--- functions/auth0/verifyAliasEmail.onExecutePreRegister.js ---
/*
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: AGPL-3.0
 */

/**
 * Handler that will be called during the execution of a PreUserRegistration flow.
 *
 * @param {Event} event - Details about the context and user that is attempting to register.
 * @param {PreUserRegistrationAPI} api - Interface whose methods can be used to change the behavior of the signup.
 */
exports.onExecutePreUserRegistration = async (event, api) => {
  if (event.user.email?.includes('+')) {
    return api.access.deny(`Email alias detected: ${event.user.email}`, 'Email aliases not allowed')
  }
}


--- images/sandbox-slim/README.md ---
# Daytona Sandbox Slim Image

[Dockerfile](./Dockerfile) contains the definition for [daytonaio/sandbox](https://hub.docker.com/r/daytonaio/sandbox) slim images which are used as default snapshots in self-hosted environments.

The slim sandbox image contains Python, Node and some popular dependencies including:

- pipx
- uv
- python-lsp-server
- numpy
- pandas
- matplotlib

- ts-node
- typescript
- typescript-language-server

## NOTE

The slim image does not contain dependencies necessary for Daytona's VNC functionality.
Please use the base image for that.


## Links discovered
- [Dockerfile](https://github.com/daytonaio/daytona/blob/main/images/sandbox-slim/Dockerfile.md)
- [daytonaio/sandbox](https://hub.docker.com/r/daytonaio/sandbox)

--- images/sandbox/README.md ---
# Daytona Sandbox Image

[Dockerfile](./Dockerfile) contains the definition for [daytonaio/sandbox](https://hub.docker.com/r/daytonaio/sandbox) which is used as the default sandbox image in Daytona Cloud.

The default sandbox image contains Python, Node and their most popular dependencies, including:

- pipx
- uv
- python-lsp-server
- numpy
- pandas
- scikit-learn
- keras
- torch
- scipy
- seaborn
- matplotlib
- django
- flask
- beautifulsoup4
- requests
- opencv-python
- pillow
- sqlalchemy
- daytona
- pydantic-ai
- langchain
- transformers
- openai
- anthropic
- llama-index
- instructor
- huggingface
- ollama
- claude-agent-sdk

- ts-node
- typescript
- typescript-language-server
- bun
- @anthropic-ai/claude-code
- openclaw
- opencode-ai


## Links discovered
- [Dockerfile](https://github.com/daytonaio/daytona/blob/main/images/sandbox/Dockerfile.md)
- [daytonaio/sandbox](https://hub.docker.com/r/daytonaio/sandbox)

--- libs/computer-use/README.md ---
# ComputerUse - Process Management for VNC Desktop Environment

This package provides a Computer Use plugin used by the Daytona Daemon to allow agents to control VNC desktop environments.

## Overview

The `ComputerUse` package manages four main processes in the correct order:

1. **Xvfb** (X Virtual Framebuffer) - Provides a virtual display
2. **xfce4** (Desktop Environment) - Starts the XFCE desktop environment
3. **x11vnc** (VNC Server) - Exposes the desktop via VNC protocol
4. **novnc** (Web-based VNC client) - Provides web access to the VNC server

## Features

- **Process Management**: Automatic startup, monitoring, and shutdown of processes
- **Priority-based Startup**: Processes start in the correct order based on dependencies
- **Auto-restart**: Failed processes are automatically restarted
- **Logging**: Individual log files for each process
- **Status Monitoring**: Check the status of all processes
- **Graceful Shutdown**: Proper cleanup when stopping processes
- **Individual Control**: Start, stop, or restart individual processes

## Dockerfile Requirements

To use the ComputerUse package, your Dockerfile must include the following VNC-related packages and setup:

### Required Packages

```dockerfile
# Prevent interactive prompts during package installation
ENV DEBIAN_FRONTEND=noninteractive
ENV DISPLAY=:1
ENV VNC_PORT=5901
ENV NO_VNC_PORT=6080
ENV VNC_RESOLUTION=1280x720

# Install VNC and desktop environment packages
RUN apt-get update && apt-get install -y \
    wget \
    git \
    vim \
    xfce4 \
    xfce4-terminal \
    dbus-x11 \
    xfonts-base \
    xfonts-100dpi \
    xfonts-75dpi \
    xfonts-scalable \
    x11vnc \
    novnc \
    supervisor \
    net-tools \
    locales \
    xvfb \
    x11-utils \
    x11-xserver-utils \
    gnome-screenshot \
    scrot \
    imagemagick \
    xdotool \
    xautomation \
    wmctrl \
    build-essential \
    libx11-dev \
    libxext-dev \
    libxtst-dev \
    libxinerama-dev \
    libx11-xcb-dev \
    libxkbcommon-dev \
    libxkbcommon-x11-dev \
    libxcb-xkb-dev \
    libpng-dev \
    chromium \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*
```

### VNC Setup

```dockerfile
# Setup VNC
RUN mkdir -p /home/daytona/.vnc && \
    chown -R daytona:daytona /home/daytona/.vnc

# NoVNC setup
RUN ln -sf /usr/share/novnc/vnc.html /usr/share/novnc/index.html && \
    sed -i 's/websockify =/websockify = --heartbeat 30/' /usr/share/novnc/utils/launch.sh
```

### Launch Script

The NoVNC launch script (`/usr/share/novnc/utils/launch.sh`) is used to start the web-based VNC client. The Dockerfile modifies this script to add heartbeat support:

```bash
# Add heartbeat to websockify for better connection stability
sed -i 's/websockify =/websockify = --heartbeat 30/' /usr/share/novnc/utils/launch.sh
```

This ensures that the WebSocket connection remains stable during long-running sessions.

### Additional Tools

The Dockerfile also installs several useful tools for VNC desktop interaction:

- **xdotool**: For mouse and keyboard automation
- **xautomation**: Additional automation tools
- **wmctrl**: Window manager control
- **scrot**: Screenshot capture
- **imagemagick**: Image processing
- **gnome-screenshot**: Alternative screenshot tool
- **chromium**: Web browser for testing

These tools are used by the toolbox API endpoints for desktop interaction.

### Environment Variables

The following environment variables should be set in your Dockerfile:

```dockerfile
ENV DEBIAN_FRONTEND=noninteractive
ENV DISPLAY=:1
ENV VNC_PORT=5901
ENV NO_VNC_PORT=6080
ENV VNC_RESOLUTION=1280x720
```

### User Setup

Ensure you have a non-root user with proper permissions:

```dockerfile
# Create the Daytona user and configure sudo access
RUN useradd -m daytona && echo "daytona ALL=(ALL) NOPASSWD:ALL" > /etc/sudoers.d/91-daytona

# Switch to the user for VNC operations
USER daytona
```

## Configuration

### Environment Variables

- `VNC_RESOLUTION`: Set the VNC resolution (default: "1920x1080")
- `VNC_PORT`: VNC server port (default: 5901)
- `NO_VNC_PORT`: NoVNC web port (default: 6080)
- `DISPLAY`: X display (default: ":1")
- `VNC_USER`: User to run VNC processes (default: "daytona")

### Process Configuration

The processes are configured with the following settings based on environment variables:

| Process | Command                                                                            | Priority | Auto-restart | Log Files | Environment                                           |
| ------- | ---------------------------------------------------------------------------------- | -------- | ------------ | --------- | ----------------------------------------------------- |
| xvfb    | `/usr/bin/Xvfb $DISPLAY -screen 0 $VNC_RESOLUTIONx24`                              | 100      | Yes          | No        | `DISPLAY`                                             |
| xfce4   | `/usr/bin/startxfce4`                                                              | 200      | Yes          | Yes       | `DISPLAY`, `HOME`, `USER`, `DBUS_SESSION_BUS_ADDRESS` |
| x11vnc  | `/usr/bin/x11vnc -display $DISPLAY -forever -shared -rfbport $VNC_PORT`            | 300      | Yes          | No        | `DISPLAY`                                             |
| novnc   | `/usr/share/novnc/utils/launch.sh --vnc localhost:$VNC_PORT --listen $NO_VNC_PORT` | 400      | Yes          | No        | `DISPLAY`                                             |

**Default Values:**

- `DISPLAY`: `:1`
- `VNC_RESOLUTION`: `1920x1080`
- `VNC_PORT`: `5901`
- `NO_VNC_PORT`: `6080`
- `VNC_USER`: `daytona`

### Log Files

Log files are stored in `~/.daytona/computeruse/`:

- `xfce4.log` - Standard output from xfce4
- `xfce4.err` - Error output from xfce4

## Integration with Toolbox

The `ComputerUse` package is integrated into the toolbox server and provides HTTP endpoints for:

- Screenshot functionality
- Mouse control
- Keyboard control
- Display information

These endpoints are available under the `/computer` route group in the toolbox API.

## Error Handling

The implementation includes comprehensive error handling:

- Process startup failures are logged and retried (if auto-restart is enabled)
- Log file access errors are handled gracefully
- Process termination is handled properly with context cancellation
- Mutex-based thread safety for concurrent access

## Thread Safety

All operations are thread-safe using appropriate mutexes:

- `sync.RWMutex` for the main `ComputerUse` struct
- `sync.Mutex` for individual `Process` structs

This allows safe concurrent access from multiple goroutines.


--- libs/opencode-plugin/README.md ---
# Daytona Sandbox Plugin for OpenCode

This is an OpenCode plugin that automatically runs OpenCode sessions in Daytona sandboxes. Each session has its own remote sandbox which is automatically synced to a local git branch.

## Features

- Securely isolate each OpenCode session in a sandbox environment
- Preserves sandbox environments indefinitely until the OpenCode session is deleted
- Generates live preview links when a server starts in the sandbox
- Synchronizes each OpenCode session to a local git branch

## Usage

### Installation

To add the plugin to a project, edit `opencode.json` in the project directory:

```json
{
  "$schema": "https://opencode.ai/config.json",
  "plugin": ["@daytonaio/opencode"]
}
```

Now that the Daytona plugin is in the plugins list, it will automatically be downloaded when OpenCode starts.

To install the plugin globally, edit `~/.config/opencode/opencode.json`.

### Environment Configuration

This plugin requires a [Daytona account](https://www.daytona.io/) and [Daytona API key](https://app.daytona.io/dashboard/keys) to create sandboxes.

Set your Daytona API key and URL as environment variables:

```bash
export DAYTONA_API_KEY="your-api-key"
```

Or create a `.env` file in your project root:

```env
DAYTONA_API_KEY=your-api-key
```

### Running OpenCode

Before starting OpenCode, ensure that your project is a git repository:

```bash
git init
```

Now start OpenCode in your project using the OpenCode command:

```bash
opencode
```

To check that the plugin is working, type `pwd` in the chat. You should see a response like `/home/daytona/project`, and a toast notification that a new sandbox was created.

OpenCode will create new branches using the format `opencode/1`, `opencode/2`, etc. To work with these changes, use normal git commands in a separate terminal window. List branches:

```
git branch
```

Check out OpenCode's latest changes on your local system:

```
git checkout [branch]
```

To view live logs from the plugin for debugging, run this command in a separate terminal:

```bash
tail -f ~/.local/share/opencode/log/daytona.log
```

## How It Works

### File Synchronization

The plugin uses git to synchronize files between the sandbox and your local system. This happens automatically and in the background, keeping your copy of the code up-to-date without exposing your system to the agent.

#### Sandbox Setup

When a new Daytona sandbox is created:

1. The plugin looks for a git repository in the local directory. If none is found, file synchronization will be disabled.
2. A parallel repository is created in the sandbox with a single `opencode` branch, mirroring the checked out local branch.
3. A new `sandbox` remote is added to the local repository using an SSH connection to the sandbox.
4. The `HEAD` of the local repository is pushed to `opencode`, and the sandbox repository is reset to match this initial state.
5. Each sandbox is assigned a unique incrementing branch number (1, 2, 3, etc.) that persists across sessions.

#### Synchronization

Each time the agent makes changes:

1. A new commit is created in the sandbox repository on the `opencode` branch.
2. The plugin pulls the latest commits from the sandbox remote into a unique local branch named `opencode/1`, `opencode/2`, etc. This keeps both environments in sync while isolating changes from different sandboxes in separate local branches.

The plugin only synchronizes changes from the sandbox to your system. To pass local changes to the agent, commit them to a local branch, and start a new OpenCode session with that branch checked out.

> [!CAUTION]
> When changes are synchronized to local `opencode` branches, any locally made changes will be overwritten.

### Session to sandbox mapping

The plugin keeps track of which sandbox belongs to each OpenCode project using local state files. This data is stored in a separate JSON file for each project:

- On macOS: `~/.local/share/opencode/storage/daytona/[projectid].json`.
- On Windows: `%LOCALAPPDATA%\opencode\storage\daytona\[projectid].json`.

Each JSON file contains the sandbox metadata for each session in the project, including when the sandbox was created, and when it was last used.

The plugin uses [XDG Base Directory](https://specifications.freedesktop.org/basedir/latest/) specifically to resolve the path to this directory, using the convention [set by OpenCode](https://github.com/anomalyco/opencode/blob/052f887a9a7aaf79d9f1a560f9b686d59faa8348/packages/opencode/src/global/index.ts#L8).

## Development

This plugin is part of the Daytona monorepo.

### Setup

First, clone the Daytona monorepo:

```bash
git clone https://github.com/daytonaio/daytona
cd daytona
```

Install dependencies:

```bash
yarn install
```

### Development and Testing

To modify the plugin, edit the source code files in `libs/opencode-plugin/.opencode`.

To test the OpenCode plugin, create a test project to run OpenCode in:

```bash
mkdir ~/myproject
cd myproject
```

Add a symlink from the project directory to the plugin source code:

```
ln -s [ABSOLUTE_PATH_TO_DAYTONA]/libs/opencode-plugin/.opencode .opencode
```

Initialize git to enable file syncing:

```
git init
```

Start OpenCode in the test project:

```bash
opencode
```

Use the instructions from [Running OpenCode](#running-opencode) above to check that the plugin is running and view live logs for debugging.

> [!NOTE]
> When developing locally with a symlink, OpenCode loads the TypeScript source directly, so no build step is required.

### Building

Build the plugin:

```bash
npx nx run opencode-plugin:build
```

This compiles the TypeScript source files in `.opencode/` to JavaScript in `dist/.opencode/`.

### Publishing

Log into npm:

```bash
npm login
```

Publish the compiled JavaScript package to npm:

```bash
npx nx run opencode-plugin:publish
```

This will publish to npm with public access and use the version number from `package.json`.

## Project Structure

```
libs/opencode-plugin/
‚îú‚îÄ‚îÄ .opencode/                     # Source TypeScript files
‚îÇ   ‚îú‚îÄ‚îÄ plugin/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ daytona/               # Main Daytona integration
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.ts               # Plugin entry point
‚îú‚îÄ‚îÄ dist/                          # Build output
‚îÇ   ‚îî‚îÄ‚îÄ .opencode/                 # Compiled JavaScript files
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .npmignore
‚îú‚îÄ‚îÄ package.json                   # Package metadata (includes main/types)
‚îú‚îÄ‚îÄ project.json                   # Nx build configuration
‚îú‚îÄ‚îÄ tsconfig.json                  # TypeScript config
‚îú‚îÄ‚îÄ tsconfig.lib.json              # TypeScript config for library build
‚îî‚îÄ‚îÄ README.md
```

## License

Apache-2.0


## Links discovered
- [Daytona account](https://www.daytona.io/)
- [Daytona API key](https://app.daytona.io/dashboard/keys)
- [XDG Base Directory](https://specifications.freedesktop.org/basedir/latest/)
- [set by OpenCode](https://github.com/anomalyco/opencode/blob/052f887a9a7aaf79d9f1a560f9b686d59faa8348/packages/opencode/src/global/index.ts#L8)

--- libs/opencode-plugin/.opencode/plugin/index.ts ---
/**
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: Apache-2.0
 */

/**
 * Main entry point for the OpenCode Daytona plugin
 * Re-exports all plugin components from the daytona module
 */

export * from './daytona/index.js'


--- libs/opencode-plugin/.opencode/plugin/daytona/index.ts ---
/**
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: Apache-2.0
 */

/**
 * OpenCode Plugin: Daytona Sandbox Integration
 *
 * OpenCode plugins extend the AI coding assistant by adding custom tools, handling events,
 * and modifying behavior. Plugins are TypeScript/JavaScript modules that export functions
 * which return hooks for various lifecycle events.
 *
 * This plugin integrates Daytona sandboxes with OpenCode, providing isolated development
 * environments for each session. It adds custom tools for file operations, command execution,
 * and search within sandboxes, and automatically cleans up resources when sessions end.
 *
 * Learn more: https://opencode.ai/docs/plugins/
 *
 * Daytona Sandbox Integration Tools
 *
 * Requires:
 * - npm install @daytonaio/sdk
 * - Environment: DAYTONA_API_KEY
 */

import { join } from 'path'
import { xdgData } from 'xdg-basedir'
import type { Plugin } from '@opencode-ai/plugin'

// Import modules
import { setLogFilePath } from './core/logger'
import { DaytonaSessionManager } from './core/session-manager'
import {
  createCustomToolsPlugin,
  createSessionCleanupPlugin,
  createSystemTransformPlugin,
  createSessionIdleAutoCommitPlugin,
} from './plugins'

// Export types for consumers
export type { EventSessionDeleted, LogLevel, SandboxInfo, SessionInfo, ProjectSessionData } from './core/types'

// Initialize logger and session manager using xdg-basedir (same as OpenCode)
const LOG_FILE = join(xdgData, 'opencode', 'log', 'daytona.log')
const STORAGE_DIR = join(xdgData, 'opencode', 'storage', 'daytona')
const REPO_PATH = '/home/daytona/project'

setLogFilePath(LOG_FILE)
const sessionManager = new DaytonaSessionManager(process.env.DAYTONA_API_KEY || '', STORAGE_DIR, REPO_PATH)

// Export plugin instances
export const CustomToolsPlugin: Plugin = createCustomToolsPlugin(sessionManager)
export const DaytonaSessionCleanupPlugin: Plugin = createSessionCleanupPlugin(sessionManager)
export const SystemTransformPlugin: Plugin = createSystemTransformPlugin(REPO_PATH)
export const DaytonaSessionIdleAutoCommitPlugin: Plugin = createSessionIdleAutoCommitPlugin(sessionManager, REPO_PATH)


--- libs/opencode-plugin/.opencode/plugin/daytona/tools.ts ---
/**
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: Apache-2.0
 */

/**
 * Tool implementations for Daytona sandbox integration
 */

import { bashTool } from './tools/bash'
import { readTool } from './tools/read'
import { writeTool } from './tools/write'
import { editTool } from './tools/edit'
import { multieditTool } from './tools/multiedit'
import { patchTool } from './tools/patch'
import { lsTool } from './tools/ls'
import { globTool } from './tools/glob'
import { grepTool } from './tools/grep'
import { lspTool } from './tools/lsp'
import { getPreviewURLTool } from './tools/get-preview-url'

import type { DaytonaSessionManager } from './core/session-manager'
import type { PluginInput } from '@opencode-ai/plugin'

export function createDaytonaTools(
  sessionManager: DaytonaSessionManager,
  projectId: string,
  worktree: string,
  pluginCtx: PluginInput,
) {
  const repoPath = sessionManager.repoPath
  return {
    bash: bashTool(sessionManager, projectId, worktree, pluginCtx, repoPath),
    read: readTool(sessionManager, projectId, worktree, pluginCtx),
    write: writeTool(sessionManager, projectId, worktree, pluginCtx),
    edit: editTool(sessionManager, projectId, worktree, pluginCtx),
    multiedit: multieditTool(sessionManager, projectId, worktree, pluginCtx),
    patch: patchTool(sessionManager, projectId, worktree, pluginCtx),
    ls: lsTool(sessionManager, projectId, worktree, pluginCtx),
    glob: globTool(sessionManager, projectId, worktree, pluginCtx),
    grep: grepTool(sessionManager, projectId, worktree, pluginCtx),
    lsp: lspTool(sessionManager, projectId, worktree, pluginCtx),
    getPreviewURL: getPreviewURLTool(sessionManager, projectId, worktree, pluginCtx),
  }
}


--- libs/opencode-plugin/.opencode/plugin/daytona/tools/bash.ts ---
/**
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: Apache-2.0
 */

import { z } from 'zod'
import type { PluginInput } from '@opencode-ai/plugin'
import type { ToolContext } from '@opencode-ai/plugin/tool'
import type { DaytonaSessionManager } from '../core/session-manager'

export const bashTool = (
  sessionManager: DaytonaSessionManager,
  projectId: string,
  worktree: string,
  pluginCtx: PluginInput,
  repoPath: string,
) => ({
  description: 'Executes shell commands in a Daytona sandbox',
  args: {
    command: z.string(),
    background: z.boolean().optional(),
  },
  async execute(args: { command: string; background?: boolean }, ctx: ToolContext) {
    const sessionId = ctx.sessionID
    const sandbox = await sessionManager.getSandbox(sessionId, projectId, worktree, pluginCtx)

    if (args.background) {
      const execSessionId = `exec-session-${sessionId}`
      try {
        await sandbox.process.getSession(execSessionId)
      } catch {
        await sandbox.process.createSession(execSessionId)
      }
      await sandbox.process.executeSessionCommand(execSessionId, {
        command: `cd ${repoPath}`,
      })
      const result = await sandbox.process.executeSessionCommand(execSessionId, {
        command: args.command,
        runAsync: true,
      })
      return `Command started in background (cmdId: ${result.cmdId})`
    } else {
      const result = await sandbox.process.executeCommand(args.command, repoPath)
      return `Exit code: ${result.exitCode}\n${result.result}`
    }
  },
})


--- libs/opencode-plugin/.opencode/plugin/daytona/plugins/custom-tools.ts ---
/**
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: Apache-2.0
 */

import type { Plugin, PluginInput } from '@opencode-ai/plugin'
import { createDaytonaTools } from '../tools'
import { logger } from '../core/logger'
import type { DaytonaSessionManager } from '../core/session-manager'
import { toast } from '../core/toast'

/**
 * Creates the custom tools plugin for Daytona sandbox integration
 * Provides tools for file operations, command execution, and search within sandboxes
 */
export function createCustomToolsPlugin(sessionManager: DaytonaSessionManager): Plugin {
  return async (pluginCtx: PluginInput) => {
    logger.info('OpenCode started with Daytona plugin')
    toast.initialize(pluginCtx.client?.tui)

    const projectId = pluginCtx.project.id
    const worktree = pluginCtx.project.worktree

    return {
      tool: createDaytonaTools(sessionManager, projectId, worktree, pluginCtx),
    }
  }
}


--- libs/opencode-plugin/.opencode/plugin/daytona/tools/edit.ts ---
/**
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: Apache-2.0
 */

import { z } from 'zod'
import type { PluginInput } from '@opencode-ai/plugin'
import type { ToolContext } from '@opencode-ai/plugin/tool'
import type { DaytonaSessionManager } from '../core/session-manager'

export const editTool = (
  sessionManager: DaytonaSessionManager,
  projectId: string,
  worktree: string,
  pluginCtx: PluginInput,
) => ({
  description: 'Replaces text in a file in Daytona sandbox',
  args: {
    filePath: z.string(),
    oldString: z.string(),
    newString: z.string(),
  },
  async execute(args: { filePath: string; oldString: string; newString: string }, ctx: ToolContext) {
    const sandbox = await sessionManager.getSandbox(ctx.sessionID, projectId, worktree, pluginCtx)
    const buffer = await sandbox.fs.downloadFile(args.filePath)
    const decoder = new TextDecoder()
    const content = decoder.decode(buffer)
    const newContent = content.replace(args.oldString, args.newString)
    await sandbox.fs.uploadFile(Buffer.from(newContent), args.filePath)
    return `Edited ${args.filePath}`
  },
})


--- libs/opencode-plugin/.opencode/plugin/daytona/tools/get-preview-url.ts ---
/**
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: Apache-2.0
 */

import { z } from 'zod'
import type { PluginInput } from '@opencode-ai/plugin'
import type { ToolContext } from '@opencode-ai/plugin/tool'
import type { DaytonaSessionManager } from '../core/session-manager'

export const getPreviewURLTool = (
  sessionManager: DaytonaSessionManager,
  projectId: string,
  worktree: string,
  pluginCtx: PluginInput,
) => ({
  description: 'Gets a preview URL for the Daytona sandbox',
  args: {
    port: z.number(),
  },
  async execute(args: { port: number }, ctx: ToolContext) {
    const sandbox = await sessionManager.getSandbox(ctx.sessionID, projectId, worktree, pluginCtx)
    const previewLink = await sandbox.getPreviewLink(args.port)
    return `Sandbox Preview URL: ${previewLink.url}`
  },
})


--- libs/opencode-plugin/.opencode/plugin/daytona/tools/glob.ts ---
/**
 * Copyright 2025 Daytona Platforms Inc.
 * SPDX-License-Identifier: Apache-2.0
 */

import { z } from 'zod'
import type { PluginInput } from '@opencode-ai/plugin'
import type { ToolContext } from '@opencode-ai/plugin/tool'
import type { DaytonaSessionManager } from '../core/session-manager'

export const globTool = (
  sessionManager: DaytonaSessionManager,
  projectId: string,
  worktree: string,
  pluginCtx: PluginInput,
) => ({
  description: 'Searches for files matching a pattern in Daytona sandbox',
  args: {
    pattern: z.string(),
  },
  async execute(args: { pattern: string }, ctx: ToolContext) {
    const sandbox = await sessionManager.getSandbox(ctx.sessionID, projectId, worktree, pluginCtx)
    const workDir = await sandbox.getWorkDir()
    if (!workDir) {
      throw new Error('Work directory not available')
    }
    const result = await sandbox.fs.searchFiles(workDir, args.pattern)
    return result.files.join('\n')
  },
})
